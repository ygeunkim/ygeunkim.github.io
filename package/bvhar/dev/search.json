[{"path":[]},{"path":"/dev/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"/dev/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others‚Äô private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"/dev/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"/dev/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"/dev/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement [INSERT CONTACT METHOD]. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"/dev/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"/dev/CODE_OF_CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"/dev/CODE_OF_CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"/dev/CODE_OF_CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"/dev/CODE_OF_CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"/dev/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.0, available https://www.contributor-covenant.org/version/2/0/ code_of_conduct.html. Community Impact Guidelines inspired Mozilla‚Äôs code conduct enforcement ladder. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https:// www.contributor-covenant.org/translations.","code":""},{"path":"/dev/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to bvhar","title":"Contributing to bvhar","text":"outlines propose change bvhar. detailed info contributing , tidyverse packages, please see development contributing guide.","code":""},{"path":"/dev/CONTRIBUTING.html","id":"fixing-typos","dir":"","previous_headings":"","what":"Fixing typos","title":"Contributing to bvhar","text":"can fix typos, spelling mistakes, grammatical errors documentation directly using GitHub web interface, long changes made source file. generally means ‚Äôll need edit roxygen2 comments .R, .Rd file. can find .R file generates .Rd reading comment first line.","code":""},{"path":"/dev/CONTRIBUTING.html","id":"bigger-changes","dir":"","previous_headings":"","what":"Bigger changes","title":"Contributing to bvhar","text":"want make bigger change, ‚Äôs good idea first file issue make sure someone team agrees ‚Äôs needed. ‚Äôve found bug, please file issue illustrates bug minimal reprex (also help write unit test, needed).","code":""},{"path":"/dev/CONTRIBUTING.html","id":"pull-request-process","dir":"","previous_headings":"Bigger changes","what":"Pull request process","title":"Contributing to bvhar","text":"Fork package clone onto computer. haven‚Äôt done , recommend using usethis::create_from_github(\"ygeunkim/bvhar\", fork = TRUE). Install development dependences devtools::install_dev_deps(), make sure package passes R CMD check running devtools::check(). R CMD check doesn‚Äôt pass cleanly, ‚Äôs good idea ask help continuing. Create Git branch pull request (PR). recommend using usethis::pr_init(\"brief-description--change\"). Make changes, commit git, create PR running usethis::pr_push(), following prompts browser. title PR briefly describe change. body PR contain Fixes #issue-number. user-facing changes, add bullet top NEWS.md (.e.¬†just first header). Follow style described https://style.tidyverse.org/news.html.","code":""},{"path":"/dev/CONTRIBUTING.html","id":"code-style","dir":"","previous_headings":"Bigger changes","what":"Code style","title":"Contributing to bvhar","text":"New code follow tidyverse style guide. can use styler package apply styles, please don‚Äôt restyle code nothing PR. use roxygen2, Markdown syntax, documentation. use testthat unit tests. Contributions test cases included easier accept.","code":""},{"path":"/dev/CONTRIBUTING.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Contributing to bvhar","text":"Please note bvhar project released Contributor Code Conduct. contributing project agree abide terms.","code":""},{"path":"/dev/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright ¬© 2007 Free Software Foundation, Inc.¬†<http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"/dev/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program‚Äìmake sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers‚Äô authors‚Äô protection, GPL clearly explains warranty free software. users‚Äô authors‚Äô sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users‚Äô freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"/dev/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"‚ÄúLicense‚Äù refers version 3 GNU General Public License. ‚ÄúCopyright‚Äù also means copyright-like laws apply kinds works, semiconductor masks. ‚ÄúProgram‚Äù refers copyrightable work licensed License. licensee addressed ‚Äú‚Äù. ‚ÄúLicensees‚Äù ‚Äúrecipients‚Äù may individuals organizations. ‚Äúmodify‚Äù work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called ‚Äúmodified version‚Äù earlier work work ‚Äúbased ‚Äù earlier work. ‚Äúcovered work‚Äù means either unmodified Program work based Program. ‚Äúpropagate‚Äù work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. ‚Äúconvey‚Äù work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays ‚ÄúAppropriate Legal Notices‚Äù extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"/dev/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"‚Äúsource code‚Äù work means preferred form work making modifications . ‚ÄúObject code‚Äù means non-source form work. ‚ÄúStandard Interface‚Äù means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. ‚ÄúSystem Libraries‚Äù executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. ‚ÄúMajor Component‚Äù, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . ‚ÄúCorresponding Source‚Äù work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work‚Äôs System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"/dev/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"/dev/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users‚Äô Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work‚Äôs users, third parties‚Äô legal rights forbid circumvention technological measures.","code":""},{"path":"/dev/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program‚Äôs source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"/dev/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 ‚Äúkeep intact notices‚Äù. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called ‚Äúaggregate‚Äù compilation resulting copyright used limit access legal rights compilation‚Äôs users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"/dev/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. ‚ÄúUser Product‚Äù either (1) ‚Äúconsumer product‚Äù, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, ‚Äúnormally used‚Äù refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. ‚ÄúInstallation Information‚Äù User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"/dev/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"‚ÄúAdditional permissions‚Äù terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered ‚Äúrestrictions‚Äù within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"/dev/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"/dev/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"/dev/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. ‚Äúentity transaction‚Äù transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party‚Äôs predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"/dev/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"‚Äúcontributor‚Äù copyright holder authorizes use License Program work Program based. work thus licensed called contributor‚Äôs ‚Äúcontributor version‚Äù. contributor‚Äôs ‚Äúessential patent claims‚Äù patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, ‚Äúcontrol‚Äù includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor‚Äôs essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, ‚Äúpatent license‚Äù express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). ‚Äúgrant‚Äù patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. ‚ÄúKnowingly relying‚Äù means actual knowledge , patent license, conveying covered work country, recipient‚Äôs use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license ‚Äúdiscriminatory‚Äù include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"/dev/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others‚Äô Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"/dev/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"/dev/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License ‚Äúlater version‚Äù applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy‚Äôs public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"/dev/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM ‚Äú‚Äù WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"/dev/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"/dev/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"/dev/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least ‚Äúcopyright‚Äù line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program‚Äôs commands might different; GUI interface, use ‚Äúbox‚Äù. also get employer (work programmer) school, , sign ‚Äúcopyright disclaimer‚Äù program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) 2023  Young Geun Kim  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. bvhar  Copyright (C) 2023  Young Geun Kim This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"/dev/SUPPORT.html","id":null,"dir":"","previous_headings":"","what":"Getting help with bvhar","title":"Getting help with bvhar","text":"Thanks using bvhar! filing issue, places explore pieces put together make process smooth possible.","code":""},{"path":"/dev/SUPPORT.html","id":"make-a-reprex","dir":"","previous_headings":"","what":"Make a reprex","title":"Getting help with bvhar","text":"Start making minimal reproducible example using reprex package. haven‚Äôt heard used reprex , ‚Äôre treat! Seriously, reprex make R-question-asking endeavors easier (pretty insane ROI five ten minutes ‚Äôll take learn ‚Äôs ). additional reprex pointers, check Get help! section tidyverse site.","code":""},{"path":"/dev/SUPPORT.html","id":"where-to-ask","dir":"","previous_headings":"","what":"Where to ask?","title":"Getting help with bvhar","text":"Armed reprex, next step figure ask. ‚Äôs question: start community.rstudio.com, /StackOverflow. people answer questions. ‚Äôs bug: ‚Äôre right place, file issue. ‚Äôre sure: let community help figure ! problem bug feature request, can easily return report . opening new issue, sure search issues pull requests make sure bug hasn‚Äôt reported /already fixed development version. default, search pre-populated :issue :open. can edit qualifiers (e.g.¬†:pr, :closed) needed. example, ‚Äôd simply remove :open search issues repo, open closed.","code":""},{"path":"/dev/SUPPORT.html","id":"what-happens-next","dir":"","previous_headings":"","what":"What happens next?","title":"Getting help with bvhar","text":"efficient possible, development tidyverse packages tends bursty, shouldn‚Äôt worry don‚Äôt get immediate response. Typically don‚Äôt look repo sufficient quantity issues accumulates, ‚Äôs burst intense activity focus efforts. makes development efficient avoids expensive context switching problems, cost taking longer get back . process makes good reprex particularly important might multiple months initial report start working . can‚Äôt reproduce bug, can‚Äôt fix !","code":""},{"path":"/dev/articles/bvhar.html","id":"data","dir":"Articles","previous_headings":"","what":"Data","title":"Introduction to bvhar","text":"Looking VAR VHAR, can learn models work perform package.","code":""},{"path":"/dev/articles/bvhar.html","id":"etf-dataset","dir":"Articles","previous_headings":"Data","what":"ETF Dataset","title":"Introduction to bvhar","text":"package includes datasets. Among , try CBOE ETF volatility index (etf_vix). Since just example, arbitrarily extract small number variables: Gold, crude oil, euro currency, china ETF.","code":"var_idx <- c(\"GVZCLS\", \"OVXCLS\", \"EVZCLS\", \"VXFXICLS\") etf <-    etf_vix |>    dplyr::select(dplyr::all_of(var_idx)) etf #> # A tibble: 905 √ó 4 #>    GVZCLS OVXCLS EVZCLS VXFXICLS #>     <dbl>  <dbl>  <dbl>    <dbl> #>  1   21.5   36.5   13.2     30.2 #>  2   21.5   35.4   12.6     28.9 #>  3   22.3   35.5   13.1     29.1 #>  4   21.6   36.6   12.8     28.5 #>  5   21.2   35.6   13.3     29.5 #>  6   21.4   34.8   13.2     29.1 #>  7   21.6   34.0   13.2     28.7 #>  8   21.1   32.6   12.8     28.0 #>  9   20.3   33.5   12.7     28.9 #> 10   19.6   33.4   12.4     28.0 #> # ‚Ñπ 895 more rows"},{"path":"/dev/articles/bvhar.html","id":"h-step-ahead-forecasting","dir":"Articles","previous_headings":"Data","what":"h-step ahead forecasting","title":"Introduction to bvhar","text":"evaluation, split data. last 19 observations test set. divide_ts() function splits time series train-test set. vignette, provide perform --sample forecasting. T: Total number observation p: VAR lag m: Dimension variable n = T - p k = m * p + 1 constant term, k = m * p without constant term","code":"h <- 19 etf_eval <- divide_ts(etf, h) # Try ?divide_ts etf_train <- etf_eval$train # train etf_test <- etf_eval$test # test # dimension--------- m <- ncol(etf)"},{"path":[]},{"path":"/dev/articles/bvhar.html","id":"var","dir":"Articles","previous_headings":"Models","what":"VAR","title":"Introduction to bvhar","text":"package indentifies VAR(p) model ùêòt=ùêú+ùõÉ1ùêòt‚àí1+‚Ä¶+ùõÉp+ùêòt‚àíp+ùõút\\mathbf{Y}_t = \\mathbf{c}+ \\boldsymbol\\beta_1 \\mathbf{Y}_{t - 1} + \\ldots + \\boldsymbol\\beta_p +\\mathbf{Y}_{t - p} + \\boldsymbol\\epsilon_t ùõút‚àºN(ùüék,Œ£e)\\boldsymbol\\epsilon_t \\sim N(\\mathbf{0}_k, \\Sigma_e) package perform VAR(p = 5) based Y0=X0A+ZY_0 = X_0 + Z Y0=[ùê≤p+1Tùê≤p+2T‚ãÆùê≤nT]s√óm‚â°Yp+1‚àà‚Ñùs√óm Y_0 = \\begin{bmatrix}   \\mathbf{y}_{p + 1}^T \\\\   \\mathbf{y}_{p + 2}^T \\\\   \\vdots \\\\   \\mathbf{y}_n^T \\end{bmatrix}_{s \\times m} \\equiv Y_{p + 1} \\\\mathbb{R}^{s \\times m} build_y0() X0=[ùê≤pT‚ãØùê≤1T1ùê≤p+1T‚ãØùê≤2T1‚ãÆ‚ãÆ‚ãØ‚ãÆùê≤T‚àí1T‚ãØùê≤T‚àípT1]s√ók=[YpYp‚àí1‚ãØùüèT‚àíp]‚àà‚Ñùs√ók X_0 = \\left[\\begin{array}{c|c|c|c}   \\mathbf{y}_p^T & \\cdots & \\mathbf{y}_1^T & 1 \\\\   \\mathbf{y}_{p + 1}^T & \\cdots & \\mathbf{y}_2^T & 1 \\\\   \\vdots & \\vdots & \\cdots & \\vdots \\\\   \\mathbf{y}_{T - 1}^T & \\cdots & \\mathbf{y}_{T - p}^T & 1 \\end{array}\\right]_{s \\times k} = \\begin{bmatrix}   Y_p & Y_{p - 1} & \\cdots & \\mathbf{1}_{T - p} \\end{bmatrix} \\\\mathbb{R}^{s \\times k} build_design(). Coefficient matrix form =[A1T‚ãÆApTùêúT]‚àà‚Ñùk√óm = \\begin{bmatrix}   A_1^T \\\\   \\vdots \\\\   A_p^T \\\\   \\mathbf{c}^T \\end{bmatrix} \\\\mathbb{R}^{k \\times m} form also corresponds model. Use var_lm(y, p) model VAR(p). can specify type = \"none\" get model without constant term. package provide S3 object.","code":"var_lag <- 5 (fit_var <- var_lm(y = etf_train, p = var_lag)) #> Call: #> var_lm(y = etf_train, p = var_lag) #>  #> VAR(5) Estimation using least squares #> ==================================================== #>  #> LSE for A1: #>           GVZCLS_1  OVXCLS_1  EVZCLS_1  VXFXICLS_1 #> GVZCLS     0.93290    0.0545    0.0659     -0.0346 #> OVXCLS    -0.02367    1.0047   -0.1447      0.0324 #> EVZCLS    -0.00789    0.0102    0.9810      0.0199 #> VXFXICLS  -0.03868    0.0109    0.0754      0.9328 #>  #>  #> LSE for A2: #>           GVZCLS_2  OVXCLS_2  EVZCLS_2  VXFXICLS_2 #> GVZCLS     -0.0781  -0.04865    0.0829      0.0561 #> OVXCLS      0.0880   0.01207    0.2729     -0.1173 #> EVZCLS      0.0195   0.00255   -0.1071     -0.0383 #> VXFXICLS    0.0896   0.04278   -0.0691      0.0419 #>  #>  #> LSE for A3: #>           GVZCLS_3  OVXCLS_3  EVZCLS_3  VXFXICLS_3 #> GVZCLS      0.0424  -0.00452  -0.03245    -0.05967 #> OVXCLS     -0.0272  -0.09144  -0.05764    -0.06255 #> EVZCLS     -0.0123   0.00864   0.08693     0.00252 #> VXFXICLS   -0.0266  -0.04810   0.00851    -0.02137 #>  #>  #> LSE for A4: #>           GVZCLS_4  OVXCLS_4  EVZCLS_4  VXFXICLS_4 #> GVZCLS    -0.00793   0.01072  -0.01513      0.0616 #> OVXCLS    -0.04343  -0.00377  -0.00694      0.1445 #> EVZCLS     0.00614  -0.02278  -0.01007      0.0200 #> VXFXICLS  -0.00755  -0.05555   0.08783     -0.1025 #>  #>  #> LSE for A5: #>           GVZCLS_5  OVXCLS_5  EVZCLS_5  VXFXICLS_5 #> GVZCLS      0.0728  -0.01745   -0.0886   -0.017273 #> OVXCLS      0.0104   0.07151   -0.0637    0.002018 #> EVZCLS     -0.0113   0.00581    0.0202    0.000498 #> VXFXICLS   -0.0155   0.04192   -0.0254    0.093984 #>  #>  #> LSE for constant: #>   GVZCLS    OVXCLS    EVZCLS  VXFXICLS   #>    0.571     0.145     0.129     0.875   #>  #>  #> -------------------------------------------------- #> *_j of the Coefficient matrix: corresponding to the j-th VAR lag # class--------------- class(fit_var) #> [1] \"varlse\"   \"olsmod\"   \"bvharmod\" # inheritance--------- is.varlse(fit_var) #> [1] TRUE # names--------------- names(fit_var) #>  [1] \"coefficients\"  \"fitted.values\" \"residuals\"     \"covmat\"        #>  [5] \"df\"            \"m\"             \"obs\"           \"y0\"            #>  [9] \"p\"             \"totobs\"        \"process\"       \"type\"          #> [13] \"design\"        \"y\"             \"method\"        \"call\""},{"path":"/dev/articles/bvhar.html","id":"vhar","dir":"Articles","previous_headings":"Models","what":"VHAR","title":"Introduction to bvhar","text":"Consider Vector HAR (VHAR) model. ùêòt=ùêú+Œ¶(d)+ùêòt‚àí1+Œ¶(w)ùêòt‚àí1(w)+Œ¶(m)ùêòt‚àí1(m)+ùõút\\mathbf{Y}_t = \\mathbf{c}+ \\Phi^{(d)} + \\mathbf{Y}_{t - 1} + \\Phi^{(w)} \\mathbf{Y}_{t - 1}^{(w)} + \\Phi^{(m)} \\mathbf{Y}_{t - 1}^{(m)} + \\boldsymbol\\epsilon_t ùêòt\\mathbf{Y}_t daily RV ùêòt(w)=15(ùêòt+‚ãØ+ùêòt‚àí4)\\mathbf{Y}_t^{(w)} = \\frac{1}{5} \\left( \\mathbf{Y}_t + \\cdots + \\mathbf{Y}_{t - 4} \\right) weekly RV ùêòt(m)=122(ùêòt+‚ãØ+ùêòt‚àí21)\\mathbf{Y}_t^{(m)} = \\frac{1}{22} \\left( \\mathbf{Y}_t + \\cdots + \\mathbf{Y}_{t - 21} \\right) monthly RV. model can expressed Y0=X1Œ¶+ZY_0 = X_1 \\Phi + Z Œ¶=[Œ¶(d)TŒ¶(w)TŒ¶(m)TùêúT]‚àà‚Ñù(3m+1)√óm \\Phi = \\begin{bmatrix}   \\Phi^{(d)T} \\\\   \\Phi^{(w)T} \\\\   \\Phi^{(m)T} \\\\   \\mathbf{c}^T \\end{bmatrix} \\\\mathbb{R}^{(3m + 1) \\times m} Let TT ‚ÑÇ0:=[10‚ãØ00‚ãØ01/51/5‚ãØ1/50‚ãØ01/221/22‚ãØ1/221/22‚ãØ1/22]‚äóIm‚àà‚Ñù3m√ó22m \\mathbb{C}_0 \\mathpunct{:}=\\begin{bmatrix}   1 & 0 & \\cdots & 0 & 0 & \\cdots & 0 \\\\   1 / 5 & 1 / 5 & \\cdots & 1 / 5 & 0 & \\cdots & 0 \\\\   1 / 22 & 1 / 22 & \\cdots & 1 / 22 & 1 / 22 & \\cdots & 1 / 22 \\end{bmatrix} \\otimes I_m \\\\mathbb{R}^{3m \\times 22m} let ‚ÑÇHAR\\mathbb{C}_{HAR} ‚ÑÇHAR:=[Tùüé3mùüé3mT1]‚àà‚Ñù(3m+1)√ó(22m+1) \\mathbb{C}_{HAR} \\mathpunct{:}=\\left[\\begin{array}{c|c}   T & \\mathbf{0}_{3m} \\\\ \\hline   \\mathbf{0}_{3m}^T & 1 \\end{array}\\right] \\\\mathbb{R}^{(3m + 1) \\times (22m + 1)} X0X_0 VAR(p), X1=X0‚ÑÇHART=[ùê≤22Tùê≤22(w)Tùê≤22(m)T1ùê≤23Tùê≤23(w)Tùê≤23(m)T1‚ãÆ‚ãÆ‚ãÆ‚ãÆùê≤T‚àí1Tùê≤T‚àí1(w)Tùê≤T‚àí1(m)T1]‚àà‚Ñùs√ó(3m+1) X_1 = X_0 \\mathbb{C}_{HAR}^T = \\begin{bmatrix}   \\mathbf{y}_{22}^T & \\mathbf{y}_{22}^{(w)T} & \\mathbf{y}_{22}^{(m)T} & 1 \\\\   \\mathbf{y}_{23}^T & \\mathbf{y}_{23}^{(w)T} & \\mathbf{y}_{23}^{(m)T} & 1 \\\\   \\vdots & \\vdots & \\vdots & \\vdots \\\\   \\mathbf{y}_{T - 1}^T & \\mathbf{y}_{T - 1}^{(w)T} & \\mathbf{y}_{T - 1}^{(m)T} & 1 \\end{bmatrix} \\\\mathbb{R}^{s \\times (3m + 1)} package fits VHAR scaling VAR(p) using ‚ÑÇHAR\\mathbb{C}_{HAR} (scale_har(m, week = 5, month = 22)). Use vhar_lm(y) fit VHAR. can specify type = \"none\" get model without constant term.","code":"(fit_har <- vhar_lm(y = etf_train)) #> Call: #> vhar_lm(y = etf_train) #>  #> VHAR Estimation==================================================== #>  #> LSE for day: #>           GVZCLS_day  OVXCLS_day  EVZCLS_day  VXFXICLS_day #> GVZCLS       0.87561      0.0447      0.1623      -0.03772 #> OVXCLS       0.04147      0.9942     -0.0605      -0.09361 #> EVZCLS       0.00305      0.0281      0.9206      -0.00748 #> VXFXICLS     0.01021      0.0569      0.0440       0.91713 #>  #>  #> LSE for week: #>           GVZCLS_week  OVXCLS_week  EVZCLS_week  VXFXICLS_week #> GVZCLS        0.01622      -0.0554      -0.1608         0.0637 #> OVXCLS       -0.07093      -0.0373       0.2000         0.1034 #> EVZCLS       -0.00334      -0.0414      -0.0101         0.0239 #> VXFXICLS     -0.03756      -0.0787      -0.0135         0.0480 #>  #>  #> LSE for month: #>           GVZCLS_month  OVXCLS_month  EVZCLS_month  VXFXICLS_month #> GVZCLS        0.084981       0.00359        0.0228         -0.0299 #> OVXCLS        0.045986       0.03825       -0.1564         -0.0157 #> EVZCLS       -0.000597       0.02030        0.0501         -0.0138 #> VXFXICLS      0.041648       0.01263        0.0639         -0.0371 #>  #>  #> LSE for constant: #>   GVZCLS    OVXCLS    EVZCLS  VXFXICLS   #>    0.491     0.135     0.105     0.926   #>  #>  #> -------------------------------------------------- #> *_day, *_week, *_month of the Coefficient matrix: daily, weekly, and monthly term in the VHAR model # class---------------- class(fit_har) #> [1] \"vharlse\"  \"olsmod\"   \"bvharmod\" # inheritance---------- is.varlse(fit_har) #> [1] FALSE is.vharlse(fit_har) #> [1] TRUE # complements---------- names(fit_har) #>  [1] \"coefficients\"  \"fitted.values\" \"residuals\"     \"covmat\"        #>  [5] \"df\"            \"m\"             \"obs\"           \"y0\"            #>  [9] \"p\"             \"week\"          \"month\"         \"totobs\"        #> [13] \"process\"       \"type\"          \"HARtrans\"      \"design\"        #> [17] \"y\"             \"method\"        \"call\""},{"path":"/dev/articles/bvhar.html","id":"bvar","dir":"Articles","previous_headings":"Models","what":"BVAR","title":"Introduction to bvhar","text":"page provides deprecated two functions examples. bvar_minnesota() bvar_flat() integrated var_bayes() removed next version.","code":""},{"path":"/dev/articles/bvhar.html","id":"minnesota-prior","dir":"Articles","previous_headings":"Models > BVAR","what":"Minnesota prior","title":"Introduction to bvhar","text":"Litterman (1986) Ba≈Ñbura et al.¬†(2010) equations centered around random walk drift. Prior mean: Recent lags provide reliable information distant ones. Prior variance: lags explain variation given variable lags variables equation. First specify prior using set_bvar(sigma, lambda, delta, eps = 1e-04). turn, bvar_minnesota(y, p, bayes_spec, include_mean = TRUE) fits BVAR(p). y: Multivariate time series data. data frame matrix, means every column numeric. column indicates variable, .e.¬†sould wide format. p: Order BVAR bayes_spec: Output set_bvar() include_mean = TRUE: default, include constant term model. bvarmn class. Bayes computation, also class normaliw bvharmod.","code":"bvar_lag <- 5 sig <- apply(etf_train, 2, sd) # sigma vector lam <- .2 # lambda delta <- rep(0, m) # delta vector (0 vector since RV stationary) eps <- 1e-04 # very small number (bvar_spec <- set_bvar(sig, lam, delta, eps)) #> Model Specification for BVAR #>  #> Parameters: Coefficent matrice and Covariance matrix #> Prior: Minnesota #> ======================================================== #>  #> Setting for 'sigma': #>   GVZCLS    OVXCLS    EVZCLS  VXFXICLS   #>     3.77     10.63      2.27      3.81   #>  #> Setting for 'lambda': #> [1]  0.2 #>  #> Setting for 'delta': #> [1]  0  0  0  0 #>  #> Setting for 'eps': #> [1]  1e-04 #>  #> Setting for 'hierarchical': #> [1]  FALSE (fit_bvar <- bvar_minnesota(etf_train, bvar_lag, num_iter = 10, bayes_spec = bvar_spec)) #> Call: #> bvar_minnesota(y = etf_train, p = bvar_lag, num_iter = 10, bayes_spec = bvar_spec) #>  #> BVAR(5) with Minnesota Prior #> ==================================================== #>  #> A ~ Matrix Normal (Mean, Precision, Scale = Sigma) #> ==================================================== #> Matrix Normal Mean for A1 part: #>           GVZCLS_1  OVXCLS_1  EVZCLS_1  VXFXICLS_1 #> GVZCLS      0.7771   0.00915    0.0628      0.0193 #> OVXCLS      0.0445   0.70884    0.1111      0.0167 #> EVZCLS      0.0104   0.01068    0.7036      0.0266 #> VXFXICLS    0.0214   0.00673    0.1044      0.7674 #>  #>  #> Matrix Normal Mean for A2 part: #>            GVZCLS_2   OVXCLS_2  EVZCLS_2  VXFXICLS_2 #> GVZCLS     0.082726  -0.006736  -0.01387     -0.0020 #> OVXCLS     0.000568   0.140781   0.02419     -0.0436 #> EVZCLS    -0.004778   0.000769   0.11756     -0.0114 #> VXFXICLS   0.013424  -0.003779   0.00369      0.1063 #>  #>  #> Matrix Normal Mean for A3 part: #>           GVZCLS_3   OVXCLS_3  EVZCLS_3  VXFXICLS_3 #> GVZCLS     0.03574  -0.003825  -0.01504    -0.00581 #> OVXCLS    -0.01733   0.054037   0.00196    -0.01874 #> EVZCLS    -0.00391   0.000223   0.05065    -0.00168 #> VXFXICLS  -0.00891  -0.006167  -0.00435     0.02176 #>  #>  #> Matrix Normal Mean for A4 part: #>           GVZCLS_4   OVXCLS_4   EVZCLS_4  VXFXICLS_4 #> GVZCLS     0.02474  -0.001932  -0.011546     0.00263 #> OVXCLS    -0.00987   0.030763   0.003771     0.00845 #> EVZCLS    -0.00318  -0.000206   0.027289     0.00161 #> VXFXICLS  -0.00898  -0.004378   0.000232     0.00582 #>  #>  #> Matrix Normal Mean for A5 part: #>           GVZCLS_5   OVXCLS_5  EVZCLS_5  VXFXICLS_5 #> GVZCLS     0.01986  -1.47e-03  -0.00970     0.00127 #> OVXCLS    -0.00357   2.10e-02   0.00339     0.01017 #> EVZCLS    -0.00284   1.59e-05   0.01729     0.00159 #> VXFXICLS  -0.00431  -1.70e-03   0.00263     0.01207 #>  #>  #> Matrix Normal Mean for constant part: #>   GVZCLS    OVXCLS    EVZCLS  VXFXICLS   #>   0.7271    0.3713    0.0971    1.2139   #>  #>  #> dim(Matrix Normal precision matrix): #> [1]  21  21 #>  #>  #> Sigma ~ Inverse-Wishart #> ==================================================== #> IW scale matrix: #>           GVZCLS  OVXCLS  EVZCLS  VXFXICLS #> GVZCLS      1285     375     115       287 #> OVXCLS       375    3638     131       397 #> EVZCLS       115     131     220       126 #> VXFXICLS     287     397     126      1186 #>  #> IW degrees of freedom: #> [1] 887 #>  #>  #> -------------------------------------------------- #> *_j of the Coefficient matrix: corresponding to the j-th BVAR lag # class--------------- class(fit_bvar) #> [1] \"bvarmn\"   \"bvharmod\" \"normaliw\" # inheritance--------- is.bvarmn(fit_bvar) #> [1] TRUE # names--------------- names(fit_bvar) #>  [1] \"coefficients\"    \"fitted.values\"   \"residuals\"       \"mn_prec\"         #>  [5] \"covmat\"          \"iw_shape\"        \"df\"              \"m\"               #>  [9] \"obs\"             \"prior_mean\"      \"prior_precision\" \"prior_scale\"     #> [13] \"prior_shape\"     \"y0\"              \"design\"          \"p\"               #> [17] \"totobs\"          \"type\"            \"y\"               \"chain\"           #> [21] \"iter\"            \"burn\"            \"thin\"            \"call\"            #> [25] \"process\"         \"spec\""},{"path":"/dev/articles/bvhar.html","id":"flat-prior","dir":"Articles","previous_headings":"Models > BVAR","what":"Flat prior","title":"Introduction to bvhar","text":"Ghosh et al.¬†(2018) provides flat prior covariance matrix, .e.¬†non-informative. Use set_bvar_flat(U). bvar_flat(y, p, bayes_spec, include_mean = TRUE):","code":"(flat_spec <- set_bvar_flat(U = 5000 * diag(m * bvar_lag + 1))) # c * I #> Model Specification for BVAR #>  #> Parameters: Coefficent matrice and Covariance matrix #> Prior: Flat #> ======================================================== #>  #> Setting for 'U': #> # A matrix:  21 x 21  #>        [,1]  [,2]  [,3]  [,4]  [,5] #>  [1,]  5000     0     0     0     0 #>  [2,]     0  5000     0     0     0 #>  [3,]     0     0  5000     0     0 #>  [4,]     0     0     0  5000     0 #>  [5,]     0     0     0     0  5000 #>  [6,]     0     0     0     0     0 #>  [7,]     0     0     0     0     0 #>  [8,]     0     0     0     0     0 #>  [9,]     0     0     0     0     0 #> [10,]     0     0     0     0     0 #> # ... with 11 more rows (fit_ghosh <- bvar_flat(etf_train, bvar_lag, num_iter = 10, bayes_spec = flat_spec)) #> Call: #> bvar_flat(y = etf_train, p = bvar_lag, num_iter = 10, bayes_spec = flat_spec) #>  #> BVAR(5) with Flat Prior #> ==================================================== #>  #> A ~ Matrix Normal (Mean, U^{-1}, Scale 2 = Sigma) #> ==================================================== #> Matrix Normal Mean for A1 part: #>           GVZCLS_1  OVXCLS_1  EVZCLS_1  VXFXICLS_1 #> GVZCLS      0.3128    0.0460    0.0205      0.0457 #> OVXCLS      0.0440    0.4128    0.0186      0.0314 #> EVZCLS      0.0174    0.0230    0.1334      0.0410 #> VXFXICLS    0.0477    0.0464    0.0481      0.3197 #>  #>  #> Matrix Normal Mean for A2 part: #>           GVZCLS_2  OVXCLS_2  EVZCLS_2  VXFXICLS_2 #> GVZCLS     0.19811   0.00287   0.00771      0.0194 #> OVXCLS     0.01595   0.23709   0.00978     -0.0111 #> EVZCLS     0.00425   0.01205   0.11715      0.0201 #> VXFXICLS   0.02725   0.01516   0.03513      0.2162 #>  #>  #> Matrix Normal Mean for A3 part: #>           GVZCLS_3  OVXCLS_3  EVZCLS_3  VXFXICLS_3 #> GVZCLS     0.13884   -0.0153  -0.00102     0.00591 #> OVXCLS    -0.00741    0.1304   0.00361    -0.02452 #> EVZCLS    -0.00353    0.0079   0.10724     0.01150 #> VXFXICLS   0.00797   -0.0146   0.02633     0.14628 #>  #>  #> Matrix Normal Mean for A4 part: #>           GVZCLS_4  OVXCLS_4  EVZCLS_4  VXFXICLS_4 #> GVZCLS     0.11392  -0.01775  -0.00653     0.00884 #> OVXCLS    -0.01626   0.09421   0.00195    -0.00572 #> EVZCLS    -0.00847   0.00565   0.10046     0.01098 #> VXFXICLS  -0.00356  -0.03067   0.02292     0.10552 #>  #>  #> Matrix Normal Mean for A5 part: #>           GVZCLS_5  OVXCLS_5  EVZCLS_5  VXFXICLS_5 #> GVZCLS     0.11282   -0.0208  -0.01028     0.01136 #> OVXCLS    -0.01507    0.1004   0.00155     0.00973 #> EVZCLS    -0.01252    0.0104   0.09667     0.01361 #> VXFXICLS  -0.00492   -0.0215   0.02342     0.10353 #>  #>  #> Matrix Normal Mean for constant part: #>   GVZCLS    OVXCLS    EVZCLS  VXFXICLS   #> 5.49e-03  7.82e-04  8.83e-05  9.82e-03   #>  #>  #> dim(Matrix Normal precision matrix): #> [1]  21  21 #>  #>  #> Sigma ~ Inverse-Wishart #> ==================================================== #> IW scale matrix: #>           GVZCLS  OVXCLS  EVZCLS  VXFXICLS #> GVZCLS      2483     595     209       535 #> OVXCLS       595    3580     216       578 #> EVZCLS       209     216     771       354 #> VXFXICLS     535     578     354      2472 #>  #>  #> -------------------------------------------------- #> *_j of the Coefficient matrix: corresponding to the j-th BVAR lag # class--------------- class(fit_ghosh) #> [1] \"bvarflat\" \"normaliw\" \"bvharmod\" # inheritance--------- is.bvarflat(fit_ghosh) #> [1] TRUE # names--------------- names(fit_ghosh) #>  [1] \"coefficients\"    \"fitted.values\"   \"residuals\"       \"mn_prec\"         #>  [5] \"covmat\"          \"iw_shape\"        \"df\"              \"m\"               #>  [9] \"obs\"             \"prior_mean\"      \"prior_precision\" \"y0\"              #> [13] \"design\"          \"y\"               \"p\"               \"type\"            #> [17] \"chain\"           \"iter\"            \"burn\"            \"thin\"            #> [21] \"call\"            \"process\"         \"spec\""},{"path":"/dev/articles/bvhar.html","id":"bvhar","dir":"Articles","previous_headings":"Models","what":"BVHAR","title":"Introduction to bvhar","text":"Consider VAR(22) form VHAR. ùêòt=ùêú+(Œ¶(d)+15Œ¶(w)+122Œ¶(m))ùêòt‚àí1+(15Œ¶(w)+122Œ¶(m))ùêòt‚àí2+‚ãØ(15Œ¶(w)+122Œ¶(m))ùêòt‚àí5+122Œ¶(m)ùêòt‚àí6+‚ãØ+122Œ¶(m)ùêòt‚àí22 \\begin{aligned}   \\mathbf{Y}_t = \\mathbf{c}& + \\left( \\Phi^{(d)} + \\frac{1}{5} \\Phi^{(w)} + \\frac{1}{22} \\Phi^{(m)} \\right) \\mathbf{Y}_{t - 1} \\\\   & + \\left( \\frac{1}{5} \\Phi^{(w)} + \\frac{1}{22} \\Phi^{(m)} \\right) \\mathbf{Y}_{t - 2} + \\cdots \\left( \\frac{1}{5} \\Phi^{(w)} + \\frac{1}{22} \\Phi^{(m)} \\right) \\mathbf{Y}_{t - 5} \\\\   & + \\frac{1}{22} \\Phi^{(m)} \\mathbf{Y}_{t - 6} + \\cdots + \\frac{1}{22} \\Phi^{(m)} \\mathbf{Y}_{t - 22} \\end{aligned} Minnesota prior mean VHAR model? equations centered around ùêòt+ùêú+Œ¶(d)ùêòt‚àí1+ùõút\\mathbf{Y}_t + \\mathbf{c}+ \\Phi^{(d)} \\mathbf{Y}_{t - 1} + \\boldsymbol\\epsilon_t Œ¶(w)\\Phi^{(w)} Œ¶(m)\\Phi^{(m)} zero WN form: Œ¥i=0\\delta_i = 0 simplicity, write coefficient matrices Œ¶(1),Œ¶(2),Œ¶(3)\\Phi^{(1)}, \\Phi^{(2)}, \\Phi^{(3)}. apply prior way, Minnesota moment becomes E[(Œ¶(l))ij]={Œ¥ij=,l=10o/wVar[(Œ¶(l))ij]={Œª2l2j=iŒΩŒª2l2œÉi2œÉj2o/w E \\left[ (\\Phi^{(l)})_{ij} \\right] = \\begin{cases}   \\delta_i & j = , \\; l = 1 \\\\   0 & o/w \\end{cases} \\quad \\mathrm{Var}\\left[ (\\Phi^{(l)})_{ij} \\right] = \\begin{cases}   \\frac{\\lambda^2}{l^2} & j = \\\\   \\nu \\frac{\\lambda^2}{l^2} \\frac{\\sigma_i^2}{\\sigma_j^2} & o/w \\end{cases} call VAR-type Minnesota prior BVHAR-S.","code":""},{"path":"/dev/articles/bvhar.html","id":"bvhar-s","dir":"Articles","previous_headings":"Models > BVHAR","what":"BVHAR-S","title":"Introduction to bvhar","text":"set_bvhar(sigma, lambda, delta, eps = 1e-04) specifies VAR-type Minnesota prior. bvhar_minnesota(y, har = c(5, 22), bayes_spec, include_mean = TRUE) can fit BVHAR prior. default prior setting. Similar functions, function also integrated vhar_bayes() removed next version. model bvharmn class.","code":"(bvhar_spec_v1 <- set_bvhar(sig, lam, delta, eps)) #> Model Specification for BVHAR #>  #> Parameters: Coefficent matrice and Covariance matrix #> Prior: MN_VAR #> ======================================================== #>  #> Setting for 'sigma': #>   GVZCLS    OVXCLS    EVZCLS  VXFXICLS   #>     3.77     10.63      2.27      3.81   #>  #> Setting for 'lambda': #> [1]  0.2 #>  #> Setting for 'delta': #> [1]  0  0  0  0 #>  #> Setting for 'eps': #> [1]  1e-04 #>  #> Setting for 'hierarchical': #> [1]  FALSE (fit_bvhar_v1 <- bvhar_minnesota(etf_train, num_iter = 10, bayes_spec = bvhar_spec_v1)) #> Call: #> bvhar_minnesota(y = etf_train, num_iter = 10, bayes_spec = bvhar_spec_v1) #>  #> BVHAR with Minnesota Prior #> ==================================================== #>  #> Phi ~ Matrix Normal (Mean, Scale 1, Scale 2 = Sigma) #> ==================================================== #> Matrix Normal Mean for day: #>           GVZCLS_day  OVXCLS_day  EVZCLS_day  VXFXICLS_day #> GVZCLS        0.7808     0.00502      0.0595        0.0181 #> OVXCLS        0.0419     0.75268      0.1293       -0.0129 #> EVZCLS        0.0109     0.00957      0.7248        0.0213 #> VXFXICLS      0.0252     0.00347      0.1003        0.8042 #>  #>  #> Matrix Normal Mean for week: #>           GVZCLS_week  OVXCLS_week  EVZCLS_week  VXFXICLS_week #> GVZCLS         0.1160    -0.007669     -0.03216       -0.00181 #> OVXCLS        -0.0211     0.152822      0.02794       -0.00136 #> EVZCLS        -0.0103    -0.000372      0.13214       -0.00158 #> VXFXICLS      -0.0177    -0.010393      0.00229        0.10274 #>  #>  #> Matrix Normal Mean for month: #>           GVZCLS_month  OVXCLS_month  EVZCLS_month  VXFXICLS_month #> GVZCLS         0.05269      -0.00345       -0.0110        -0.00302 #> OVXCLS         0.00556       0.05169       -0.0225        -0.01051 #> EVZCLS        -0.00441       0.00410        0.0502        -0.00138 #> VXFXICLS       0.00733      -0.00321        0.0109         0.00573 #>  #>  #> Matrix Normal Mean for constant part: #>   GVZCLS    OVXCLS    EVZCLS  VXFXICLS   #>   0.6107    0.1410    0.0741    1.1544   #>  #>  #> dim(Matrix Normal precision matrix): #> [1]  13  13 #>  #>  #> Sigma ~ Inverse-Wishart #> ==================================================== #> IW scale matrix: #>           GVZCLS  OVXCLS  EVZCLS  VXFXICLS #> GVZCLS      1268     366     114       286 #> OVXCLS       366    3742     131       378 #> EVZCLS       114     131     219       121 #> VXFXICLS     286     378     121      1189 # class--------------- class(fit_bvhar_v1) #> [1] \"bvharmn\"  \"bvharmod\" \"normaliw\" # inheritance--------- is.bvharmn(fit_bvhar_v1) #> [1] TRUE # names--------------- names(fit_bvhar_v1) #>  [1] \"coefficients\"    \"fitted.values\"   \"residuals\"       \"mn_prec\"         #>  [5] \"covmat\"          \"iw_shape\"        \"df\"              \"m\"               #>  [9] \"obs\"             \"prior_mean\"      \"prior_precision\" \"prior_scale\"     #> [13] \"prior_shape\"     \"y0\"              \"design\"          \"p\"               #> [17] \"week\"            \"month\"           \"totobs\"          \"type\"            #> [21] \"HARtrans\"        \"y\"               \"chain\"           \"iter\"            #> [25] \"burn\"            \"thin\"            \"call\"            \"process\"         #> [29] \"spec\""},{"path":"/dev/articles/bvhar.html","id":"bvhar-l","dir":"Articles","previous_headings":"Models > BVHAR","what":"BVHAR-L","title":"Introduction to bvhar","text":"Set Œ¥i\\delta_i weekly monthly coefficient matrices Minnesota moments: E[(Œ¶(l))ij]={dij=,l=1wij=,l=2mij=,l=3 E \\left[ (\\Phi^{(l)})_{ij} \\right] = \\begin{cases}   d_i & j = , \\; l = 1 \\\\   w_i & j = , \\; l = 2 \\\\   m_i & j = , \\; l = 3 \\end{cases} .e.¬†instead one delta vector, set three vector daily weekly monthly called VHAR-type Minnesota prior BVHAR-L. set_weight_bvhar(sigma, lambda, eps, daily, weekly, monthly) defines BVHAR-L. bayes_spec option bvhar_minnesota() gets value, can use prior intuitively.","code":"daily <- rep(.1, m) weekly <- rep(.1, m) monthly <- rep(.1, m) (bvhar_spec_v2 <- set_weight_bvhar(sig, lam, eps, daily, weekly, monthly)) #> Model Specification for BVHAR #>  #> Parameters: Coefficent matrice and Covariance matrix #> Prior: MN_VHAR #> ======================================================== #>  #> Setting for 'sigma': #>   GVZCLS    OVXCLS    EVZCLS  VXFXICLS   #>     3.77     10.63      2.27      3.81   #>  #> Setting for 'lambda': #> [1]  0.2 #>  #> Setting for 'eps': #> [1]  1e-04 #>  #> Setting for 'daily': #> [1]  0.1  0.1  0.1  0.1 #>  #> Setting for 'weekly': #> [1]  0.1  0.1  0.1  0.1 #>  #> Setting for 'monthly': #> [1]  0.1  0.1  0.1  0.1 #>  #> Setting for 'hierarchical': #> [1]  FALSE fit_bvhar_v2 <- bvhar_minnesota(   etf_train,   num_iter = 10,   bayes_spec = bvhar_spec_v2 ) fit_bvhar_v2 #> Call: #> bvhar_minnesota(y = etf_train, num_iter = 10, bayes_spec = bvhar_spec_v2) #>  #> BVHAR with Minnesota Prior #> ==================================================== #>  #> Phi ~ Matrix Normal (Mean, Scale 1, Scale 2 = Sigma) #> ==================================================== #> Matrix Normal Mean for day: #>           GVZCLS_day  OVXCLS_day  EVZCLS_day  VXFXICLS_day #> GVZCLS        0.7670     0.00504      0.0644       0.01884 #> OVXCLS        0.0497     0.73098      0.0999      -0.00317 #> EVZCLS        0.0122     0.00907      0.7094       0.02036 #> VXFXICLS      0.0259     0.00429      0.0976       0.79368 #>  #>  #> Matrix Normal Mean for week: #>           GVZCLS_week  OVXCLS_week  EVZCLS_week  VXFXICLS_week #> GVZCLS         0.1259    -0.008055     -0.03361       -0.00353 #> OVXCLS        -0.0222     0.168704      0.01523       -0.00218 #> EVZCLS        -0.0108    -0.000896      0.14770       -0.00294 #> VXFXICLS      -0.0199    -0.010546     -0.00238        0.11358 #>  #>  #> Matrix Normal Mean for month: #>           GVZCLS_month  OVXCLS_month  EVZCLS_month  VXFXICLS_month #> GVZCLS         0.06476      -0.00349      -0.01286        -0.00584 #> OVXCLS         0.00142       0.06915      -0.03315        -0.01117 #> EVZCLS        -0.00492       0.00329       0.06611        -0.00337 #> VXFXICLS       0.00474      -0.00312       0.00592         0.01821 #>  #>  #> Matrix Normal Mean for constant part: #>   GVZCLS    OVXCLS    EVZCLS  VXFXICLS   #>   0.5517    0.0335    0.0834    1.0025   #>  #>  #> dim(Matrix Normal precision matrix): #> [1]  13  13 #>  #>  #> Sigma ~ Inverse-Wishart #> ==================================================== #> IW scale matrix: #>           GVZCLS  OVXCLS  EVZCLS  VXFXICLS #> GVZCLS      1194     372     115       286 #> OVXCLS       372    3124     125       387 #> EVZCLS       115     125     193       119 #> VXFXICLS     286     387     119      1123"},{"path":"/dev/articles/forecasting.html","id":"simulation","dir":"Articles","previous_headings":"","what":"Simulation","title":"Forecasting","text":"Given VAR coefficient VHAR coefficient , sim_var(num_sim, num_burn, var_coef, var_lag, sig_error, init) generates VAR process sim_vhar(num_sim, num_burn, vhar_coef, sig_error, init) generates VHAR process use coefficient matrix estimated VAR(5) introduction vignette. Consider ","code":"coef(ex_fit) #>              GVZCLS   OVXCLS    EVZCLS VXFXICLS #> GVZCLS_1    0.93302 -0.02332 -0.007712 -0.03853 #> OVXCLS_1    0.05429  1.00399  0.009806  0.01062 #> EVZCLS_1    0.06794 -0.13900  0.983825  0.07783 #> VXFXICLS_1 -0.03399  0.03404  0.020719  0.93350 #> GVZCLS_2   -0.07831  0.08753  0.019302  0.08939 #> OVXCLS_2   -0.04770  0.01480  0.003888  0.04392 #> EVZCLS_2    0.08082  0.26704 -0.110017 -0.07163 #> VXFXICLS_2  0.05465 -0.12154 -0.040349  0.04012 #> GVZCLS_3    0.04332 -0.02459 -0.011041 -0.02556 #> OVXCLS_3   -0.00594 -0.09550  0.006638 -0.04981 #> EVZCLS_3   -0.02952 -0.04926  0.091056  0.01204 #> VXFXICLS_3 -0.05876 -0.05995  0.003803 -0.02027 #> GVZCLS_4   -0.00845 -0.04490  0.005415 -0.00817 #> OVXCLS_4    0.01070 -0.00383 -0.022806 -0.05557 #> EVZCLS_4   -0.01971 -0.02008 -0.016535  0.08229 #> VXFXICLS_4  0.06139  0.14403  0.019780 -0.10271 #> GVZCLS_5    0.07301  0.01093 -0.010994 -0.01526 #> OVXCLS_5   -0.01658  0.07401  0.007035  0.04297 #> EVZCLS_5   -0.08794 -0.06189  0.021082 -0.02465 #> VXFXICLS_5 -0.01739  0.00169  0.000335  0.09384 #> const       0.57370  0.15256  0.132842  0.87785 ex_fit$covmat #>          GVZCLS OVXCLS EVZCLS VXFXICLS #> GVZCLS    1.157  0.403  0.127    0.332 #> OVXCLS    0.403  1.740  0.115    0.438 #> EVZCLS    0.127  0.115  0.144    0.127 #> VXFXICLS  0.332  0.438  0.127    1.028 m <- ncol(ex_fit$coefficients) # generate VAR(5)----------------- y <- sim_var(   num_sim = 1500,    num_burn = 100,    var_coef = coef(ex_fit),    var_lag = 5L,    sig_error = ex_fit$covmat,    init = matrix(0L, nrow = 5L, ncol = m) ) # colname: y1, y2, ...------------ colnames(y) <- paste0(\"y\", 1:m) head(y) #>        y1   y2   y3   y4 #> [1,] 18.7 26.5 7.55 26.2 #> [2,] 18.2 25.8 7.39 25.6 #> [3,] 19.7 25.3 7.40 26.1 #> [4,] 20.6 24.5 7.34 26.4 #> [5,] 21.6 24.6 7.06 27.8 #> [6,] 22.5 23.7 7.02 25.8 h <- 20 y_eval <- divide_ts(y, h) y_train <- y_eval$train # train y_test <- y_eval$test # test"},{"path":[]},{"path":"/dev/articles/forecasting.html","id":"var5-and-vhar","dir":"Articles","previous_headings":"Fitting Models","what":"VAR(5) and VHAR","title":"Forecasting","text":"","code":"# VAR(5) model_var <- var_lm(y_train, 5) # VHAR model_vhar <- vhar_lm(y_train)"},{"path":"/dev/articles/forecasting.html","id":"bvar5","dir":"Articles","previous_headings":"Fitting Models","what":"BVAR(5)","title":"Forecasting","text":"Minnesota prior","code":"# hyper parameters--------------------------- y_sig <- apply(y_train, 2, sd) # sigma vector y_lam <- .2 # lambda y_delta <- rep(.2, m) # delta vector (0 vector since RV stationary) eps <- 1e-04 # very small number spec_bvar <- set_bvar(y_sig, y_lam, y_delta, eps) # fit--------------------------------------- model_bvar <- bvar_minnesota(y_train, p = 5, bayes_spec = spec_bvar)"},{"path":"/dev/articles/forecasting.html","id":"bvhar","dir":"Articles","previous_headings":"Fitting Models","what":"BVHAR","title":"Forecasting","text":"BVHAR-S BVHAR-L","code":"spec_bvhar_v1 <- set_bvhar(y_sig, y_lam, y_delta, eps) # fit--------------------------------------- model_bvhar_v1 <- bvhar_minnesota(y_train, bayes_spec = spec_bvhar_v1) # weights---------------------------------- y_day <- rep(.1, m) y_week <- rep(.01, m) y_month <- rep(.01, m) # spec------------------------------------- spec_bvhar_v2 <- set_weight_bvhar(   y_sig,   y_lam,   eps,   y_day,   y_week,   y_month ) # fit-------------------------------------- model_bvhar_v2 <- bvhar_minnesota(y_train, bayes_spec = spec_bvhar_v2)"},{"path":"/dev/articles/forecasting.html","id":"splitting","dir":"Articles","previous_headings":"","what":"Splitting","title":"Forecasting","text":"can forecast using predict() method objects. set step forecasting using n_ahead argument. addition, result forecast return another class called predbvhar use methods, Plot: autoplot.predbvhar() Evaluation: mse.predbvhar(), mae.predbvhar(), mape.predbvhar(), mase.predbvhar(), mrae.predbvhar(), relmae.predbvhar() Relative error: rmape.predbvhar(), rmase.predbvhar(), rmase.predbvhar(), rmsfe.predbvhar(), rmafe.predbvhar()","code":""},{"path":"/dev/articles/forecasting.html","id":"var","dir":"Articles","previous_headings":"Splitting","what":"VAR","title":"Forecasting","text":"package provides evaluation function mse(predbvhar, test): MSE mape(predbvhar, test): MAPE","code":"(pred_var <- predict(model_var, n_ahead = h)) #>         y1   y2   y3   y4 #>  [1,] 17.0 37.3 9.56 22.2 #>  [2,] 16.8 37.4 9.56 22.4 #>  [3,] 16.7 37.3 9.58 22.5 #>  [4,] 16.7 37.2 9.57 22.6 #>  [5,] 16.7 37.1 9.58 22.7 #>  [6,] 16.6 37.0 9.58 22.7 #>  [7,] 16.6 36.9 9.58 22.8 #>  [8,] 16.5 36.8 9.59 22.9 #>  [9,] 16.5 36.8 9.59 22.9 #> [10,] 16.4 36.7 9.59 23.0 #> [11,] 16.4 36.6 9.60 23.1 #> [12,] 16.3 36.5 9.60 23.1 #> [13,] 16.3 36.4 9.60 23.2 #> [14,] 16.3 36.3 9.60 23.3 #> [15,] 16.2 36.3 9.61 23.3 #> [16,] 16.2 36.2 9.61 23.4 #> [17,] 16.2 36.1 9.61 23.4 #> [18,] 16.1 36.0 9.61 23.5 #> [19,] 16.1 35.9 9.61 23.5 #> [20,] 16.1 35.9 9.61 23.6 class(pred_var) #> [1] \"predbvhar\" names(pred_var) #> [1] \"process\"     \"forecast\"    \"se\"          \"lower\"       \"upper\"       #> [6] \"lower_joint\" \"upper_joint\" \"y\" (mse_var <- mse(pred_var, y_test)) #>     y1     y2     y3     y4  #>  2.416 22.739  0.372  3.115"},{"path":"/dev/articles/forecasting.html","id":"vhar","dir":"Articles","previous_headings":"Splitting","what":"VHAR","title":"Forecasting","text":"MSE:","code":"(pred_vhar <- predict(model_vhar, n_ahead = h)) #>         y1   y2   y3   y4 #>  [1,] 17.0 37.5 9.57 22.4 #>  [2,] 16.9 37.4 9.56 22.5 #>  [3,] 16.8 37.3 9.55 22.5 #>  [4,] 16.7 37.2 9.54 22.5 #>  [5,] 16.6 37.2 9.53 22.6 #>  [6,] 16.5 37.1 9.52 22.6 #>  [7,] 16.4 37.0 9.51 22.6 #>  [8,] 16.3 36.9 9.49 22.6 #>  [9,] 16.2 36.9 9.48 22.6 #> [10,] 16.2 36.8 9.46 22.6 #> [11,] 16.1 36.7 9.45 22.7 #> [12,] 16.0 36.7 9.43 22.7 #> [13,] 15.9 36.6 9.42 22.7 #> [14,] 15.9 36.6 9.41 22.7 #> [15,] 15.8 36.5 9.40 22.8 #> [16,] 15.8 36.5 9.40 22.8 #> [17,] 15.7 36.4 9.39 22.9 #> [18,] 15.7 36.4 9.39 22.9 #> [19,] 15.7 36.3 9.39 23.0 #> [20,] 15.6 36.3 9.39 23.0 (mse_vhar <- mse(pred_vhar, y_test)) #>    y1    y2    y3    y4  #>  3.29 24.46  0.27  3.05"},{"path":"/dev/articles/forecasting.html","id":"bvar","dir":"Articles","previous_headings":"Splitting","what":"BVAR","title":"Forecasting","text":"MSE:","code":"(pred_bvar <- predict(model_bvar, n_ahead = h)) #>         y1   y2   y3   y4 #>  [1,] 17.0 37.4 9.52 22.4 #>  [2,] 17.0 37.3 9.51 22.6 #>  [3,] 16.9 37.1 9.51 22.7 #>  [4,] 16.8 37.0 9.51 22.8 #>  [5,] 16.8 36.9 9.51 22.9 #>  [6,] 16.7 36.8 9.52 22.9 #>  [7,] 16.7 36.7 9.52 23.0 #>  [8,] 16.6 36.6 9.52 23.1 #>  [9,] 16.6 36.5 9.52 23.2 #> [10,] 16.5 36.3 9.53 23.3 #> [11,] 16.5 36.2 9.53 23.3 #> [12,] 16.4 36.1 9.53 23.4 #> [13,] 16.4 36.0 9.53 23.5 #> [14,] 16.4 35.9 9.53 23.5 #> [15,] 16.3 35.8 9.53 23.6 #> [16,] 16.3 35.7 9.54 23.6 #> [17,] 16.3 35.6 9.54 23.7 #> [18,] 16.2 35.5 9.54 23.8 #> [19,] 16.2 35.4 9.54 23.8 #> [20,] 16.2 35.3 9.54 23.9 (mse_bvar <- mse(pred_bvar, y_test)) #>     y1     y2     y3     y4  #>  2.202 19.792  0.319  3.414"},{"path":[]},{"path":"/dev/articles/forecasting.html","id":"var-type-minnesota","dir":"Articles","previous_headings":"Splitting > BVHAR","what":"VAR-type Minnesota","title":"Forecasting","text":"MSE:","code":"(pred_bvhar_v1 <- predict(model_bvhar_v1, n_ahead = h)) #>         y1   y2   y3   y4 #>  [1,] 16.9 37.4 9.53 22.4 #>  [2,] 16.9 37.2 9.50 22.5 #>  [3,] 16.8 37.1 9.48 22.5 #>  [4,] 16.8 36.9 9.47 22.6 #>  [5,] 16.7 36.8 9.46 22.7 #>  [6,] 16.6 36.7 9.45 22.7 #>  [7,] 16.5 36.6 9.44 22.8 #>  [8,] 16.5 36.5 9.43 22.8 #>  [9,] 16.4 36.4 9.43 22.8 #> [10,] 16.3 36.3 9.42 22.9 #> [11,] 16.3 36.2 9.41 22.9 #> [12,] 16.2 36.1 9.41 23.0 #> [13,] 16.2 36.0 9.40 23.0 #> [14,] 16.1 36.0 9.40 23.1 #> [15,] 16.1 35.9 9.40 23.1 #> [16,] 16.1 35.8 9.40 23.2 #> [17,] 16.0 35.8 9.40 23.2 #> [18,] 16.0 35.7 9.40 23.3 #> [19,] 16.0 35.6 9.40 23.3 #> [20,] 16.0 35.5 9.40 23.4 (mse_bvhar_v1 <- mse(pred_bvhar_v1, y_test)) #>     y1     y2     y3     y4  #>  2.655 19.914  0.256  3.103"},{"path":"/dev/articles/forecasting.html","id":"vhar-type-minnesota","dir":"Articles","previous_headings":"Splitting > BVHAR","what":"VHAR-type Minnesota","title":"Forecasting","text":"MSE:","code":"(pred_bvhar_v2 <- predict(model_bvhar_v2, n_ahead = h)) #>         y1   y2   y3   y4 #>  [1,] 16.9 37.4 9.53 22.4 #>  [2,] 16.9 37.2 9.50 22.5 #>  [3,] 16.8 37.0 9.47 22.5 #>  [4,] 16.8 36.9 9.46 22.6 #>  [5,] 16.7 36.8 9.45 22.6 #>  [6,] 16.6 36.7 9.44 22.7 #>  [7,] 16.5 36.6 9.43 22.7 #>  [8,] 16.5 36.5 9.43 22.8 #>  [9,] 16.4 36.4 9.42 22.8 #> [10,] 16.4 36.3 9.41 22.9 #> [11,] 16.3 36.2 9.40 22.9 #> [12,] 16.2 36.1 9.40 22.9 #> [13,] 16.2 36.0 9.39 23.0 #> [14,] 16.2 35.9 9.39 23.0 #> [15,] 16.1 35.9 9.39 23.1 #> [16,] 16.1 35.8 9.39 23.1 #> [17,] 16.0 35.7 9.39 23.2 #> [18,] 16.0 35.7 9.39 23.2 #> [19,] 16.0 35.6 9.39 23.3 #> [20,] 16.0 35.5 9.39 23.3 (mse_bvhar_v2 <- mse(pred_bvhar_v2, y_test)) #>     y1     y2     y3     y4  #>  2.630 19.668  0.252  3.095"},{"path":[]},{"path":"/dev/articles/forecasting.html","id":"region","dir":"Articles","previous_headings":"Splitting > Compare","what":"Region","title":"Forecasting","text":"autoplot(predbvhar) autolayer(predbvhar) draws results forecasting.","code":"autoplot(pred_var, x_cut = 1470, ci_alpha = .7, type = \"wrap\") +   autolayer(pred_vhar, ci_alpha = .5) +   autolayer(pred_bvar, ci_alpha = .4) +   autolayer(pred_bvhar_v1, ci_alpha = .2) +   autolayer(pred_bvhar_v2, ci_alpha = .1) +   geom_eval(y_test, colour = \"#000000\", alpha = .5)"},{"path":"/dev/articles/forecasting.html","id":"error","dir":"Articles","previous_headings":"Splitting > Compare","what":"Error","title":"Forecasting","text":"Mean MSE variable, can see error plot.  Relative MAPE (MAPE), benchmark model: VAR","code":"list(   VAR = mse_var,   VHAR = mse_vhar,   BVAR = mse_bvar,   BVHAR1 = mse_bvhar_v1,   BVHAR2 = mse_bvhar_v2 ) |>    lapply(mean) |>    unlist() |>    sort() #> BVHAR2   BVAR BVHAR1    VAR   VHAR  #>   6.41   6.43   6.48   7.16   7.77 list(   pred_var,   pred_vhar,   pred_bvar,   pred_bvhar_v1,   pred_bvhar_v2 ) |>    gg_loss(y = y_test, \"mse\") list(   VAR = pred_var,   VHAR = pred_vhar,   BVAR = pred_bvar,   BVHAR1 = pred_bvhar_v1,   BVHAR2 = pred_bvhar_v2 ) |>    lapply(rmape, pred_bench = pred_var, y = y_test) |>    unlist() #>    VAR   VHAR   BVAR BVHAR1 BVHAR2  #>  1.000  1.020  0.965  0.954  0.948"},{"path":"/dev/articles/forecasting.html","id":"out-of-sample-forecasting","dir":"Articles","previous_headings":"","what":"Out-of-Sample Forecasting","title":"Forecasting","text":"time series research, --sample forecasting plays key role. , provide --sample forecasting function based Rolling window: forecast_roll(object, n_ahead, y_test) Expanding window: forecast_expand(object, n_ahead, y_test)","code":""},{"path":"/dev/articles/forecasting.html","id":"rolling-windows","dir":"Articles","previous_headings":"Out-of-Sample Forecasting","what":"Rolling windows","title":"Forecasting","text":"forecast_roll(object, n_ahead, y_test) conducts h >= 1 step rolling windows forecasting. fixes window size moves window. window training set. package, set window size = original input data. Iterating step model fitted training set. fitted model, researcher forecast next h >= 1 step ahead. longest forecast horizon num_test - h + 1. window, move window process. Get forecasted values possible (longest forecast horizon). 5-step --sample: Denote nrow longest forecast horizon. apply evaluation methods, class named bvharcv defined. can use functions . Relative MAPE, benchmark model: VAR","code":"(var_roll <- forecast_roll(model_var, 5, y_test)) #>         y1   y2   y3   y4 #>  [1,] 16.7 37.1 9.58 22.7 #>  [2,] 17.6 34.9 9.48 23.4 #>  [3,] 16.7 35.0 9.73 22.5 #>  [4,] 16.6 32.5 8.98 21.7 #>  [5,] 16.0 31.6 8.83 22.3 #>  [6,] 16.5 32.9 8.64 22.6 #>  [7,] 17.1 32.9 9.12 22.8 #>  [8,] 17.5 32.2 9.27 22.5 #>  [9,] 17.5 30.7 9.57 22.1 #> [10,] 18.5 32.8 9.93 22.2 #> [11,] 18.2 31.6 9.67 21.5 #> [12,] 18.2 30.5 9.47 22.6 #> [13,] 18.1 30.9 9.19 21.5 #> [14,] 17.3 30.7 8.83 21.0 #> [15,] 19.0 31.3 9.18 23.2 #> [16,] 17.6 31.1 8.71 22.9 class(var_roll) #> [1] \"predbvhar_roll\" \"bvharcv\" names(var_roll) #> [1] \"process\"  \"forecast\" \"eval_id\"  \"y\" vhar_roll <- forecast_roll(model_vhar, 5, y_test) bvar_roll <- forecast_roll(model_bvar, 5, y_test) bvhar_roll_v1 <- forecast_roll(model_bvhar_v1, 5, y_test) bvhar_roll_v2 <- forecast_roll(model_bvhar_v2, 5, y_test) list(   VAR = var_roll,   VHAR = vhar_roll,   BVAR = bvar_roll,   BVHAR1 = bvhar_roll_v1,   BVHAR2 = bvhar_roll_v2 ) |>    lapply(rmape, pred_bench = var_roll, y = y_test) |>    unlist() #>    VAR   VHAR   BVAR BVHAR1 BVHAR2  #>  1.000  0.989  0.982  0.973  0.973"},{"path":"/dev/articles/forecasting.html","id":"expanding-windows","dir":"Articles","previous_headings":"Out-of-Sample Forecasting","what":"Expanding Windows","title":"Forecasting","text":"forecast_expand(object, n_ahead, y_test) conducts h >= 1 step expanding window forecasting. Different rolling windows, expanding windows method fixes starting point. . class bvharcv. Relative MAPE, benchmark model: VAR","code":"(var_expand <- forecast_expand(model_var, 5, y_test)) #>         y1   y2   y3   y4 #>  [1,] 16.7 37.1 9.58 22.7 #>  [2,] 17.6 34.9 9.48 23.4 #>  [3,] 16.7 35.0 9.73 22.5 #>  [4,] 16.6 32.4 8.97 21.7 #>  [5,] 16.0 31.6 8.82 22.3 #>  [6,] 16.5 32.9 8.63 22.6 #>  [7,] 17.1 32.9 9.12 22.8 #>  [8,] 17.5 32.2 9.27 22.5 #>  [9,] 17.5 30.7 9.58 22.1 #> [10,] 18.5 32.8 9.95 22.2 #> [11,] 18.2 31.6 9.68 21.5 #> [12,] 18.2 30.5 9.48 22.6 #> [13,] 18.1 30.9 9.19 21.5 #> [14,] 17.3 30.7 8.84 21.0 #> [15,] 19.0 31.3 9.17 23.2 #> [16,] 17.6 31.1 8.70 22.9 class(var_expand) #> [1] \"predbvhar_expand\" \"bvharcv\" names(var_expand) #> [1] \"process\"  \"forecast\" \"eval_id\"  \"y\" vhar_expand <- forecast_expand(model_vhar, 5, y_test) bvar_expand <- forecast_expand(model_bvar, 5, y_test) bvhar_expand_v1 <- forecast_expand(model_bvhar_v1, 5, y_test) bvhar_expand_v2 <- forecast_expand(model_bvhar_v2, 5, y_test) list(   VAR = var_expand,   VHAR = vhar_expand,   BVAR = bvar_expand,   BVHAR1 = bvhar_expand_v1,   BVHAR2 = bvhar_expand_v2 ) |>    lapply(rmape, pred_bench = var_expand, y = y_test) |>    unlist() #>    VAR   VHAR   BVAR BVHAR1 BVHAR2  #>  1.000  0.985  0.982  0.969  0.969"},{"path":"/dev/articles/minnesota.html","id":"normal-inverse-wishart-matrix","dir":"Articles","previous_headings":"","what":"Normal-inverse-Wishart Matrix","title":"Minnesota Prior","text":"provide functions generate matrix-variate Normal inverse-Wishart. sim_mnormal(num_sim, mu, sig): num_sim ùêói‚àºiidN(ùõç,Œ£)\\mathbf{X}_i \\stackrel{iid}{\\sim} N(\\boldsymbol{\\mu}, \\Sigma). sim_matgaussian(mat_mean, mat_scale_u, mat_scale_v): One Xm√ón‚àºMN(Mm√ón,Um√óm,Vn√ón)X_{m \\times n} \\sim MN(M_{m \\times n}, U_{m \\times m}, V_{n \\times n}) means vec(X)‚àºN(vec(M),V‚äóU)vec(X) \\sim N(vec(M), V \\otimes U). sim_iw(mat_scale, shape): One Œ£‚àºIW(Œ®,ŒΩ)\\Sigma \\sim IW(\\Psi, \\nu). sim_mniw(num_sim, mat_mean, mat_scale_u, mat_scale, shape): num_sim (Xi,Œ£i)‚àºiidMNIW(M,U,V,ŒΩ)(X_i, \\Sigma_i) \\stackrel{iid}{\\sim} MNIW(M, U, V, \\nu). Multivariate Normal generation gives num_sim x dim matrix. example, generating 3 vector Normal(ùõç=ùüé2\\boldsymbol{\\mu} = \\mathbf{0}_2, Œ£=diag(ùüè2)\\Sigma = diag(\\mathbf{1}_2)): output sim_matgaussian() matrix. generating IW, violating ŒΩ>dim‚àí1\\nu > dim - 1 gives error. ignore ŒΩ>dim+1\\nu > dim + 1 (condition mean existence) function. Nonetheless, recommend keep ŒΩ>dim+1\\nu > dim + 1 condition. mentioned, guarantees existence mean. case sim_mniw(), returns list mn (stacked MN matrices) iw (stacked IW matrices). mn iw draw lists. function defined next simulation functions.","code":"sim_mnormal(3, rep(0, 2), diag(2)) #>        [,1]   [,2] #> [1,] -0.626  0.184 #> [2,] -0.836  1.595 #> [3,]  0.330 -0.820 sim_matgaussian(matrix(1:20, nrow = 4), diag(4), diag(5), FALSE) #>      [,1] [,2]  [,3] [,4] [,5] #> [1,] 1.49 5.74  9.58 12.7 18.5 #> [2,] 2.39 5.38  7.79 15.1 18.0 #> [3,] 2.98 7.94 11.82 15.6 19.9 #> [4,] 4.78 8.07 10.01 16.6 19.9 sim_iw(diag(5), 7) #>         [,1]    [,2]    [,3]    [,4]    [,5] #> [1,]  0.1827  0.0894 -0.0411 -0.0924 -0.1305 #> [2,]  0.0894  0.6110  0.0860 -0.3754 -0.1015 #> [3,] -0.0411  0.0860  0.2189 -0.1649 -0.0988 #> [4,] -0.0924 -0.3754 -0.1649  0.4577  0.2136 #> [5,] -0.1305 -0.1015 -0.0988  0.2136  0.7444 sim_mniw(2, matrix(1:20, nrow = 4), diag(4), diag(5), 7, FALSE) #> $mn #> $mn[[1]] #>      [,1] [,2]  [,3] [,4] [,5] #> [1,] 1.19 4.96  8.03 12.7 14.6 #> [2,] 2.13 5.17 10.41 14.1 19.3 #> [3,] 3.01 7.15 10.29 14.9 18.1 #> [4,] 4.59 7.99 12.12 15.0 18.5 #>  #> $mn[[2]] #>       [,1] [,2]  [,3] [,4] [,5] #> [1,] 0.323 5.07  8.24 13.1 17.4 #> [2,] 2.022 5.56  9.96 13.9 19.4 #> [3,] 3.380 7.24 11.34 15.5 17.9 #> [4,] 3.755 8.79 11.84 15.6 19.6 #>  #>  #> $iw #> $iw[[1]] #>         [,1]     [,2]     [,3]    [,4]   [,5] #> [1,]  0.2887 -0.04393  0.11892 -0.2959  0.110 #> [2,] -0.0439  0.33357  0.00197  0.0106 -0.167 #> [3,]  0.1189  0.00197  1.30074 -0.0291  2.210 #> [4,] -0.2959  0.01061 -0.02913  0.5072  0.250 #> [5,]  0.1104 -0.16736  2.20957  0.2504  4.623 #>  #> $iw[[2]] #>          [,1]    [,2]     [,3]    [,4]   [,5] #> [1,]  0.28118 -0.1397  0.00529  0.0283  0.038 #> [2,] -0.13965  0.2876  0.06156 -0.1575 -0.186 #> [3,]  0.00529  0.0616  0.31282 -0.1372 -0.299 #> [4,]  0.02831 -0.1575 -0.13724  0.3441  0.122 #> [5,]  0.03803 -0.1856 -0.29860  0.1217  0.738"},{"path":[]},{"path":"/dev/articles/minnesota.html","id":"bvar","dir":"Articles","previous_headings":"Minnesota Prior","what":"BVAR","title":"Minnesota Prior","text":"Consider BVAR Minnesota prior setting, ‚àºMN(A0,Œ©0,Œ£e)\\sim MN(A_0, \\Omega_0, \\Sigma_e) Œ£e‚àºIW(S0,Œ±0)\\Sigma_e \\sim IW(S_0, \\alpha_0) Litterman (1986) Ba≈Ñbura et al.¬†(2010) build_xdummy() build_ydummy() Œ£e=diag(œÉ12,‚Ä¶,œÉm2)\\Sigma_e = diag(\\sigma_1^2, \\ldots, \\sigma_m^2) œÉi2/œÉj2\\sigma_i^2 / \\sigma_j^2: different scale variability data Controls overall tightness prior distribution around RW WN Œª=0\\lambda = 0, posterior = prior data influence estimates. Œª=‚àû\\lambda = \\infty, posterior expectations = OLS. m increases, Œª\\lambda smaller avoid overfitting (De Mol et al.¬†(2008)) Litterman (1986) originally sets high persistence Œ¥i=1\\delta_i = 1 Non-stationary variables: random walk prior Œ¥i=1\\delta_i = 1 stationary variables: white noise prior Œ¥i=0\\delta_i = 0 eps: small number make matrix invertible sim_mncoef(p, bayes_spec, full = TRUE) can generate AA Œ£\\Sigma matrices. bayes_spec, set_bvar() works. full = FALSE, Œ£\\Sigma random. diag(sigma) bayes_spec. full = TRUE default.","code":"bvar_lag <- 5 (spec_to_sim <- set_bvar(   sigma = c(3.25, 11.1, 2.2, 6.8), # sigma vector   lambda = .2, # lambda   delta = rep(1, 4), # 4-dim delta vector   eps = 1e-04 # very small number )) #> Model Specification for BVAR #>  #> Parameters: Coefficent matrice and Covariance matrix #> Prior: Minnesota #> ======================================================== #>  #> Setting for 'sigma': #> [1]   3.25  11.10   2.20   6.80 #>  #> Setting for 'lambda': #> [1]  0.2 #>  #> Setting for 'delta': #> [1]  1  1  1  1 #>  #> Setting for 'eps': #> [1]  1e-04 #>  #> Setting for 'hierarchical': #> [1]  FALSE (sim_mncoef(bvar_lag, spec_to_sim)) #> $coefficients #>            [,1]     [,2]      [,3]     [,4] #>  [1,]  0.996255 -0.19084 -0.026363  0.07600 #>  [2,] -0.017158  1.07873 -0.033404 -0.00816 #>  [3,] -0.225869  0.31165  0.927705 -0.48148 #>  [4,] -0.002706 -0.26068  0.038566  0.84105 #>  [5,] -0.023064 -0.11717 -0.030881  0.35496 #>  [6,]  0.000253 -0.05523 -0.018351  0.03580 #>  [7,] -0.001364 -0.06563 -0.051615 -0.33330 #>  [8,] -0.025569  0.11938 -0.011720 -0.15248 #>  [9,]  0.062006 -0.07985 -0.001830  0.15440 #> [10,]  0.008609 -0.03437  0.016242  0.00866 #> [11,] -0.069804  0.11559  0.003275  0.30043 #> [12,]  0.001677  0.01789 -0.000582 -0.02224 #> [13,] -0.000864  0.05893  0.038960  0.06788 #> [14,]  0.008799 -0.04337  0.005557  0.02273 #> [15,] -0.053924  0.16120 -0.006870  0.10085 #> [16,] -0.009109  0.00284 -0.008880 -0.01168 #> [17,]  0.008001 -0.05816  0.012293 -0.05256 #> [18,] -0.006107  0.03645 -0.004491 -0.00687 #> [19,] -0.011204  0.05703  0.036651  0.13185 #> [20,] -0.003148 -0.05735  0.016794  0.04086 #>  #> $covmat #>        [,1]     [,2]    [,3]   [,4] #> [1,]  2.615  -5.1044  0.1522   2.44 #> [2,] -5.104  32.2768 -0.0549 -12.04 #> [3,]  0.152  -0.0549  1.4573   0.31 #> [4,]  2.440 -12.0446  0.3101  30.83"},{"path":"/dev/articles/minnesota.html","id":"bvhar","dir":"Articles","previous_headings":"Minnesota Prior","what":"BVHAR","title":"Minnesota Prior","text":"sim_mnvhar_coef(bayes_spec, full = TRUE) generates BVHAR model setting: Œ¶‚à£Œ£e‚àºMN(M0,Œ©0,Œ£e)\\Phi \\mid \\Sigma_e \\sim MN(M_0, \\Omega_0, \\Sigma_e) Œ£e‚àºIW(Œ®0,ŒΩ0)\\Sigma_e \\sim IW(\\Psi_0, \\nu_0) set_bvhar() set_weight_bvhar() full = TRUE, .","code":""},{"path":"/dev/articles/minnesota.html","id":"bvhar-s","dir":"Articles","previous_headings":"Minnesota Prior > BVHAR","what":"BVHAR-S","title":"Minnesota Prior","text":"","code":"(bvhar_var_spec <- set_bvhar(   sigma = c(1.2, 2.3), # sigma vector   lambda = .2, # lambda   delta = c(.3, 1), # 2-dim delta vector   eps = 1e-04 # very small number )) #> Model Specification for BVHAR #>  #> Parameters: Coefficent matrice and Covariance matrix #> Prior: MN_VAR #> ======================================================== #>  #> Setting for 'sigma': #> [1]  1.2  2.3 #>  #> Setting for 'lambda': #> [1]  0.2 #>  #> Setting for 'delta': #> [1]  0.3  1.0 #>  #> Setting for 'eps': #> [1]  1e-04 #>  #> Setting for 'hierarchical': #> [1]  FALSE (sim_mnvhar_coef(bvhar_var_spec)) #> $coefficients #>          [,1]    [,2] #> [1,]  0.30349 -0.2954 #> [2,] -0.01177  1.2277 #> [3,]  0.05543 -0.2689 #> [4,]  0.00235  0.0574 #> [5,] -0.05121  0.1928 #> [6,] -0.00891  0.0245 #>  #> $covmat #>        [,1]   [,2] #> [1,]  0.322 -0.407 #> [2,] -0.407  3.195"},{"path":"/dev/articles/minnesota.html","id":"bvhar-l","dir":"Articles","previous_headings":"Minnesota Prior > BVHAR","what":"BVHAR-L","title":"Minnesota Prior","text":"","code":"(bvhar_vhar_spec <- set_weight_bvhar(   sigma = c(1.2, 2.3), # sigma vector   lambda = .2, # lambda   eps = 1e-04, # very small number   daily = c(.5, 1), # 2-dim daily weight vector   weekly = c(.2, .3), # 2-dim weekly weight vector   monthly = c(.1, .1) # 2-dim monthly weight vector )) #> Model Specification for BVHAR #>  #> Parameters: Coefficent matrice and Covariance matrix #> Prior: MN_VHAR #> ======================================================== #>  #> Setting for 'sigma': #> [1]  1.2  2.3 #>  #> Setting for 'lambda': #> [1]  0.2 #>  #> Setting for 'eps': #> [1]  1e-04 #>  #> Setting for 'daily': #> [1]  0.5  1.0 #>  #> Setting for 'weekly': #> [1]  0.2  0.3 #>  #> Setting for 'monthly': #> [1]  0.1  0.1 #>  #> Setting for 'hierarchical': #> [1]  FALSE (sim_mnvhar_coef(bvhar_vhar_spec)) #> $coefficients #>          [,1]    [,2] #> [1,]  0.38047  0.2058 #> [2,]  0.14585  0.5599 #> [3,]  0.09613 -0.0491 #> [4,]  0.05043  0.0088 #> [5,]  0.05409  0.3732 #> [6,] -0.00569 -0.0482 #>  #> $covmat #>       [,1]   [,2] #> [1,] 0.566  0.263 #> [2,] 0.263 14.995"},{"path":"/dev/articles/shrinkage.html","id":"bayesian-var-and-vhar","dir":"Articles","previous_headings":"","what":"Bayesian VAR and VHAR","title":"Bayesian VAR and VHAR Models","text":"var_bayes() vhar_bayes() fit BVAR BVHAR various priors. y: Multivariate time series data. data frame matrix, means every column numeric. column indicates variable, .e.¬†sould wide format. p har: VAR lag, order VHAR OpenMP enabled, parallel loop run. num_iter: Total number iterations num_burn: Number burn-thinning: Thinning BVAR: set_bvar() BVHAR: set_bvhar() set_weight_bvhar() Can induce prior Œª\\lambda using lambda = set_lambda() SSVS prior: set_ssvs() Horseshoe prior: set_horseshoe() NG prior: set_ng() DL prior: set_dl() contem_spec: Contemporaneous prior specification. cov_spec: Covariance prior specification. Use set_ldlt() homoskedastic model. include_mean = TRUE: default, include constant term model. minnesota = c(\"\", \"short\", \"longrun\"): Minnesota-type shrinkage. verbose = FALSE: Progress bar Used parallel multi-chain loop option valid OpenMP user‚Äôs machine.","code":""},{"path":"/dev/articles/shrinkage.html","id":"stochastic-search-variable-selection-ssvs-prior","dir":"Articles","previous_headings":"Bayesian VAR and VHAR","what":"Stochastic Search Variable Selection (SSVS) Prior","title":"Bayesian VAR and VHAR Models","text":"autoplot() fit (bvharsp object) provides coefficients heatmap. type argument, default type = \"coef\" draws heatmap.","code":"(fit_ssvs <- vhar_bayes(etf_train, num_chains = 1, num_iter = 20, coef_spec = set_ssvs(), contem_spec = set_ssvs(), cov_spec = set_ldlt(), include_mean = FALSE, minnesota = \"longrun\")) #> Call: #> vhar_bayes(y = etf_train, num_chains = 1, num_iter = 20, coef_spec = set_ssvs(),  #>     contem_spec = set_ssvs(), cov_spec = set_ldlt(), include_mean = FALSE,  #>     minnesota = \"longrun\") #>  #> BVHAR with SSVS prior + SSVS prior #> Fitted by Gibbs sampling #> Total number of iteration: 20 #> Number of burn-in: 10 #> ==================================================== #>  #> Parameter Record: #> # A draws_df: 10 iterations, 1 chains, and 90 variables #>      phi[1]   phi[2]   phi[3]     phi[4]   phi[5]   phi[6]  phi[7]  phi[8] #> 1   -0.0876  -0.0175  -0.2211   0.048667   0.2732   0.0339   0.755   0.355 #> 2    0.1705  -0.0185  -0.1899   0.198807  -0.0889  -0.0591  -0.169   0.201 #> 3   -0.1823  -0.3229  -0.1574  -0.000812   0.3271  -0.2168   0.614   0.154 #> 4   -0.0456   0.4376  -0.2301   0.105966  -0.7925  -0.1346  -0.401   0.235 #> 5    0.1391   0.5049  -0.3111  -0.383728  -0.7563  -0.1516   0.386   0.835 #> 6    0.1806  -0.1231   0.0320  -0.500005   0.1669  -0.4150   0.738   0.131 #> 7   -0.0620  -0.3463   0.1281  -0.177550   0.5410  -0.4273   1.408   0.466 #> 8    0.1520   0.3084  -0.0333  -0.851727  -0.5724  -0.4793   0.781   1.111 #> 9    0.2625  -0.0168  -0.0794  -0.864491   0.2769  -0.0485   0.494   0.621 #> 10   0.3484   0.5000  -0.2022  -0.970879  -0.5480  -0.1629   0.801   0.874 #> # ... with 82 more variables #> # ... hidden reserved variables {'.chain', '.iteration', '.draw'} autoplot(fit_ssvs)"},{"path":"/dev/articles/shrinkage.html","id":"horseshoe-prior","dir":"Articles","previous_headings":"Bayesian VAR and VHAR","what":"Horseshoe Prior","title":"Bayesian VAR and VHAR Models","text":"coef_spec initial specification set_horseshoe(). Others .","code":"(fit_hs <- vhar_bayes(etf_train, num_chains = 2, num_iter = 20, coef_spec = set_horseshoe(), contem_spec = set_horseshoe(), cov_spec = set_ldlt(), include_mean = FALSE, minnesota = \"longrun\")) #> Call: #> vhar_bayes(y = etf_train, num_chains = 2, num_iter = 20, coef_spec = set_horseshoe(),  #>     contem_spec = set_horseshoe(), cov_spec = set_ldlt(), include_mean = FALSE,  #>     minnesota = \"longrun\") #>  #> BVHAR with Horseshoe prior + Horseshoe prior #> Fitted by Gibbs sampling #> Number of chains: 2 #> Total number of iteration: 20 #> Number of burn-in: 10 #> ==================================================== #>  #> Parameter Record: #> # A draws_df: 10 iterations, 2 chains, and 124 variables #>       phi[1]   phi[2]     phi[3]   phi[4]  phi[5]  phi[6]     phi[7]   phi[8] #> 1   -0.04495  -0.2428  -0.408630   0.2169   1.363   0.663  -2.49e-02  -0.1709 #> 2    0.08816   0.0361   0.000658  -0.2194   0.715   0.721   1.18e-02  -0.2143 #> 3    0.00684   0.0276  -0.111765   0.0407   1.079   0.931   3.58e-04  -0.0892 #> 4    0.00944   0.0530   0.168523  -0.0199  -0.477   0.959  -1.54e-03   0.0292 #> 5   -0.00226   0.0121  -0.054365   0.2389   0.682   0.971   1.99e-03   0.0678 #> 6    0.03164  -0.0434  -0.105660  -0.0190   0.203   0.898   2.89e-04   0.0595 #> 7   -0.20536  -0.1265  -0.009287   0.4954  -0.123   0.608   1.29e-04  -0.1439 #> 8    0.00274  -0.1432  -0.000363  -0.1834   0.194   0.679  -6.89e-05  -0.1870 #> 9    0.16452  -0.0938   0.009767  -0.0540   0.255   0.573  -5.64e-04  -0.2881 #> 10   0.18610  -0.3555   0.000239   0.4681  -0.181   0.686   1.01e-03  -0.2060 #> # ... with 10 more draws, and 116 more variables #> # ... hidden reserved variables {'.chain', '.iteration', '.draw'} autoplot(fit_hs)"},{"path":"/dev/articles/shrinkage.html","id":"minnesota-prior","dir":"Articles","previous_headings":"Bayesian VAR and VHAR","what":"Minnesota Prior","title":"Bayesian VAR and VHAR Models","text":"","code":"(fit_mn <- vhar_bayes(etf_train, num_chains = 2, num_iter = 20, coef_spec = set_bvhar(lambda = set_lambda()), cov_spec = set_ldlt(), include_mean = FALSE, minnesota = \"longrun\")) #> Call: #> vhar_bayes(y = etf_train, num_chains = 2, num_iter = 20, coef_spec = set_bvhar(lambda = set_lambda()),  #>     cov_spec = set_ldlt(), include_mean = FALSE, minnesota = \"longrun\") #>  #> BVHAR with MN_Hierarchical prior + MN_Hierarchical prior #> Fitted by Gibbs sampling #> Number of chains: 2 #> Total number of iteration: 20 #> Number of burn-in: 10 #> ==================================================== #>  #> Parameter Record: #> # A draws_df: 10 iterations, 2 chains, and 63 variables #>      phi[1]    phi[2]    phi[3]    phi[4]    phi[5]  phi[6]   phi[7]   phi[8] #> 1    0.0772  -0.19792  -0.02059   0.02107   0.18810   0.653   0.6363  -0.1294 #> 2    0.1971   0.03031   0.02267  -0.16524   0.16601   0.963   0.5907   0.1467 #> 3   -0.0652   0.04858   0.13853   0.41502   0.21091   0.913   0.0569  -0.2873 #> 4    0.0462   0.01200   0.24799   0.28023   0.05044   1.155  -0.0932   0.0422 #> 5    0.3616  -0.13088   0.16699   0.00432   0.12119   0.705  -0.0217   0.1122 #> 6    0.3236  -0.11465   0.01582   0.03471   0.00207   0.675  -0.1075  -0.0457 #> 7    0.1022  -0.11147  -0.00271  -0.00526   0.11684   0.538   0.3197   0.0984 #> 8    0.2079   0.00524   0.02906  -0.06189  -0.07685   0.781   0.1671   0.0594 #> 9    0.4017  -0.11320   0.07950  -0.08998   0.05990   0.959   0.2355  -0.1646 #> 10   0.2470  -0.29699   0.25608  -0.05925  -0.00420   0.736   0.2196  -0.2519 #> # ... with 10 more draws, and 55 more variables #> # ... hidden reserved variables {'.chain', '.iteration', '.draw'}"},{"path":"/dev/articles/shrinkage.html","id":"normal-gamma-prior","dir":"Articles","previous_headings":"Bayesian VAR and VHAR","what":"Normal-Gamma prior","title":"Bayesian VAR and VHAR Models","text":"","code":"(fit_ng <- vhar_bayes(etf_train, num_chains = 2, num_iter = 20, coef_spec = set_ng(), cov_spec = set_ldlt(), include_mean = FALSE, minnesota = \"longrun\")) #> Call: #> vhar_bayes(y = etf_train, num_chains = 2, num_iter = 20, coef_spec = set_ng(),  #>     cov_spec = set_ldlt(), include_mean = FALSE, minnesota = \"longrun\") #>  #> BVHAR with NG prior + NG prior #> Fitted by Metropolis-within-Gibbs #> Number of chains: 2 #> Total number of iteration: 20 #> Number of burn-in: 10 #> ==================================================== #>  #> Parameter Record: #> # A draws_df: 10 iterations, 2 chains, and 97 variables #>       phi[1]    phi[2]    phi[3]    phi[4]   phi[5]  phi[6]    phi[7]   phi[8] #> 1    0.29085   0.01876   0.00254   0.53359   0.7936   1.001  -0.00506  -0.1146 #> 2    0.27410  -0.00536  -0.00289  -0.08364   0.3323   0.916   0.00200   0.0479 #> 3    0.14191   0.00524  -0.00385   0.04266   0.5909   1.105   0.24897  -0.0465 #> 4    0.14230  -0.00688  -0.00775  -0.08325   0.2356   1.178  -0.06971  -0.0873 #> 5    0.06147  -0.08083  -0.01876  -0.01126   0.3633   0.905   0.01817  -0.0240 #> 6    0.01886   0.10961  -0.01871  -0.01531   0.0815   1.002   0.01369   0.0155 #> 7    0.06842  -0.01518  -0.04223   0.03511  -0.0854   1.007  -0.05042   0.0542 #> 8    0.10784  -0.00400  -0.02816  -0.00807  -0.1218   0.967  -0.04223  -0.0218 #> 9   -0.00779  -0.04138   0.03443  -0.00719  -0.0669   0.914  -0.02592   0.0282 #> 10  -0.05957  -0.04837   0.03679  -0.05329  -0.4538   0.989   0.49214   0.0819 #> # ... with 10 more draws, and 89 more variables #> # ... hidden reserved variables {'.chain', '.iteration', '.draw'}"},{"path":"/dev/articles/shrinkage.html","id":"dirichlet-laplace-prior","dir":"Articles","previous_headings":"Bayesian VAR and VHAR","what":"Dirichlet-Laplace prior","title":"Bayesian VAR and VHAR Models","text":"","code":"(fit_dl <- vhar_bayes(etf_train, num_chains = 2, num_iter = 20, coef_spec = set_dl(), cov_spec = set_ldlt(), include_mean = FALSE, minnesota = \"longrun\")) #> Call: #> vhar_bayes(y = etf_train, num_chains = 2, num_iter = 20, coef_spec = set_dl(),  #>     cov_spec = set_ldlt(), include_mean = FALSE, minnesota = \"longrun\") #>  #> BVHAR with DL prior + DL prior #> Fitted by Gibbs sampling #> Number of chains: 2 #> Total number of iteration: 20 #> Number of burn-in: 10 #> ==================================================== #>  #> Parameter Record: #> # A draws_df: 10 iterations, 2 chains, and 91 variables #>     phi[1]     phi[2]    phi[3]     phi[4]     phi[5]  phi[6]    phi[7] #> 1    0.475   0.054925   0.05211   0.295807   8.65e-03   1.040  -0.00754 #> 2    0.286  -0.011270   0.17011   0.472838   1.45e-02   1.052   0.11047 #> 3    0.485   0.020806  -0.00340   0.334332   2.32e-02   1.070   0.01431 #> 4    0.225  -0.021273   0.00787   0.252865  -1.52e-03   1.027  -0.09594 #> 5    0.410  -0.002813   0.04916  -0.049722  -5.29e-04   0.848   0.01767 #> 6    0.284   0.000958   0.32848  -0.000480  -2.06e-03   0.746   0.34579 #> 7    0.307  -0.000115   0.29406   0.001189   9.94e-04   1.205  -0.00690 #> 8    0.195  -0.003034   0.60744   0.000355  -6.74e-04   0.881   0.16946 #> 9    0.410  -0.059060   0.32520  -0.000557  -7.36e-05   1.019  -0.00190 #> 10   0.226  -0.043607   0.68878   0.152129  -7.01e-05   1.085   0.00128 #>        phi[8] #> 1   -5.57e-04 #> 2    2.48e-05 #> 3    1.35e-03 #> 4   -9.89e-03 #> 5    1.34e-01 #> 6    1.58e-02 #> 7    4.67e-02 #> 8    1.10e-02 #> 9   -1.41e-03 #> 10   1.43e-03 #> # ... with 10 more draws, and 83 more variables #> # ... hidden reserved variables {'.chain', '.iteration', '.draw'}"},{"path":"/dev/articles/shrinkage.html","id":"bayesian-visualization","dir":"Articles","previous_headings":"","what":"Bayesian visualization","title":"Bayesian VAR and VHAR Models","text":"autoplot() also provides Bayesian visualization. type = \"trace\" gives MCMC trace plot.  type = \"dens\" draws MCMC density plot. specifying additional argument facet_args = list(dir = \"v\") bayesplot, can see plot format coefficient matrix.","code":"autoplot(fit_hs, type = \"trace\", regex_pars = \"tau\") autoplot(fit_hs, type = \"dens\", regex_pars = \"kappa\", facet_args = list(dir = \"v\", nrow = nrow(fit_hs$coefficients)))"},{"path":"/dev/articles/stochastic-volatility.html","id":"models-with-stochastic-volatilities","dir":"Articles","previous_headings":"","what":"Models with Stochastic Volatilities","title":"Stochastic Volatility Models","text":"specifying cov_spec = set_sv(), var_bayes() vhar_bayes() fits VAR-SV VHAR-SV shrinkage priors, respectively. BVAR: set_bvar() BVHAR: set_bvhar() set_weight_bvhar() SSVS prior: set_ssvs() Horseshoe prior: set_horseshoe() NG prior: set_ng() DL prior: set_dl() sv_spec: prior settings SV, set_sv() intercept: prior constant term, set_intercept()","code":"set_sv() #> Model Specification for SV with Cholesky Prior #>  #> Parameters: Contemporaneous coefficients, State variance, Initial state #> Prior: Cholesky #> ======================================================== #> Setting for 'shape': #> [1]  rep(3, dim) #>  #> Setting for 'scale': #> [1]  rep(0.01, dim) #>  #> Setting for 'initial_mean': #> [1]  rep(1, dim) #>  #> Setting for 'initial_prec': #> [1]  0.1 * diag(dim)"},{"path":"/dev/articles/stochastic-volatility.html","id":"ssvs","dir":"Articles","previous_headings":"Models with Stochastic Volatilities","what":"SSVS","title":"Stochastic Volatility Models","text":"","code":"(fit_ssvs <- vhar_bayes(etf_train, num_chains = 2, num_iter = 20, coef_spec = set_ssvs(), cov_spec = set_sv(), include_mean = FALSE, minnesota = \"longrun\")) #> Call: #> vhar_bayes(y = etf_train, num_chains = 2, num_iter = 20, coef_spec = set_ssvs(),  #>     cov_spec = set_sv(), include_mean = FALSE, minnesota = \"longrun\") #>  #> BVHAR with Stochastic Volatility #> Fitted by Gibbs sampling #> Number of chains: 2 #> Total number of iteration: 20 #> Number of burn-in: 10 #> ==================================================== #>  #> Parameter Record: #> # A draws_df: 10 iterations, 2 chains, and 177 variables #>      phi[1]  phi[2]  phi[3]   phi[4]  phi[5]  phi[6]  phi[7]   phi[8] #> 1   -0.2809  -0.435  -0.132   0.0164   1.632  0.6737   1.506   0.4338 #> 2   -0.6398  -0.671  -1.804  -0.2749   2.726  1.4386   1.466   0.2481 #> 3   -0.1688  -0.194  -0.273   0.4175   1.932  0.5967   1.070  -0.0451 #> 4    0.0548  -0.344  -0.509   0.7781   0.789  0.1965   0.977  -0.1877 #> 5   -0.1710  -0.260  -1.072  -0.2136   2.007  0.2803  -0.482  -0.4731 #> 6   -0.0850  -0.251  -0.780   0.1651   1.843  0.0452  -0.751  -0.7045 #> 7   -0.4064  -0.299  -0.621   0.3135   1.570  0.6197   1.189   0.2086 #> 8   -0.1958  -0.306  -0.756  -0.0284   2.209  0.8177   0.786  -0.1558 #> 9   -0.4582  -0.509  -1.145  -0.1341   2.061  0.6314   0.395   0.0669 #> 10  -0.3015  -0.323  -1.456  -0.4003   2.746  0.1895   0.527  -0.3645 #> # ... with 10 more draws, and 169 more variables #> # ... hidden reserved variables {'.chain', '.iteration', '.draw'}"},{"path":"/dev/articles/stochastic-volatility.html","id":"horseshoe","dir":"Articles","previous_headings":"Models with Stochastic Volatilities","what":"Horseshoe","title":"Stochastic Volatility Models","text":"","code":"(fit_hs <- vhar_bayes(etf_train, num_chains = 2, num_iter = 20, coef_spec = set_horseshoe(), cov_spec = set_sv(), include_mean = FALSE, minnesota = \"longrun\")) #> Call: #> vhar_bayes(y = etf_train, num_chains = 2, num_iter = 20, coef_spec = set_horseshoe(),  #>     cov_spec = set_sv(), include_mean = FALSE, minnesota = \"longrun\") #>  #> BVHAR with Stochastic Volatility #> Fitted by Gibbs sampling #> Number of chains: 2 #> Total number of iteration: 20 #> Number of burn-in: 10 #> ==================================================== #>  #> Parameter Record: #> # A draws_df: 10 iterations, 2 chains, and 211 variables #>      phi[1]   phi[2]   phi[3]    phi[4]   phi[5]   phi[6]   phi[7]     phi[8] #> 1   -0.0304  -0.0309   0.4039  -0.04124  -0.1909   0.0206   0.0882   0.033078 #> 2    0.0177  -0.0218   0.1822   0.00925   0.9670  -0.0115   0.3481   0.247849 #> 3   -0.0891  -0.0189  -0.0337   0.01162   0.4190   0.0393   0.1657  -0.035753 #> 4   -0.1159  -0.0660  -0.1383  -0.05007   0.2089   0.4171  -0.1424   0.129915 #> 5   -0.1867  -0.0577  -0.1094   0.06793   0.0804   0.4281  -0.1954   0.067185 #> 6   -0.2408  -0.0842   0.0510  -0.08670   0.3418  -0.0325  -0.6220  -0.044931 #> 7   -0.2050  -0.1970  -0.0949  -0.58709   0.0457   0.3472  -0.5688   0.036126 #> 8   -0.1667  -0.0684   0.0127   0.37730  -0.1097  -0.0351  -0.7691  -0.055198 #> 9   -0.2836  -0.0533   0.1063  -0.06070   0.4966   0.1201  -0.3582   0.000847 #> 10  -0.0980  -0.1000   0.0668  -0.06924   0.2454   0.2899  -0.1129   0.055355 #> # ... with 10 more draws, and 203 more variables #> # ... hidden reserved variables {'.chain', '.iteration', '.draw'}"},{"path":"/dev/articles/stochastic-volatility.html","id":"normal-gamma-prior","dir":"Articles","previous_headings":"Models with Stochastic Volatilities","what":"Normal-Gamma prior","title":"Stochastic Volatility Models","text":"","code":"(fit_ng <- vhar_bayes(etf_train, num_chains = 2, num_iter = 20, coef_spec = set_ng(), cov_spec = set_sv(), include_mean = FALSE, minnesota = \"longrun\")) #> Call: #> vhar_bayes(y = etf_train, num_chains = 2, num_iter = 20, coef_spec = set_ng(),  #>     cov_spec = set_sv(), include_mean = FALSE, minnesota = \"longrun\") #>  #> BVHAR with Stochastic Volatility #> Fitted by Metropolis-within-Gibbs #> Number of chains: 2 #> Total number of iteration: 20 #> Number of burn-in: 10 #> ==================================================== #>  #> Parameter Record: #> # A draws_df: 10 iterations, 2 chains, and 184 variables #>     phi[1]   phi[2]   phi[3]   phi[4]    phi[5]  phi[6]    phi[7]    phi[8] #> 1   0.0163  -0.2097  -0.2567  -0.0240   1.18921  0.0884  -0.00159  -0.25690 #> 2   0.0638  -0.0326  -0.2059   0.0562   0.61534  0.0264   0.05115   0.02492 #> 3   0.0547  -0.1303   0.1697   0.1383  -0.20499  0.0158  -0.00102  -0.01696 #> 4   0.2011  -0.0707   0.3999  -0.2971  -0.57085  0.3386  -0.06278   0.00699 #> 5   0.0901  -0.0309  -0.0367  -0.1016  -0.04590  0.2839   0.17475   0.02876 #> 6   0.4087   0.0346   0.0456  -0.0183   0.01097  0.3827   0.00866   0.11522 #> 7   0.3760  -0.0289   0.0864   0.0130  -0.01013  0.3841   0.00161  -0.07671 #> 8   0.7592  -0.0359   0.3242   0.0197  -0.05092  0.4131   0.12073   0.16257 #> 9   0.3201  -0.0498   0.0851   0.0352   0.21481  0.5987  -0.10256  -0.06171 #> 10  0.2380  -0.0225   0.1437   0.0886   0.00587  0.5508  -0.26221  -0.37486 #> # ... with 10 more draws, and 176 more variables #> # ... hidden reserved variables {'.chain', '.iteration', '.draw'}"},{"path":"/dev/articles/stochastic-volatility.html","id":"dirichlet-laplace-prior","dir":"Articles","previous_headings":"Models with Stochastic Volatilities","what":"Dirichlet-Laplace prior","title":"Stochastic Volatility Models","text":"","code":"(fit_dl <- vhar_bayes(etf_train, num_chains = 2, num_iter = 20, coef_spec = set_dl(), cov_spec = set_sv(), include_mean = FALSE, minnesota = \"longrun\")) #> Call: #> vhar_bayes(y = etf_train, num_chains = 2, num_iter = 20, coef_spec = set_dl(),  #>     cov_spec = set_sv(), include_mean = FALSE, minnesota = \"longrun\") #>  #> BVHAR with Stochastic Volatility #> Fitted by Gibbs sampling #> Number of chains: 2 #> Total number of iteration: 20 #> Number of burn-in: 10 #> ==================================================== #>  #> Parameter Record: #> # A draws_df: 10 iterations, 2 chains, and 178 variables #>       phi[1]    phi[2]    phi[3]     phi[4]   phi[5]    phi[6]    phi[7] #> 1    0.00748   0.13291   0.04639   0.011642   0.2212   0.01788   0.24556 #> 2   -0.02351  -0.07930   0.01324  -0.008135   0.6338  -0.01306  -0.06538 #> 3   -0.00167  -0.03925   0.02584  -0.005772  -0.3211  -0.00127   0.11515 #> 4   -0.01316  -0.01056   0.06144  -0.002228  -0.4073   0.00070  -0.14095 #> 5   -0.01329  -0.00228  -0.00488  -0.001493  -0.1545  -0.00529   0.03903 #> 6    0.00558  -0.01154  -0.03222  -0.003665  -0.0167   0.02611   0.03366 #> 7    0.06363  -0.00909  -0.02406   0.000727   0.1396   0.09105  -0.00148 #> 8   -0.22652   0.03128   0.13404   0.000510  -0.1946   0.00773   0.00545 #> 9    0.10193  -0.10966   0.00554  -0.000764   0.2897   0.00304  -0.00380 #> 10   0.04194   0.00683  -0.00989  -0.000337   0.0232   0.00636   0.01094 #>        phi[8] #> 1    0.005781 #> 2   -0.034383 #> 3    0.020210 #> 4   -0.062570 #> 5    0.025049 #> 6   -0.021208 #> 7    0.005351 #> 8   -0.000236 #> 9    0.003069 #> 10   0.000639 #> # ... with 10 more draws, and 170 more variables #> # ... hidden reserved variables {'.chain', '.iteration', '.draw'}"},{"path":"/dev/articles/stochastic-volatility.html","id":"bayesian-visualization","dir":"Articles","previous_headings":"Models with Stochastic Volatilities","what":"Bayesian visualization","title":"Stochastic Volatility Models","text":"autoplot() also provides Bayesian visualization. type = \"trace\" gives MCMC trace plot.  type = \"dens\" draws MCMC density plot.","code":"autoplot(fit_hs, type = \"trace\", regex_pars = \"tau\") autoplot(fit_hs, type = \"dens\", regex_pars = \"tau\")"},{"path":"/dev/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Young Geun Kim. Author, maintainer, copyright holder. Changryong Baek. Contributor.","code":""},{"path":"/dev/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Kim Y, Baek C (2023). bvhar: Bayesian Vector Heterogeneous Autoregressive Modeling. doi:10.32614/CRAN.package.bvhar, R package version 2.2.2.9011, https://cran.r-project.org/package=bvhar. Kim Y, Baek C (2024). ‚ÄúBayesian Vector Heterogeneous Autoregressive Modeling.‚Äù Journal Statistical Computation Simulation, 94(6), 1139‚Äì1157. doi:10.1080/00949655.2023.2281644.","code":"@Manual{,   title = {{bvhar}: Bayesian Vector Heterogeneous Autoregressive Modeling},   author = {Young Geun Kim and Changryong Baek},   year = {2023},   doi = {10.32614/CRAN.package.bvhar},   note = {R package version 2.2.2.9011},   url = {https://cran.r-project.org/package=bvhar}, } @Article{,   title = {Bayesian Vector Heterogeneous Autoregressive Modeling},   author = {Young Geun Kim and Changryong Baek},   journal = {Journal of Statistical Computation and Simulation},   year = {2024},   volume = {94},   number = {6},   pages = {1139--1157},   doi = {10.1080/00949655.2023.2281644}, }"},{"path":[]},{"path":"/dev/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Bayesian Vector Heterogeneous Autoregressive Modeling","text":"bvhar provides functions analyze forecast multivariate time series using VAR VHAR (Vector HAR) BVAR (Bayesian VAR) BVHAR (Bayesian VHAR) Basically, package focuses research forecasting.","code":""},{"path":"/dev/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Bayesian Vector Heterogeneous Autoregressive Modeling","text":"","code":"install.packages(\"bvhar\")"},{"path":"/dev/index.html","id":"development-version","dir":"","previous_headings":"Installation","what":"Development version","title":"Bayesian Vector Heterogeneous Autoregressive Modeling","text":"can install development version develop branch. started develop Python version python directory. bvhar Python Source code","code":"# install.packages(\"remotes\") remotes::install_github(\"ygeunkim/bvhar@develop\")"},{"path":"/dev/index.html","id":"models","dir":"","previous_headings":"","what":"Models","title":"Bayesian Vector Heterogeneous Autoregressive Modeling","text":"Repeatedly, bvhar research tool analyze multivariate time series model readme document shows forecasting procedure briefly. Details function vignettes help documents. Note bvar_minnesota() bvhar_minnesota() integrated var_bayes() vhar_bayes() removed near future. h-step ahead forecasting:","code":"library(bvhar) # this package library(dplyr) h <- 19 etf_split <- divide_ts(etf_vix, h) # Try ?divide_ts etf_tr <- etf_split$train etf_te <- etf_split$test"},{"path":"/dev/index.html","id":"var","dir":"","previous_headings":"Models","what":"VAR","title":"Bayesian Vector Heterogeneous Autoregressive Modeling","text":"VAR(5): Forecasting: MSE:","code":"mod_var <- var_lm(y = etf_tr, p = 5) forecast_var <- predict(mod_var, h) (msevar <- mse(forecast_var, etf_te)) #>   GVZCLS   OVXCLS VXFXICLS VXEEMCLS VXSLVCLS   EVZCLS VXXLECLS VXGDXCLS  #>    5.381   14.689    2.838    9.451   10.078    0.654   22.436    9.992  #> VXEWZCLS  #>   10.647"},{"path":"/dev/index.html","id":"vhar","dir":"","previous_headings":"Models","what":"VHAR","title":"Bayesian Vector Heterogeneous Autoregressive Modeling","text":"MSE:","code":"mod_vhar <- vhar_lm(y = etf_tr) forecast_vhar <- predict(mod_vhar, h) (msevhar <- mse(forecast_vhar, etf_te)) #>   GVZCLS   OVXCLS VXFXICLS VXEEMCLS VXSLVCLS   EVZCLS VXXLECLS VXGDXCLS  #>     6.15     2.49     1.52     1.58    10.55     1.35     8.79     4.43  #> VXEWZCLS  #>     3.84"},{"path":"/dev/index.html","id":"bvar","dir":"","previous_headings":"Models","what":"BVAR","title":"Bayesian Vector Heterogeneous Autoregressive Modeling","text":"Minnesota prior: MSE:","code":"lam <- .3 delta <- rep(1, ncol(etf_vix)) # litterman sig <- apply(etf_tr, 2, sd) eps <- 1e-04 (bvar_spec <- set_bvar(sig, lam, delta, eps)) #> Model Specification for BVAR #>  #> Parameters: Coefficent matrice and Covariance matrix #> Prior: Minnesota #> ======================================================== #>  #> Setting for 'sigma': #>   GVZCLS    OVXCLS  VXFXICLS  VXEEMCLS  VXSLVCLS    EVZCLS  VXXLECLS  VXGDXCLS   #>     3.77     10.63      3.81      4.39      5.99      2.27      4.88      7.45   #> VXEWZCLS   #>     7.03   #>  #> Setting for 'lambda': #> [1]  0.3 #>  #> Setting for 'delta': #> [1]  1  1  1  1  1  1  1  1  1 #>  #> Setting for 'eps': #> [1]  1e-04 #>  #> Setting for 'hierarchical': #> [1]  FALSE mod_bvar <- bvar_minnesota(y = etf_tr, p = 5, bayes_spec = bvar_spec) forecast_bvar <- predict(mod_bvar, h) (msebvar <- mse(forecast_bvar, etf_te)) #>   GVZCLS   OVXCLS VXFXICLS VXEEMCLS VXSLVCLS   EVZCLS VXXLECLS VXGDXCLS  #>    4.651   13.248    1.845   10.356    9.894    0.667   21.040    6.262  #> VXEWZCLS  #>    8.864"},{"path":"/dev/index.html","id":"bvhar","dir":"","previous_headings":"Models","what":"BVHAR","title":"Bayesian Vector Heterogeneous Autoregressive Modeling","text":"BVHAR-S: MSE: BVHAR-L: MSE:","code":"(bvhar_spec_v1 <- set_bvhar(sig, lam, delta, eps)) #> Model Specification for BVHAR #>  #> Parameters: Coefficent matrice and Covariance matrix #> Prior: MN_VAR #> ======================================================== #>  #> Setting for 'sigma': #>   GVZCLS    OVXCLS  VXFXICLS  VXEEMCLS  VXSLVCLS    EVZCLS  VXXLECLS  VXGDXCLS   #>     3.77     10.63      3.81      4.39      5.99      2.27      4.88      7.45   #> VXEWZCLS   #>     7.03   #>  #> Setting for 'lambda': #> [1]  0.3 #>  #> Setting for 'delta': #> [1]  1  1  1  1  1  1  1  1  1 #>  #> Setting for 'eps': #> [1]  1e-04 #>  #> Setting for 'hierarchical': #> [1]  FALSE mod_bvhar_v1 <- bvhar_minnesota(y = etf_tr, bayes_spec = bvhar_spec_v1) forecast_bvhar_v1 <- predict(mod_bvhar_v1, h) (msebvhar_v1 <- mse(forecast_bvhar_v1, etf_te)) #>   GVZCLS   OVXCLS VXFXICLS VXEEMCLS VXSLVCLS   EVZCLS VXXLECLS VXGDXCLS  #>    3.199    6.067    1.471    5.142    5.946    0.878   12.165    2.553  #> VXEWZCLS  #>    6.462 day <- rep(.1, ncol(etf_vix)) week <- rep(.1, ncol(etf_vix)) month <- rep(.1, ncol(etf_vix)) #---------------------------------- (bvhar_spec_v2 <- set_weight_bvhar(sig, lam, eps, day, week, month)) #> Model Specification for BVHAR #>  #> Parameters: Coefficent matrice and Covariance matrix #> Prior: MN_VHAR #> ======================================================== #>  #> Setting for 'sigma': #>   GVZCLS    OVXCLS  VXFXICLS  VXEEMCLS  VXSLVCLS    EVZCLS  VXXLECLS  VXGDXCLS   #>     3.77     10.63      3.81      4.39      5.99      2.27      4.88      7.45   #> VXEWZCLS   #>     7.03   #>  #> Setting for 'lambda': #> [1]  0.3 #>  #> Setting for 'eps': #> [1]  1e-04 #>  #> Setting for 'daily': #> [1]  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1 #>  #> Setting for 'weekly': #> [1]  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1 #>  #> Setting for 'monthly': #> [1]  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1 #>  #> Setting for 'hierarchical': #> [1]  FALSE mod_bvhar_v2 <- bvhar_minnesota(y = etf_tr, bayes_spec = bvhar_spec_v2) forecast_bvhar_v2 <- predict(mod_bvhar_v2, h) (msebvhar_v2 <- mse(forecast_bvhar_v2, etf_te)) #>   GVZCLS   OVXCLS VXFXICLS VXEEMCLS VXSLVCLS   EVZCLS VXXLECLS VXGDXCLS  #>     3.63     3.85     1.64     5.12     5.75     1.08    13.60     2.58  #> VXEWZCLS  #>     5.54"},{"path":"/dev/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Bayesian Vector Heterogeneous Autoregressive Modeling","text":"Please cite package following BibTeX:","code":"@Manual{,   title = {{bvhar}: Bayesian Vector Heterogeneous Autoregressive Modeling},   author = {Young Geun Kim and Changryong Baek},   year = {2023},   doi = {10.32614/CRAN.package.bvhar},   note = {R package version 2.2.2},   url = {https://cran.r-project.org/package=bvhar}, }  @Article{,   title = {Bayesian Vector Heterogeneous Autoregressive Modeling},   author = {Young Geun Kim and Changryong Baek},   journal = {Journal of Statistical Computation and Simulation},   year = {2024},   volume = {94},   number = {6},   pages = {1139--1157},   doi = {10.1080/00949655.2023.2281644}, }"},{"path":"/dev/index.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Bayesian Vector Heterogeneous Autoregressive Modeling","text":"Please note bvhar project released Contributor Code Conduct. contributing project, agree abide terms.","code":""},{"path":"/dev/reference/FPE.html","id":null,"dir":"Reference","previous_headings":"","what":"Final Prediction Error Criterion ‚Äî FPE","title":"Final Prediction Error Criterion ‚Äî FPE","text":"Compute FPE VAR(p) VHAR","code":""},{"path":"/dev/reference/FPE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Final Prediction Error Criterion ‚Äî FPE","text":"","code":"FPE(object, ...)  # S3 method for class 'varlse' FPE(object, ...)  # S3 method for class 'vharlse' FPE(object, ...)"},{"path":"/dev/reference/FPE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Final Prediction Error Criterion ‚Äî FPE","text":"object Model fit ... used","code":""},{"path":"/dev/reference/FPE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Final Prediction Error Criterion ‚Äî FPE","text":"FPE value.","code":""},{"path":"/dev/reference/FPE.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Final Prediction Error Criterion ‚Äî FPE","text":"Let \\(\\tilde{\\Sigma}_e\\) MLE let \\(\\hat{\\Sigma}_e\\) unbiased estimator (covmat) \\(\\Sigma_e\\). Note $$\\tilde{\\Sigma}_e = \\frac{n - k}{T} \\hat{\\Sigma}_e$$ $$FPE(p) = (\\frac{n + k}{n - k})^m \\det \\tilde{\\Sigma}_e$$","code":""},{"path":"/dev/reference/FPE.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Final Prediction Error Criterion ‚Äî FPE","text":"L√ºtkepohl, H. (2007). New Introduction Multiple Time Series Analysis. Springer Publishing.","code":""},{"path":"/dev/reference/HQ.html","id":null,"dir":"Reference","previous_headings":"","what":"Hannan-Quinn Criterion ‚Äî HQ","title":"Hannan-Quinn Criterion ‚Äî HQ","text":"Compute HQ VAR(p), VHAR, BVAR(p), BVHAR","code":""},{"path":"/dev/reference/HQ.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hannan-Quinn Criterion ‚Äî HQ","text":"","code":"HQ(object, ...)  # S3 method for class 'logLik' HQ(object, ...)  # S3 method for class 'varlse' HQ(object, ...)  # S3 method for class 'vharlse' HQ(object, ...)  # S3 method for class 'bvarmn' HQ(object, ...)  # S3 method for class 'bvarflat' HQ(object, ...)  # S3 method for class 'bvharmn' HQ(object, ...)"},{"path":"/dev/reference/HQ.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hannan-Quinn Criterion ‚Äî HQ","text":"object logLik object Model fit ... used","code":""},{"path":"/dev/reference/HQ.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hannan-Quinn Criterion ‚Äî HQ","text":"HQ value.","code":""},{"path":"/dev/reference/HQ.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Hannan-Quinn Criterion ‚Äî HQ","text":"formula $$HQ = -2 \\log p(y \\mid \\hat\\theta) + k \\log\\log(T)$$ can computed AIC(object, ..., k = 2 * log(log(nobs(object)))) stats::AIC(). Let \\(\\tilde{\\Sigma}_e\\) MLE let \\(\\hat{\\Sigma}_e\\) unbiased estimator (covmat) \\(\\Sigma_e\\). Note $$\\tilde{\\Sigma}_e = \\frac{n - k}{T} \\hat{\\Sigma}_e$$ $$HQ(p) = \\log \\det \\Sigma_e + \\frac{2 \\log \\log n}{n}(\\text{number freely estimated parameters})$$ number freely estimated parameters \\(pm^2\\).","code":""},{"path":"/dev/reference/HQ.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Hannan-Quinn Criterion ‚Äî HQ","text":"Hannan, E.J. Quinn, B.G. (1979). Determination Order Autoregression. Journal Royal Statistical Society: Series B (Methodological), 41: 190-195. Hannan, E.J. Quinn, B.G. (1979). Determination Order Autoregression. Journal Royal Statistical Society: Series B (Methodological), 41: 190-195. L√ºtkepohl, H. (2007). New Introduction Multiple Time Series Analysis. Springer Publishing. Quinn, B.G. (1980). Order Determination Multivariate Autoregression. Journal Royal Statistical Society: Series B (Methodological), 42: 182-185.","code":""},{"path":"/dev/reference/VARtoVMA.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert VAR to VMA(infinite) ‚Äî VARtoVMA","title":"Convert VAR to VMA(infinite) ‚Äî VARtoVMA","text":"Convert VAR process infinite vector MA process","code":""},{"path":"/dev/reference/VARtoVMA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert VAR to VMA(infinite) ‚Äî VARtoVMA","text":"","code":"VARtoVMA(object, lag_max)"},{"path":"/dev/reference/VARtoVMA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert VAR to VMA(infinite) ‚Äî VARtoVMA","text":"object varlse object lag_max Maximum lag VMA","code":""},{"path":"/dev/reference/VARtoVMA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert VAR to VMA(infinite) ‚Äî VARtoVMA","text":"VMA coefficient k(lag-max + 1) x k dimension","code":""},{"path":"/dev/reference/VARtoVMA.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert VAR to VMA(infinite) ‚Äî VARtoVMA","text":"Let VAR(p) stable. $$Y_t = c + \\sum_{j = 0} W_j Z_{t - j}$$ VAR coefficient \\(B_1, B_2, \\ldots, B_p\\), $$= (W_0 + W_1 L + W_2 L^2 + \\cdots + ) (- B_1 L - B_2 L^2 - \\cdots - B_p L^p)$$ Recursively, $$W_0 = $$ $$W_1 = W_0 B_1 (W_1^T = B_1^T W_0^T)$$ $$W_2 = W_1 B_1 + W_0 B_2 (W_2^T = B_1^T W_1^T + B_2^T W_0^T)$$ $$W_j = \\sum_{j = 1}^k W_{k - j} B_j (W_j^T = \\sum_{j = 1}^k B_j^T W_{k - j}^T)$$","code":""},{"path":"/dev/reference/VARtoVMA.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Convert VAR to VMA(infinite) ‚Äî VARtoVMA","text":"L√ºtkepohl, H. (2007). New Introduction Multiple Time Series Analysis. Springer Publishing.","code":""},{"path":"/dev/reference/VHARtoVMA.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert VHAR to VMA(infinite) ‚Äî VHARtoVMA","title":"Convert VHAR to VMA(infinite) ‚Äî VHARtoVMA","text":"Convert VHAR process infinite vector MA process","code":""},{"path":"/dev/reference/VHARtoVMA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert VHAR to VMA(infinite) ‚Äî VHARtoVMA","text":"","code":"VHARtoVMA(object, lag_max)"},{"path":"/dev/reference/VHARtoVMA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert VHAR to VMA(infinite) ‚Äî VHARtoVMA","text":"object vharlse object lag_max Maximum lag VMA","code":""},{"path":"/dev/reference/VHARtoVMA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert VHAR to VMA(infinite) ‚Äî VHARtoVMA","text":"VMA coefficient k(lag-max + 1) x k dimension","code":""},{"path":"/dev/reference/VHARtoVMA.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert VHAR to VMA(infinite) ‚Äî VHARtoVMA","text":"Let VAR(p) stable let VAR(p) \\(Y_0 = X_0 B + Z\\) VHAR VAR(22) $$Y_0 = X_1 B + Z = ((X_0 \\tilde{T}^T)) \\Phi + Z$$ Observe $$B = \\tilde{T}^T \\Phi$$","code":""},{"path":"/dev/reference/VHARtoVMA.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Convert VHAR to VMA(infinite) ‚Äî VHARtoVMA","text":"L√ºtkepohl, H. (2007). New Introduction Multiple Time Series Analysis. Springer Publishing.","code":""},{"path":"/dev/reference/alpl.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Density Forecast Based on Average Log Predictive Likelihood (APLP) ‚Äî alpl","title":"Evaluate the Density Forecast Based on Average Log Predictive Likelihood (APLP) ‚Äî alpl","text":"function computes ALPL given forecasting Bayesian models.","code":""},{"path":"/dev/reference/alpl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Density Forecast Based on Average Log Predictive Likelihood (APLP) ‚Äî alpl","text":"","code":"alpl(x, ...)  # S3 method for class 'bvharcv' alpl(x, ...)"},{"path":"/dev/reference/alpl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Density Forecast Based on Average Log Predictive Likelihood (APLP) ‚Äî alpl","text":"x --sample forecasting object use ... used","code":""},{"path":"/dev/reference/autoplot.bvhardynsp.html","id":null,"dir":"Reference","previous_headings":"","what":"Dynamic Spillover Indices Plot ‚Äî autoplot.bvhardynsp","title":"Dynamic Spillover Indices Plot ‚Äî autoplot.bvhardynsp","text":"Draws dynamic directional spillover plot.","code":""},{"path":"/dev/reference/autoplot.bvhardynsp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dynamic Spillover Indices Plot ‚Äî autoplot.bvhardynsp","text":"","code":"# S3 method for class 'bvhardynsp' autoplot(   object,   type = c(\"tot\", \"to\", \"from\", \"net\"),   hcol = \"grey\",   hsize = 1.5,   row_facet = NULL,   col_facet = NULL,   ... )"},{"path":"/dev/reference/autoplot.bvhardynsp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dynamic Spillover Indices Plot ‚Äî autoplot.bvhardynsp","text":"object bvhardynsp object type Index draw hcol color horizontal line = 0 (default, grey) hsize size horizontal line = 0 (default, 1.5) row_facet nrow ggplot2::facet_wrap() col_facet ncol ggplot2::facet_wrap() ... Additional","code":""},{"path":"/dev/reference/autoplot.bvharirf.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Impulse Responses ‚Äî autoplot.bvharirf","title":"Plot Impulse Responses ‚Äî autoplot.bvharirf","text":"Draw impulse responses response ~ impulse facet.","code":""},{"path":"/dev/reference/autoplot.bvharirf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Impulse Responses ‚Äî autoplot.bvharirf","text":"","code":"# S3 method for class 'bvharirf' autoplot(object, ...)"},{"path":"/dev/reference/autoplot.bvharirf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Impulse Responses ‚Äî autoplot.bvharirf","text":"object bvharirf object ... arguments passed ggplot2::geom_path().","code":""},{"path":"/dev/reference/autoplot.bvharirf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Impulse Responses ‚Äî autoplot.bvharirf","text":"ggplot object","code":""},{"path":[]},{"path":"/dev/reference/autoplot.bvharsp.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the Result of BVAR and BVHAR MCMC ‚Äî autoplot.bvharsp","title":"Plot the Result of BVAR and BVHAR MCMC ‚Äî autoplot.bvharsp","text":"Draw BVAR BVHAR MCMC plots.","code":""},{"path":"/dev/reference/autoplot.bvharsp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the Result of BVAR and BVHAR MCMC ‚Äî autoplot.bvharsp","text":"","code":"# S3 method for class 'bvharsp' autoplot(   object,   type = c(\"coef\", \"trace\", \"dens\", \"area\"),   pars = character(),   regex_pars = character(),   ... )"},{"path":"/dev/reference/autoplot.bvharsp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the Result of BVAR and BVHAR MCMC ‚Äî autoplot.bvharsp","text":"object bvharsp object type type plot. Posterior coefficient (coef), Trace plot (trace), kernel density plot (dens), interval estimates plot (area). pars Parameter names draw. regex_pars Regular expression parameter names draw. ... options bayesplot::mcmc_trace(), bayesplot::mcmc_dens(), bayesplot::mcmc_areas().","code":""},{"path":"/dev/reference/autoplot.bvharsp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot the Result of BVAR and BVHAR MCMC ‚Äî autoplot.bvharsp","text":"ggplot object","code":""},{"path":"/dev/reference/autoplot.normaliw.html","id":null,"dir":"Reference","previous_headings":"","what":"Residual Plot for Minnesota Prior VAR Model ‚Äî autoplot.normaliw","title":"Residual Plot for Minnesota Prior VAR Model ‚Äî autoplot.normaliw","text":"function draws residual plot covariance matrix Minnesota prior VAR model.","code":""},{"path":"/dev/reference/autoplot.normaliw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Residual Plot for Minnesota Prior VAR Model ‚Äî autoplot.normaliw","text":"","code":"# S3 method for class 'normaliw' autoplot(object, hcol = \"grey\", hsize = 1.5, ...)"},{"path":"/dev/reference/autoplot.normaliw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Residual Plot for Minnesota Prior VAR Model ‚Äî autoplot.normaliw","text":"object normaliw object hcol color horizontal line = 0 (default, grey) hsize size horizontal line = 0 (default, 1.5) ... additional options geom_point","code":""},{"path":"/dev/reference/autoplot.normaliw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Residual Plot for Minnesota Prior VAR Model ‚Äî autoplot.normaliw","text":"ggplot object","code":""},{"path":"/dev/reference/autoplot.predbvhar.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Forecast Result ‚Äî autoplot.predbvhar","title":"Plot Forecast Result ‚Äî autoplot.predbvhar","text":"Plots forecasting result forecast regions.","code":""},{"path":"/dev/reference/autoplot.predbvhar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Forecast Result ‚Äî autoplot.predbvhar","text":"","code":"# S3 method for class 'predbvhar' autoplot(   object,   type = c(\"grid\", \"wrap\"),   ci_alpha = 0.7,   alpha_scale = 0.3,   x_cut = 1,   viridis = FALSE,   viridis_option = \"D\",   NROW = NULL,   NCOL = NULL,   ... )  # S3 method for class 'predbvhar' autolayer(object, ci_fill = \"grey70\", ci_alpha = 0.5, alpha_scale = 0.3, ...)"},{"path":"/dev/reference/autoplot.predbvhar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Forecast Result ‚Äî autoplot.predbvhar","text":"object predbvhar object type Divide variables using ggplot2::facet_grid() (\"grid\": default) ggplot2::facet_wrap() (\"wrap\") ci_alpha Transparency CI alpha_scale Scale transparency parameter (alpha) two layers. alpha CI ribbon = alpha_scale * alpha path (default, .5) x_cut plot x axes x_cut visibility viridis TRUE, scale CI forecast line using ggplot2::scale_fill_viridis_d() ggplot2::scale_colour_viridis_d, respectively. viridis_option Option viridis string. See option ggplot2::scale_colour_viridis_d. Choose one c(\"\", \"B\", \"C\", \"D\", \"E\"). default, D. NROW nrow ggplot2::facet_wrap() NCOL ncol ggplot2::facet_wrap() ... additional option ggplot2::geom_path() ci_fill color CI","code":""},{"path":"/dev/reference/autoplot.predbvhar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Forecast Result ‚Äî autoplot.predbvhar","text":"ggplot object ggplot layer","code":""},{"path":"/dev/reference/autoplot.summary.bvharsp.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the Heatmap of SSVS Coefficients ‚Äî autoplot.summary.bvharsp","title":"Plot the Heatmap of SSVS Coefficients ‚Äî autoplot.summary.bvharsp","text":"Draw heatmap SSVS prior coefficients.","code":""},{"path":"/dev/reference/autoplot.summary.bvharsp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the Heatmap of SSVS Coefficients ‚Äî autoplot.summary.bvharsp","text":"","code":"# S3 method for class 'summary.bvharsp' autoplot(object, point = FALSE, ...)"},{"path":"/dev/reference/autoplot.summary.bvharsp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the Heatmap of SSVS Coefficients ‚Äî autoplot.summary.bvharsp","text":"object summary.bvharsp object point Use point sparsity representation ... arguments passed ggplot2::geom_tile().","code":""},{"path":"/dev/reference/autoplot.summary.bvharsp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot the Heatmap of SSVS Coefficients ‚Äî autoplot.summary.bvharsp","text":"ggplot object","code":""},{"path":"/dev/reference/autoplot.summary.normaliw.html","id":null,"dir":"Reference","previous_headings":"","what":"Density Plot for Minnesota Prior VAR Model ‚Äî autoplot.summary.normaliw","title":"Density Plot for Minnesota Prior VAR Model ‚Äî autoplot.summary.normaliw","text":"function draws density plot coefficient matrices Minnesota prior VAR model.","code":""},{"path":"/dev/reference/autoplot.summary.normaliw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Density Plot for Minnesota Prior VAR Model ‚Äî autoplot.summary.normaliw","text":"","code":"# S3 method for class 'summary.normaliw' autoplot(   object,   type = c(\"trace\", \"dens\", \"area\"),   pars = character(),   regex_pars = character(),   ... )"},{"path":"/dev/reference/autoplot.summary.normaliw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Density Plot for Minnesota Prior VAR Model ‚Äî autoplot.summary.normaliw","text":"object summary.normaliw object type type plot. Trace plot (trace), kernel density plot (dens), interval estimates plot (area). pars Parameter names draw. regex_pars Regular expression parameter names draw. ... options bayesplot::mcmc_trace(), bayesplot::mcmc_dens(), bayesplot::mcmc_areas().","code":""},{"path":"/dev/reference/autoplot.summary.normaliw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Density Plot for Minnesota Prior VAR Model ‚Äî autoplot.summary.normaliw","text":"ggplot object","code":""},{"path":"/dev/reference/bound_bvhar.html","id":null,"dir":"Reference","previous_headings":"","what":"Setting Empirical Bayes Optimization Bounds ‚Äî bound_bvhar","title":"Setting Empirical Bayes Optimization Bounds ‚Äî bound_bvhar","text":"function sets lower upper bounds set_bvar(), set_bvhar(), set_weight_bvhar().","code":""},{"path":"/dev/reference/bound_bvhar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Setting Empirical Bayes Optimization Bounds ‚Äî bound_bvhar","text":"","code":"bound_bvhar(   init_spec = set_bvhar(),   lower_spec = set_bvhar(),   upper_spec = set_bvhar() )  # S3 method for class 'boundbvharemp' print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  is.boundbvharemp(x)  # S3 method for class 'boundbvharemp' knit_print(x, ...)"},{"path":"/dev/reference/bound_bvhar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Setting Empirical Bayes Optimization Bounds ‚Äî bound_bvhar","text":"init_spec Initial Bayes model specification lower_spec Lower bound Bayes model specification upper_spec Upper bound Bayes model specification x object digits digit option print ... used","code":""},{"path":"/dev/reference/bound_bvhar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Setting Empirical Bayes Optimization Bounds ‚Äî bound_bvhar","text":"boundbvharemp class","code":""},{"path":"/dev/reference/bvar_flat.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting Bayesian VAR(p) of Flat Prior ‚Äî bvar_flat","title":"Fitting Bayesian VAR(p) of Flat Prior ‚Äî bvar_flat","text":"function fits BVAR(p) flat prior.","code":""},{"path":"/dev/reference/bvar_flat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting Bayesian VAR(p) of Flat Prior ‚Äî bvar_flat","text":"","code":"bvar_flat(   y,   p,   num_chains = 1,   num_iter = 1000,   num_burn = floor(num_iter/2),   thinning = 1,   bayes_spec = set_bvar_flat(),   include_mean = TRUE,   verbose = FALSE,   num_thread = 1 )  # S3 method for class 'bvarflat' print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  # S3 method for class 'bvarflat' logLik(object, ...)  # S3 method for class 'bvarflat' AIC(object, ...)  # S3 method for class 'bvarflat' BIC(object, ...)  is.bvarflat(x)  # S3 method for class 'bvarflat' knit_print(x, ...)"},{"path":"/dev/reference/bvar_flat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting Bayesian VAR(p) of Flat Prior ‚Äî bvar_flat","text":"y Time series data columns indicate variables p VAR lag num_chains Number MCMC chains num_iter MCMC iteration number num_burn Number burn-(warm-). Half iteration default choice. thinning Thinning every thinning-th iteration bayes_spec BVAR model specification set_bvar_flat(). include_mean Add constant term (Default: TRUE) (FALSE) verbose Print progress bar console. default, FALSE. num_thread Number threads x object digits digit option print ... used object bvarflat object","code":""},{"path":"/dev/reference/bvar_flat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting Bayesian VAR(p) of Flat Prior ‚Äî bvar_flat","text":"bvar_flat() returns object bvarflat class. list following components: coefficients Posterior Mean matrix Matrix Normal distribution fitted.values Fitted values residuals Residuals mn_prec Posterior precision matrix Matrix Normal distribution iw_scale Posterior scale matrix posterior inverse-wishart distribution iw_shape Posterior shape inverse-wishart distribution df Numer Coefficients: mp + 1 mp p Lag VAR m Dimension time series obs Sample size used training = totobs - p totobs Total number observation process Process string bayes_spec: BVAR_Flat spec Model specification (bvharspec) type include constant term (const) (none) call Matched call prior_mean Prior mean matrix Matrix Normal distribution: zero matrix prior_precision Prior precision matrix Matrix Normal distribution: \\(U^{-1}\\) y0 \\(Y_0\\) design \\(X_0\\) y Raw input (matrix)","code":""},{"path":"/dev/reference/bvar_flat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting Bayesian VAR(p) of Flat Prior ‚Äî bvar_flat","text":"Ghosh et al. (2018) gives flat prior residual matrix BVAR. setting, many models hierarchical non-hierarchical. function chooses simple non-hierarchical matrix normal prior Section 3.1. $$\\mid \\Sigma_e \\sim MN(0, U^{-1}, \\Sigma_e)$$ U: precision matrix (MN: matrix normal). $$p (\\Sigma_e) \\propto 1$$","code":""},{"path":"/dev/reference/bvar_flat.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting Bayesian VAR(p) of Flat Prior ‚Äî bvar_flat","text":"Ghosh, S., Khare, K., & Michailidis, G. (2018). High-Dimensional Posterior Consistency Bayesian Vector Autoregressive Models. Journal American Statistical Association, 114(526). Litterman, R. B. (1986). Forecasting Bayesian Vector Autoregressions: Five Years Experience. Journal Business & Economic Statistics, 4(1), 25.","code":""},{"path":[]},{"path":"/dev/reference/bvar_minnesota.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting Bayesian VAR(p) of Minnesota Prior ‚Äî bvar_minnesota","title":"Fitting Bayesian VAR(p) of Minnesota Prior ‚Äî bvar_minnesota","text":"function fits BVAR(p) Minnesota prior.","code":""},{"path":"/dev/reference/bvar_minnesota.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting Bayesian VAR(p) of Minnesota Prior ‚Äî bvar_minnesota","text":"","code":"bvar_minnesota(   y,   p = 1,   num_chains = 1,   num_iter = 1000,   num_burn = floor(num_iter/2),   thinning = 1,   bayes_spec = set_bvar(),   scale_variance = 0.05,   include_mean = TRUE,   parallel = list(),   verbose = FALSE,   num_thread = 1 )  # S3 method for class 'bvarmn' print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  # S3 method for class 'bvarhm' print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  # S3 method for class 'bvarmn' logLik(object, ...)  # S3 method for class 'bvarmn' AIC(object, ...)  # S3 method for class 'bvarmn' BIC(object, ...)  is.bvarmn(x)  # S3 method for class 'bvarmn' knit_print(x, ...)  # S3 method for class 'bvarhm' knit_print(x, ...)"},{"path":"/dev/reference/bvar_minnesota.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting Bayesian VAR(p) of Minnesota Prior ‚Äî bvar_minnesota","text":"y Time series data columns indicate variables p VAR lag (Default: 1) num_chains Number MCMC chains num_iter MCMC iteration number num_burn Number burn-(warm-). Half iteration default choice. thinning Thinning every thinning-th iteration bayes_spec BVAR model specification set_bvar(). scale_variance Proposal distribution scaling constant adjust acceptance rate include_mean Add constant term (Default: TRUE) (FALSE) parallel List argument optimParallel::optimParallel(). default, empty, function execute parallel computation. verbose Print progress bar console. default, FALSE. num_thread Number threads x object digits digit option print ... used object bvarmn object","code":""},{"path":"/dev/reference/bvar_minnesota.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting Bayesian VAR(p) of Minnesota Prior ‚Äî bvar_minnesota","text":"bvar_minnesota() returns object bvarmn class. list following components: coefficients Posterior Mean fitted.values Fitted values residuals Residuals mn_mean Posterior mean matrix Matrix Normal distribution mn_prec Posterior precision matrix Matrix Normal distribution iw_scale Posterior scale matrix posterior inverse-Wishart distribution iw_shape Posterior shape inverse-Wishart distribution (\\(alpha_0\\) - obs + 2). \\(\\alpha_0\\): nrow(Dummy observation) - k df Numer Coefficients: mp + 1 mp m Dimension time series obs Sample size used training = totobs - p prior_mean Prior mean matrix Matrix Normal distribution: \\(A_0\\) prior_precision Prior precision matrix Matrix Normal distribution: \\(\\Omega_0^{-1}\\) prior_scale Prior scale matrix inverse-Wishart distribution: \\(S_0\\) prior_shape Prior shape inverse-Wishart distribution: \\(\\alpha_0\\) y0 \\(Y_0\\) design \\(X_0\\) p Lag VAR totobs Total number observation type include constant term (const) (none) y Raw input (matrix) call Matched call process Process string bayes_spec: BVAR_Minnesota spec Model specification (bvharspec) also normaliw bvharmod class.","code":""},{"path":"/dev/reference/bvar_minnesota.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting Bayesian VAR(p) of Minnesota Prior ‚Äî bvar_minnesota","text":"Minnesota prior gives prior parameters \\(\\) (VAR matrices) \\(\\Sigma_e\\) (residual covariance). $$\\mid \\Sigma_e \\sim MN(A_0, \\Omega_0, \\Sigma_e)$$ $$\\Sigma_e \\sim IW(S_0, \\alpha_0)$$ (MN: matrix normal, IW: inverse-wishart)","code":""},{"path":"/dev/reference/bvar_minnesota.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting Bayesian VAR(p) of Minnesota Prior ‚Äî bvar_minnesota","text":"Ba≈Ñbura, M., Giannone, D., & Reichlin, L. (2010). Large Bayesian vector auto regressions. Journal Applied Econometrics, 25(1). Giannone, D., Lenza, M., & Primiceri, G. E. (2015). Prior Selection Vector Autoregressions. Review Economics Statistics, 97(2). Litterman, R. B. (1986). Forecasting Bayesian Vector Autoregressions: Five Years Experience. Journal Business & Economic Statistics, 4(1), 25. KADIYALA, K.R. KARLSSON, S. (1997), NUMERICAL METHODS ESTIMATION INFERENCE BAYESIAN VAR-MODELS. J. Appl. Econ., 12: 99-132. Karlsson, S. (2013). Chapter 15 Forecasting Bayesian Vector Autoregression. Handbook Economic Forecasting, 2, 791-897. Sims, C. ., & Zha, T. (1998). Bayesian Methods Dynamic Multivariate Models. International Economic Review, 39(4), 949-968.","code":""},{"path":[]},{"path":"/dev/reference/bvar_minnesota.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting Bayesian VAR(p) of Minnesota Prior ‚Äî bvar_minnesota","text":"","code":"# Perform the function using etf_vix dataset fit <- bvar_minnesota(y = etf_vix[,1:3], p = 2) class(fit) #> [1] \"bvarmn\"   \"bvharmod\" \"normaliw\"  # Extract coef, fitted values, and residuals coef(fit) #>                   GVZCLS       OVXCLS      VXFXICLS #> GVZCLS_1    0.9687374922  0.003277859 -2.127158e-03 #> OVXCLS_1   -0.0006560685  0.995091728  1.835137e-03 #> VXFXICLS_1  0.0005525222 -0.010547068  9.692097e-01 #> GVZCLS_2   -0.0063751732  0.005301266  5.301308e-03 #> OVXCLS_2   -0.0015610550 -0.001598387  1.827248e-05 #> VXFXICLS_2  0.0035974867 -0.002866207 -4.303821e-03 #> const       0.6384546093  0.355905198  7.620063e-01 head(residuals(fit)) #>            [,1]       [,2]       [,3] #> [1,]  0.9565672  0.1633277  0.2936904 #> [2,] -0.5842806  1.1471284 -0.4752438 #> [3,] -0.2615766 -0.8953073  1.1790744 #> [4,]  0.3237965 -0.7384529 -0.3004217 #> [5,]  0.3217985 -0.7440802 -0.3050897 #> [6,] -0.3306978 -1.3119988 -0.5944614 head(fitted(fit)) #>        GVZCLS   OVXCLS VXFXICLS #> [1,] 21.38343 35.35667 28.76631 #> [2,] 22.18428 35.44287 28.93524 #> [3,] 21.46158 36.51531 28.36093 #> [4,] 21.07620 35.53345 29.40542 #> [5,] 21.27820 34.71408 28.97509 #> [6,] 21.47070 33.90200 28.55446"},{"path":"/dev/reference/bvhar-package.html","id":null,"dir":"Reference","previous_headings":"","what":"bvhar: Bayesian Vector Heterogeneous Autoregressive Modeling ‚Äî bvhar-package","title":"bvhar: Bayesian Vector Heterogeneous Autoregressive Modeling ‚Äî bvhar-package","text":"Tools model forecast multivariate time series including Bayesian Vector heterogeneous autoregressive (VHAR) model Kim & Baek (2023) (doi:10.1080/00949655.2023.2281644 ). 'bvhar' can model Vector Autoregressive (VAR), VHAR, Bayesian VAR (BVAR), Bayesian VHAR (BVHAR) models.","code":""},{"path":"/dev/reference/bvhar-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"bvhar: Bayesian Vector Heterogeneous Autoregressive Modeling ‚Äî bvhar-package","text":"bvhar package provides function analyze forecast multivariate time series data via vector autoregressive modeling. , vector autoregressive modelling includes: Vector autoregressive (VAR) model: var_lm() Vector heterogeneous autoregressive (VHAR) model: vhar_lm() Bayesian VAR (BVAR) model: var_bayes() Bayesian VHAR (BVHAR) model: vhar_bayes()","code":""},{"path":"/dev/reference/bvhar-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"bvhar: Bayesian Vector Heterogeneous Autoregressive Modeling ‚Äî bvhar-package","text":"Kim, Y. G., Baek, C. (2024). Bayesian vector heterogeneous autoregressive modeling. Journal Statistical Computation Simulation, 94(6), 1139-1157. Kim, Y. G., Baek, C. (n.d.). Working paper.","code":""},{"path":[]},{"path":"/dev/reference/bvhar-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"bvhar: Bayesian Vector Heterogeneous Autoregressive Modeling ‚Äî bvhar-package","text":"Maintainer: Young Geun Kim ygeunkimstat@gmail.com (ORCID) [copyright holder] contributors: Changryong Baek [contributor]","code":""},{"path":"/dev/reference/bvhar_minnesota.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting Bayesian VHAR of Minnesota Prior ‚Äî bvhar_minnesota","title":"Fitting Bayesian VHAR of Minnesota Prior ‚Äî bvhar_minnesota","text":"function fits BVHAR Minnesota prior.","code":""},{"path":"/dev/reference/bvhar_minnesota.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting Bayesian VHAR of Minnesota Prior ‚Äî bvhar_minnesota","text":"","code":"bvhar_minnesota(   y,   har = c(5, 22),   num_chains = 1,   num_iter = 1000,   num_burn = floor(num_iter/2),   thinning = 1,   bayes_spec = set_bvhar(),   scale_variance = 0.05,   include_mean = TRUE,   parallel = list(),   verbose = FALSE,   num_thread = 1 )  # S3 method for class 'bvharmn' print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  # S3 method for class 'bvharhm' print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  # S3 method for class 'bvharmn' logLik(object, ...)  # S3 method for class 'bvharmn' AIC(object, ...)  # S3 method for class 'bvharmn' BIC(object, ...)  is.bvharmn(x)  # S3 method for class 'bvharmn' knit_print(x, ...)  # S3 method for class 'bvharhm' knit_print(x, ...)"},{"path":"/dev/reference/bvhar_minnesota.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting Bayesian VHAR of Minnesota Prior ‚Äî bvhar_minnesota","text":"y Time series data columns indicate variables har Numeric vector weekly monthly order. default, c(5, 22). num_chains Number MCMC chains num_iter MCMC iteration number num_burn Number burn-(warm-). Half iteration default choice. thinning Thinning every thinning-th iteration bayes_spec BVHAR model specification set_bvhar() (default) set_weight_bvhar(). scale_variance Proposal distribution scaling constant adjust acceptance rate include_mean Add constant term (Default: TRUE) (FALSE) parallel List argument optimParallel::optimParallel(). default, empty, function execute parallel computation. verbose Print progress bar console. default, FALSE. num_thread Number threads x object digits digit option print ... used object bvharmn object","code":""},{"path":"/dev/reference/bvhar_minnesota.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting Bayesian VHAR of Minnesota Prior ‚Äî bvhar_minnesota","text":"bvhar_minnesota() returns object bvharmn class. list following components: coefficients Posterior Mean fitted.values Fitted values residuals Residuals mn_mean Posterior mean matrix Matrix Normal distribution mn_prec Posterior precision matrix Matrix Normal distribution iw_scale Posterior scale matrix posterior inverse-wishart distribution iw_shape Posterior shape inverse-Wishart distribution (\\(\\nu_0\\) - obs + 2). \\(\\nu_0\\): nrow(Dummy observation) - k df Numer Coefficients: 3m + 1 3m m Dimension time series obs Sample size used training = totobs - 22 prior_mean Prior mean matrix Matrix Normal distribution: \\(M_0\\) prior_precision Prior precision matrix Matrix Normal distribution: \\(\\Omega_0^{-1}\\) prior_scale Prior scale matrix inverse-Wishart distribution: \\(\\Psi_0\\) prior_shape Prior shape inverse-Wishart distribution: \\(\\nu_0\\) y0 \\(Y_0\\) design \\(X_0\\) p 3, element exists run functions week Order weekly term month Order monthly term totobs Total number observation type include constant term (const) (none) HARtrans VHAR linear transformation matrix: \\(C_{HAR}\\) y Raw input (matrix) call Matched call process Process string bayes_spec: BVHAR_MN_VAR (BVHAR-S) BVHAR_MN_VHAR (BVHAR-L) spec Model specification (bvharspec) also normaliw bvharmod class.","code":""},{"path":"/dev/reference/bvhar_minnesota.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting Bayesian VHAR of Minnesota Prior ‚Äî bvhar_minnesota","text":"Apply Minnesota prior Vector HAR: \\(\\Phi\\) (VHAR matrices) \\(\\Sigma_e\\) (residual covariance). $$\\Phi \\mid \\Sigma_e \\sim MN(M_0, \\Omega_0, \\Sigma_e)$$ $$\\Sigma_e \\sim IW(\\Psi_0, \\nu_0)$$ (MN: matrix normal, IW: inverse-wishart) two types Minnesota priors BVHAR: VAR-type Minnesota prior specified set_bvhar(), -called BVHAR-S model. VHAR-type Minnesota prior specified set_weight_bvhar(), -called BVHAR-L model.","code":""},{"path":"/dev/reference/bvhar_minnesota.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting Bayesian VHAR of Minnesota Prior ‚Äî bvhar_minnesota","text":"Kim, Y. G., Baek, C. (2024). Bayesian vector heterogeneous autoregressive modeling. Journal Statistical Computation Simulation, 94(6), 1139-1157.","code":""},{"path":[]},{"path":"/dev/reference/bvhar_minnesota.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting Bayesian VHAR of Minnesota Prior ‚Äî bvhar_minnesota","text":"","code":"# Perform the function using etf_vix dataset fit <- bvhar_minnesota(y = etf_vix[,1:3]) class(fit) #> [1] \"bvharmn\"  \"bvharmod\" \"normaliw\"  # Extract coef, fitted values, and residuals coef(fit) #>                       GVZCLS        OVXCLS      VXFXICLS #> GVZCLS_day      9.563078e-01  0.0049571622  0.0023012975 #> OVXCLS_day     -1.124095e-03  0.9934581488  0.0021059646 #> VXFXICLS_day   -3.655575e-04 -0.0196286064  0.9707085757 #> GVZCLS_week     7.114698e-04  0.0003115497 -0.0029533997 #> OVXCLS_week    -1.272095e-03 -0.0007333494 -0.0010949289 #> VXFXICLS_week   2.842160e-03  0.0074516208 -0.0054726494 #> GVZCLS_month    9.807968e-03  0.0035140103  0.0030645736 #> OVXCLS_month   -8.954785e-05  0.0008878183  0.0008366598 #> VXFXICLS_month  1.183747e-03  0.0012979345 -0.0008406757 #> const           5.747434e-01  0.2878285856  0.7849725826 head(residuals(fit)) #>             [,1]        [,2]        [,3] #> [1,]  0.31184618 -0.01743843 -0.26993926 #> [2,] -0.57825789  0.17050304 -0.64147554 #> [3,] -0.24663283  0.44836077  3.18688370 #> [4,] -0.61879508  0.57710447 -1.03884178 #> [5,]  0.18365992  0.42795339 -0.09427081 #> [6,]  0.06251278  1.29400222  0.49667649 head(fitted(fit)) #>        GVZCLS   OVXCLS VXFXICLS #> [1,] 20.37815 32.33744 29.72994 #> [2,] 20.60826 32.25950 29.31148 #> [3,] 19.97663 32.38164 28.54312 #> [4,] 19.68880 32.72290 31.50884 #> [5,] 19.05634 33.21205 30.28427 #> [6,] 19.21749 33.55600 30.01332"},{"path":"/dev/reference/choose_bayes.html","id":null,"dir":"Reference","previous_headings":"","what":"Finding the Set of Hyperparameters of Bayesian Model ‚Äî choose_bayes","title":"Finding the Set of Hyperparameters of Bayesian Model ‚Äî choose_bayes","text":"function chooses set hyperparameters Bayesian model using stats::optim() function.","code":""},{"path":"/dev/reference/choose_bayes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Finding the Set of Hyperparameters of Bayesian Model ‚Äî choose_bayes","text":"","code":"choose_bayes(   bayes_bound = bound_bvhar(),   ...,   eps = 1e-04,   y,   order = c(5, 22),   include_mean = TRUE,   parallel = list() )"},{"path":"/dev/reference/choose_bayes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Finding the Set of Hyperparameters of Bayesian Model ‚Äî choose_bayes","text":"bayes_bound Empirical Bayes optimization bound specification defined bound_bvhar(). ... Additional arguments stats::optim(). eps Hyperparameter eps fixed. default, 1e-04. y Time series data order Order BVAR BVHAR. p bvar_minnesota() har bvhar_minnesota(). default, c(5, 22) har. include_mean Add constant term (Default: TRUE) (FALSE) parallel List argument optimParallel::optimParallel(). default, empty, function execute parallel computation.","code":""},{"path":"/dev/reference/choose_bayes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Finding the Set of Hyperparameters of Bayesian Model ‚Äî choose_bayes","text":"bvharemp class list ... Many components stats::optim() optimParallel::optimParallel() spec Corresponding bvharspec fit Chosen Bayesian model ml Marginal likelihood final model","code":""},{"path":"/dev/reference/choose_bayes.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Finding the Set of Hyperparameters of Bayesian Model ‚Äî choose_bayes","text":"Giannone, D., Lenza, M., & Primiceri, G. E. (2015). Prior Selection Vector Autoregressions. Review Economics Statistics, 97(2). Kim, Y. G., Baek, C. (2024). Bayesian vector heterogeneous autoregressive modeling. Journal Statistical Computation Simulation, 94(6), 1139-1157.","code":""},{"path":[]},{"path":"/dev/reference/choose_bvar.html","id":null,"dir":"Reference","previous_headings":"","what":"Finding the Set of Hyperparameters of Individual Bayesian Model ‚Äî choose_bvar","title":"Finding the Set of Hyperparameters of Individual Bayesian Model ‚Äî choose_bvar","text":"Instead functions, can use choose_bayes().","code":""},{"path":"/dev/reference/choose_bvar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Finding the Set of Hyperparameters of Individual Bayesian Model ‚Äî choose_bvar","text":"","code":"choose_bvar(   bayes_spec = set_bvar(),   lower = 0.01,   upper = 10,   ...,   eps = 1e-04,   y,   p,   include_mean = TRUE,   parallel = list() )  choose_bvhar(   bayes_spec = set_bvhar(),   lower = 0.01,   upper = 10,   ...,   eps = 1e-04,   y,   har = c(5, 22),   include_mean = TRUE,   parallel = list() )  # S3 method for class 'bvharemp' print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  is.bvharemp(x)  # S3 method for class 'bvharemp' knit_print(x, ...)"},{"path":"/dev/reference/choose_bvar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Finding the Set of Hyperparameters of Individual Bayesian Model ‚Äî choose_bvar","text":"bayes_spec Initial Bayes model specification. lower Lower bound. default, .01. upper Upper bound. default, 10. ... used eps Hyperparameter eps fixed. default, 1e-04. y Time series data p BVAR lag include_mean Add constant term (Default: TRUE) (FALSE) parallel List argument optimParallel::optimParallel(). default, empty, function execute parallel computation. har Numeric vector weekly monthly order. default, c(5, 22). x object digits digit option print","code":""},{"path":"/dev/reference/choose_bvar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Finding the Set of Hyperparameters of Individual Bayesian Model ‚Äî choose_bvar","text":"bvharemp class list stats::optim() optimParallel::optimParallel() chosen bvharspec set Bayesian model fit result chosen specification ... Many components stats::optim() optimParallel::optimParallel() spec Corresponding bvharspec fit Chosen Bayesian model ml Marginal likelihood final model","code":""},{"path":"/dev/reference/choose_bvar.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Finding the Set of Hyperparameters of Individual Bayesian Model ‚Äî choose_bvar","text":"Empirical Bayes method maximizes marginal likelihood selects set hyperparameters. functions implement L-BFGS-B method stats::optim() find maximum marginal likelihood. want set lower upper option carefully, deal like stats::optim() order set_bvar(), set_bvhar(), set_weight_bvhar()'s argument (except eps). words, just arrange vector.","code":""},{"path":"/dev/reference/choose_bvar.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Finding the Set of Hyperparameters of Individual Bayesian Model ‚Äî choose_bvar","text":"Byrd, R. H., Lu, P., Nocedal, J., & Zhu, C. (1995). limited memory algorithm bound constrained optimization. SIAM Journal scientific computing, 16(5), 1190-1208. Gelman, ., Carlin, J. B., Stern, H. S., & Rubin, D. B. (2013). Bayesian data analysis. Chapman Hall/CRC. Giannone, D., Lenza, M., & Primiceri, G. E. (2015). Prior Selection Vector Autoregressions. Review Economics Statistics, 97(2). Kim, Y. G., Baek, C. (2024). Bayesian vector heterogeneous autoregressive modeling. Journal Statistical Computation Simulation, 94(6), 1139-1157.","code":""},{"path":"/dev/reference/choose_var.html","id":null,"dir":"Reference","previous_headings":"","what":"Choose the Best VAR based on Information Criteria ‚Äî choose_var","title":"Choose the Best VAR based on Information Criteria ‚Äî choose_var","text":"function computes AIC, FPE, BIC, HQ p = lag_max VAR model.","code":""},{"path":"/dev/reference/choose_var.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Choose the Best VAR based on Information Criteria ‚Äî choose_var","text":"","code":"choose_var(y, lag_max = 5, include_mean = TRUE, parallel = FALSE)"},{"path":"/dev/reference/choose_var.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Choose the Best VAR based on Information Criteria ‚Äî choose_var","text":"y Time series data columns indicate variables lag_max Maximum Var lag explore (default = 5) include_mean Add constant term (Default: TRUE) (FALSE) parallel Parallel computation using foreach::foreach()? default, FALSE.","code":""},{"path":"/dev/reference/choose_var.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Choose the Best VAR based on Information Criteria ‚Äî choose_var","text":"Minimum order information criteria values","code":""},{"path":"/dev/reference/coef.html","id":null,"dir":"Reference","previous_headings":"","what":"Coefficient Matrix of Multivariate Time Series Models ‚Äî coef","title":"Coefficient Matrix of Multivariate Time Series Models ‚Äî coef","text":"defining stats::coef() model, function returns coefficient matrix estimates.","code":""},{"path":"/dev/reference/coef.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coefficient Matrix of Multivariate Time Series Models ‚Äî coef","text":"","code":"# S3 method for class 'varlse' coef(object, ...)  # S3 method for class 'vharlse' coef(object, ...)  # S3 method for class 'bvarmn' coef(object, ...)  # S3 method for class 'bvarflat' coef(object, ...)  # S3 method for class 'bvharmn' coef(object, ...)  # S3 method for class 'bvharsp' coef(object, ...)  # S3 method for class 'summary.bvharsp' coef(object, ...)"},{"path":"/dev/reference/coef.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coefficient Matrix of Multivariate Time Series Models ‚Äî coef","text":"object Model object ... used","code":""},{"path":"/dev/reference/coef.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coefficient Matrix of Multivariate Time Series Models ‚Äî coef","text":"matrix object appropriate dimension.","code":""},{"path":"/dev/reference/compute_dic.html","id":null,"dir":"Reference","previous_headings":"","what":"Deviance Information Criterion of Multivariate Time Series Model ‚Äî compute_dic","title":"Deviance Information Criterion of Multivariate Time Series Model ‚Äî compute_dic","text":"Compute DIC BVAR BVHAR.","code":""},{"path":"/dev/reference/compute_dic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Deviance Information Criterion of Multivariate Time Series Model ‚Äî compute_dic","text":"","code":"compute_dic(object, ...)  # S3 method for class 'bvarmn' compute_dic(object, n_iter = 100L, ...)"},{"path":"/dev/reference/compute_dic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Deviance Information Criterion of Multivariate Time Series Model ‚Äî compute_dic","text":"object Model fit ... used n_iter Number sample","code":""},{"path":"/dev/reference/compute_dic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Deviance Information Criterion of Multivariate Time Series Model ‚Äî compute_dic","text":"DIC value.","code":""},{"path":"/dev/reference/compute_dic.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Deviance Information Criterion of Multivariate Time Series Model ‚Äî compute_dic","text":"Deviance information criteria (DIC) $$- 2 \\log p(y \\mid \\hat\\theta_{bayes}) + 2 p_{DIC}$$ \\(p_{DIC}\\) effective number parameters defined $$p_{DIC} = 2 ( \\log p(y \\mid \\hat\\theta_{bayes}) - E_{post} \\log p(y \\mid \\theta) )$$ Random sampling posterior distribution gives computation, \\(\\theta_i \\sim \\theta \\mid y, = 1, \\ldots, M\\) $$p_{DIC}^{computed} = 2 ( \\log p(y \\mid \\hat\\theta_{bayes}) - \\frac{1}{M} \\sum_i \\log p(y \\mid \\theta_i) )$$","code":""},{"path":"/dev/reference/compute_dic.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Deviance Information Criterion of Multivariate Time Series Model ‚Äî compute_dic","text":"Gelman, ., Carlin, J. B., Stern, H. S., & Rubin, D. B. (2013). Bayesian data analysis. Chapman Hall/CRC. Spiegelhalter, D.J., Best, N.G., Carlin, B.P. Van Der Linde, . (2002). Bayesian measures model complexity fit. Journal Royal Statistical Society: Series B (Statistical Methodology), 64: 583-639.","code":""},{"path":"/dev/reference/compute_logml.html","id":null,"dir":"Reference","previous_headings":"","what":"Extracting Log of Marginal Likelihood ‚Äî compute_logml","title":"Extracting Log of Marginal Likelihood ‚Äî compute_logml","text":"Compute log marginal likelihood Bayesian Fit","code":""},{"path":"/dev/reference/compute_logml.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extracting Log of Marginal Likelihood ‚Äî compute_logml","text":"","code":"compute_logml(object, ...)  # S3 method for class 'bvarmn' compute_logml(object, ...)  # S3 method for class 'bvharmn' compute_logml(object, ...)"},{"path":"/dev/reference/compute_logml.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extracting Log of Marginal Likelihood ‚Äî compute_logml","text":"object Model fit ... used","code":""},{"path":"/dev/reference/compute_logml.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extracting Log of Marginal Likelihood ‚Äî compute_logml","text":"log likelihood Minnesota prior model.","code":""},{"path":"/dev/reference/compute_logml.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extracting Log of Marginal Likelihood ‚Äî compute_logml","text":"Closed form Marginal Likelihood BVAR can derived $$p(Y_0) = \\pi^{-mn / 2} \\frac{\\Gamma_m ((\\alpha_0 + n) / 2)}{\\Gamma_m (\\alpha_0 / 2)} \\det(\\Omega_0)^{-m / 2} \\det(S_0)^{\\alpha_0 / 2} \\det(\\hat{V})^{- m / 2} \\det(\\hat{\\Sigma}_e)^{-(\\alpha_0 + n) / 2}$$ Closed form Marginal Likelihood BVHAR can derived $$p(Y_0) = \\pi^{-ms_0 / 2} \\frac{\\Gamma_m ((d_0 + n) / 2)}{\\Gamma_m (d_0 / 2)} \\det(P_0)^{-m / 2} \\det(U_0)^{d_0 / 2} \\det(\\hat{V}_{HAR})^{- m / 2} \\det(\\hat{\\Sigma}_e)^{-(d_0 + n) / 2}$$","code":""},{"path":"/dev/reference/compute_logml.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extracting Log of Marginal Likelihood ‚Äî compute_logml","text":"Giannone, D., Lenza, M., & Primiceri, G. E. (2015). Prior Selection Vector Autoregressions. Review Economics Statistics, 97(2).","code":""},{"path":"/dev/reference/conf_fdr.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Sparsity Estimation Based on FDR ‚Äî conf_fdr","title":"Evaluate the Sparsity Estimation Based on FDR ‚Äî conf_fdr","text":"function computes false discovery rate (FDR) sparse element true coefficients given threshold.","code":""},{"path":"/dev/reference/conf_fdr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Sparsity Estimation Based on FDR ‚Äî conf_fdr","text":"","code":"conf_fdr(x, y, ...)  # S3 method for class 'summary.bvharsp' conf_fdr(x, y, truth_thr = 0, ...)"},{"path":"/dev/reference/conf_fdr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Sparsity Estimation Based on FDR ‚Äî conf_fdr","text":"x summary.bvharsp object. y True inclusion variable. ... used truth_thr Threshold value using non-sparse true coefficient matrix. default, 0 sparse matrix.","code":""},{"path":"/dev/reference/conf_fdr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Sparsity Estimation Based on FDR ‚Äî conf_fdr","text":"FDR value confusion table","code":""},{"path":"/dev/reference/conf_fdr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Sparsity Estimation Based on FDR ‚Äî conf_fdr","text":"using function, true coefficient matrix \\(\\Phi\\) sparse. False discovery rate (FDR) computed $$FDR = \\frac{FP}{TP + FP}$$ TP true positive, FP false positive.","code":""},{"path":"/dev/reference/conf_fdr.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Sparsity Estimation Based on FDR ‚Äî conf_fdr","text":"Bai, R., & Ghosh, M. (2018). High-dimensional multivariate posterior consistency global-local shrinkage priors. Journal Multivariate Analysis, 167, 157-170.","code":""},{"path":[]},{"path":"/dev/reference/conf_fnr.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Sparsity Estimation Based on FNR ‚Äî conf_fnr","title":"Evaluate the Sparsity Estimation Based on FNR ‚Äî conf_fnr","text":"function computes false negative rate (FNR) sparse element true coefficients given threshold.","code":""},{"path":"/dev/reference/conf_fnr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Sparsity Estimation Based on FNR ‚Äî conf_fnr","text":"","code":"conf_fnr(x, y, ...)  # S3 method for class 'summary.bvharsp' conf_fnr(x, y, truth_thr = 0, ...)"},{"path":"/dev/reference/conf_fnr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Sparsity Estimation Based on FNR ‚Äî conf_fnr","text":"x summary.bvharsp object. y True inclusion variable. ... used truth_thr Threshold value using non-sparse true coefficient matrix. default, 0 sparse matrix.","code":""},{"path":"/dev/reference/conf_fnr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Sparsity Estimation Based on FNR ‚Äî conf_fnr","text":"FNR value confusion table","code":""},{"path":"/dev/reference/conf_fnr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Sparsity Estimation Based on FNR ‚Äî conf_fnr","text":"False negative rate (FNR) computed $$FNR = \\frac{FN}{TP + FN}$$ TP true positive, FN false negative.","code":""},{"path":"/dev/reference/conf_fnr.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Sparsity Estimation Based on FNR ‚Äî conf_fnr","text":"Bai, R., & Ghosh, M. (2018). High-dimensional multivariate posterior consistency global-local shrinkage priors. Journal Multivariate Analysis, 167, 157-170.","code":""},{"path":[]},{"path":"/dev/reference/conf_fscore.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Sparsity Estimation Based on F1 Score ‚Äî conf_fscore","title":"Evaluate the Sparsity Estimation Based on F1 Score ‚Äî conf_fscore","text":"function computes F1 score sparse element true coefficients given threshold.","code":""},{"path":"/dev/reference/conf_fscore.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Sparsity Estimation Based on F1 Score ‚Äî conf_fscore","text":"","code":"conf_fscore(x, y, ...)  # S3 method for class 'summary.bvharsp' conf_fscore(x, y, truth_thr = 0, ...)"},{"path":"/dev/reference/conf_fscore.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Sparsity Estimation Based on F1 Score ‚Äî conf_fscore","text":"x summary.bvharsp object. y True inclusion variable. ... used truth_thr Threshold value using non-sparse true coefficient matrix. default, 0 sparse matrix.","code":""},{"path":"/dev/reference/conf_fscore.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Sparsity Estimation Based on F1 Score ‚Äî conf_fscore","text":"F1 score confusion table","code":""},{"path":"/dev/reference/conf_fscore.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Sparsity Estimation Based on F1 Score ‚Äî conf_fscore","text":"F1 score computed $$F_1 = \\frac{2 precision \\times recall}{precision + recall}$$","code":""},{"path":[]},{"path":"/dev/reference/conf_prec.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Sparsity Estimation Based on Precision ‚Äî conf_prec","title":"Evaluate the Sparsity Estimation Based on Precision ‚Äî conf_prec","text":"function computes precision sparse element true coefficients given threshold.","code":""},{"path":"/dev/reference/conf_prec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Sparsity Estimation Based on Precision ‚Äî conf_prec","text":"","code":"conf_prec(x, y, ...)  # S3 method for class 'summary.bvharsp' conf_prec(x, y, truth_thr = 0, ...)"},{"path":"/dev/reference/conf_prec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Sparsity Estimation Based on Precision ‚Äî conf_prec","text":"x summary.bvharsp object. y True inclusion variable. ... used truth_thr Threshold value using non-sparse true coefficient matrix. default, 0 sparse matrix.","code":""},{"path":"/dev/reference/conf_prec.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Sparsity Estimation Based on Precision ‚Äî conf_prec","text":"Precision value confusion table","code":""},{"path":"/dev/reference/conf_prec.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Sparsity Estimation Based on Precision ‚Äî conf_prec","text":"element estimate \\(\\hat\\Phi\\) smaller threshold, treated zero. precision computed $$precision = \\frac{TP}{TP + FP}$$ TP true positive, FP false positive.","code":""},{"path":"/dev/reference/conf_prec.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Sparsity Estimation Based on Precision ‚Äî conf_prec","text":"Bai, R., & Ghosh, M. (2018). High-dimensional multivariate posterior consistency global-local shrinkage priors. Journal Multivariate Analysis, 167, 157-170.","code":""},{"path":[]},{"path":"/dev/reference/conf_recall.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Sparsity Estimation Based on Recall ‚Äî conf_recall","title":"Evaluate the Sparsity Estimation Based on Recall ‚Äî conf_recall","text":"function computes recall sparse element true coefficients given threshold.","code":""},{"path":"/dev/reference/conf_recall.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Sparsity Estimation Based on Recall ‚Äî conf_recall","text":"","code":"conf_recall(x, y, ...)  # S3 method for class 'summary.bvharsp' conf_recall(x, y, truth_thr = 0L, ...)"},{"path":"/dev/reference/conf_recall.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Sparsity Estimation Based on Recall ‚Äî conf_recall","text":"x summary.bvharsp object. y True inclusion variable. ... used truth_thr Threshold value using non-sparse true coefficient matrix. default, 0 sparse matrix.","code":""},{"path":"/dev/reference/conf_recall.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Sparsity Estimation Based on Recall ‚Äî conf_recall","text":"Recall value confusion table","code":""},{"path":"/dev/reference/conf_recall.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Sparsity Estimation Based on Recall ‚Äî conf_recall","text":"Precision computed $$recall = \\frac{TP}{TP + FN}$$ TP true positive, FN false negative.","code":""},{"path":"/dev/reference/conf_recall.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Sparsity Estimation Based on Recall ‚Äî conf_recall","text":"Bai, R., & Ghosh, M. (2018). High-dimensional multivariate posterior consistency global-local shrinkage priors. Journal Multivariate Analysis, 167, 157-170.","code":""},{"path":[]},{"path":"/dev/reference/confusion.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Sparsity Estimation Based on Confusion Matrix ‚Äî confusion","title":"Evaluate the Sparsity Estimation Based on Confusion Matrix ‚Äî confusion","text":"function computes FDR (false discovery rate) FNR (false negative rate) sparse element true coefficients given threshold.","code":""},{"path":"/dev/reference/confusion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Sparsity Estimation Based on Confusion Matrix ‚Äî confusion","text":"","code":"confusion(x, y, ...)  # S3 method for class 'summary.bvharsp' confusion(x, y, truth_thr = 0, ...)"},{"path":"/dev/reference/confusion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Sparsity Estimation Based on Confusion Matrix ‚Äî confusion","text":"x summary.bvharsp object. y True inclusion variable. ... used truth_thr Threshold value using non-sparse true coefficient matrix. default, 0 sparse matrix.","code":""},{"path":"/dev/reference/confusion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Sparsity Estimation Based on Confusion Matrix ‚Äî confusion","text":"Confusion table following.","code":""},{"path":"/dev/reference/confusion.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Sparsity Estimation Based on Confusion Matrix ‚Äî confusion","text":"using function, true coefficient matrix \\(\\Phi\\) sparse. confusion matrix, positive (0) means sparsity. FP false positive, TP true positive. FN false negative, FN false negative.","code":""},{"path":"/dev/reference/confusion.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Sparsity Estimation Based on Confusion Matrix ‚Äî confusion","text":"Bai, R., & Ghosh, M. (2018). High-dimensional multivariate posterior consistency global-local shrinkage priors. Journal Multivariate Analysis, 167, 157-170.","code":""},{"path":"/dev/reference/divide_ts.html","id":null,"dir":"Reference","previous_headings":"","what":"Split a Time Series Dataset into Train-Test Set ‚Äî divide_ts","title":"Split a Time Series Dataset into Train-Test Set ‚Äî divide_ts","text":"Split given time series dataset train test set evaluation.","code":""},{"path":"/dev/reference/divide_ts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split a Time Series Dataset into Train-Test Set ‚Äî divide_ts","text":"","code":"divide_ts(y, n_ahead)"},{"path":"/dev/reference/divide_ts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split a Time Series Dataset into Train-Test Set ‚Äî divide_ts","text":"y Time series data columns indicate variables n_ahead step evaluate","code":""},{"path":"/dev/reference/divide_ts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split a Time Series Dataset into Train-Test Set ‚Äî divide_ts","text":"List two datasets, train test.","code":""},{"path":"/dev/reference/dynamic_spillover.html","id":null,"dir":"Reference","previous_headings":"","what":"Dynamic Spillover ‚Äî dynamic_spillover","title":"Dynamic Spillover ‚Äî dynamic_spillover","text":"function gives connectedness table h-step ahead normalized spillover index (.k.. variance shares).","code":""},{"path":"/dev/reference/dynamic_spillover.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dynamic Spillover ‚Äî dynamic_spillover","text":"","code":"dynamic_spillover(object, n_ahead = 10L, ...)  # S3 method for class 'bvhardynsp' print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  # S3 method for class 'bvhardynsp' knit_print(x, ...)  # S3 method for class 'olsmod' dynamic_spillover(object, n_ahead = 10L, window, num_thread = 1, ...)  # S3 method for class 'normaliw' dynamic_spillover(   object,   n_ahead = 10L,   window,   num_iter = 1000L,   num_burn = floor(num_iter/2),   thinning = 1,   num_thread = 1,   ... )  # S3 method for class 'ldltmod' dynamic_spillover(   object,   n_ahead = 10L,   window,   level = 0.05,   sparse = FALSE,   num_thread = 1,   ... )  # S3 method for class 'svmod' dynamic_spillover(   object,   n_ahead = 10L,   level = 0.05,   sparse = FALSE,   num_thread = 1,   ... )"},{"path":"/dev/reference/dynamic_spillover.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dynamic Spillover ‚Äî dynamic_spillover","text":"object Model object n_ahead step forecast. default, 10. ... used x bvhardynsp object digits digit option print window Window size num_thread Number threads num_iter Number sample MNIW distribution num_burn Number burn-thinning Thinning every thinning-th iteration level Specify alpha confidence interval level 100(1 - alpha) percentage. default, .05. sparse Apply restriction. default, FALSE.","code":""},{"path":"/dev/reference/dynamic_spillover.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Dynamic Spillover ‚Äî dynamic_spillover","text":"Diebold, F. X., & Yilmaz, K. (2012). Better give receive: Predictive directional measurement volatility spillovers. International Journal forecasting, 28(1), 57-66.","code":""},{"path":"/dev/reference/etf_vix.html","id":null,"dir":"Reference","previous_headings":"","what":"CBOE ETF Volatility Index Dataset ‚Äî etf_vix","title":"CBOE ETF Volatility Index Dataset ‚Äî etf_vix","text":"Chicago Board Options Exchage (CBOE) Exchange Traded Funds (ETFs) volatility index FRED.","code":""},{"path":"/dev/reference/etf_vix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CBOE ETF Volatility Index Dataset ‚Äî etf_vix","text":"","code":"etf_vix"},{"path":"/dev/reference/etf_vix.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"CBOE ETF Volatility Index Dataset ‚Äî etf_vix","text":"data frame 1006 row 9 columns: 2012-01-09 2015-06-27, 33 missing observations interpolated stats::approx() linear. GVZCLS Gold ETF volatility index VXFXICLS China ETF volatility index OVXCLS Crude Oil ETF volatility index VXEEMCLS Emerging Markets ETF volatility index EVZCLS EuroCurrency ETF volatility index VXSLVCLS Silver ETF volatility index VXGDXCLS Gold Miners ETF volatility index VXXLECLS Energy Sector ETF volatility index VXEWZCLS Brazil ETF volatility index","code":""},{"path":"/dev/reference/etf_vix.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"CBOE ETF Volatility Index Dataset ‚Äî etf_vix","text":"Source: https://www.cboe.com Release: https://www.cboe.com/us/options/market_statistics/daily/","code":""},{"path":"/dev/reference/etf_vix.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"CBOE ETF Volatility Index Dataset ‚Äî etf_vix","text":"Copyright, 2016, Chicago Board Options Exchange, Inc. Note , data frame, dates column removed. dataset interpolated 36 missing observations (nontrading dates) using imputeTS::na_interpolation().","code":""},{"path":"/dev/reference/etf_vix.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"CBOE ETF Volatility Index Dataset ‚Äî etf_vix","text":"Chicago Board Options Exchange, CBOE Gold ETF Volatility Index (GVZCLS), retrieved FRED, Federal Reserve Bank St. Louis; https://fred.stlouisfed.org/series/GVZCLS, July 31, 2021. Chicago Board Options Exchange, CBOE China ETF Volatility Index (VXFXICLS), retrieved FRED, Federal Reserve Bank St. Louis; https://fred.stlouisfed.org/series/VXFXICLS, August 1, 2021. Chicago Board Options Exchange, CBOE Crude Oil ETF Volatility Index (OVXCLS), retrieved FRED, Federal Reserve Bank St. Louis; https://fred.stlouisfed.org/series/OVXCLS, August 1, 2021. Chicago Board Options Exchange, CBOE Emerging Markets ETF Volatility Index (VXEEMCLS), retrieved FRED, Federal Reserve Bank St. Louis; https://fred.stlouisfed.org/series/VXEEMCLS, August 1, 2021. Chicago Board Options Exchange, CBOE EuroCurrency ETF Volatility Index (EVZCLS), retrieved FRED, Federal Reserve Bank St. Louis; https://fred.stlouisfed.org/series/EVZCLS, August 2, 2021. Chicago Board Options Exchange, CBOE Silver ETF Volatility Index (VXSLVCLS), retrieved FRED, Federal Reserve Bank St. Louis; https://fred.stlouisfed.org/series/VXSLVCLS, August 1, 2021. Chicago Board Options Exchange, CBOE Gold Miners ETF Volatility Index (VXGDXCLS), retrieved FRED, Federal Reserve Bank St. Louis; https://fred.stlouisfed.org/series/VXGDXCLS, August 1, 2021. Chicago Board Options Exchange, CBOE Energy Sector ETF Volatility Index (VXXLECLS), retrieved FRED, Federal Reserve Bank St. Louis; https://fred.stlouisfed.org/series/VXXLECLS, August 1, 2021. Chicago Board Options Exchange, CBOE Brazil ETF Volatility Index (VXEWZCLS), retrieved FRED, Federal Reserve Bank St. Louis; https://fred.stlouisfed.org/series/VXEWZCLS, August 2, 2021.","code":""},{"path":"/dev/reference/financial_history_appendix.html","id":null,"dir":"Reference","previous_headings":"","what":"Time points and Financial Events ‚Äî financial_history_appendix","title":"Time points and Financial Events ‚Äî financial_history_appendix","text":"page describes important financial events 20th century. might give hint cutting data provides datasets limited period.","code":""},{"path":"/dev/reference/financial_history_appendix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Time points and Financial Events ‚Äî financial_history_appendix","text":"","code":"trading_day"},{"path":"/dev/reference/financial_history_appendix.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Time points and Financial Events ‚Äî financial_history_appendix","text":"vector trading_day saves dates etf_vix.","code":""},{"path":"/dev/reference/financial_history_appendix.html","id":"outline","dir":"Reference","previous_headings":"","what":"Outline","title":"Time points and Financial Events ‚Äî financial_history_appendix","text":"2000: Dot-com bubble 2001: September 11 terror Enron scandal 2003: Iraq war (2011) 2007 2008: Financial crisis (US) 2007: Subprime morgage crisis 2008: Bankrupcy Lehman Brothers 2010 2016: European sovereign dept crisis 2010: Greek debt crisis 2011: Italian default 2015: Greek default 2016: Brexit 2018: US-China trade war 2019: Brexit 2020: COVID-19","code":""},{"path":"/dev/reference/financial_history_appendix.html","id":"about-datasets-in-this-package","dir":"Reference","previous_headings":"","what":"About Datasets in this package","title":"Time points and Financial Events ‚Äî financial_history_appendix","text":"etf_vix ranges 2012-01-09 2015-06-27 (weekdays). year corresponds Italian default Grexit. wonder exact vector date, see trading_day vector.","code":""},{"path":"/dev/reference/financial_history_appendix.html","id":"notice","dir":"Reference","previous_headings":"","what":"Notice","title":"Time points and Financial Events ‚Äî financial_history_appendix","text":"want time period, see codes Github repo dataset: ygeunkim/bvhar/data-raw/etf_vix.R can download want changing lines.","code":""},{"path":"/dev/reference/fitted.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitted Matrix from Multivariate Time Series Models ‚Äî fitted","title":"Fitted Matrix from Multivariate Time Series Models ‚Äî fitted","text":"defining stats::fitted() model, function returns fitted matrix.","code":""},{"path":"/dev/reference/fitted.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitted Matrix from Multivariate Time Series Models ‚Äî fitted","text":"","code":"# S3 method for class 'varlse' fitted(object, ...)  # S3 method for class 'vharlse' fitted(object, ...)  # S3 method for class 'bvarmn' fitted(object, ...)  # S3 method for class 'bvarflat' fitted(object, ...)  # S3 method for class 'bvharmn' fitted(object, ...)"},{"path":"/dev/reference/fitted.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitted Matrix from Multivariate Time Series Models ‚Äî fitted","text":"object Model object ... used","code":""},{"path":"/dev/reference/fitted.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitted Matrix from Multivariate Time Series Models ‚Äî fitted","text":"matrix object.","code":""},{"path":"/dev/reference/forecast_expand.html","id":null,"dir":"Reference","previous_headings":"","what":"Out-of-sample Forecasting based on Expanding Window ‚Äî forecast_expand","title":"Out-of-sample Forecasting based on Expanding Window ‚Äî forecast_expand","text":"function conducts expanding window forecasting.","code":""},{"path":"/dev/reference/forecast_expand.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Out-of-sample Forecasting based on Expanding Window ‚Äî forecast_expand","text":"","code":"forecast_expand(   object,   n_ahead,   y_test,   level = 0.05,   newxreg = NULL,   num_thread = 1,   ... )  # S3 method for class 'olsmod' forecast_expand(   object,   n_ahead,   y_test,   level = 0.05,   newxreg = NULL,   num_thread = 1,   ... )  # S3 method for class 'normaliw' forecast_expand(   object,   n_ahead,   y_test,   level = 0.05,   newxreg = NULL,   num_thread = 1,   use_fit = TRUE,   ... )  # S3 method for class 'ldltmod' forecast_expand(   object,   n_ahead,   y_test,   level = 0.05,   newxreg = NULL,   num_thread = 1,   stable = FALSE,   sparse = FALSE,   med = FALSE,   lpl = FALSE,   mcmc = TRUE,   use_fit = TRUE,   verbose = FALSE,   ... )  # S3 method for class 'svmod' forecast_expand(   object,   n_ahead,   y_test,   level = 0.05,   newxreg = NULL,   num_thread = 1,   use_sv = TRUE,   stable = FALSE,   sparse = FALSE,   med = FALSE,   lpl = FALSE,   mcmc = TRUE,   use_fit = TRUE,   verbose = FALSE,   ... )"},{"path":"/dev/reference/forecast_expand.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Out-of-sample Forecasting based on Expanding Window ‚Äî forecast_expand","text":"object Model object n_ahead Step forecast rolling window scheme y_test Test data compared. Use divide_ts() separate evaluation dataset. level Specify alpha confidence interval level 100(1 - alpha) percentage. default, .05. newxreg New values exogenous variables. row numbers y_test. num_thread Number threads ... Additional arguments. use_fit Use object result first window. default, TRUE. stable Filter stable coefficient draws MCMC records. sparse Apply restriction. default, FALSE. med TRUE, use median forecast draws instead mean (default). lpl Compute log-predictive likelihood (LPL). default, FALSE. mcmc TRUE, run new MCMC new windows. default, TRUE. verbose Print progress bar console. default, FALSE. use_sv Use SV term","code":""},{"path":"/dev/reference/forecast_expand.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Out-of-sample Forecasting based on Expanding Window ‚Äî forecast_expand","text":"predbvhar_expand class","code":""},{"path":"/dev/reference/forecast_expand.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Out-of-sample Forecasting based on Expanding Window ‚Äî forecast_expand","text":"Expanding windows forecasting fixes starting period. moves window ahead forecast h-ahead y_test set.","code":""},{"path":"/dev/reference/forecast_expand.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Out-of-sample Forecasting based on Expanding Window ‚Äî forecast_expand","text":"Hyndman, R. J., & Athanasopoulos, G. (2021). Forecasting: Principles practice (3rd ed.). OTEXTS. https://otexts.com/fpp3/","code":""},{"path":"/dev/reference/forecast_roll.html","id":null,"dir":"Reference","previous_headings":"","what":"Out-of-sample Forecasting based on Rolling Window ‚Äî forecast_roll","title":"Out-of-sample Forecasting based on Rolling Window ‚Äî forecast_roll","text":"function conducts rolling window forecasting.","code":""},{"path":"/dev/reference/forecast_roll.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Out-of-sample Forecasting based on Rolling Window ‚Äî forecast_roll","text":"","code":"forecast_roll(   object,   n_ahead,   y_test,   level = 0.05,   newxreg = NULL,   num_thread = 1,   ... )  # S3 method for class 'bvharcv' print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  is.bvharcv(x)  # S3 method for class 'bvharcv' knit_print(x, ...)  # S3 method for class 'olsmod' forecast_roll(   object,   n_ahead,   y_test,   level = 0.05,   newxreg = NULL,   num_thread = 1,   ... )  # S3 method for class 'normaliw' forecast_roll(   object,   n_ahead,   y_test,   level = 0.05,   newxreg = NULL,   num_thread = 1,   use_fit = TRUE,   ... )  # S3 method for class 'ldltmod' forecast_roll(   object,   n_ahead,   y_test,   level = 0.05,   newxreg = NULL,   num_thread = 1,   stable = FALSE,   sparse = FALSE,   med = FALSE,   lpl = FALSE,   mcmc = TRUE,   use_fit = TRUE,   verbose = FALSE,   ... )  # S3 method for class 'svmod' forecast_roll(   object,   n_ahead,   y_test,   level = 0.05,   newxreg = NULL,   num_thread = 1,   use_sv = TRUE,   stable = FALSE,   sparse = FALSE,   med = FALSE,   lpl = FALSE,   mcmc = TRUE,   use_fit = TRUE,   verbose = FALSE,   ... )"},{"path":"/dev/reference/forecast_roll.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Out-of-sample Forecasting based on Rolling Window ‚Äî forecast_roll","text":"object Model object n_ahead Step forecast rolling window scheme y_test Test data compared. Use divide_ts() separate evaluation dataset. level Specify alpha confidence interval level 100(1 - alpha) percentage. default, .05. newxreg New values exogenous variables. row numbers y_test. num_thread Number threads ... used x object digits digit option print use_fit Use object result first window. default, TRUE. stable Filter stable coefficient draws MCMC records. sparse Apply restriction. default, FALSE. med TRUE, use median forecast draws instead mean (default). lpl Compute log-predictive likelihood (LPL). default, FALSE. mcmc TRUE, run new MCMC new windows. default, TRUE. verbose Print progress bar console. default, FALSE. use_sv Use SV term","code":""},{"path":"/dev/reference/forecast_roll.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Out-of-sample Forecasting based on Rolling Window ‚Äî forecast_roll","text":"predbvhar_roll class","code":""},{"path":"/dev/reference/forecast_roll.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Out-of-sample Forecasting based on Rolling Window ‚Äî forecast_roll","text":"Rolling windows forecasting fixes window size. moves window ahead forecast h-ahead y_test set.","code":""},{"path":"/dev/reference/forecast_roll.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Out-of-sample Forecasting based on Rolling Window ‚Äî forecast_roll","text":"Hyndman, R. J., & Athanasopoulos, G. (2021). Forecasting: Principles practice (3rd ed.). OTEXTS.","code":""},{"path":"/dev/reference/fromse.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Estimation Based on Frobenius Norm ‚Äî fromse","title":"Evaluate the Estimation Based on Frobenius Norm ‚Äî fromse","text":"function computes estimation error given estimated model true coefficient.","code":""},{"path":"/dev/reference/fromse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Estimation Based on Frobenius Norm ‚Äî fromse","text":"","code":"fromse(x, y, ...)  # S3 method for class 'bvharsp' fromse(x, y, ...)"},{"path":"/dev/reference/fromse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Estimation Based on Frobenius Norm ‚Äî fromse","text":"x Estimated model. y Coefficient matrix compared. ... used","code":""},{"path":"/dev/reference/fromse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Estimation Based on Frobenius Norm ‚Äî fromse","text":"Frobenius norm value","code":""},{"path":"/dev/reference/fromse.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Estimation Based on Frobenius Norm ‚Äî fromse","text":"Consider Frobenius Norm \\(\\lVert \\cdot \\rVert_F\\). let \\(\\hat{\\Phi}\\) nrow x k estimates, let \\(\\Phi\\) true coefficients matrix. function computes estimation error $$MSE = 100 \\frac{\\lVert \\hat{\\Phi} - \\Phi \\rVert_F}{nrow \\times k}$$","code":""},{"path":"/dev/reference/fromse.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Estimation Based on Frobenius Norm ‚Äî fromse","text":"Bai, R., & Ghosh, M. (2018). High-dimensional multivariate posterior consistency global-local shrinkage priors. Journal Multivariate Analysis, 167, 157-170.","code":""},{"path":"/dev/reference/geom_eval.html","id":null,"dir":"Reference","previous_headings":"","what":"Adding Test Data Layer ‚Äî geom_eval","title":"Adding Test Data Layer ‚Äî geom_eval","text":"function adds layer test dataset.","code":""},{"path":"/dev/reference/geom_eval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adding Test Data Layer ‚Äî geom_eval","text":"","code":"geom_eval(data, colour = \"red\", ...)"},{"path":"/dev/reference/geom_eval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adding Test Data Layer ‚Äî geom_eval","text":"data Test data draw, format train data. colour Color line (default, red). ... arguments passed ggplot2::geom_path().","code":""},{"path":"/dev/reference/geom_eval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adding Test Data Layer ‚Äî geom_eval","text":"ggplot layer","code":""},{"path":"/dev/reference/gg_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare Lists of Models ‚Äî gg_loss","title":"Compare Lists of Models ‚Äî gg_loss","text":"Draw plot test error given models","code":""},{"path":"/dev/reference/gg_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare Lists of Models ‚Äî gg_loss","text":"","code":"gg_loss(   mod_list,   y,   type = c(\"mse\", \"mae\", \"mape\", \"mase\"),   mean_line = FALSE,   line_param = list(),   mean_param = list(),   viridis = FALSE,   viridis_option = \"D\",   NROW = NULL,   NCOL = NULL,   ... )"},{"path":"/dev/reference/gg_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare Lists of Models ‚Äî gg_loss","text":"mod_list Lists forecast results (predbvhar objects) y Test data compared. format train data predict$forecast. type Loss function used (mse: MSE, mae: MAE, mape: MAPE, mase: MASE) mean_line Whether draw average loss. default, FALSE. line_param Parameter lists ggplot2::geom_path(). mean_param Parameter lists average loss ggplot2::geom_hline(). viridis TRUE, scale CI forecast line using ggplot2::scale_fill_viridis_d() ggplot2::scale_colour_viridis_d, respectively. viridis_option Option viridis string. See option ggplot2::scale_colour_viridis_d. Choose one c(\"\", \"B\", \"C\", \"D\", \"E\"). default, D. NROW nrow ggplot2::facet_wrap() NCOL ncol ggplot2::facet_wrap() ... Additional options geom_loss (inherit.aes show.legend)","code":""},{"path":"/dev/reference/gg_loss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare Lists of Models ‚Äî gg_loss","text":"ggplot object","code":""},{"path":[]},{"path":"/dev/reference/irf.html","id":null,"dir":"Reference","previous_headings":"","what":"Impulse Response Analysis ‚Äî irf.varlse","title":"Impulse Response Analysis ‚Äî irf.varlse","text":"Computes responses impulses orthogonal impulses","code":""},{"path":"/dev/reference/irf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Impulse Response Analysis ‚Äî irf.varlse","text":"","code":"# S3 method for class 'varlse' irf(object, lag_max = 10, orthogonal = TRUE, impulse_var, response_var, ...)  # S3 method for class 'vharlse' irf(object, lag_max = 10, orthogonal = TRUE, impulse_var, response_var, ...)  # S3 method for class 'bvharirf' print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  irf(object, lag_max, orthogonal, impulse_var, response_var, ...)  is.bvharirf(x)  # S3 method for class 'bvharirf' knit_print(x, ...)"},{"path":"/dev/reference/irf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Impulse Response Analysis ‚Äî irf.varlse","text":"object Model object lag_max Maximum lag investigate impulse responses (default, 10) orthogonal Orthogonal impulses (TRUE) just impulses (FALSE) impulse_var Impulse variables character vector. specified, use every variable. response_var Response variables character vector. specified, use every variable. ... used x object digits digit option print","code":""},{"path":"/dev/reference/irf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Impulse Response Analysis ‚Äî irf.varlse","text":"bvharirf class","code":""},{"path":"/dev/reference/irf.html","id":"responses-to-forecast-errors","dir":"Reference","previous_headings":"","what":"Responses to forecast errors","title":"Impulse Response Analysis ‚Äî irf.varlse","text":"orthogonal = FALSE, function gives \\(W_j\\) VMA representation process $$Y_t = \\sum_{j = 0}^\\infty W_j \\epsilon_{t - j}$$","code":""},{"path":"/dev/reference/irf.html","id":"responses-to-orthogonal-impulses","dir":"Reference","previous_headings":"","what":"Responses to orthogonal impulses","title":"Impulse Response Analysis ‚Äî irf.varlse","text":"orthogonal = TRUE, gives orthogonalized VMA representation $$\\Theta$$. Based variance decomposition (Cholesky decomposition) $$\\Sigma = P P^T$$ \\(P\\) lower triangular matrix, impulse response analysis performed MA representation $$y_t = \\sum_{= 0}^\\infty \\Theta_i v_{t - }$$ , $$\\Theta_i = W_i P$$ \\(v_t = P^{-1} \\epsilon_t\\) orthogonal.","code":""},{"path":"/dev/reference/irf.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Impulse Response Analysis ‚Äî irf.varlse","text":"L√ºtkepohl, H. (2007). New Introduction Multiple Time Series Analysis. Springer Publishing.","code":""},{"path":[]},{"path":"/dev/reference/is.stable.html","id":null,"dir":"Reference","previous_headings":"","what":"Stability of the process ‚Äî is.stable","title":"Stability of the process ‚Äî is.stable","text":"Check stability condition coefficient matrix.","code":""},{"path":"/dev/reference/is.stable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stability of the process ‚Äî is.stable","text":"","code":"is.stable(x, ...)  # S3 method for class 'varlse' is.stable(x, ...)  # S3 method for class 'vharlse' is.stable(x, ...)  # S3 method for class 'bvarmn' is.stable(x, ...)  # S3 method for class 'bvarflat' is.stable(x, ...)  # S3 method for class 'bvharmn' is.stable(x, ...)"},{"path":"/dev/reference/is.stable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stability of the process ‚Äî is.stable","text":"x Model fit ... used","code":""},{"path":"/dev/reference/is.stable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stability of the process ‚Äî is.stable","text":"logical class logical class","code":""},{"path":"/dev/reference/is.stable.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Stability of the process ‚Äî is.stable","text":"VAR(p) stable $$\\det(I_m - z) \\neq 0$$ \\(\\lvert z \\rvert \\le 1\\).","code":""},{"path":"/dev/reference/is.stable.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Stability of the process ‚Äî is.stable","text":"L√ºtkepohl, H. (2007). New Introduction Multiple Time Series Analysis. Springer Publishing.","code":""},{"path":"/dev/reference/mae.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Model Based on MAE (Mean Absolute Error) ‚Äî mae","title":"Evaluate the Model Based on MAE (Mean Absolute Error) ‚Äî mae","text":"function computes MAE given prediction result versus evaluation set.","code":""},{"path":"/dev/reference/mae.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Model Based on MAE (Mean Absolute Error) ‚Äî mae","text":"","code":"mae(x, y, ...)  # S3 method for class 'predbvhar' mae(x, y, ...)  # S3 method for class 'bvharcv' mae(x, y, ...)"},{"path":"/dev/reference/mae.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Model Based on MAE (Mean Absolute Error) ‚Äî mae","text":"x Forecasting object y Test data compared. format train data. ... used","code":""},{"path":"/dev/reference/mae.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Model Based on MAE (Mean Absolute Error) ‚Äî mae","text":"MAE vector corressponding variable.","code":""},{"path":"/dev/reference/mae.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Model Based on MAE (Mean Absolute Error) ‚Äî mae","text":"Let \\(e_t = y_t - \\hat{y}_t\\). MAE defined $$MSE = mean(\\lvert e_t \\rvert)$$ researchers prefer MAE MSE less sensitive outliers.","code":""},{"path":"/dev/reference/mae.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Model Based on MAE (Mean Absolute Error) ‚Äî mae","text":"Hyndman, R. J., & Koehler, . B. (2006). Another look measures forecast accuracy. International Journal Forecasting, 22(4), 679-688.","code":""},{"path":"/dev/reference/mape.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Model Based on MAPE (Mean Absolute Percentage Error) ‚Äî mape","title":"Evaluate the Model Based on MAPE (Mean Absolute Percentage Error) ‚Äî mape","text":"function computes MAPE given prediction result versus evaluation set.","code":""},{"path":"/dev/reference/mape.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Model Based on MAPE (Mean Absolute Percentage Error) ‚Äî mape","text":"","code":"mape(x, y, ...)  # S3 method for class 'predbvhar' mape(x, y, ...)  # S3 method for class 'bvharcv' mape(x, y, ...)"},{"path":"/dev/reference/mape.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Model Based on MAPE (Mean Absolute Percentage Error) ‚Äî mape","text":"x Forecasting object y Test data compared. format train data. ... used","code":""},{"path":"/dev/reference/mape.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Model Based on MAPE (Mean Absolute Percentage Error) ‚Äî mape","text":"MAPE vector corresponding variable.","code":""},{"path":"/dev/reference/mape.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Model Based on MAPE (Mean Absolute Percentage Error) ‚Äî mape","text":"Let \\(e_t = y_t - \\hat{y}_t\\). Percentage error defined \\(p_t = 100 e_t / Y_t\\) (100 can omitted since comparison focus). $$MAPE = mean(\\lvert p_t \\rvert)$$","code":""},{"path":"/dev/reference/mape.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Model Based on MAPE (Mean Absolute Percentage Error) ‚Äî mape","text":"Hyndman, R. J., & Koehler, . B. (2006). Another look measures forecast accuracy. International Journal Forecasting, 22(4), 679-688.","code":""},{"path":"/dev/reference/mase.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Model Based on MASE (Mean Absolute Scaled Error) ‚Äî mase","title":"Evaluate the Model Based on MASE (Mean Absolute Scaled Error) ‚Äî mase","text":"function computes MASE given prediction result versus evaluation set.","code":""},{"path":"/dev/reference/mase.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Model Based on MASE (Mean Absolute Scaled Error) ‚Äî mase","text":"","code":"mase(x, y, ...)  # S3 method for class 'predbvhar' mase(x, y, ...)  # S3 method for class 'bvharcv' mase(x, y, ...)"},{"path":"/dev/reference/mase.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Model Based on MASE (Mean Absolute Scaled Error) ‚Äî mase","text":"x Forecasting object y Test data compared. format train data. ... used","code":""},{"path":"/dev/reference/mase.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Model Based on MASE (Mean Absolute Scaled Error) ‚Äî mase","text":"MASE vector corresponding variable.","code":""},{"path":"/dev/reference/mase.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Model Based on MASE (Mean Absolute Scaled Error) ‚Äî mase","text":"Let \\(e_t = y_t - \\hat{y}_t\\). Scaled error defined $$q_t = \\frac{e_t}{\\sum_{= 2}^{n} \\lvert Y_i - Y_{- 1} \\rvert / (n - 1)}$$ error can free data scale. $$MASE = mean(\\lvert q_t \\rvert)$$ , \\(Y_i\\) points sample, .e. errors scaled -sample mean absolute error (\\(mean(\\lvert e_t \\rvert)\\)) naive random walk forecasting.","code":""},{"path":"/dev/reference/mase.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Model Based on MASE (Mean Absolute Scaled Error) ‚Äî mase","text":"Hyndman, R. J., & Koehler, . B. (2006). Another look measures forecast accuracy. International Journal Forecasting, 22(4), 679-688.","code":""},{"path":"/dev/reference/mrae.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Model Based on MRAE (Mean Relative Absolute Error) ‚Äî mrae","title":"Evaluate the Model Based on MRAE (Mean Relative Absolute Error) ‚Äî mrae","text":"function computes MRAE given prediction result versus evaluation set.","code":""},{"path":"/dev/reference/mrae.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Model Based on MRAE (Mean Relative Absolute Error) ‚Äî mrae","text":"","code":"mrae(x, pred_bench, y, ...)  # S3 method for class 'predbvhar' mrae(x, pred_bench, y, ...)  # S3 method for class 'bvharcv' mrae(x, pred_bench, y, ...)"},{"path":"/dev/reference/mrae.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Model Based on MRAE (Mean Relative Absolute Error) ‚Äî mrae","text":"x Forecasting object use pred_bench forecasting object benchmark model y Test data compared. format train data. ... used","code":""},{"path":"/dev/reference/mrae.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Model Based on MRAE (Mean Relative Absolute Error) ‚Äî mrae","text":"MRAE vector corresponding variable.","code":""},{"path":"/dev/reference/mrae.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Model Based on MRAE (Mean Relative Absolute Error) ‚Äî mrae","text":"Let \\(e_t = y_t - \\hat{y}_t\\). MRAE implements benchmark model scaling method. Relative error defined $$r_t = \\frac{e_t}{e_t^{\\ast}}$$ \\(e_t^\\ast\\) error benchmark method. $$MRAE = mean(\\lvert r_t \\rvert)$$","code":""},{"path":"/dev/reference/mrae.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Model Based on MRAE (Mean Relative Absolute Error) ‚Äî mrae","text":"Hyndman, R. J., & Koehler, . B. (2006). Another look measures forecast accuracy. International Journal Forecasting, 22(4), 679-688.","code":""},{"path":"/dev/reference/mse.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Model Based on MSE (Mean Square Error) ‚Äî mse","title":"Evaluate the Model Based on MSE (Mean Square Error) ‚Äî mse","text":"function computes MSE given prediction result versus evaluation set.","code":""},{"path":"/dev/reference/mse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Model Based on MSE (Mean Square Error) ‚Äî mse","text":"","code":"mse(x, y, ...)  # S3 method for class 'predbvhar' mse(x, y, ...)  # S3 method for class 'bvharcv' mse(x, y, ...)"},{"path":"/dev/reference/mse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Model Based on MSE (Mean Square Error) ‚Äî mse","text":"x Forecasting object y Test data compared. format train data. ... used","code":""},{"path":"/dev/reference/mse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Model Based on MSE (Mean Square Error) ‚Äî mse","text":"MSE vector corresponding variable.","code":""},{"path":"/dev/reference/mse.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Model Based on MSE (Mean Square Error) ‚Äî mse","text":"Let \\(e_t = y_t - \\hat{y}_t\\). $$MSE = mean(e_t^2)$$ MSE used accuracy measure.","code":""},{"path":"/dev/reference/mse.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Model Based on MSE (Mean Square Error) ‚Äî mse","text":"Hyndman, R. J., & Koehler, . B. (2006). Another look measures forecast accuracy. International Journal Forecasting, 22(4), 679-688.","code":""},{"path":"/dev/reference/predict.html","id":null,"dir":"Reference","previous_headings":"","what":"Forecasting Multivariate Time Series ‚Äî predict","title":"Forecasting Multivariate Time Series ‚Äî predict","text":"Forecasts multivariate time series using given model.","code":""},{"path":"/dev/reference/predict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forecasting Multivariate Time Series ‚Äî predict","text":"","code":"# S3 method for class 'varlse' predict(object, n_ahead, level = 0.05, newxreg, ...)  # S3 method for class 'vharlse' predict(object, n_ahead, level = 0.05, newxreg, ...)  # S3 method for class 'bvarmn' predict(object, n_ahead, n_iter = 100L, level = 0.05, num_thread = 1, ...)  # S3 method for class 'bvharmn' predict(object, n_ahead, n_iter = 100L, level = 0.05, num_thread = 1, ...)  # S3 method for class 'bvarflat' predict(object, n_ahead, n_iter = 100L, level = 0.05, num_thread = 1, ...)  # S3 method for class 'bvarldlt' predict(   object,   n_ahead,   level = 0.05,   newxreg,   stable = FALSE,   num_thread = 1,   sparse = FALSE,   med = FALSE,   warn = FALSE,   ... )  # S3 method for class 'bvharldlt' predict(   object,   n_ahead,   level = 0.05,   newxreg,   stable = FALSE,   num_thread = 1,   sparse = FALSE,   med = FALSE,   warn = FALSE,   ... )  # S3 method for class 'bvarsv' predict(   object,   n_ahead,   level = 0.05,   newxreg,   stable = FALSE,   num_thread = 1,   use_sv = TRUE,   sparse = FALSE,   med = FALSE,   warn = FALSE,   ... )  # S3 method for class 'bvharsv' predict(   object,   n_ahead,   level = 0.05,   newxreg,   stable = FALSE,   num_thread = 1,   use_sv = TRUE,   sparse = FALSE,   med = FALSE,   warn = FALSE,   ... )  # S3 method for class 'predbvhar' print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  is.predbvhar(x)  # S3 method for class 'predbvhar' knit_print(x, ...)"},{"path":"/dev/reference/predict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forecasting Multivariate Time Series ‚Äî predict","text":"object Model object n_ahead step forecast level Specify alpha confidence interval level 100(1 - alpha) percentage. default, .05. newxreg New values exogenous variables. row numbers n_ahead. ... used n_iter Number sample residual matrix inverse-wishart distribution. default, 100. num_thread Number threads stable Filter stable coefficient draws MCMC records. sparse Apply restriction. default, FALSE. Give CI level (e.g. .05) instead TRUE use credible interval across MCMC restriction. med TRUE, use median forecast draws instead mean (default). warn Give warning stability coefficients record. default, FALSE. use_sv Use SV term x object digits digit option print","code":""},{"path":"/dev/reference/predict.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Forecasting Multivariate Time Series ‚Äî predict","text":"predbvhar class following components: process object$process forecast forecast matrix se standard error matrix lower lower confidence interval upper upper confidence interval lower_joint lower CI adjusted (Bonferroni) upper_joint upper CI adjusted (Bonferroni) y object$y","code":""},{"path":"/dev/reference/predict.html","id":"n-step-ahead-forecasting-var-p-","dir":"Reference","previous_headings":"","what":"n-step ahead forecasting VAR(p)","title":"Forecasting Multivariate Time Series ‚Äî predict","text":"See pp35 L√ºtkepohl (2007). Consider h-step ahead forecasting (e.g. n + 1, ... n + h). Let \\(y_{(n)}^T = (y_n^T, ..., y_{n - p + 1}^T, 1)\\). one-step ahead (point) forecasting: $$\\hat{y}_{n + 1}^T = y_{(n)}^T \\hat{B}$$ Recursively, let \\(\\hat{y}_{(n + 1)}^T = (\\hat{y}_{n + 1}^T, y_n^T, ..., y_{n - p + 2}^T, 1)\\). two-step ahead (point) forecasting: $$\\hat{y}_{n + 2}^T = \\hat{y}_{(n + 1)}^T \\hat{B}$$ Similarly, h-step ahead (point) forecasting: $$\\hat{y}_{n + h}^T = \\hat{y}_{(n + h - 1)}^T \\hat{B}$$ confident region? Confidence interval h-period $$y_{k,t}(h) \\pm z_(\\alpha / 2) \\sigma_k (h)$$ Joint forecast region \\(100(1-\\alpha)\\)% can computed $$\\{ (y_{k, 1}, y_{k, h}) \\mid y_{k, n}() - z_{(\\alpha / 2h)} \\sigma_n() \\le y_{n, } \\le y_{k, n}() + z_{(\\alpha / 2h)} \\sigma_k(), = 1, \\ldots, h \\}$$ See pp41 L√ºtkepohl (2007). compute covariance matrix, needs VMA representation: $$Y_{t}(h) = c + \\sum_{= h}^{\\infty} W_{} \\epsilon_{t + h - } = c + \\sum_{= 0}^{\\infty} W_{h + } \\epsilon_{t - }$$ $$\\Sigma_y(h) = MSE [ y_t(h) ] = \\sum_{= 0}^{h - 1} W_i \\Sigma_{\\epsilon} W_i^T = \\Sigma_y(h - 1) + W_{h - 1} \\Sigma_{\\epsilon} W_{h - 1}^T$$","code":""},{"path":"/dev/reference/predict.html","id":"n-step-ahead-forecasting-vhar","dir":"Reference","previous_headings":"","what":"n-step ahead forecasting VHAR","title":"Forecasting Multivariate Time Series ‚Äî predict","text":"Let \\(T_{HAR}\\) VHAR linear transformation matrix. Since VHAR linearly transformed VAR(22), let \\(y_{(n)}^T = (y_n^T, y_{n - 1}^T, ..., y_{n - 21}^T, 1)\\). one-step ahead (point) forecasting: $$\\hat{y}_{n + 1}^T = y_{(n)}^T T_{HAR} \\hat{\\Phi}$$ Recursively, let \\(\\hat{y}_{(n + 1)}^T = (\\hat{y}_{n + 1}^T, y_n^T, ..., y_{n - 20}^T, 1)\\). two-step ahead (point) forecasting: $$\\hat{y}_{n + 2}^T = \\hat{y}_{(n + 1)}^T T_{HAR} \\hat{\\Phi}$$ h-step ahead (point) forecasting: $$\\hat{y}_{n + h}^T = \\hat{y}_{(n + h - 1)}^T T_{HAR} \\hat{\\Phi}$$","code":""},{"path":"/dev/reference/predict.html","id":"n-step-ahead-forecasting-bvar-p-with-minnesota-prior","dir":"Reference","previous_headings":"","what":"n-step ahead forecasting BVAR(p) with minnesota prior","title":"Forecasting Multivariate Time Series ‚Äî predict","text":"Point forecasts computed posterior mean parameters. See Section 3 Ba≈Ñbura et al. (2010). Let \\(\\hat{B}\\) posterior MN mean let \\(\\hat{V}\\) posterior MN precision. predictive posterior step $$y_{n + 1} \\mid \\Sigma_e, y \\sim N( vec(y_{(n)}^T ), \\Sigma_e \\otimes (1 + y_{(n)}^T \\hat{V}^{-1} y_{(n)}) )$$ $$y_{n + 2} \\mid \\Sigma_e, y \\sim N( vec(\\hat{y}_{(n + 1)}^T ), \\Sigma_e \\otimes (1 + \\hat{y}_{(n + 1)}^T \\hat{V}^{-1} \\hat{y}_{(n + 1)}) )$$ recursively, $$y_{n + h} \\mid \\Sigma_e, y \\sim N( vec(\\hat{y}_{(n + h - 1)}^T ), \\Sigma_e \\otimes (1 + \\hat{y}_{(n + h - 1)}^T \\hat{V}^{-1} \\hat{y}_{(n + h - 1)}) )$$","code":""},{"path":"/dev/reference/predict.html","id":"n-step-ahead-forecasting-bvhar","dir":"Reference","previous_headings":"","what":"n-step ahead forecasting BVHAR","title":"Forecasting Multivariate Time Series ‚Äî predict","text":"Let \\(\\hat\\Phi\\) posterior MN mean let \\(\\hat\\Psi\\) posterior MN precision. predictive posterior step $$y_{n + 1} \\mid \\Sigma_e, y \\sim N( vec(y_{(n)}^T \\tilde{T}^T \\Phi), \\Sigma_e \\otimes (1 + y_{(n)}^T \\tilde{T} \\hat\\Psi^{-1} \\tilde{T} y_{(n)}) )$$ $$y_{n + 2} \\mid \\Sigma_e, y \\sim N( vec(y_{(n + 1)}^T \\tilde{T}^T \\Phi), \\Sigma_e \\otimes (1 + y_{(n + 1)}^T \\tilde{T} \\hat\\Psi^{-1} \\tilde{T} y_{(n + 1)}) )$$ recursively, $$y_{n + h} \\mid \\Sigma_e, y \\sim N( vec(y_{(n + h - 1)}^T \\tilde{T}^T \\Phi), \\Sigma_e \\otimes (1 + y_{(n + h - 1)}^T \\tilde{T} \\hat\\Psi^{-1} \\tilde{T} y_{(n + h - 1)}) )$$","code":""},{"path":"/dev/reference/predict.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Forecasting Multivariate Time Series ‚Äî predict","text":"L√ºtkepohl, H. (2007). New Introduction Multiple Time Series Analysis. Springer Publishing. Corsi, F. (2008). Simple Approximate Long-Memory Model Realized Volatility. Journal Financial Econometrics, 7(2), 174-196. Baek, C. Park, M. (2021). Sparse vector heterogeneous autoregressive modeling realized volatility. J. Korean Stat. Soc. 50, 495-510. Ba≈Ñbura, M., Giannone, D., & Reichlin, L. (2010). Large Bayesian vector auto regressions. Journal Applied Econometrics, 25(1). Gelman, ., Carlin, J. B., Stern, H. S., & Rubin, D. B. (2013). Bayesian data analysis. Chapman Hall/CRC. Karlsson, S. (2013). Chapter 15 Forecasting Bayesian Vector Autoregression. Handbook Economic Forecasting, 2, 791-897. Litterman, R. B. (1986). Forecasting Bayesian Vector Autoregressions: Five Years Experience. Journal Business & Economic Statistics, 4(1), 25. Ghosh, S., Khare, K., & Michailidis, G. (2018). High-Dimensional Posterior Consistency Bayesian Vector Autoregressive Models. Journal American Statistical Association, 114(526). Korobilis, D. (2013). VAR FORECASTING USING BAYESIAN VARIABLE SELECTION. Journal Applied Econometrics, 28(2). Korobilis, D. (2013). VAR FORECASTING USING BAYESIAN VARIABLE SELECTION. Journal Applied Econometrics, 28(2). Huber, F., Koop, G., & Onorante, L. (2021). Inducing Sparsity Shrinkage Time-Varying Parameter Models. Journal Business & Economic Statistics, 39(3), 669-683.","code":""},{"path":"/dev/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages ‚Äî reexports","title":"Objects exported from other packages ‚Äî reexports","text":"objects imported packages. Follow links see documentation. ggplot2 autolayer, autoplot","code":""},{"path":"/dev/reference/relmae.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Model Based on RelMAE (Relative MAE) ‚Äî relmae","title":"Evaluate the Model Based on RelMAE (Relative MAE) ‚Äî relmae","text":"function computes RelMAE given prediction result versus evaluation set.","code":""},{"path":"/dev/reference/relmae.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Model Based on RelMAE (Relative MAE) ‚Äî relmae","text":"","code":"relmae(x, pred_bench, y, ...)  # S3 method for class 'predbvhar' relmae(x, pred_bench, y, ...)  # S3 method for class 'bvharcv' relmae(x, pred_bench, y, ...)"},{"path":"/dev/reference/relmae.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Model Based on RelMAE (Relative MAE) ‚Äî relmae","text":"x Forecasting object use pred_bench forecasting object benchmark model y Test data compared. format train data. ... used","code":""},{"path":"/dev/reference/relmae.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Model Based on RelMAE (Relative MAE) ‚Äî relmae","text":"RelMAE vector corresponding variable.","code":""},{"path":"/dev/reference/relmae.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Model Based on RelMAE (Relative MAE) ‚Äî relmae","text":"Let \\(e_t = y_t - \\hat{y}_t\\). RelMAE implements MAE benchmark model relative measures. Let \\(MAE_b\\) MAE benchmark model. $$RelMAE = \\frac{MAE}{MAE_b}$$ \\(MAE\\) MAE model.","code":""},{"path":"/dev/reference/relmae.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Model Based on RelMAE (Relative MAE) ‚Äî relmae","text":"Hyndman, R. J., & Koehler, . B. (2006). Another look measures forecast accuracy. International Journal Forecasting, 22(4), 679-688.","code":""},{"path":"/dev/reference/relspne.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Estimation Based on Relative Spectral Norm Error ‚Äî relspne","title":"Evaluate the Estimation Based on Relative Spectral Norm Error ‚Äî relspne","text":"function computes relative estimation error given estimated model true coefficient.","code":""},{"path":"/dev/reference/relspne.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Estimation Based on Relative Spectral Norm Error ‚Äî relspne","text":"","code":"relspne(x, y, ...)  # S3 method for class 'bvharsp' relspne(x, y, ...)"},{"path":"/dev/reference/relspne.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Estimation Based on Relative Spectral Norm Error ‚Äî relspne","text":"x Estimated model. y Coefficient matrix compared. ... used","code":""},{"path":"/dev/reference/relspne.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Estimation Based on Relative Spectral Norm Error ‚Äî relspne","text":"Spectral norm value","code":""},{"path":"/dev/reference/relspne.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Estimation Based on Relative Spectral Norm Error ‚Äî relspne","text":"Let \\(\\lVert \\cdot \\rVert_2\\) spectral norm matrix, let \\(\\hat{\\Phi}\\) estimates, let \\(\\Phi\\) true coefficients matrix. function computes relative estimation error $$\\frac{\\lVert \\hat{\\Phi} - \\Phi \\rVert_2}{\\lVert \\Phi \\rVert_2}$$","code":""},{"path":"/dev/reference/relspne.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Estimation Based on Relative Spectral Norm Error ‚Äî relspne","text":"Ghosh, S., Khare, K., & Michailidis, G. (2018). High-Dimensional Posterior Consistency Bayesian Vector Autoregressive Models. Journal American Statistical Association, 114(526).","code":""},{"path":"/dev/reference/residuals.html","id":null,"dir":"Reference","previous_headings":"","what":"Residual Matrix from Multivariate Time Series Models ‚Äî residuals","title":"Residual Matrix from Multivariate Time Series Models ‚Äî residuals","text":"defining stats::residuals() model, function returns residual.","code":""},{"path":"/dev/reference/residuals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Residual Matrix from Multivariate Time Series Models ‚Äî residuals","text":"","code":"# S3 method for class 'varlse' residuals(object, ...)  # S3 method for class 'vharlse' residuals(object, ...)  # S3 method for class 'bvarmn' residuals(object, ...)  # S3 method for class 'bvarflat' residuals(object, ...)  # S3 method for class 'bvharmn' residuals(object, ...)"},{"path":"/dev/reference/residuals.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Residual Matrix from Multivariate Time Series Models ‚Äî residuals","text":"object Model object ... used","code":""},{"path":"/dev/reference/residuals.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Residual Matrix from Multivariate Time Series Models ‚Äî residuals","text":"matrix object.","code":""},{"path":"/dev/reference/rmafe.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Model Based on RMAFE ‚Äî rmafe","title":"Evaluate the Model Based on RMAFE ‚Äî rmafe","text":"function computes RMAFE (Mean Absolute Forecast Error Relative Benchmark)","code":""},{"path":"/dev/reference/rmafe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Model Based on RMAFE ‚Äî rmafe","text":"","code":"rmafe(x, pred_bench, y, ...)  # S3 method for class 'predbvhar' rmafe(x, pred_bench, y, ...)  # S3 method for class 'bvharcv' rmafe(x, pred_bench, y, ...)"},{"path":"/dev/reference/rmafe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Model Based on RMAFE ‚Äî rmafe","text":"x Forecasting object use pred_bench forecasting object benchmark model y Test data compared. format train data. ... used","code":""},{"path":"/dev/reference/rmafe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Model Based on RMAFE ‚Äî rmafe","text":"RMAFE vector corresponding variable.","code":""},{"path":"/dev/reference/rmafe.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Model Based on RMAFE ‚Äî rmafe","text":"Let \\(e_t = y_t - \\hat{y}_t\\). RMAFE ratio L1 norm \\(e_t\\) forecasting object benchmark model. $$RMAFE = \\frac{sum(\\lVert e_t \\rVert)}{sum(\\lVert e_t^{(b)} \\rVert)}$$ \\(e_t^{(b)}\\) error benchmark model.","code":""},{"path":"/dev/reference/rmafe.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Model Based on RMAFE ‚Äî rmafe","text":"Hyndman, R. J., & Koehler, . B. (2006). Another look measures forecast accuracy. International Journal Forecasting, 22(4), 679-688. Ba≈Ñbura, M., Giannone, D., & Reichlin, L. (2010). Large Bayesian vector auto regressions. Journal Applied Econometrics, 25(1). Ghosh, S., Khare, K., & Michailidis, G. (2018). High-Dimensional Posterior Consistency Bayesian Vector Autoregressive Models. Journal American Statistical Association, 114(526).","code":""},{"path":"/dev/reference/rmape.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Model Based on RMAPE (Relative MAPE) ‚Äî rmape","title":"Evaluate the Model Based on RMAPE (Relative MAPE) ‚Äî rmape","text":"function computes RMAPE given prediction result versus evaluation set.","code":""},{"path":"/dev/reference/rmape.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Model Based on RMAPE (Relative MAPE) ‚Äî rmape","text":"","code":"rmape(x, pred_bench, y, ...)  # S3 method for class 'predbvhar' rmape(x, pred_bench, y, ...)  # S3 method for class 'bvharcv' rmape(x, pred_bench, y, ...)"},{"path":"/dev/reference/rmape.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Model Based on RMAPE (Relative MAPE) ‚Äî rmape","text":"x Forecasting object use pred_bench forecasting object benchmark model y Test data compared. format train data. ... used","code":""},{"path":"/dev/reference/rmape.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Model Based on RMAPE (Relative MAPE) ‚Äî rmape","text":"RMAPE vector corresponding variable.","code":""},{"path":"/dev/reference/rmape.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Model Based on RMAPE (Relative MAPE) ‚Äî rmape","text":"RMAPE ratio MAPE given model benchmark one. Let \\(MAPE_b\\) MAPE benchmark model. $$RMAPE = \\frac{mean(MAPE)}{mean(MAPE_b)}$$ \\(MAPE\\) MAPE model.","code":""},{"path":"/dev/reference/rmape.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Model Based on RMAPE (Relative MAPE) ‚Äî rmape","text":"Hyndman, R. J., & Koehler, . B. (2006). Another look measures forecast accuracy. International Journal Forecasting, 22(4), 679-688.","code":""},{"path":"/dev/reference/rmase.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Model Based on RMASE (Relative MASE) ‚Äî rmase","title":"Evaluate the Model Based on RMASE (Relative MASE) ‚Äî rmase","text":"function computes RMASE given prediction result versus evaluation set.","code":""},{"path":"/dev/reference/rmase.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Model Based on RMASE (Relative MASE) ‚Äî rmase","text":"","code":"rmase(x, pred_bench, y, ...)  # S3 method for class 'predbvhar' rmase(x, pred_bench, y, ...)  # S3 method for class 'bvharcv' rmase(x, pred_bench, y, ...)"},{"path":"/dev/reference/rmase.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Model Based on RMASE (Relative MASE) ‚Äî rmase","text":"x Forecasting object use pred_bench forecasting object benchmark model y Test data compared. format train data. ... used","code":""},{"path":"/dev/reference/rmase.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Model Based on RMASE (Relative MASE) ‚Äî rmase","text":"RMASE vector corresponding variable.","code":""},{"path":"/dev/reference/rmase.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Model Based on RMASE (Relative MASE) ‚Äî rmase","text":"RMASE ratio MAPE given model benchmark one. Let \\(MASE_b\\) MAPE benchmark model. $$RMASE = \\frac{mean(MASE)}{mean(MASE_b)}$$ \\(MASE\\) MASE model.","code":""},{"path":"/dev/reference/rmase.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Model Based on RMASE (Relative MASE) ‚Äî rmase","text":"Hyndman, R. J., & Koehler, . B. (2006). Another look measures forecast accuracy. International Journal Forecasting, 22(4), 679-688.","code":""},{"path":"/dev/reference/rmsfe.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Model Based on RMSFE ‚Äî rmsfe","title":"Evaluate the Model Based on RMSFE ‚Äî rmsfe","text":"function computes RMSFE (Mean Squared Forecast Error Relative Benchmark)","code":""},{"path":"/dev/reference/rmsfe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Model Based on RMSFE ‚Äî rmsfe","text":"","code":"rmsfe(x, pred_bench, y, ...)  # S3 method for class 'predbvhar' rmsfe(x, pred_bench, y, ...)  # S3 method for class 'bvharcv' rmsfe(x, pred_bench, y, ...)"},{"path":"/dev/reference/rmsfe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Model Based on RMSFE ‚Äî rmsfe","text":"x Forecasting object use pred_bench forecasting object benchmark model y Test data compared. format train data. ... used","code":""},{"path":"/dev/reference/rmsfe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Model Based on RMSFE ‚Äî rmsfe","text":"RMSFE vector corresponding variable.","code":""},{"path":"/dev/reference/rmsfe.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Model Based on RMSFE ‚Äî rmsfe","text":"Let \\(e_t = y_t - \\hat{y}_t\\). RMSFE ratio L2 norm \\(e_t\\) forecasting object benchmark model. $$RMSFE = \\frac{sum(\\lVert e_t \\rVert)}{sum(\\lVert e_t^{(b)} \\rVert)}$$ \\(e_t^{(b)}\\) error benchmark model.","code":""},{"path":"/dev/reference/rmsfe.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Model Based on RMSFE ‚Äî rmsfe","text":"Hyndman, R. J., & Koehler, . B. (2006). Another look measures forecast accuracy. International Journal Forecasting, 22(4), 679-688. Ba≈Ñbura, M., Giannone, D., & Reichlin, L. (2010). Large Bayesian vector auto regressions. Journal Applied Econometrics, 25(1). Ghosh, S., Khare, K., & Michailidis, G. (2018). High-Dimensional Posterior Consistency Bayesian Vector Autoregressive Models. Journal American Statistical Association, 114(526).","code":""},{"path":"/dev/reference/set_bvar.html","id":null,"dir":"Reference","previous_headings":"","what":"Hyperparameters for Bayesian Models ‚Äî set_bvar","title":"Hyperparameters for Bayesian Models ‚Äî set_bvar","text":"Set hyperparameters Bayesian VAR VHAR models.","code":""},{"path":"/dev/reference/set_bvar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hyperparameters for Bayesian Models ‚Äî set_bvar","text":"","code":"set_bvar(sigma, lambda = 0.1, delta, eps = 1e-04)  set_bvar_flat(U)  set_bvhar(sigma, lambda = 0.1, delta, eps = 1e-04)  set_weight_bvhar(sigma, lambda = 0.1, eps = 1e-04, daily, weekly, monthly)  # S3 method for class 'bvharspec' print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  is.bvharspec(x)  # S3 method for class 'bvharspec' knit_print(x, ...)"},{"path":"/dev/reference/set_bvar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hyperparameters for Bayesian Models ‚Äî set_bvar","text":"sigma Standard error vector variable (Default: sd) lambda Tightness prior around random walk white noise (Default: .1) delta Persistence (Default: Litterman sets 1 = random walk prior, White noise prior = 0) eps small number (Default: 1e-04) U Positive definite matrix. default, identity matrix dimension ncol(X0) daily delta VHAR type (Default: 1 Litterman) weekly Fill second part first block (Default: 1) monthly Fill third part first block (Default: 1) x object digits digit option print ... used","code":""},{"path":"/dev/reference/set_bvar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hyperparameters for Bayesian Models ‚Äî set_bvar","text":"Every function returns bvharspec class. list components arguments provided. argument specified, NULL assigned . default values mentioned considered fitting function. process Model name: BVAR, BVHAR prior Prior name: Minnesota (Minnesota prior BVAR), Hierarchical (Hierarchical prior BVAR), MN_VAR (BVHAR-S), MN_VHAR (BVHAR-L), Flat (Flat prior BVAR) sigma Vector value (bvharpriorspec class) assigned sigma lambda Value (bvharpriorspec class) assigned lambda delta Vector value assigned delta eps Value assigned epsilon set_weight_bvhar() different component delta due different construction. daily Vector value assigned daily weight weekly Vector value assigned weekly weight monthly Vector value assigned monthly weight","code":""},{"path":"/dev/reference/set_bvar.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Hyperparameters for Bayesian Models ‚Äî set_bvar","text":"Missing arguments set default values model function mentioned . set_bvar() sets hyperparameters bvar_minnesota(). delta (vector), lambda (length 1), sigma (vector), eps (vector) corresponds \\(\\delta_j\\), \\(\\lambda\\), \\(\\delta_j\\), \\(\\epsilon\\). \\(\\delta_i\\) related belief random walk. \\(\\delta_i = 1\\) , random walk prior \\(\\delta_i = 0\\) , white noise prior \\(\\lambda\\) controls overall tightness prior around two prior beliefs. \\(\\lambda = 0\\), posterior equivalent prior data influence estimates. \\(\\lambda = \\infty\\), posterior mean becomes OLS estimates (VAR). \\(\\sigma_i^2 / \\sigma_j^2\\) Minnesota moments explain data scales. set_bvar_flat sets hyperparameters bvar_flat(). set_bvhar() sets hyperparameters bvhar_minnesota() VAR-type Minnesota prior, .e. BVHAR-S model. set_weight_bvhar() sets hyperparameters bvhar_minnesota() VHAR-type Minnesota prior, .e. BVHAR-L model.","code":""},{"path":"/dev/reference/set_bvar.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Hyperparameters for Bayesian Models ‚Äî set_bvar","text":"using set_psi() set_lambda() , hierarchical modeling available.","code":""},{"path":"/dev/reference/set_bvar.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Hyperparameters for Bayesian Models ‚Äî set_bvar","text":"Ba≈Ñbura, M., Giannone, D., & Reichlin, L. (2010). Large Bayesian vector auto regressions. Journal Applied Econometrics, 25(1). Litterman, R. B. (1986). Forecasting Bayesian Vector Autoregressions: Five Years Experience. Journal Business & Economic Statistics, 4(1), 25. Ghosh, S., Khare, K., & Michailidis, G. (2018). High-Dimensional Posterior Consistency Bayesian Vector Autoregressive Models. Journal American Statistical Association, 114(526). Kim, Y. G., Baek, C. (2024). Bayesian vector heterogeneous autoregressive modeling. Journal Statistical Computation Simulation, 94(6), 1139-1157. Kim, Y. G., Baek, C. (2024). Bayesian vector heterogeneous autoregressive modeling. Journal Statistical Computation Simulation, 94(6), 1139-1157.","code":""},{"path":[]},{"path":"/dev/reference/set_bvar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hyperparameters for Bayesian Models ‚Äî set_bvar","text":"","code":"# Minnesota BVAR specification------------------------ bvar_spec <- set_bvar(   sigma = c(.03, .02, .01), # Sigma = diag(.03^2, .02^2, .01^2)   lambda = .2, # lambda = .2   delta = rep(.1, 3), # delta1 = .1, delta2 = .1, delta3 = .1   eps = 1e-04 # eps = 1e-04 ) class(bvar_spec) #> [1] \"bvharspec\" str(bvar_spec) #> List of 7 #>  $ process     : chr \"BVAR\" #>  $ prior       : chr \"Minnesota\" #>  $ sigma       : num [1:3] 0.03 0.02 0.01 #>  $ lambda      : num 0.2 #>  $ delta       : num [1:3] 0.1 0.1 0.1 #>  $ eps         : num 1e-04 #>  $ hierarchical: logi FALSE #>  - attr(*, \"class\")= chr \"bvharspec\" # Flat BVAR specification------------------------- # 3-dim # p = 5 with constant term # U = 500 * I(mp + 1) bvar_flat_spec <- set_bvar_flat(U = 500 * diag(16)) class(bvar_flat_spec) #> [1] \"bvharspec\" str(bvar_flat_spec) #> List of 3 #>  $ process: chr \"BVAR\" #>  $ prior  : chr \"Flat\" #>  $ U      : num [1:16, 1:16] 500 0 0 0 0 0 0 0 0 0 ... #>  - attr(*, \"class\")= chr \"bvharspec\" # BVHAR-S specification----------------------- bvhar_var_spec <- set_bvhar(   sigma = c(.03, .02, .01), # Sigma = diag(.03^2, .02^2, .01^2)   lambda = .2, # lambda = .2   delta = rep(.1, 3), # delta1 = .1, delta2 = .1, delta3 = .1   eps = 1e-04 # eps = 1e-04 ) class(bvhar_var_spec) #> [1] \"bvharspec\" str(bvhar_var_spec) #> List of 7 #>  $ process     : chr \"BVHAR\" #>  $ prior       : chr \"MN_VAR\" #>  $ sigma       : num [1:3] 0.03 0.02 0.01 #>  $ lambda      : num 0.2 #>  $ delta       : num [1:3] 0.1 0.1 0.1 #>  $ eps         : num 1e-04 #>  $ hierarchical: logi FALSE #>  - attr(*, \"class\")= chr \"bvharspec\" # BVHAR-L specification--------------------------- bvhar_vhar_spec <- set_weight_bvhar(   sigma = c(.03, .02, .01), # Sigma = diag(.03^2, .02^2, .01^2)   lambda = .2, # lambda = .2   eps = 1e-04, # eps = 1e-04   daily = rep(.2, 3), # daily1 = .2, daily2 = .2, daily3 = .2   weekly = rep(.1, 3), # weekly1 = .1, weekly2 = .1, weekly3 = .1   monthly = rep(.05, 3) # monthly1 = .05, monthly2 = .05, monthly3 = .05 ) class(bvhar_vhar_spec) #> [1] \"bvharspec\" str(bvhar_vhar_spec) #> List of 9 #>  $ process     : chr \"BVHAR\" #>  $ prior       : chr \"MN_VHAR\" #>  $ sigma       : num [1:3] 0.03 0.02 0.01 #>  $ lambda      : num 0.2 #>  $ eps         : num 1e-04 #>  $ daily       : num [1:3] 0.2 0.2 0.2 #>  $ weekly      : num [1:3] 0.1 0.1 0.1 #>  $ monthly     : num [1:3] 0.05 0.05 0.05 #>  $ hierarchical: logi FALSE #>  - attr(*, \"class\")= chr \"bvharspec\""},{"path":"/dev/reference/set_dl.html","id":null,"dir":"Reference","previous_headings":"","what":"Dirichlet-Laplace Hyperparameter for Coefficients and Contemporaneous Coefficients ‚Äî set_dl","title":"Dirichlet-Laplace Hyperparameter for Coefficients and Contemporaneous Coefficients ‚Äî set_dl","text":"Set DL hyperparameters VAR VHAR coefficient contemporaneous coefficient.","code":""},{"path":"/dev/reference/set_dl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dirichlet-Laplace Hyperparameter for Coefficients and Contemporaneous Coefficients ‚Äî set_dl","text":"","code":"set_dl(dir_grid = 100L, shape = 0.01, scale = 0.01)  # S3 method for class 'dlspec' print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  is.dlspec(x)"},{"path":"/dev/reference/set_dl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dirichlet-Laplace Hyperparameter for Coefficients and Contemporaneous Coefficients ‚Äî set_dl","text":"dir_grid Griddy gibbs grid size Dirichlet hyperparameter shape Inverse Gamma shape scale Inverse Gamma scale x object digits digit option print ... used","code":""},{"path":"/dev/reference/set_dl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Dirichlet-Laplace Hyperparameter for Coefficients and Contemporaneous Coefficients ‚Äî set_dl","text":"dlspec object","code":""},{"path":"/dev/reference/set_dl.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Dirichlet-Laplace Hyperparameter for Coefficients and Contemporaneous Coefficients ‚Äî set_dl","text":"Bhattacharya, ., Pati, D., Pillai, N. S., & Dunson, D. B. (2015). Dirichlet-Laplace Priors Optimal Shrinkage. Journal American Statistical Association, 110(512), 1479-1490. Korobilis, D., & Shimizu, K. (2022). Bayesian Approaches Shrinkage Sparse Estimation. Foundations Trends¬Æ Econometrics, 11(4), 230-354.","code":""},{"path":"/dev/reference/set_gdp.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized Double Pareto Shrinkage Hyperparameters for Coefficients and Contemporaneous Coefficients ‚Äî set_gdp","title":"Generalized Double Pareto Shrinkage Hyperparameters for Coefficients and Contemporaneous Coefficients ‚Äî set_gdp","text":"Set GDP hyperparameters VAR VHAR coefficient contemporaneous coefficient.","code":""},{"path":"/dev/reference/set_gdp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized Double Pareto Shrinkage Hyperparameters for Coefficients and Contemporaneous Coefficients ‚Äî set_gdp","text":"","code":"set_gdp(shape_grid = 100L, rate_grid = 100L)  is.gdpspec(x)"},{"path":"/dev/reference/set_gdp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized Double Pareto Shrinkage Hyperparameters for Coefficients and Contemporaneous Coefficients ‚Äî set_gdp","text":"shape_grid Griddy gibbs grid size Gamma shape hyperparameter rate_grid Griddy gibbs grid size Gamma rate hyperparameter x object","code":""},{"path":"/dev/reference/set_gdp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized Double Pareto Shrinkage Hyperparameters for Coefficients and Contemporaneous Coefficients ‚Äî set_gdp","text":"gdpspec object","code":""},{"path":"/dev/reference/set_gdp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generalized Double Pareto Shrinkage Hyperparameters for Coefficients and Contemporaneous Coefficients ‚Äî set_gdp","text":"Armagan, ., Dunson, D. B., & Lee, J. (2013). GENERALIZED DOUBLE PARETO SHRINKAGE. Statistica Sinica, 23(1), 119‚Äì143. Korobilis, D., & Shimizu, K. (2022). Bayesian Approaches Shrinkage Sparse Estimation. Foundations Trends¬Æ Econometrics, 11(4), 230-354.","code":""},{"path":"/dev/reference/set_horseshoe.html","id":null,"dir":"Reference","previous_headings":"","what":"Horseshoe Prior Specification ‚Äî set_horseshoe","title":"Horseshoe Prior Specification ‚Äî set_horseshoe","text":"Set initial hyperparameters parameter starting Gibbs sampler Horseshoe prior.","code":""},{"path":"/dev/reference/set_horseshoe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Horseshoe Prior Specification ‚Äî set_horseshoe","text":"","code":"set_horseshoe(local_sparsity = 1, group_sparsity = 1, global_sparsity = 1)  # S3 method for class 'horseshoespec' print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  is.horseshoespec(x)  # S3 method for class 'horseshoespec' knit_print(x, ...)"},{"path":"/dev/reference/set_horseshoe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Horseshoe Prior Specification ‚Äî set_horseshoe","text":"local_sparsity Initial local shrinkage hyperparameters group_sparsity Initial group shrinkage hyperparameters global_sparsity Initial global shrinkage hyperparameter x object digits digit option print ... used","code":""},{"path":"/dev/reference/set_horseshoe.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Horseshoe Prior Specification ‚Äî set_horseshoe","text":"Set horseshoe prior initialization VAR family. local_sparsity: Initial local shrinkage group_sparsity: Initial group shrinkage global_sparsity: Initial global shrinkage package, horseshoe prior model estimated Gibbs sampling, initial means initial values gibbs sampler.","code":""},{"path":"/dev/reference/set_horseshoe.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Horseshoe Prior Specification ‚Äî set_horseshoe","text":"Carvalho, C. M., Polson, N. G., & Scott, J. G. (2010). horseshoe estimator sparse signals. Biometrika, 97(2), 465-480. Makalic, E., & Schmidt, D. F. (2016). Simple Sampler Horseshoe Estimator. IEEE Signal Processing Letters, 23(1), 179-182.","code":""},{"path":"/dev/reference/set_intercept.html","id":null,"dir":"Reference","previous_headings":"","what":"Prior for Constant Term ‚Äî set_intercept","title":"Prior for Constant Term ‚Äî set_intercept","text":"Set Normal prior hyperparameters constant term","code":""},{"path":"/dev/reference/set_intercept.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prior for Constant Term ‚Äî set_intercept","text":"","code":"set_intercept(mean = 0, sd = 0.1)  # S3 method for class 'interceptspec' print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  is.interceptspec(x)  # S3 method for class 'interceptspec' knit_print(x, ...)"},{"path":"/dev/reference/set_intercept.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prior for Constant Term ‚Äî set_intercept","text":"mean Normal mean constant term sd Normal standard deviance constant term x object digits digit option print ... used","code":""},{"path":"/dev/reference/set_lambda.html","id":null,"dir":"Reference","previous_headings":"","what":"Hyperpriors for Bayesian Models ‚Äî set_lambda","title":"Hyperpriors for Bayesian Models ‚Äî set_lambda","text":"Set hyperpriors Bayesian VAR VHAR models.","code":""},{"path":"/dev/reference/set_lambda.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hyperpriors for Bayesian Models ‚Äî set_lambda","text":"","code":"set_lambda(   mode = 0.2,   sd = 0.4,   param = NULL,   lower = 1e-05,   upper = 3,   grid_size = 100L )  set_psi(shape = 4e-04, scale = 4e-04, lower = 1e-05, upper = 3)  # S3 method for class 'bvharpriorspec' print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  is.bvharpriorspec(x)  # S3 method for class 'bvharpriorspec' knit_print(x, ...)"},{"path":"/dev/reference/set_lambda.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hyperpriors for Bayesian Models ‚Äî set_lambda","text":"mode Mode Gamma distribution. default, .2. sd Standard deviation Gamma distribution. default, .4. param Shape rate Gamma distribution, form c(shape, rate). specified, ignore mode sd. lower Lower bound stats::optim(). default, 1e-5. upper Upper bound stats::optim(). default, 3. grid_size Griddy gibbs grid size lag scaling shape Shape Inverse Gamma distribution. default, (.02)^2. scale Scale Inverse Gamma distribution. default, (.02)^2. x object digits digit option print ... used","code":""},{"path":"/dev/reference/set_lambda.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hyperpriors for Bayesian Models ‚Äî set_lambda","text":"bvharpriorspec object","code":""},{"path":"/dev/reference/set_lambda.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Hyperpriors for Bayesian Models ‚Äî set_lambda","text":"addition Normal-IW priors set_bvar(), set_bvhar(), set_weight_bvhar(), functions give hierarchical structure model. set_lambda() specifies hyperprior \\(\\lambda\\) (lambda), Gamma distribution. set_psi() specifies hyperprior \\(\\psi / (\\nu_0 - k - 1) = \\sigma^2\\) (sigma), Inverse gamma distribution. following set (mode, sd) recommended Sims Zha (1998) set_lambda(). (mode = .2, sd = .4): default (mode = 1, sd = 1) Giannone et al. (2015) suggested data-based selection set_psi(). chooses (0.02)^2 based empirical data set.","code":""},{"path":"/dev/reference/set_lambda.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Hyperpriors for Bayesian Models ‚Äî set_lambda","text":"Giannone, D., Lenza, M., & Primiceri, G. E. (2015). Prior Selection Vector Autoregressions. Review Economics Statistics, 97(2).","code":""},{"path":"/dev/reference/set_lambda.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hyperpriors for Bayesian Models ‚Äî set_lambda","text":"","code":"# Hirearchical BVAR specification------------------------ set_bvar(   sigma = set_psi(shape = 4e-4, scale = 4e-4),   lambda = set_lambda(mode = .2, sd = .4),   delta = rep(1, 3),   eps = 1e-04 # eps = 1e-04 ) #> Model Specification for BVAR #>  #> Parameters: Coefficent matrice and Covariance matrix #> Prior: MN_Hierarchical #> ======================================================== #>  #> Setting for 'sigma': #> Hyperprior specification for psi #>  #> [1]  psi ~ Inv-Gamma(shape = 4e-04, scale =4e-04) #>  #> Setting for 'lambda': #> Hyperprior specification for lambda #>  #> [1]  lambda ~ Gamma(shape = 1.64038820320221, rate =3.20194101601104) #>  #> Setting for 'delta': #> [1]  1  1  1 #>  #> Setting for 'eps': #> [1]  1e-04 #>  #> Setting for 'hierarchical': #> [1]  TRUE #>"},{"path":"/dev/reference/set_ldlt.html","id":null,"dir":"Reference","previous_headings":"","what":"Covariance Matrix Prior Specification ‚Äî set_ldlt","title":"Covariance Matrix Prior Specification ‚Äî set_ldlt","text":"Set prior covariance matrix.","code":""},{"path":"/dev/reference/set_ldlt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Covariance Matrix Prior Specification ‚Äî set_ldlt","text":"","code":"set_ldlt(ig_shape = 3, ig_scl = 0.01)  set_sv(ig_shape = 3, ig_scl = 0.01, initial_mean = 1, initial_prec = 0.1)  # S3 method for class 'covspec' print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  is.covspec(x)  is.svspec(x)  is.ldltspec(x)"},{"path":"/dev/reference/set_ldlt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Covariance Matrix Prior Specification ‚Äî set_ldlt","text":"ig_shape Inverse-Gamma shape Cholesky diagonal vector. SV (set_sv()), state variance. ig_scl Inverse-Gamma scale Cholesky diagonal vector. SV (set_sv()), state variance. initial_mean Prior mean initial state. initial_prec Prior precision initial state. x object digits digit option print ... used","code":""},{"path":"/dev/reference/set_ldlt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Covariance Matrix Prior Specification ‚Äî set_ldlt","text":"set_ldlt() specifies LDLT precision matrix, $$\\Sigma^{-1} = L^T D^{-1} L$$ set_sv() specifices time varying precision matrix stochastic volatility framework based $$\\Sigma_t^{-1} = L^T D_t^{-1} L$$","code":""},{"path":"/dev/reference/set_ldlt.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Covariance Matrix Prior Specification ‚Äî set_ldlt","text":"Carriero, ., Chan, J., Clark, T. E., & Marcellino, M. (2022). Corrigendum ‚ÄúLarge Bayesian vector autoregressions stochastic volatility non-conjugate priors‚Äù [J. Econometrics 212 (1)(2019) 137-154]. Journal Econometrics, 227(2), 506-512. Chan, J., Koop, G., Poirier, D., & Tobias, J. (2019). Bayesian Econometric Methods (2nd ed., Econometric Exercises). Cambridge: Cambridge University Press.","code":""},{"path":"/dev/reference/set_ng.html","id":null,"dir":"Reference","previous_headings":"","what":"Normal-Gamma Hyperparameter for Coefficients and Contemporaneous Coefficients ‚Äî set_ng","title":"Normal-Gamma Hyperparameter for Coefficients and Contemporaneous Coefficients ‚Äî set_ng","text":"Set NG hyperparameters VAR VHAR coefficient contemporaneous coefficient.","code":""},{"path":"/dev/reference/set_ng.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normal-Gamma Hyperparameter for Coefficients and Contemporaneous Coefficients ‚Äî set_ng","text":"","code":"set_ng(   shape_sd = 0.01,   group_shape = 0.01,   group_scale = 0.01,   global_shape = 0.01,   global_scale = 0.01 )  # S3 method for class 'ngspec' print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  is.ngspec(x)"},{"path":"/dev/reference/set_ng.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normal-Gamma Hyperparameter for Coefficients and Contemporaneous Coefficients ‚Äî set_ng","text":"shape_sd Standard deviation used MH Gamma shape group_shape Inverse gamma prior shape coefficient group shrinkage group_scale Inverse gamma prior scale coefficient group shrinkage global_shape Inverse gamma prior shape coefficient global shrinkage global_scale Inverse gamma prior scale coefficient global shrinkage x object digits digit option print ... used","code":""},{"path":"/dev/reference/set_ng.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normal-Gamma Hyperparameter for Coefficients and Contemporaneous Coefficients ‚Äî set_ng","text":"ngspec object","code":""},{"path":"/dev/reference/set_ng.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Normal-Gamma Hyperparameter for Coefficients and Contemporaneous Coefficients ‚Äî set_ng","text":"Chan, J. C. C. (2021). Minnesota-type adaptive hierarchical priors large Bayesian VARs. International Journal Forecasting, 37(3), 1212-1226. Huber, F., & Feldkircher, M. (2019). Adaptive Shrinkage Bayesian Vector Autoregressive Models. Journal Business & Economic Statistics, 37(1), 27-39. Korobilis, D., & Shimizu, K. (2022). Bayesian Approaches Shrinkage Sparse Estimation. Foundations Trends¬Æ Econometrics, 11(4), 230-354.","code":""},{"path":"/dev/reference/set_ssvs.html","id":null,"dir":"Reference","previous_headings":"","what":"Stochastic Search Variable Selection (SSVS) Hyperparameter for Coefficients Matrix and Cholesky Factor ‚Äî set_ssvs","title":"Stochastic Search Variable Selection (SSVS) Hyperparameter for Coefficients Matrix and Cholesky Factor ‚Äî set_ssvs","text":"Set SSVS hyperparameters VAR VHAR coefficient matrix Cholesky factor.","code":""},{"path":"/dev/reference/set_ssvs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stochastic Search Variable Selection (SSVS) Hyperparameter for Coefficients Matrix and Cholesky Factor ‚Äî set_ssvs","text":"","code":"set_ssvs(   spike_grid = 100L,   slab_shape = 0.01,   slab_scl = 0.01,   s1 = c(1, 1),   s2 = c(1, 1),   shape = 0.01,   rate = 0.01 )  # S3 method for class 'ssvsinput' print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  is.ssvsinput(x)  # S3 method for class 'ssvsinput' knit_print(x, ...)"},{"path":"/dev/reference/set_ssvs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stochastic Search Variable Selection (SSVS) Hyperparameter for Coefficients Matrix and Cholesky Factor ‚Äî set_ssvs","text":"spike_grid Griddy gibbs grid size scaling factor (0 1) spike sd Spike sd = c * slab sd slab_shape Inverse gamma shape slab sd slab_scl Inverse gamma scale slab sd s1 First shape coefficients prior beta distribution s2 Second shape coefficients prior beta distribution shape Gamma shape parameters precision matrix (See Details). rate Gamma rate parameters precision matrix (See Details). x object digits digit option print ... used","code":""},{"path":"/dev/reference/set_ssvs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stochastic Search Variable Selection (SSVS) Hyperparameter for Coefficients Matrix and Cholesky Factor ‚Äî set_ssvs","text":"ssvsinput object","code":""},{"path":"/dev/reference/set_ssvs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Stochastic Search Variable Selection (SSVS) Hyperparameter for Coefficients Matrix and Cholesky Factor ‚Äî set_ssvs","text":"Let \\(\\alpha\\) vectorized coefficient, \\(\\alpha = vec()\\). Spike-slab prior given using two normal distributions. $$\\alpha_j \\mid \\gamma_j \\sim (1 - \\gamma_j) N(0, \\tau_{0j}^2) + \\gamma_j N(0, \\tau_{1j}^2)$$ spike-slab prior suggests, set \\(\\tau_{0j}\\) small (point mass zero: spike distribution) set \\(\\tau_{1j}\\) large (symmetric zero: slab distribution). \\(\\gamma_j\\) proportion nonzero coefficients follows $$\\gamma_j \\sim Bernoulli(p_j)$$ coef_spike: \\(\\tau_{0j}\\) coef_slab: \\(\\tau_{1j}\\) coef_mixture: \\(p_j\\) \\(j = 1, \\ldots, mk\\): vectorized format corresponding coefficient matrix one value provided, model function read replicated value. coef_non: vectorized constant term given prior Normal distribution variance \\(cI\\). , coef_non \\(\\sqrt{c}\\). Next precision matrix \\(\\Sigma_e^{-1}\\), SSVS applies Cholesky decomposition. $$\\Sigma_e^{-1} = \\Psi \\Psi^T$$ \\(\\Psi = \\{\\psi_{ij}\\}\\) upper triangular. Diagonal components follow gamma distribution. $$\\psi_{jj}^2 \\sim Gamma(shape = a_j, rate = b_j)$$ row -diagonal (upper-triangular) components, apply spike-slab prior . $$\\psi_{ij} \\mid w_{ij} \\sim (1 - w_{ij}) N(0, \\kappa_{0,ij}^2) + w_{ij} N(0, \\kappa_{1,ij}^2)$$ $$w_{ij} \\sim Bernoulli(q_{ij})$$ shape: \\(a_j\\) rate: \\(b_j\\) chol_spike: \\(\\kappa_{0,ij}\\) chol_slab: \\(\\kappa_{1,ij}\\) chol_mixture: \\(q_{ij}\\) \\(j = 1, \\ldots, mk\\): vectorized format corresponding coefficient matrix \\(= 1, \\ldots, j - 1\\) \\(j = 2, \\ldots, m\\): \\(\\eta = (\\psi_{12}, \\psi_{13}, \\psi_{23}, \\psi_{14}, \\ldots, \\psi_{34}, \\ldots, \\psi_{1m}, \\ldots, \\psi_{m - 1, m})^T\\) chol_ arguments can one value replication, vector, upper triangular matrix.","code":""},{"path":"/dev/reference/set_ssvs.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Stochastic Search Variable Selection (SSVS) Hyperparameter for Coefficients Matrix and Cholesky Factor ‚Äî set_ssvs","text":"George, E. ., & McCulloch, R. E. (1993). Variable Selection via Gibbs Sampling. Journal American Statistical Association, 88(423), 881-889. George, E. ., Sun, D., & Ni, S. (2008). Bayesian stochastic search VAR model restrictions. Journal Econometrics, 142(1), 553-580. Ishwaran, H., & Rao, J. S. (2005). Spike slab variable selection: Frequentist Bayesian strategies. Annals Statistics, 33(2). Koop, G., & Korobilis, D. (2009). Bayesian Multivariate Time Series Methods Empirical Macroeconomics. Foundations Trends¬Æ Econometrics, 3(4), 267-358.","code":""},{"path":"/dev/reference/sim_iw.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Inverse-Wishart Random Matrix ‚Äî sim_iw","title":"Generate Inverse-Wishart Random Matrix ‚Äî sim_iw","text":"function samples one matrix IW matrix.","code":""},{"path":"/dev/reference/sim_iw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Inverse-Wishart Random Matrix ‚Äî sim_iw","text":"","code":"sim_iw(mat_scale, shape)"},{"path":"/dev/reference/sim_iw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Inverse-Wishart Random Matrix ‚Äî sim_iw","text":"mat_scale Scale matrix shape Shape","code":""},{"path":"/dev/reference/sim_iw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Inverse-Wishart Random Matrix ‚Äî sim_iw","text":"One k x k matrix following IW distribution","code":""},{"path":"/dev/reference/sim_iw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate Inverse-Wishart Random Matrix ‚Äî sim_iw","text":"Consider \\(\\Sigma \\sim IW(\\Psi, \\nu)\\). Upper triangular Bartlett decomposition: k x k matrix \\(Q = [q_{ij}]\\) upper triangular \\(q_{ii}^2 \\chi_{\\nu - + 1}^2\\) \\(q_{ij} \\sim N(0, 1)\\) < j (upper triangular) Lower triangular Cholesky decomposition: \\(\\Psi = L L^T\\) \\(= L (Q^{-1})^T\\) \\(\\Sigma = ^T \\sim IW(\\Psi, \\nu)\\)","code":""},{"path":"/dev/reference/sim_matgaussian.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Matrix Normal Random Matrix ‚Äî sim_matgaussian","title":"Generate Matrix Normal Random Matrix ‚Äî sim_matgaussian","text":"function samples one matrix gaussian matrix.","code":""},{"path":"/dev/reference/sim_matgaussian.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Matrix Normal Random Matrix ‚Äî sim_matgaussian","text":"","code":"sim_matgaussian(mat_mean, mat_scale_u, mat_scale_v, u_prec)"},{"path":"/dev/reference/sim_matgaussian.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Matrix Normal Random Matrix ‚Äî sim_matgaussian","text":"mat_mean Mean matrix mat_scale_u First scale matrix mat_scale_v Second scale matrix u_prec TRUE, use mat_scale_u inverse.","code":""},{"path":"/dev/reference/sim_matgaussian.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Matrix Normal Random Matrix ‚Äî sim_matgaussian","text":"One n x k matrix following MN distribution.","code":""},{"path":"/dev/reference/sim_matgaussian.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate Matrix Normal Random Matrix ‚Äî sim_matgaussian","text":"Consider n x k matrix \\(Y_1, \\ldots, Y_n \\sim MN(M, U, V)\\) M n x k, U n x n, V k x k. Lower triangular Cholesky decomposition: \\(U = P P^T\\) \\(V = L L^T\\) Standard normal generation: s x m matrix \\(Z_i = [z_{ij} \\sim N(0, 1)]\\) row-wise direction. \\(Y_i = M + P Z_i L^T\\) function generates one matrix, .e. \\(Y_1\\).","code":""},{"path":"/dev/reference/sim_mncoef.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Minnesota BVAR Parameters ‚Äî sim_mncoef","title":"Generate Minnesota BVAR Parameters ‚Äî sim_mncoef","text":"function generates parameters BVAR Minnesota prior.","code":""},{"path":"/dev/reference/sim_mncoef.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Minnesota BVAR Parameters ‚Äî sim_mncoef","text":"","code":"sim_mncoef(p, bayes_spec = set_bvar(), full = TRUE)"},{"path":"/dev/reference/sim_mncoef.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Minnesota BVAR Parameters ‚Äî sim_mncoef","text":"p VAR lag bayes_spec BVAR model specification set_bvar(). full Generate variance matrix IW (default: TRUE) (FALSE)?","code":""},{"path":"/dev/reference/sim_mncoef.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Minnesota BVAR Parameters ‚Äî sim_mncoef","text":"List following component. coefficients BVAR coefficient (MN) covmat BVAR variance (IW diagonal matrix sigma bayes_spec)","code":""},{"path":"/dev/reference/sim_mncoef.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate Minnesota BVAR Parameters ‚Äî sim_mncoef","text":"Implementing dummy observation constructions, Ba≈Ñbura et al. (2010) sets Normal-IW prior. $$\\mid \\Sigma_e \\sim MN(A_0, \\Omega_0, \\Sigma_e)$$ $$\\Sigma_e \\sim IW(S_0, \\alpha_0)$$ full = FALSE, result \\(\\Sigma_e\\) input (diag(sigma)).","code":""},{"path":"/dev/reference/sim_mncoef.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generate Minnesota BVAR Parameters ‚Äî sim_mncoef","text":"Ba≈Ñbura, M., Giannone, D., & Reichlin, L. (2010). Large Bayesian vector auto regressions. Journal Applied Econometrics, 25(1). Karlsson, S. (2013). Chapter 15 Forecasting Bayesian Vector Autoregression. Handbook Economic Forecasting, 2, 791-897. Litterman, R. B. (1986). Forecasting Bayesian Vector Autoregressions: Five Years Experience. Journal Business & Economic Statistics, 4(1), 25.","code":""},{"path":[]},{"path":"/dev/reference/sim_mncoef.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Minnesota BVAR Parameters ‚Äî sim_mncoef","text":"","code":"# Generate (A, Sigma) # BVAR(p = 2) # sigma: 1, 1, 1 # lambda: .1 # delta: .1, .1, .1 # epsilon: 1e-04 set.seed(1) sim_mncoef(   p = 2,   bayes_spec = set_bvar(     sigma = rep(1, 3),     lambda = .1,     delta = rep(.1, 3),     eps = 1e-04   ),   full = TRUE ) #> $coefficients #>              [,1]         [,2]         [,3] #> [1,]  0.081071630  0.002721103  0.092414563 #> [2,]  0.049041658  0.062491732 -0.032011373 #> [3,] -0.018590620 -0.008312152  0.066508409 #> [4,]  0.008099504 -0.017944600  0.007603526 #> [5,] -0.039740346  0.001970018 -0.017502085 #> [6,]  0.004281752  0.014382071  0.007386941 #>  #> $covmat #>             [,1]        [,2]       [,3] #> [1,]  0.41248285 -0.06400052 0.24882667 #> [2,] -0.06400052  0.14995663 0.01758338 #> [3,]  0.24882667  0.01758338 0.35941383 #>"},{"path":"/dev/reference/sim_mniw.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Normal-IW Random Family ‚Äî sim_mniw","title":"Generate Normal-IW Random Family ‚Äî sim_mniw","text":"function samples normal inverse-wishart matrices.","code":""},{"path":"/dev/reference/sim_mniw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Normal-IW Random Family ‚Äî sim_mniw","text":"","code":"sim_mniw(num_sim, mat_mean, mat_scale_u, mat_scale, shape, u_prec = FALSE)"},{"path":"/dev/reference/sim_mniw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Normal-IW Random Family ‚Äî sim_mniw","text":"num_sim Number generate mat_mean Mean matrix MN mat_scale_u First scale matrix MN mat_scale Scale matrix IW shape Shape IW u_prec TRUE, use mat_scale_u inverse. default, FALSE.","code":""},{"path":"/dev/reference/sim_mniw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate Normal-IW Random Family ‚Äî sim_mniw","text":"Consider \\((Y_i, \\Sigma_i) \\sim MIW(M, U, \\Psi, \\nu)\\). Generate upper triangular factor \\(\\Sigma_i = C_i C_i^T\\) upper triangular Bartlett decomposition. Standard normal generation: n x k matrix \\(Z_i = [z_{ij} \\sim N(0, 1)]\\) row-wise direction. Lower triangular Cholesky decomposition: \\(U = P P^T\\) \\(A_i = M + P Z_i C_i^T\\)","code":""},{"path":"/dev/reference/sim_mnormal.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Multivariate Normal Random Vector ‚Äî sim_mnormal","title":"Generate Multivariate Normal Random Vector ‚Äî sim_mnormal","text":"function samples n x muti-dimensional normal random matrix.","code":""},{"path":"/dev/reference/sim_mnormal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Multivariate Normal Random Vector ‚Äî sim_mnormal","text":"","code":"sim_mnormal(   num_sim,   mu = rep(0, 5),   sig = diag(5),   method = c(\"eigen\", \"chol\") )"},{"path":"/dev/reference/sim_mnormal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Multivariate Normal Random Vector ‚Äî sim_mnormal","text":"num_sim Number generate process mu Mean vector sig Variance matrix method Method compute \\(\\Sigma^{1/2}\\). Choose eigen (spectral decomposition) chol (cholesky decomposition). default, eigen.","code":""},{"path":"/dev/reference/sim_mnormal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Multivariate Normal Random Vector ‚Äî sim_mnormal","text":"T x k matrix","code":""},{"path":"/dev/reference/sim_mnormal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate Multivariate Normal Random Vector ‚Äî sim_mnormal","text":"Consider \\(x_1, \\ldots, x_n \\sim N_m (\\mu, \\Sigma)\\). Lower triangular Cholesky decomposition: \\(\\Sigma = L L^T\\) Standard normal generation: \\(Z_{i1}, Z_{} \\stackrel{iid}{\\sim} N(0, 1)\\) \\(Z_i = (Z_{i1}, \\ldots, Z_{})^T\\) \\(X_i = L Z_i + \\mu\\)","code":""},{"path":"/dev/reference/sim_mnvhar_coef.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Minnesota BVAR Parameters ‚Äî sim_mnvhar_coef","title":"Generate Minnesota BVAR Parameters ‚Äî sim_mnvhar_coef","text":"function generates parameters BVAR Minnesota prior.","code":""},{"path":"/dev/reference/sim_mnvhar_coef.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Minnesota BVAR Parameters ‚Äî sim_mnvhar_coef","text":"","code":"sim_mnvhar_coef(bayes_spec = set_bvhar(), full = TRUE)"},{"path":"/dev/reference/sim_mnvhar_coef.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Minnesota BVAR Parameters ‚Äî sim_mnvhar_coef","text":"bayes_spec BVHAR model specification set_bvhar() (default) set_weight_bvhar(). full Generate variance matrix IW (default: TRUE) (FALSE)?","code":""},{"path":"/dev/reference/sim_mnvhar_coef.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Minnesota BVAR Parameters ‚Äî sim_mnvhar_coef","text":"List following component. coefficients BVHAR coefficient (MN) covmat BVHAR variance (IW diagonal matrix sigma bayes_spec)","code":""},{"path":"/dev/reference/sim_mnvhar_coef.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate Minnesota BVAR Parameters ‚Äî sim_mnvhar_coef","text":"Normal-IW family vector HAR model: $$\\Phi \\mid \\Sigma_e \\sim MN(M_0, \\Omega_0, \\Sigma_e)$$ $$\\Sigma_e \\sim IW(\\Psi_0, \\nu_0)$$","code":""},{"path":"/dev/reference/sim_mnvhar_coef.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generate Minnesota BVAR Parameters ‚Äî sim_mnvhar_coef","text":"Kim, Y. G., Baek, C. (2024). Bayesian vector heterogeneous autoregressive modeling. Journal Statistical Computation Simulation, 94(6), 1139-1157.","code":""},{"path":[]},{"path":"/dev/reference/sim_mnvhar_coef.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Minnesota BVAR Parameters ‚Äî sim_mnvhar_coef","text":"","code":"# Generate (Phi, Sigma) # BVHAR-S # sigma: 1, 1, 1 # lambda: .1 # delta: .1, .1, .1 # epsilon: 1e-04 set.seed(1) sim_mnvhar_coef(   bayes_spec = set_bvhar(     sigma = rep(1, 3),     lambda = .1,     delta = rep(.1, 3),     eps = 1e-04   ),   full = TRUE ) #> $coefficients #>               [,1]         [,2]         [,3] #>  [1,]  0.081071630  0.002721103  0.092414563 #>  [2,]  0.049041658  0.062491732 -0.032011373 #>  [3,] -0.018590620 -0.008312152  0.066508409 #>  [4,]  0.008099504 -0.017944600  0.007603526 #>  [5,] -0.039740346  0.001970018 -0.017502085 #>  [6,]  0.004281752  0.014382071  0.007386941 #>  [7,]  0.010781378  0.011870368  0.001985094 #>  [8,] -0.027501057  0.004849875 -0.019751320 #>  [9,] -0.011622302 -0.003601531 -0.018535816 #>  #> $covmat #>             [,1]        [,2]       [,3] #> [1,]  0.41248285 -0.06400052 0.24882667 #> [2,] -0.06400052  0.14995663 0.01758338 #> [3,]  0.24882667  0.01758338 0.35941383 #>"},{"path":"/dev/reference/sim_mvt.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Multivariate t Random Vector ‚Äî sim_mvt","title":"Generate Multivariate t Random Vector ‚Äî sim_mvt","text":"function samples n x multi-dimensional t-random matrix.","code":""},{"path":"/dev/reference/sim_mvt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Multivariate t Random Vector ‚Äî sim_mvt","text":"","code":"sim_mvt(num_sim, df, mu, sig, method = c(\"eigen\", \"chol\"))"},{"path":"/dev/reference/sim_mvt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Multivariate t Random Vector ‚Äî sim_mvt","text":"num_sim Number generate process. df Degrees freedom. mu Location vector sig Scale matrix. method Method compute \\(\\Sigma^{1/2}\\). Choose eigen (spectral decomposition) chol (cholesky decomposition). default, eigen.","code":""},{"path":"/dev/reference/sim_mvt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Multivariate t Random Vector ‚Äî sim_mvt","text":"T x k matrix","code":""},{"path":"/dev/reference/sim_var.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Multivariate Time Series Process Following VAR(p) ‚Äî sim_var","title":"Generate Multivariate Time Series Process Following VAR(p) ‚Äî sim_var","text":"function generates multivariate time series dataset follows VAR(p).","code":""},{"path":"/dev/reference/sim_var.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Multivariate Time Series Process Following VAR(p) ‚Äî sim_var","text":"","code":"sim_var(   num_sim,   num_burn,   var_coef,   var_lag,   sig_error = diag(ncol(var_coef)),   init = matrix(0L, nrow = var_lag, ncol = ncol(var_coef)),   method = c(\"eigen\", \"chol\"),   process = c(\"gaussian\", \"student\"),   t_param = 5 )"},{"path":"/dev/reference/sim_var.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Multivariate Time Series Process Following VAR(p) ‚Äî sim_var","text":"num_sim Number generated process num_burn Number burn-var_coef VAR coefficient. format output coef() var_lm() var_lag Lag VAR sig_error Variance matrix error term. default, diag(dim). init Initial y1, ..., yp matrix simulate VAR model. Try matrix(0L, nrow = var_lag, ncol = dim). method Method compute \\(\\Sigma^{1/2}\\). Choose eigen (spectral decomposition) chol (cholesky decomposition). default, eigen. process Process generate error term. gaussian: Normal distribution (default) student: Multivariate t-distribution. t_param argument MVT, e.g. DF: 5.","code":""},{"path":"/dev/reference/sim_var.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Multivariate Time Series Process Following VAR(p) ‚Äî sim_var","text":"T x k matrix","code":""},{"path":"/dev/reference/sim_var.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate Multivariate Time Series Process Following VAR(p) ‚Äî sim_var","text":"Generate \\(\\epsilon_1, \\epsilon_n \\sim N(0, \\Sigma)\\) = 1, ... n, $$y_{p + } = (y_{p + - 1}^T, \\ldots, y_i^T, 1)^T B + \\epsilon_i$$ output \\((y_{p + 1}, \\ldots, y_{n + p})^T\\) Initial values might set zero vector \\((I_m - A_1 - \\cdots - A_p)^{-1} c\\).","code":""},{"path":"/dev/reference/sim_var.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generate Multivariate Time Series Process Following VAR(p) ‚Äî sim_var","text":"L√ºtkepohl, H. (2007). New Introduction Multiple Time Series Analysis. Springer Publishing.","code":""},{"path":"/dev/reference/sim_vhar.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Multivariate Time Series Process Following VAR(p) ‚Äî sim_vhar","title":"Generate Multivariate Time Series Process Following VAR(p) ‚Äî sim_vhar","text":"function generates multivariate time series dataset follows VAR(p).","code":""},{"path":"/dev/reference/sim_vhar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Multivariate Time Series Process Following VAR(p) ‚Äî sim_vhar","text":"","code":"sim_vhar(   num_sim,   num_burn,   vhar_coef,   week = 5L,   month = 22L,   sig_error = diag(ncol(vhar_coef)),   init = matrix(0L, nrow = month, ncol = ncol(vhar_coef)),   method = c(\"eigen\", \"chol\"),   process = c(\"gaussian\", \"student\"),   t_param = 5 )"},{"path":"/dev/reference/sim_vhar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Multivariate Time Series Process Following VAR(p) ‚Äî sim_vhar","text":"num_sim Number generated process num_burn Number burn-vhar_coef VAR coefficient. format output coef() var_lm() week Weekly order VHAR. default, 5. month Weekly order VHAR. default, 22. sig_error Variance matrix error term. default, diag(dim). init Initial y1, ..., yp matrix simulate VAR model. Try matrix(0L, nrow = month, ncol = dim). method Method compute \\(\\Sigma^{1/2}\\). Choose eigen (spectral decomposition) chol (cholesky decomposition). default, eigen. process Process generate error term. gaussian: Normal distribution (default) student: Multivariate t-distribution. t_param argument MVT, e.g. DF: 5.","code":""},{"path":"/dev/reference/sim_vhar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Multivariate Time Series Process Following VAR(p) ‚Äî sim_vhar","text":"T x k matrix","code":""},{"path":"/dev/reference/sim_vhar.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate Multivariate Time Series Process Following VAR(p) ‚Äî sim_vhar","text":"Let \\(M\\) month order, e.g. \\(M = 22\\). Generate \\(\\epsilon_1, \\epsilon_n \\sim N(0, \\Sigma)\\) = 1, ... n, $$y_{M + } = (y_{M + - 1}^T, \\ldots, y_i^T, 1)^T C_{HAR}^T \\Phi + \\epsilon_i$$ output \\((y_{M + 1}, \\ldots, y_{n + M})^T\\) = 1, ... n, $$y_{p + } = (y_{p + - 1}^T, \\ldots, y_i^T, 1)^T B + \\epsilon_i$$ output \\((y_{p + 1}, \\ldots, y_{n + p})^T\\) Initial values might set zero vector \\((I_m - A_1 - \\cdots - A_p)^{-1} c\\).","code":""},{"path":"/dev/reference/sim_vhar.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generate Multivariate Time Series Process Following VAR(p) ‚Äî sim_vhar","text":"L√ºtkepohl, H. (2007). New Introduction Multiple Time Series Analysis. Springer Publishing.","code":""},{"path":"/dev/reference/spillover.html","id":null,"dir":"Reference","previous_headings":"","what":"h-step ahead Normalized Spillover ‚Äî spillover","title":"h-step ahead Normalized Spillover ‚Äî spillover","text":"function gives connectedness table h-step ahead normalized spillover index (.k.. variance shares).","code":""},{"path":"/dev/reference/spillover.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"h-step ahead Normalized Spillover ‚Äî spillover","text":"","code":"spillover(object, n_ahead = 10L, ...)  # S3 method for class 'bvharspillover' print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  # S3 method for class 'bvharspillover' knit_print(x, ...)  # S3 method for class 'olsmod' spillover(object, n_ahead = 10L, ...)  # S3 method for class 'normaliw' spillover(   object,   n_ahead = 10L,   num_iter = 5000L,   num_burn = floor(num_iter/2),   thinning = 1L,   ... )  # S3 method for class 'bvarldlt' spillover(object, n_ahead = 10L, level = 0.05, sparse = FALSE, ...)  # S3 method for class 'bvharldlt' spillover(object, n_ahead = 10L, level = 0.05, sparse = FALSE, ...)"},{"path":"/dev/reference/spillover.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"h-step ahead Normalized Spillover ‚Äî spillover","text":"object Model object n_ahead step forecast. default, 10. ... used x bvharspillover object digits digit option print num_iter Number sample MNIW distribution num_burn Number burn-thinning Thinning every thinning-th iteration level Specify alpha confidence interval level 100(1 - alpha) percentage. default, .05. sparse Apply restriction. default, FALSE.","code":""},{"path":"/dev/reference/spillover.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"h-step ahead Normalized Spillover ‚Äî spillover","text":"Diebold, F. X., & Yilmaz, K. (2012). Better give receive: Predictive directional measurement volatility spillovers. International Journal forecasting, 28(1), 57-66.","code":""},{"path":"/dev/reference/spne.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Estimation Based on Spectral Norm Error ‚Äî spne","title":"Evaluate the Estimation Based on Spectral Norm Error ‚Äî spne","text":"function computes estimation error given estimated model true coefficient.","code":""},{"path":"/dev/reference/spne.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Estimation Based on Spectral Norm Error ‚Äî spne","text":"","code":"spne(x, y, ...)  # S3 method for class 'bvharsp' spne(x, y, ...)"},{"path":"/dev/reference/spne.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Estimation Based on Spectral Norm Error ‚Äî spne","text":"x Estimated model. y Coefficient matrix compared. ... used","code":""},{"path":"/dev/reference/spne.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Estimation Based on Spectral Norm Error ‚Äî spne","text":"Spectral norm value","code":""},{"path":"/dev/reference/spne.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Estimation Based on Spectral Norm Error ‚Äî spne","text":"Let \\(\\lVert \\cdot \\rVert_2\\) spectral norm matrix, let \\(\\hat{\\Phi}\\) estimates, let \\(\\Phi\\) true coefficients matrix. function computes estimation error $$\\lVert \\hat{\\Phi} - \\Phi \\rVert_2$$","code":""},{"path":"/dev/reference/spne.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Estimation Based on Spectral Norm Error ‚Äî spne","text":"Ghosh, S., Khare, K., & Michailidis, G. (2018). High-Dimensional Posterior Consistency Bayesian Vector Autoregressive Models. Journal American Statistical Association, 114(526).","code":""},{"path":"/dev/reference/stableroot.html","id":null,"dir":"Reference","previous_headings":"","what":"Roots of characteristic polynomial ‚Äî stableroot","title":"Roots of characteristic polynomial ‚Äî stableroot","text":"Compute character polynomial coefficient matrix.","code":""},{"path":"/dev/reference/stableroot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Roots of characteristic polynomial ‚Äî stableroot","text":"","code":"stableroot(x, ...)  # S3 method for class 'varlse' stableroot(x, ...)  # S3 method for class 'vharlse' stableroot(x, ...)  # S3 method for class 'bvarmn' stableroot(x, ...)  # S3 method for class 'bvarflat' stableroot(x, ...)  # S3 method for class 'bvharmn' stableroot(x, ...)"},{"path":"/dev/reference/stableroot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Roots of characteristic polynomial ‚Äî stableroot","text":"x Model fit ... used","code":""},{"path":"/dev/reference/stableroot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Roots of characteristic polynomial ‚Äî stableroot","text":"Numeric vector.","code":""},{"path":"/dev/reference/stableroot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Roots of characteristic polynomial ‚Äî stableroot","text":"know whether process stable , make characteristic polynomial. $$\\det(I_m - z) = 0$$ \\(\\) VAR(1) coefficient matrix representation.","code":""},{"path":"/dev/reference/stableroot.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Roots of characteristic polynomial ‚Äî stableroot","text":"L√ºtkepohl, H. (2007). New Introduction Multiple Time Series Analysis. Springer Publishing.","code":""},{"path":"/dev/reference/summary.bvharsp.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarizing BVAR and BVHAR with Shrinkage Priors ‚Äî print.summary.bvharsp","title":"Summarizing BVAR and BVHAR with Shrinkage Priors ‚Äî print.summary.bvharsp","text":"Conduct variable selection.","code":""},{"path":"/dev/reference/summary.bvharsp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarizing BVAR and BVHAR with Shrinkage Priors ‚Äî print.summary.bvharsp","text":"","code":"# S3 method for class 'summary.bvharsp' print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  # S3 method for class 'summary.bvharsp' knit_print(x, ...)  # S3 method for class 'ssvsmod' summary(object, method = c(\"pip\", \"ci\"), threshold = 0.5, level = 0.05, ...)  # S3 method for class 'hsmod' summary(object, method = c(\"pip\", \"ci\"), threshold = 0.5, level = 0.05, ...)  # S3 method for class 'ngmod' summary(object, level = 0.05, ...)"},{"path":"/dev/reference/summary.bvharsp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarizing BVAR and BVHAR with Shrinkage Priors ‚Äî print.summary.bvharsp","text":"x summary.bvharsp object digits digit option print ... used object Model fit method Use PIP (pip) credible interval (ci). threshold Threshold posterior inclusion probability level Specify alpha credible interval level 100(1 - alpha) percentage. default, .05.","code":""},{"path":"/dev/reference/summary.bvharsp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarizing BVAR and BVHAR with Shrinkage Priors ‚Äî print.summary.bvharsp","text":"summary.ssvsmod object hsmod object ngmod object","code":""},{"path":"/dev/reference/summary.bvharsp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Summarizing BVAR and BVHAR with Shrinkage Priors ‚Äî print.summary.bvharsp","text":"George, E. ., & McCulloch, R. E. (1993). Variable Selection via Gibbs Sampling. Journal American Statistical Association, 88(423), 881-889. George, E. ., Sun, D., & Ni, S. (2008). Bayesian stochastic search VAR model restrictions. Journal Econometrics, 142(1), 553-580. Koop, G., & Korobilis, D. (2009). Bayesian Multivariate Time Series Methods Empirical Macroeconomics. Foundations Trends¬Æ Econometrics, 3(4), 267-358. O‚ÄôHara, R. B., & Sillanp√§√§, M. J. (2009). review Bayesian variable selection methods: , . Bayesian Analysis, 4(1), 85-117.","code":""},{"path":"/dev/reference/summary.normaliw.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarizing Bayesian Multivariate Time Series Model ‚Äî summary.normaliw","title":"Summarizing Bayesian Multivariate Time Series Model ‚Äî summary.normaliw","text":"summary method normaliw class.","code":""},{"path":"/dev/reference/summary.normaliw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarizing Bayesian Multivariate Time Series Model ‚Äî summary.normaliw","text":"","code":"# S3 method for class 'normaliw' summary(   object,   num_chains = 1,   num_iter = 1000,   num_burn = floor(num_iter/2),   thinning = 1,   verbose = FALSE,   num_thread = 1,   ... )  # S3 method for class 'summary.normaliw' print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  # S3 method for class 'summary.normaliw' knit_print(x, ...)"},{"path":"/dev/reference/summary.normaliw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarizing Bayesian Multivariate Time Series Model ‚Äî summary.normaliw","text":"object normaliw object num_chains Number MCMC chains num_iter MCMC iteration number num_burn Number burn-(warm-). Half iteration default choice. thinning Thinning every thinning-th iteration verbose Print progress bar console. default, FALSE. num_thread Number threads ... used x summary.normaliw object digits digit option print","code":""},{"path":"/dev/reference/summary.normaliw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarizing Bayesian Multivariate Time Series Model ‚Äî summary.normaliw","text":"summary.normaliw class following components: names Variable names totobs Total number observation obs Sample size used training = totobs - p p Lag VAR m Dimension data call Matched call spec Model specification (bvharspec) mn_mean MN Mean posterior distribution (MN-IW) mn_prec MN Precision posterior distribution (MN-IW) iw_scale IW scale posterior distribution (MN-IW) iw_shape IW df posterior distribution (MN-IW) iter Number MCMC iterations burn Number MCMC burn-thin MCMC thinning alpha_record (BVAR) phi_record (BVHAR) MCMC record coefficients vector psi_record MCMC record upper cholesky factor omega_record MCMC record diagonal cholesky factor eta_record MCMC record upper part cholesky factor param MCMC record every parameter coefficients Posterior mean coefficients covmat Posterior mean covariance","code":""},{"path":"/dev/reference/summary.normaliw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarizing Bayesian Multivariate Time Series Model ‚Äî summary.normaliw","text":"Minnesota prior, set coefficient matrices residual covariance matrix matrix Normal Inverse-Wishart distribution. BVAR: $$(, \\Sigma_e) \\sim MNIW(\\hat{}, \\hat{V}^{-1}, \\hat\\Sigma_e, \\alpha_0 + n)$$ \\(\\hat{V} = X_\\ast^T X_\\ast\\) posterior precision MN. BVHAR: $$(\\Phi, \\Sigma_e) \\sim MNIW(\\hat\\Phi, \\hat{V}_H^{-1}, \\hat\\Sigma_e, \\nu + n)$$ \\(\\hat{V}_H = X_{+}^T X_{+}\\) posterior precision MN.","code":""},{"path":"/dev/reference/summary.normaliw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Summarizing Bayesian Multivariate Time Series Model ‚Äî summary.normaliw","text":"Litterman, R. B. (1986). Forecasting Bayesian Vector Autoregressions: Five Years Experience. Journal Business & Economic Statistics, 4(1), 25. Ba≈Ñbura, M., Giannone, D., & Reichlin, L. (2010). Large Bayesian vector auto regressions. Journal Applied Econometrics, 25(1).","code":""},{"path":"/dev/reference/summary.varlse.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarizing Vector Autoregressive Model ‚Äî summary.varlse","title":"Summarizing Vector Autoregressive Model ‚Äî summary.varlse","text":"summary method varlse class.","code":""},{"path":"/dev/reference/summary.varlse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarizing Vector Autoregressive Model ‚Äî summary.varlse","text":"","code":"# S3 method for class 'varlse' summary(object, ...)  # S3 method for class 'summary.varlse' print(x, digits = max(3L, getOption(\"digits\") - 3L), signif_code = TRUE, ...)  # S3 method for class 'summary.varlse' knit_print(x, ...)"},{"path":"/dev/reference/summary.varlse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarizing Vector Autoregressive Model ‚Äî summary.varlse","text":"object varlse object ... used x summary.varlse object digits digit option print signif_code Check significant rows (Default: TRUE)","code":""},{"path":"/dev/reference/summary.varlse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarizing Vector Autoregressive Model ‚Äî summary.varlse","text":"summary.varlse class additionally computes following names Variable names totobs Total number observation obs Sample size used training = totobs - p p Lag VAR coefficients Coefficient Matrix call Matched call process Process: VAR covmat Covariance matrix residuals corrmat Correlation matrix residuals roots Roots characteristic polynomials is_stable Whether process stable based roots log_lik log-likelihood ic Information criteria vector AIC - AIC BIC - BIC HQ - HQ FPE - FPE","code":""},{"path":"/dev/reference/summary.varlse.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Summarizing Vector Autoregressive Model ‚Äî summary.varlse","text":"L√ºtkepohl, H. (2007). New Introduction Multiple Time Series Analysis. Springer Publishing.","code":""},{"path":"/dev/reference/summary.vharlse.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarizing Vector HAR Model ‚Äî summary.vharlse","title":"Summarizing Vector HAR Model ‚Äî summary.vharlse","text":"summary method vharlse class.","code":""},{"path":"/dev/reference/summary.vharlse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarizing Vector HAR Model ‚Äî summary.vharlse","text":"","code":"# S3 method for class 'vharlse' summary(object, ...)  # S3 method for class 'summary.vharlse' print(x, digits = max(3L, getOption(\"digits\") - 3L), signif_code = TRUE, ...)  # S3 method for class 'summary.vharlse' knit_print(x, ...)"},{"path":"/dev/reference/summary.vharlse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarizing Vector HAR Model ‚Äî summary.vharlse","text":"object vharlse object ... used x summary.vharlse object digits digit option print signif_code Check significant rows (Default: TRUE)","code":""},{"path":"/dev/reference/summary.vharlse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarizing Vector HAR Model ‚Äî summary.vharlse","text":"summary.vharlse class additionally computes following names Variable names totobs Total number observation obs Sample size used training = totobs - p p 3 week Order weekly term month Order monthly term coefficients Coefficient Matrix call Matched call process Process: VAR covmat Covariance matrix residuals corrmat Correlation matrix residuals roots Roots characteristic polynomials is_stable Whether process stable based roots log_lik log-likelihood ic Information criteria vector AIC - AIC BIC - BIC HQ - HQ FPE - FPE","code":""},{"path":"/dev/reference/summary.vharlse.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Summarizing Vector HAR Model ‚Äî summary.vharlse","text":"L√ºtkepohl, H. (2007). New Introduction Multiple Time Series Analysis. Springer Publishing. Corsi, F. (2008). Simple Approximate Long-Memory Model Realized Volatility. Journal Financial Econometrics, 7(2), 174-196. Baek, C. Park, M. (2021). Sparse vector heterogeneous autoregressive modeling realized volatility. J. Korean Stat. Soc. 50, 495-510.","code":""},{"path":"/dev/reference/var_bayes.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting Bayesian VAR with Coefficient and Covariance Prior ‚Äî var_bayes","title":"Fitting Bayesian VAR with Coefficient and Covariance Prior ‚Äî var_bayes","text":"function fits BVAR. Covariance term can homoskedastic heteroskedastic (stochastic volatility). can Minnesota, SSVS, Horseshoe prior.","code":""},{"path":"/dev/reference/var_bayes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting Bayesian VAR with Coefficient and Covariance Prior ‚Äî var_bayes","text":"","code":"var_bayes(   y,   p,   exogen = NULL,   s = 0,   num_chains = 1,   num_iter = 1000,   num_burn = floor(num_iter/2),   thinning = 1,   coef_spec = set_bvar(),   contem_spec = coef_spec,   cov_spec = set_ldlt(),   intercept = set_intercept(),   exogen_spec = coef_spec,   include_mean = TRUE,   minnesota = TRUE,   ggl = TRUE,   save_init = FALSE,   convergence = NULL,   verbose = FALSE,   num_thread = 1 )  # S3 method for class 'bvarsv' print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  # S3 method for class 'bvarldlt' print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  # S3 method for class 'bvarsv' knit_print(x, ...)  # S3 method for class 'bvarldlt' knit_print(x, ...)"},{"path":"/dev/reference/var_bayes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting Bayesian VAR with Coefficient and Covariance Prior ‚Äî var_bayes","text":"y Time series data columns indicate variables p VAR lag exogen Unmodeled variables s Lag exogeneous variables VARX(p, s). default, s = 0. num_chains Number MCMC chains num_iter MCMC iteration number num_burn Number burn-(warm-). Half iteration default choice. thinning Thinning every thinning-th iteration coef_spec Coefficient prior specification set_bvar(), set_ssvs(), set_horseshoe(). contem_spec Contemporaneous coefficient prior specification set_bvar(), set_ssvs(), set_horseshoe(). cov_spec SV specification set_sv(). intercept Prior constant term set_intercept(). exogen_spec Exogenous coefficient prior specification. include_mean Add constant term (Default: TRUE) (FALSE) minnesota Apply cross-variable shrinkage structure (Minnesota-way). default, TRUE. ggl TRUE (default), use additional group shrinkage parameter group structure. Otherwise, use group shrinkage parameter instead global shirnkage parameter. Applies HS, NG, DL priors. save_init Save every record starting initial values (TRUE). default, exclude initial values record (FALSE), even num_burn = 0 thinning = 1. num_burn > 0 thinning != 1, option ignored. convergence Convergence threshold rhat < convergence. default, NULL means warning. verbose Print progress bar console. default, FALSE. num_thread Number threads x bvarldlt object digits digit option print ... used","code":""},{"path":"/dev/reference/var_bayes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting Bayesian VAR with Coefficient and Covariance Prior ‚Äî var_bayes","text":"var_bayes() returns object named bvarsv class. coefficients Posterior mean coefficients. chol_posterior Posterior mean contemporaneous effects. param Every set MCMC trace. param_names Name every parameter. group Indicators group. num_group Number groups. df Numer Coefficients: 3m + 1 3m p VAR lag m Dimension data obs Sample size used training = totobs - p totobs Total number observation call Matched call process Description model, e.g. VHAR_SSVS_SV, VHAR_Horseshoe_SV, VHAR_minnesota-part_SV type include constant term (const) (none) spec Coefficients prior specification sv log volatility prior specification intercept Intercept prior specification init Initial values chain numer chains iter Total iterations burn Burn-thin Thinning y0 \\(Y_0\\) design \\(X_0\\) y Raw input SSVS Horseshoe: pip Posterior inclusion probabilities.","code":""},{"path":"/dev/reference/var_bayes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting Bayesian VAR with Coefficient and Covariance Prior ‚Äî var_bayes","text":"Cholesky stochastic volatility modeling VAR based $$\\Sigma_t^{-1} = L^T D_t^{-1} L$$, implements corrected triangular algorithm Gibbs sampler.","code":""},{"path":"/dev/reference/var_bayes.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting Bayesian VAR with Coefficient and Covariance Prior ‚Äî var_bayes","text":"Carriero, ., Chan, J., Clark, T. E., & Marcellino, M. (2022). Corrigendum ‚ÄúLarge Bayesian vector autoregressions stochastic volatility non-conjugate priors‚Äù [J. Econometrics 212 (1)(2019) 137-154]. Journal Econometrics, 227(2), 506-512. Chan, J., Koop, G., Poirier, D., & Tobias, J. (2019). Bayesian Econometric Methods (2nd ed., Econometric Exercises). Cambridge: Cambridge University Press. Cogley, T., & Sargent, T. J. (2005). Drifts volatilities: monetary policies outcomes post WWII US. Review Economic Dynamics, 8(2), 262-302. Gruber, L., & Kastner, G. (2022). Forecasting macroeconomic data Bayesian VARs: Sparse dense? depends! arXiv. Huber, F., Koop, G., & Onorante, L. (2021). Inducing Sparsity Shrinkage Time-Varying Parameter Models. Journal Business & Economic Statistics, 39(3), 669-683. Korobilis, D., & Shimizu, K. (2022). Bayesian Approaches Shrinkage Sparse Estimation. Foundations Trends¬Æ Econometrics, 11(4), 230-354. Ray, P., & Bhattacharya, . (2018). Signal Adaptive Variable Selector Horseshoe Prior. arXiv.","code":""},{"path":"/dev/reference/var_lm.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting Vector Autoregressive Model of Order p Model ‚Äî var_lm","title":"Fitting Vector Autoregressive Model of Order p Model ‚Äî var_lm","text":"function fits VAR(p) using OLS method.","code":""},{"path":"/dev/reference/var_lm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting Vector Autoregressive Model of Order p Model ‚Äî var_lm","text":"","code":"var_lm(   y,   p = 1,   exogen = NULL,   s = 0,   include_mean = TRUE,   method = c(\"nor\", \"chol\", \"qr\") )  # S3 method for class 'varlse' print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  # S3 method for class 'varlse' logLik(object, ...)  # S3 method for class 'varlse' AIC(object, ...)  # S3 method for class 'varlse' BIC(object, ...)  is.varlse(x)  is.bvharmod(x)  # S3 method for class 'varlse' knit_print(x, ...)"},{"path":"/dev/reference/var_lm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting Vector Autoregressive Model of Order p Model ‚Äî var_lm","text":"y Time series data columns indicate variables p Lag VAR (Default: 1) exogen Exogenous variables s Lag exogeneous variables VARX(p, s). default, s = 0. include_mean Add constant term (Default: TRUE) (FALSE) method Method solve linear equation system. (: normal equation (default), chol: Cholesky, qr: HouseholderQR) x object digits digit option print ... used object varlse object","code":""},{"path":"/dev/reference/var_lm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting Vector Autoregressive Model of Order p Model ‚Äî var_lm","text":"var_lm() returns object named varlse class. list following components: coefficients Coefficient Matrix fitted.values Fitted response values residuals Residuals covmat LS estimate covariance matrix df Numer Coefficients p Lag VAR m Dimension data obs Sample size used training = totobs - p totobs Total number observation call Matched call process Process: VAR type include constant term (const) (none) design Design matrix y Raw input y0 Multivariate response matrix method Solving method call Matched call also bvharmod class.","code":""},{"path":"/dev/reference/var_lm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting Vector Autoregressive Model of Order p Model ‚Äî var_lm","text":"package specifies VAR(p) model $$Y_{t} = A_1 Y_{t - 1} + \\cdots + A_p Y_{t - p} + c + \\epsilon_t$$ include_type = TRUE, constant term. function estimates every coefficient matrix. Consider response matrix \\(Y_0\\). Let \\(T\\) total number sample, let \\(m\\) dimension time series, let \\(p\\) order model, let \\(n = T - p\\). Likelihood VAR(p) $$Y_0 \\mid B, \\Sigma_e \\sim MN(X_0 B, I_s, \\Sigma_e)$$ \\(X_0\\) design matrix, MN matrix normal distribution. log-likelihood vector autoregressive model family specified $$\\log p(Y_0 \\mid B, \\Sigma_e) = - \\frac{nm}{2} \\log 2\\pi - \\frac{n}{2} \\log \\det \\Sigma_e - \\frac{1}{2} tr( (Y_0 - X_0 B) \\Sigma_e^{-1} (Y_0 - X_0 B)^T )$$ addition, recall OLS estimator matrix coefficient matrix MLE Gaussian assumption. MLE \\(\\Sigma_e\\) different denominator, \\(n\\). $$\\hat{B} = \\hat{B}^{LS} = \\hat{B}^{ML} = (X_0^T X_0)^{-1} X_0^T Y_0$$ $$\\hat\\Sigma_e = \\frac{1}{s - k} (Y_0 - X_0 \\hat{B})^T (Y_0 - X_0 \\hat{B})$$ $$\\tilde\\Sigma_e = \\frac{1}{s} (Y_0 - X_0 \\hat{B})^T (Y_0 - X_0 \\hat{B}) = \\frac{s - k}{s} \\hat\\Sigma_e$$ Let \\(\\tilde{\\Sigma}_e\\) MLE let \\(\\hat{\\Sigma}_e\\) unbiased estimator (covmat) \\(\\Sigma_e\\). Note $$\\tilde{\\Sigma}_e = \\frac{n - k}{n} \\hat{\\Sigma}_e$$ $$AIC(p) = \\log \\det \\Sigma_e + \\frac{2}{n}(\\text{number freely estimated parameters})$$ number freely estimated parameters \\(mk\\), .e. \\(pm^2\\) \\(pm^2 + m\\). Let \\(\\tilde{\\Sigma}_e\\) MLE let \\(\\hat{\\Sigma}_e\\) unbiased estimator (covmat) \\(\\Sigma_e\\). Note $$\\tilde{\\Sigma}_e = \\frac{n - k}{T} \\hat{\\Sigma}_e$$ $$BIC(p) = \\log \\det \\Sigma_e + \\frac{\\log n}{n}(\\text{number freely estimated parameters})$$ number freely estimated parameters \\(pm^2\\).","code":""},{"path":"/dev/reference/var_lm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting Vector Autoregressive Model of Order p Model ‚Äî var_lm","text":"L√ºtkepohl, H. (2007). New Introduction Multiple Time Series Analysis. Springer Publishing. Akaike, H. (1969). Fitting autoregressive models prediction. Ann Inst Stat Math 21, 243-247. Akaike, H. (1971). Autoregressive model fitting control. Ann Inst Stat Math 23, 163-180. Akaike H. (1974). new look statistical model identification. IEEE Transactions Automatic Control, vol. 19, . 6, pp. 716-723. Akaike H. (1998). Information Theory Extension Maximum Likelihood Principle. : Parzen E., Tanabe K., Kitagawa G. (eds) Selected Papers Hirotugu Akaike. Springer Series Statistics (Perspectives Statistics). Springer, New York, NY. Gideon Schwarz. (1978). Estimating Dimension Model. Ann. Statist. 6 (2) 461 - 464.","code":""},{"path":[]},{"path":"/dev/reference/var_lm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting Vector Autoregressive Model of Order p Model ‚Äî var_lm","text":"","code":"# Perform the function using etf_vix dataset fit <- var_lm(y = etf_vix, p = 2) class(fit) #> [1] \"varlse\"   \"olsmod\"   \"bvharmod\" str(fit) #> List of 16 #>  $ coefficients : num [1:19, 1:9] 0.9588 0.0313 -0.0235 -0.0944 -0.0048 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:19] \"GVZCLS_1\" \"OVXCLS_1\" \"VXFXICLS_1\" \"VXEEMCLS_1\" ... #>   .. ..$ : chr [1:9] \"GVZCLS\" \"OVXCLS\" \"VXFXICLS\" \"VXEEMCLS\" ... #>  $ fitted.values: num [1:903, 1:9] 21.3 22.2 21.5 21.1 21.3 ... #>  $ residuals    : num [1:903, 1:9] 1.008 -0.639 -0.284 0.298 0.308 ... #>  $ covmat       : num [1:9, 1:9] 1.113 0.373 0.304 0.445 1.366 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:9] \"GVZCLS\" \"OVXCLS\" \"VXFXICLS\" \"VXEEMCLS\" ... #>   .. ..$ : chr [1:9] \"GVZCLS\" \"OVXCLS\" \"VXFXICLS\" \"VXEEMCLS\" ... #>  $ df           : int 19 #>  $ m            : int 9 #>  $ obs          : int 903 #>  $ y0           : num [1:903, 1:9] 22.3 21.6 21.2 21.4 21.6 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : NULL #>   .. ..$ : chr [1:9] \"GVZCLS\" \"OVXCLS\" \"VXFXICLS\" \"VXEEMCLS\" ... #>  $ p            : int 2 #>  $ totobs       : num 905 #>  $ process      : chr \"VAR\" #>  $ type         : chr \"const\" #>  $ design       : num [1:903, 1:19] 21.5 22.3 21.6 21.2 21.4 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : NULL #>   .. ..$ : chr [1:19] \"GVZCLS_1\" \"OVXCLS_1\" \"VXFXICLS_1\" \"VXEEMCLS_1\" ... #>  $ y            : num [1:905, 1:9] 21.5 21.5 22.3 21.6 21.2 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : NULL #>   .. ..$ : chr [1:9] \"GVZCLS\" \"OVXCLS\" \"VXFXICLS\" \"VXEEMCLS\" ... #>  $ method       : chr \"nor\" #>  $ call         : language var_lm(y = etf_vix, p = 2) #>  - attr(*, \"class\")= chr [1:3] \"varlse\" \"olsmod\" \"bvharmod\"  # Extract coef, fitted values, and residuals coef(fit) #>                  GVZCLS       OVXCLS     VXFXICLS    VXEEMCLS     VXSLVCLS #> GVZCLS_1    0.958839561 -0.062827385 -0.019710690  0.01257027  0.291868669 #> OVXCLS_1    0.031306519  0.946200622 -0.006632872 -0.03089072  0.005701801 #> VXFXICLS_1 -0.023546344 -0.052053167  0.853672620 -0.06031077 -0.096749298 #> VXEEMCLS_1 -0.094354618 -0.073106564  0.074752695  0.86705288 -0.048927384 #> VXSLVCLS_1 -0.004803889  0.011100124 -0.028180528 -0.00787754  0.741225547 #> EVZCLS_1    0.125516130 -0.138276981  0.077667943 -0.05620528  0.213417413 #> VXXLECLS_1  0.077038206  0.116602536  0.049019313  0.19068844  0.123664057 #> VXGDXCLS_1 -0.041364201  0.022893379 -0.012790918 -0.02444514 -0.051351386 #> VXEWZCLS_1  0.032078312  0.081017743  0.002689773  0.02421098  0.011793646 #> GVZCLS_2   -0.104834812 -0.017750378 -0.063640299 -0.06563731 -0.284901251 #> OVXCLS_2   -0.057264753  0.000198619 -0.012230807  0.01529842 -0.021755404 #> VXFXICLS_2 -0.010770464  0.007308545  0.070962129  0.06532811  0.035457057 #> VXEEMCLS_2  0.109941832  0.031515218 -0.087805109  0.05027743  0.106490192 #> VXSLVCLS_2  0.031836190  0.026261295  0.084884303  0.07330380  0.165164782 #> EVZCLS_2   -0.039927065  0.240594601  0.018595199  0.07171981 -0.095041473 #> VXXLECLS_2 -0.063856767 -0.045562528 -0.052978615 -0.18149299 -0.106494854 #> VXGDXCLS_2  0.084605713  0.007572189  0.029414253  0.02242848  0.085005069 #> VXEWZCLS_2 -0.033916295 -0.071267512  0.007601670 -0.02085634 -0.019106806 #> const       0.484435224  0.071858917  0.764593553  0.73643928  0.993267584 #>                   EVZCLS     VXXLECLS     VXGDXCLS     VXEWZCLS #> GVZCLS_1   -0.0070051856  0.010258469  0.186062079  0.016397003 #> OVXCLS_1    0.0057743474 -0.055730279 -0.008620592 -0.017425642 #> VXFXICLS_1 -0.0013000787 -0.071102522 -0.019267681 -0.093669606 #> VXEEMCLS_1  0.0082641013  0.043573682  0.052515700  0.111449434 #> VXSLVCLS_1  0.0048970514 -0.010365439 -0.037485186 -0.035578884 #> EVZCLS_1    0.9530755788 -0.159179164 -0.029104883 -0.109896535 #> VXXLECLS_1  0.0073924911  1.090977549  0.173739155  0.097903592 #> VXGDXCLS_1 -0.0170045623 -0.002534079  0.717661085  0.014081721 #> VXEWZCLS_1  0.0295958720  0.039727624  0.029208637  0.919861136 #> GVZCLS_2    0.0011140822 -0.064661782 -0.129207944 -0.025690608 #> OVXCLS_2   -0.0013553534  0.045540919  0.007661278  0.007209753 #> VXFXICLS_2  0.0193175978  0.067148832  0.057541033  0.120471274 #> VXEEMCLS_2 -0.0273314378 -0.088654468 -0.128280935 -0.177756749 #> VXSLVCLS_2  0.0074048747  0.057079506  0.076151265  0.072552465 #> EVZCLS_2   -0.0026576824  0.171823659 -0.062484101  0.077971334 #> VXXLECLS_2 -0.0007146444 -0.109371143 -0.146653392 -0.060460831 #> VXGDXCLS_2  0.0111059419  0.007634580  0.222052920 -0.026452775 #> VXEWZCLS_2 -0.0304841577 -0.030496662 -0.018978557  0.055930225 #> const       0.1341878224  0.742494021  0.705738212  0.796582789 head(residuals(fit)) #>            [,1]        [,2]       [,3]        [,4]       [,5]        [,6] #> [1,]  1.0084235 -0.01665024 -0.1189584  0.18259423  1.0345739  0.54161189 #> [2,] -0.6393271  1.07781122 -0.7889172  0.06023516 -0.2598844 -0.30429270 #> [3,] -0.2841251 -1.13853760  0.8285284  1.09281272  1.3066535  0.53399638 #> [4,]  0.2975186 -0.89689641 -0.5797484 -0.31164787  1.3474286 -0.09610840 #> [5,]  0.3075188 -0.98987446 -0.6230728 -0.46134610  1.2499047  0.01799667 #> [6,] -0.4052045 -1.62792068 -0.9718923 -2.26508501 -1.1137253 -0.25997035 #>             [,7]       [,8]       [,9] #> [1,]  0.97639374  0.3811097 -0.2513162 #> [2,]  0.08960441 -0.6696317  0.4110768 #> [3,]  0.24450709 -0.9864375  1.7865058 #> [4,] -0.20575733  0.6892149 -0.3931113 #> [5,] -0.21831258  1.3123282 -0.5570114 #> [6,] -0.18371357 -1.1068942 -1.1856081 head(fitted(fit)) #>          [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8] #> [1,] 21.33158 35.53665 29.17896 29.63741 42.47543 12.57839 26.67361 33.37889 #> [2,] 22.23933 35.51219 29.24892 29.94976 43.08988 13.07429 27.55040 34.16963 #> [3,] 21.48413 36.75854 28.71147 30.03719 42.17335 12.77600 27.55549 33.79644 #> [4,] 21.10248 35.69190 29.68475 30.97165 42.64257 13.32611 27.66076 33.26579 #> [5,] 21.29248 34.95987 29.29307 30.65135 43.25010 13.13200 27.32831 33.78767 #> [6,] 21.54520 34.21792 28.93189 30.24509 43.75373 13.04997 27.03371 34.90689 #>          [,9] #> [1,] 30.43132 #> [2,] 30.33892 #> [3,] 30.91349 #> [4,] 32.54811 #> [5,] 32.16701 #> [6,] 31.65561"},{"path":"/dev/reference/vhar_bayes.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting Bayesian VHAR with Coefficient and Covariance Prior ‚Äî vhar_bayes","title":"Fitting Bayesian VHAR with Coefficient and Covariance Prior ‚Äî vhar_bayes","text":"function fits BVHAR. Covariance term can homoskedastic heteroskedastic (stochastic volatility). can Minnesota, SSVS, Horseshoe prior.","code":""},{"path":"/dev/reference/vhar_bayes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting Bayesian VHAR with Coefficient and Covariance Prior ‚Äî vhar_bayes","text":"","code":"vhar_bayes(   y,   har = c(5, 22),   exogen = NULL,   s = 0,   num_chains = 1,   num_iter = 1000,   num_burn = floor(num_iter/2),   thinning = 1,   coef_spec = set_bvhar(),   contem_spec = coef_spec,   cov_spec = set_ldlt(),   intercept = set_intercept(),   exogen_spec = coef_spec,   include_mean = TRUE,   minnesota = c(\"longrun\", \"short\", \"no\"),   ggl = TRUE,   save_init = FALSE,   convergence = NULL,   verbose = FALSE,   num_thread = 1 )  # S3 method for class 'bvharsv' print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  # S3 method for class 'bvharldlt' print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  # S3 method for class 'bvharsv' knit_print(x, ...)  # S3 method for class 'bvharldlt' knit_print(x, ...)"},{"path":"/dev/reference/vhar_bayes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting Bayesian VHAR with Coefficient and Covariance Prior ‚Äî vhar_bayes","text":"y Time series data columns indicate variables har Numeric vector weekly monthly order. default, c(5, 22). exogen Unmodeled variables s Lag exogeneous variables VARX(p, s). default, s = 0. num_chains Number MCMC chains num_iter MCMC iteration number num_burn Number burn-(warm-). Half iteration default choice. thinning Thinning every thinning-th iteration coef_spec Coefficient prior specification set_bvar(), set_ssvs(), set_horseshoe(). contem_spec Contemporaneous coefficient prior specification set_bvar(), set_ssvs(), set_horseshoe(). cov_spec SV specification set_sv(). intercept Prior constant term set_intercept(). exogen_spec Exogenous coefficient prior specification. include_mean Add constant term (Default: TRUE) (FALSE) minnesota Apply cross-variable shrinkage structure (Minnesota-way). Two type: short type longrun (default) type. can also set . ggl TRUE (default), use additional group shrinkage parameter group structure. Otherwise, use group shrinkage parameter instead global shirnkage parameter. Applies HS, NG, DL priors. save_init Save every record starting initial values (TRUE). default, exclude initial values record (FALSE), even num_burn = 0 thinning = 1. num_burn > 0 thinning != 1, option ignored. convergence Convergence threshold rhat < convergence. default, NULL means warning. verbose Print progress bar console. default, FALSE. num_thread Number threads x bvharldlt object digits digit option print ... used","code":""},{"path":"/dev/reference/vhar_bayes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting Bayesian VHAR with Coefficient and Covariance Prior ‚Äî vhar_bayes","text":"vhar_bayes() returns object named bvharsv class. list following components: coefficients Posterior mean coefficients. chol_posterior Posterior mean contemporaneous effects. param Every set MCMC trace. param_names Name every parameter. group Indicators group. num_group Number groups. df Numer Coefficients: 3m + 1 3m p 3 (number terms. contains element usage functions.) week Order weekly term month Order monthly term m Dimension data obs Sample size used training = totobs - p totobs Total number observation call Matched call process Description model, e.g. VHAR_SSVS_SV, VHAR_Horseshoe_SV, VHAR_minnesota-part_SV type include constant term (const) (none) spec Coefficients prior specification sv log volatility prior specification init Initial values intercept Intercept prior specification chain numer chains iter Total iterations burn Burn-thin Thinning HARtrans VHAR linear transformation matrix y0 \\(Y_0\\) design \\(X_0\\) y Raw input SSVS Horseshoe: pip Posterior inclusion probabilities.","code":""},{"path":"/dev/reference/vhar_bayes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting Bayesian VHAR with Coefficient and Covariance Prior ‚Äî vhar_bayes","text":"Cholesky stochastic volatility modeling VHAR based $$\\Sigma_t^{-1} = L^T D_t^{-1} L$$","code":""},{"path":"/dev/reference/vhar_bayes.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting Bayesian VHAR with Coefficient and Covariance Prior ‚Äî vhar_bayes","text":"Kim, Y. G., Baek, C. (2024). Bayesian vector heterogeneous autoregressive modeling. Journal Statistical Computation Simulation, 94(6), 1139-1157. Kim, Y. G., Baek, C. (n.d.). Working paper.","code":""},{"path":"/dev/reference/vhar_lm.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting Vector Heterogeneous Autoregressive Model ‚Äî vhar_lm","title":"Fitting Vector Heterogeneous Autoregressive Model ‚Äî vhar_lm","text":"function fits VHAR using OLS method.","code":""},{"path":"/dev/reference/vhar_lm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting Vector Heterogeneous Autoregressive Model ‚Äî vhar_lm","text":"","code":"vhar_lm(   y,   har = c(5, 22),   exogen = NULL,   s = 0,   include_mean = TRUE,   method = c(\"nor\", \"chol\", \"qr\") )  # S3 method for class 'vharlse' print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  # S3 method for class 'vharlse' logLik(object, ...)  # S3 method for class 'vharlse' AIC(object, ...)  # S3 method for class 'vharlse' BIC(object, ...)  is.vharlse(x)  # S3 method for class 'vharlse' knit_print(x, ...)"},{"path":"/dev/reference/vhar_lm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting Vector Heterogeneous Autoregressive Model ‚Äî vhar_lm","text":"y Time series data columns indicate variables har Numeric vector weekly monthly order. default, c(5, 22). exogen Exogenous variables s Lag exogeneous variables VHARX. default, s = 0. include_mean Add constant term (Default: TRUE) (FALSE) method Method solve linear equation system. (: normal equation (default), chol: Cholesky, qr: HouseholderQR) x object digits digit option print ... used object vharlse object","code":""},{"path":"/dev/reference/vhar_lm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting Vector Heterogeneous Autoregressive Model ‚Äî vhar_lm","text":"vhar_lm() returns object named vharlse class. list following components: coefficients Coefficient Matrix fitted.values Fitted response values residuals Residuals covmat LS estimate covariance matrix df Numer Coefficients m Dimension data obs Sample size used training = totobs - month y0 Multivariate response matrix p 3 (number terms. vharlse contains element usage functions.) week Order weekly term month Order monthly term totobs Total number observation process Process: VHAR type include constant term (const) (none) HARtrans VHAR linear transformation matrix design Design matrix VAR(month) y Raw input method Solving method call Matched call also bvharmod class.","code":""},{"path":"/dev/reference/vhar_lm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting Vector Heterogeneous Autoregressive Model ‚Äî vhar_lm","text":"VHAR model $$Y_{t} = \\Phi^{(d)} Y_{t - 1} + \\Phi^{(w)} Y_{t - 1}^{(w)} + \\Phi^{(m)} Y_{t - 1}^{(m)} + \\epsilon_t$$ function gives basic values.","code":""},{"path":"/dev/reference/vhar_lm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting Vector Heterogeneous Autoregressive Model ‚Äî vhar_lm","text":"Baek, C. Park, M. (2021). Sparse vector heterogeneous autoregressive modeling realized volatility. J. Korean Stat. Soc. 50, 495-510. Bub√°k, V., Koƒçenda, E., & ≈Ωike≈°, F. (2011). Volatility transmission emerging European foreign exchange markets. Journal Banking & Finance, 35(11), 2829-2841. Corsi, F. (2008). Simple Approximate Long-Memory Model Realized Volatility. Journal Financial Econometrics, 7(2), 174-196.","code":""},{"path":[]},{"path":"/dev/reference/vhar_lm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting Vector Heterogeneous Autoregressive Model ‚Äî vhar_lm","text":"","code":"# Perform the function using etf_vix dataset fit <- vhar_lm(y = etf_vix) class(fit) #> [1] \"vharlse\"  \"olsmod\"   \"bvharmod\" str(fit) #> List of 19 #>  $ coefficients : num [1:28, 1:9] 0.8698 0.02988 -0.01632 -0.10078 0.00306 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:28] \"GVZCLS_day\" \"OVXCLS_day\" \"VXFXICLS_day\" \"VXEEMCLS_day\" ... #>   .. ..$ : chr [1:9] \"GVZCLS\" \"OVXCLS\" \"VXFXICLS\" \"VXEEMCLS\" ... #>  $ fitted.values: num [1:883, 1:9] 20.4 20.6 20.1 19.9 19.3 ... #>  $ residuals    : num [1:883, 1:9] 0.3176 -0.5873 -0.3752 -0.8374 -0.0281 ... #>  $ covmat       : num [1:9, 1:9] 1.119 0.375 0.299 0.437 1.37 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:9] \"GVZCLS\" \"OVXCLS\" \"VXFXICLS\" \"VXEEMCLS\" ... #>   .. ..$ : chr [1:9] \"GVZCLS\" \"OVXCLS\" \"VXFXICLS\" \"VXEEMCLS\" ... #>  $ df           : int 28 #>  $ m            : int 9 #>  $ obs          : int 883 #>  $ y0           : num [1:883, 1:9] 20.7 20 19.7 19.1 19.2 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : NULL #>   .. ..$ : chr [1:9] \"GVZCLS\" \"OVXCLS\" \"VXFXICLS\" \"VXEEMCLS\" ... #>  $ p            : int 3 #>  $ week         : int 5 #>  $ month        : int 22 #>  $ totobs       : num 905 #>  $ process      : chr \"VHAR\" #>  $ type         : chr \"const\" #>  $ HARtrans     : num [1:28, 1:199] 1 0 0 0 0 0 0 0 0 0.2 ... #>  $ design       : num [1:883, 1:199] 20.4 20.7 20 19.7 19.1 ... #>  $ y            : num [1:905, 1:9] 21.5 21.5 22.3 21.6 21.2 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : NULL #>   .. ..$ : chr [1:9] \"GVZCLS\" \"OVXCLS\" \"VXFXICLS\" \"VXEEMCLS\" ... #>  $ method       : chr \"nor\" #>  $ call         : language vhar_lm(y = etf_vix) #>  - attr(*, \"class\")= chr [1:3] \"vharlse\" \"olsmod\" \"bvharmod\"  # Extract coef, fitted values, and residuals coef(fit) #>                      GVZCLS      OVXCLS      VXFXICLS     VXEEMCLS #> GVZCLS_day      0.869796005 -0.04681230 -0.0172897224  0.049002224 #> OVXCLS_day      0.029877159  0.91358257  0.0350799026  0.010047707 #> VXFXICLS_day   -0.016319909 -0.13959548  0.8575034005 -0.033709406 #> VXEEMCLS_day   -0.100780743 -0.08210474  0.0121290737  0.655662834 #> VXSLVCLS_day    0.003060357  0.03668387  0.0282158214  0.013830263 #> EVZCLS_day      0.186426595 -0.17282244  0.0494563262 -0.062064078 #> VXXLECLS_day    0.078818472  0.10515479  0.0728823779  0.279901357 #> VXGDXCLS_day   -0.039080303  0.04925811 -0.0428945531 -0.033003536 #> VXEWZCLS_day    0.032080106  0.07853175  0.0131343314  0.069517084 #> GVZCLS_week    -0.040418408 -0.07188231 -0.0938952991 -0.157648897 #> OVXCLS_week    -0.085524289 -0.06406862 -0.0701989801 -0.038293713 #> VXFXICLS_week  -0.029907441  0.12562086  0.0749857892  0.139908054 #> VXEEMCLS_week   0.230258633  0.05761231  0.0006402918  0.126209971 #> VXSLVCLS_week   0.027500102  0.02993123  0.0442818765  0.042748861 #> EVZCLS_week    -0.236308396  0.28602174 -0.0005685013  0.140233072 #> VXXLECLS_week  -0.120360477 -0.05095917 -0.1126391194 -0.332190330 #> VXGDXCLS_week   0.054947386 -0.06808223  0.0506682953  0.025319297 #> VXEWZCLS_week  -0.043554254 -0.05055300  0.0078698375 -0.007277838 #> GVZCLS_month    0.023458944  0.01754305 -0.0253911426  0.003596504 #> OVXCLS_month    0.001541434  0.07383772 -0.0059125573 -0.012132076 #> VXFXICLS_month -0.011772882 -0.02021036 -0.0587438676 -0.128208430 #> VXEEMCLS_month -0.134015581 -0.03842329 -0.0059768395  0.135807907 #> VXSLVCLS_month -0.002659358 -0.01415388 -0.0158012078  0.038533007 #> EVZCLS_month    0.185251113 -0.05458701  0.1512782039 -0.012040779 #> VXXLECLS_month  0.105997340  0.09819774  0.0508482758  0.101087018 #> VXGDXCLS_month  0.033825430  0.05583194  0.0377451676  0.024847951 #> VXEWZCLS_month  0.020348604 -0.01547358 -0.0074385193 -0.065668936 #> const           0.257508640 -0.75244225  0.7874223172  0.329901821 #>                     VXSLVCLS        EVZCLS     VXXLECLS    VXGDXCLS #> GVZCLS_day      0.2171686933 -8.528593e-04 -0.006316449  0.14468642 #> OVXCLS_day     -0.0038224358  1.317614e-02  0.023484352  0.06339221 #> VXFXICLS_day   -0.0821022074 -2.145593e-02 -0.074931174 -0.05632922 #> VXEEMCLS_day   -0.0951773758 -1.278904e-02 -0.111052628 -0.05281887 #> VXSLVCLS_day    0.6911996371  4.988352e-03  0.009943586  0.07416401 #> EVZCLS_day      0.2247289953  8.908482e-01 -0.164489289 -0.02651442 #> VXXLECLS_day    0.1848839755  2.688135e-02  1.110417850  0.20178781 #> VXGDXCLS_day   -0.0326865958 -1.097720e-02  0.015583137  0.65845387 #> VXEWZCLS_day    0.0086576066  2.741950e-02  0.057451312  0.06060228 #> GVZCLS_week    -0.1717505332  5.820058e-03 -0.062671994 -0.07765708 #> OVXCLS_week     0.0013998157 -3.043820e-02 -0.081955633 -0.06014147 #> VXFXICLS_week   0.0351147921  4.615955e-02  0.148110845  0.14285833 #> VXEEMCLS_week   0.2351233848  5.680828e-03  0.007968589  0.02454380 #> VXSLVCLS_week   0.1788828526 -8.453363e-05  0.023363480 -0.06368503 #> EVZCLS_week    -0.4461793985  1.019828e-02  0.182684876 -0.09790030 #> VXXLECLS_week  -0.2019441922 -2.813833e-02 -0.236461970 -0.21181825 #> VXGDXCLS_week   0.0003105573 -7.379189e-03 -0.011074423  0.20755785 #> VXEWZCLS_week  -0.0240538695 -2.495159e-02  0.001237576 -0.08368461 #> GVZCLS_month   -0.0834085916 -2.856799e-02 -0.047705620 -0.12266095 #> OVXCLS_month   -0.0657907568  1.107681e-02  0.017294294 -0.05920651 #> VXFXICLS_month -0.1051804654 -1.719717e-02 -0.087376926 -0.15744156 #> VXEEMCLS_month -0.0829087351 -1.492401e-02  0.038494367 -0.02320949 #> VXSLVCLS_month  0.0325418895  1.020723e-02  0.048603609  0.05950528 #> EVZCLS_month    0.5392049317  7.115211e-02  0.002772821  0.24304619 #> VXXLECLS_month  0.0824108862  2.585456e-02  0.176619398  0.06498108 #> VXGDXCLS_month  0.1042356427  2.218512e-02  0.016276608  0.11878639 #> VXEWZCLS_month  0.0298234196 -1.661517e-05 -0.049185431  0.06065243 #> const           0.8310348716 -2.382650e-02  0.258939806  0.60556631 #>                    VXEWZCLS #> GVZCLS_day      0.060810440 #> OVXCLS_day     -0.021328545 #> VXFXICLS_day   -0.103241781 #> VXEEMCLS_day   -0.050810494 #> VXSLVCLS_day   -0.041214628 #> EVZCLS_day     -0.044510366 #> VXXLECLS_day    0.286415660 #> VXGDXCLS_day   -0.004629846 #> VXEWZCLS_day    0.952152534 #> GVZCLS_week    -0.232659033 #> OVXCLS_week     0.029438686 #> VXFXICLS_week   0.233415007 #> VXEEMCLS_week  -0.104629279 #> VXSLVCLS_week   0.174714784 #> EVZCLS_week     0.123320940 #> VXXLECLS_week  -0.239829609 #> VXGDXCLS_week  -0.012408245 #> VXEWZCLS_week   0.018610770 #> GVZCLS_month    0.334911077 #> OVXCLS_month    0.012987518 #> VXFXICLS_month -0.111977668 #> VXEEMCLS_month  0.133305259 #> VXSLVCLS_month -0.181258940 #> EVZCLS_month   -0.129656359 #> VXXLECLS_month -0.041980863 #> VXGDXCLS_month -0.027342181 #> VXEWZCLS_month -0.009420411 #> const           1.047643911 head(residuals(fit)) #>             [,1]        [,2]       [,3]        [,4]       [,5]       [,6] #> [1,]  0.31758364 -0.11022615 -0.5296023  0.04716717 -0.5378020 -0.4659005 #> [2,] -0.58729937 -0.02977095 -0.9556970 -0.70126942 -1.4850409 -0.5500010 #> [3,] -0.37519058  0.15466899  2.8092305  1.54460103 -0.4209523  0.4631326 #> [4,] -0.83743454  0.32276054 -1.2472184 -1.66328320 -2.0118629 -0.4732741 #> [5,] -0.02811876  0.29432487 -0.2286953  0.48869052  0.5149326  0.3606493 #> [6,] -0.14617138  1.20662142  0.3416573  1.34978100 -0.7638851  0.6622565 #>             [,7]       [,8]       [,9] #> [1,] -0.03896889 -0.8878031  0.8547725 #> [2,] -0.01517932 -1.2314864 -0.6129635 #> [3,]  2.49685115  0.9469600  2.3957692 #> [4,] -2.00237189 -1.4008812 -1.1284324 #> [5,] -0.26141669  0.4395067  1.5021262 #> [6,]  0.71563874  0.7208909  1.7436068 head(fitted(fit)) #>          [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8] #> [1,] 20.37242 32.43023 29.98960 28.28283 40.30780 12.91590 24.22897 32.12780 #> [2,] 20.61730 32.45977 29.62570 28.64127 39.48504 12.51000 24.56518 32.01149 #> [3,] 20.10519 32.67533 28.92077 28.50540 38.21095 12.07687 25.06315 31.72304 #> [4,] 19.90743 32.97724 31.71722 30.56328 38.13186 12.61327 27.88237 33.30088 #> [5,] 19.26812 33.34568 30.41870 29.20131 36.60507 12.20935 26.08142 32.38049 #> [6,] 19.42617 33.64338 30.16834 29.66022 37.24389 12.58774 25.84436 33.12911 #>          [,9] #> [1,] 29.00523 #> [2,] 29.72296 #> [3,] 29.20423 #> [4,] 31.84843 #> [5,] 30.60787 #> [6,] 31.67639"},{"path":"/dev/news/index.html","id":"bvhar-development-version","dir":"Changelog","previous_headings":"","what":"bvhar (development version)","title":"bvhar (development version)","text":"Requires R >= 4.2 due Rtools 4.0 error optional parameters C++. Changed bayes_spec argument coef_spec contem_spec enable different priors Added mcmc option forecast_roll() forecast_expand() ldltmod svmod classes.","code":""},{"path":"/dev/news/index.html","id":"exogenous-variables-development-version","dir":"Changelog","previous_headings":"","what":"Exogenous variables","title":"bvhar (development version)","text":"var_lm() vhar_lm() can run VARX VHARX via exogen s. var_bayes() vhar_bayes() can run Bayesian VARX VHARX via exogen, s, exogen_spec. exogen_spec determines prior exogenous term. forecasting VARX VHARX models, predict() requires newxreg.","code":""},{"path":"/dev/news/index.html","id":"internal-changes-c-development-version","dir":"Changelog","previous_headings":"","what":"Internal changes (C++)","title":"bvhar (development version)","text":"Added shrinkage headers strategy design pattern. Added McmcParams, McmcAlgo, McmcRun (changed original McmcRun CtaRun) extensibility MCMC algorithms. Also added base forecaster classes. Changed way OLS spillover classes work. Added OlsSpilloverRun OlsDynamicSpillover volatility spillover OLS. defining USE_BVHAR_DEBUG macro variable compiling, users can see debug messages.","code":""},{"path":"/dev/news/index.html","id":"bvhar-222","dir":"Changelog","previous_headings":"","what":"bvhar 2.2.2","title":"bvhar 2.2.2","text":"CRAN release: 2025-02-28 Fix unlist() error print methods r-devel (4.5.0).","code":""},{"path":"/dev/news/index.html","id":"bvhar-221","dir":"Changelog","previous_headings":"","what":"bvhar 2.2.1","title":"bvhar 2.2.1","text":"CRAN release: 2025-02-25","code":""},{"path":"/dev/news/index.html","id":"bvhar-220","dir":"Changelog","previous_headings":"","what":"bvhar 2.2.0","title":"bvhar 2.2.0","text":"CRAN release: 2025-02-06 Requires R >= 4.1 following tidyverse R version support schedule stable = TRUE can filter MCMC draws coefficient stable forecasting. Changed Eigen boost assertion behavior (eigen_assert BOOST_ASSERT) give error instead abort. Transpose predictive distribution update loop. med = TRUE gives median forecast draws point forecast. var_bayes() vhar_bayes() can choose use group shrinkage parameters without global parameter ggl = FALSE option. set_gdp() can use Generalized Double Pareto (GDP) shrinkage prior. alpl() gives summary LPL across every horizon.","code":""},{"path":"/dev/news/index.html","id":"internal-changes-2-2-0","dir":"Changelog","previous_headings":"","what":"Internal changes","title":"bvhar 2.2.0","text":"Apply Devroye (2014) draw GIG instead H√∂rmann Leydold. Use spdlog (using RcppSpdlog) logger instead custom progress bar (bvharprogress). Use RcppThread make logger thread-safe (eddelbuettel/rcppspdlog#22) Use inverse-gamma prior group parameters DL. SAVS penalty zero -lag.","code":""},{"path":"/dev/news/index.html","id":"removal-or-deprecation-2-2-0","dir":"Changelog","previous_headings":"","what":"Removal or deprecation","title":"bvhar 2.2.0","text":"Removed sim_gig() R function.","code":""},{"path":"/dev/news/index.html","id":"c-header-file-changes-2-2-0","dir":"Changelog","previous_headings":"","what":"C++ Header file changes","title":"bvhar 2.2.0","text":"Use template avoid code duplicates among LDLT SV models. Can easily conduct MCMC using McmcRun class C++ source. Can easily implement forecasting LDLT SV MCMC using McmcVarforecastRun<> McmcVharforecastRun<>. Can easily use rolling expanding forecast LDLT ans SV MCMC using McmcVarforecastRun<> McmcVharforecastRun<>.","code":""},{"path":"/dev/news/index.html","id":"removal-of-deprecated-functions-2-2-0","dir":"Changelog","previous_headings":"","what":"Removal of deprecated functions","title":"bvhar 2.2.0","text":"Removed bvar_sv() bvhar_sv(). Removed bvar_ssvs(), bvhar_ssvs(), init_ssvs(), choose_ssvs(), sim_ssvs_var(), sim_ssvs_vhar(). Removed bvar_horseshoe(), bvhar_horseshoe(), sim_horseshoe_var(), sim_horseshoe_vhar().","code":""},{"path":"/dev/news/index.html","id":"bvhar-212","dir":"Changelog","previous_headings":"","what":"bvhar 2.1.2","title":"bvhar 2.1.2","text":"CRAN release: 2024-10-11 Fix MCMC algorithm include_mean = TRUE case. Fix predictive distribution update codes (predict(), forecast_roll(), forecast_expand() ldltmod svmod classes). Fix --forecasting (forecast_roll() forecast_expand()) result process codes.","code":""},{"path":"/dev/news/index.html","id":"bvhar-211","dir":"Changelog","previous_headings":"","what":"bvhar 2.1.1","title":"bvhar 2.1.1","text":"CRAN release: 2024-10-05 using GIG generation MCMC, maximum iteration numbers statement. Defined USE_RCPP macro C++ header Rcpp source usage works fine.","code":""},{"path":"/dev/news/index.html","id":"bvhar-210","dir":"Changelog","previous_headings":"","what":"bvhar 2.1.0","title":"bvhar 2.1.0","text":"CRAN release: 2024-09-16 Use Signal Adaptive Variable Selector (SAVS) generate sparse coefficient shrinkage priors. var_bayes() vhar_bayes() now handle shrinkage priors stochastic volatility. bvar_ssvs(), bvar_horseshoe(), bvar_sv(), bvhar_ssvs(), bvhar_horseshoe(), bvhar_sv() deprecated, removed v2.1.0 source functions. set_horseshoe() additional setting group_shrinkage. Horseshoe sampling now additional group shrinkage level parameters. set_ssvs() now additionally specify different Beta hyperparameters -lag cross-lag. set_ssvs() sets scaling factor inverse-gamma hyperparameters coefficients cholesky factor slab sd. Use full bayesian approach SSVS spike slab sd‚Äôs instead semi-automatic approach, var_bayes() vhar_bayes(). MCMC functions return give $param $param_names, individual $*_record members. sim_gig() generates Generalized Inverse Gaussian (GIG) random numbers using algorithm R package GIGrvg.","code":""},{"path":"/dev/news/index.html","id":"new-priors-2-1-0","dir":"Changelog","previous_headings":"","what":"New priors","title":"bvhar 2.1.0","text":"set_dl() specifies Dirichlet-Laplace (DL) prior var_bayes() vhar_bayes(). set_ng() specifies Normal-Gamma (NG) prior var_bayes() vhar_bayes(). bvar_sv() bvhar_sv() supports hierarchical Minnesota prior.","code":""},{"path":"/dev/news/index.html","id":"internal-changes-2-1-0","dir":"Changelog","previous_headings":"","what":"Internal changes","title":"bvhar 2.1.0","text":"Added regularization step internal Normal posterior generation function non-existing LLT case. Added BOOST_DISABLE_ASSERTS flag boost asserts.","code":""},{"path":"/dev/news/index.html","id":"spillover-effects-2-1-0","dir":"Changelog","previous_headings":"","what":"Spillover effects","title":"bvhar 2.1.0","text":"spillover() computes static spillover given model. dynamic_spillover() computes dynamic spillover given model.","code":""},{"path":"/dev/news/index.html","id":"forecasting-2-1-0","dir":"Changelog","previous_headings":"","what":"Forecasting","title":"bvhar 2.1.0","text":"predict(), forecast_roll(), forecast_expand() LDLT models can use CI level adding sparsity. predict(), forecast_roll(), forecast_expand() ldltmod sparse option use sparsity. predict(), forecast_roll(), forecast_expand() SV models can use CI level adding sparsity. predict(), forecast_roll(), forecast_expand() svmod sparse option use sparsity. --sample forecasting functions now S3 generics (forecast_roll() forecast_expand()). Add Rolling-window forecasting LDLT models (forecast_roll.ldltmod()). Add Expanding-window forecasting LDLT models (forecast_expand.ldltmod()). Add Rolling-window forecasting SV models (forecast_roll.svmod()). Add Expanding-window forecasting SV models (forecast_expand.svmod()). forecasting SV models, available choose whether use time-varying covariance (use_sv option, TRUE default). forecast_roll() forecast_expand() can implement OpenMP multithreading, except bvarflat class. model uses multiple chain MCMC, static schedule used forecast_roll() dynamic schedule forecast_expand(). sim_mniw() output format changed list lists. Now can use MNIW generation including header (std::vector<Eigen::MatrixXd> sim_mn_iw(...)). Compute LPL inside forecast_roll.svmod() forecast_expand.svmod() using lpl option. Instead, lpl method removed.","code":""},{"path":"/dev/news/index.html","id":"bvhar-201","dir":"Changelog","previous_headings":"","what":"bvhar 2.0.1","title":"bvhar 2.0.1","text":"CRAN release: 2024-03-01 Fix internal vectorization unvectorization behavior. Used Eigen 3.4 feature (reshaped()) solve (RcppEigen >= 0.3.4.0.0).","code":""},{"path":"/dev/news/index.html","id":"bvhar-200","dir":"Changelog","previous_headings":"","what":"bvhar 2.0.0","title":"bvhar 2.0.0","text":"CRAN release: 2024-02-14 Start implement OOP C++ source model, ready major update. Add SV specification (sv_spec argument) bvhar_sv() bvar_sv() (set_sv()). Prevent SSVS overflow issues using log-sum-exp trick computing Bernoulli posterior probability. Add separate constant term prior specification (intercept) bvhar_sv() bvar_sv() (set_intercept()). Convert every header file inst/include header-format. enables external inclusion classes, structs, Rcpp functions using LinkingTo (R package development) // [[Rcpp::depends(RcppEigen, BH, bvhar)]].","code":""},{"path":"/dev/news/index.html","id":"parallel-chain-mcmc-2-0-0","dir":"Changelog","previous_headings":"","what":"Parallel Chain MCMC","title":"bvhar 2.0.0","text":"Use OpenMP parallel loop Progress bar show status master thread OpenMP enabled. Interruption detect just save values break loop, return immediately. burn-thinning returnRecords() method make pre-process parallel chains easier. Use boost library (BH package) RNG instead Rf_* RNG Rcpp thread-safety. Introduce function overloading internal Rcpp random generation functions temporarily. ‚Äôs maintaining set.seed() usage functions.","code":""},{"path":"/dev/news/index.html","id":"bvhar-120","dir":"Changelog","previous_headings":"","what":"bvhar 1.2.0","title":"bvhar 1.2.0","text":"CRAN release: 2024-01-09 Replace progress bar RcppProgress package custom header (bvharprogress.h). Replace checking user interruption package custom header (bvharinterrupt.h). Fix triangular algorithm. Found missing update variables (bvar_sv() bvhar_sv()).","code":""},{"path":"/dev/news/index.html","id":"bvhar-110","dir":"Changelog","previous_headings":"","what":"bvhar 1.1.0","title":"bvhar 1.1.0","text":"CRAN release: 2023-12-18 new research, add new features shrinkage priors. Add Shrinkage priors SSVS Horseshoe (bvar_ssvs(), bvhar_ssvs(), bvar_horseshoe(), bvhar_horseshoe()). bvar_sv(), bvhar_sv() works SSVS (set_ssvs()) Horseshoe (set_horseshoe()). Update shrinkage structure spirit Minnesota. (minnesota = TRUE, minnesota = c(\"\", \"short\", \"longrun\")). Stochastic volatility models implement corrected triangular algorithm Carriero et al.¬†(2021).","code":""},{"path":"/dev/news/index.html","id":"bvhar-102","dir":"Changelog","previous_headings":"","what":"bvhar 1.0.2","title":"bvhar 1.0.2","text":"CRAN release: 2023-12-06 License changed GPLv3. Remove unnecessary Rcpp plugins source files.","code":""},{"path":"/dev/news/index.html","id":"bvhar-101","dir":"Changelog","previous_headings":"","what":"bvhar 1.0.1","title":"bvhar 1.0.1","text":"CRAN release: 2023-11-10 Fix knitr::knit_print() method export methods (#2).","code":""},{"path":"/dev/news/index.html","id":"bvhar-100","dir":"Changelog","previous_headings":"","what":"bvhar 1.0.0","title":"bvhar 1.0.0","text":"CRAN release: 2023-11-08 ‚ÄúBayesian Vector Heterogeneous Autoregressive Modeling‚Äù accepted JSCS üéâ Update major version publication.","code":""},{"path":[]},{"path":"/dev/news/index.html","id":"bvhar-0140","dir":"Changelog","previous_headings":"","what":"bvhar 0.14.0","title":"bvhar 0.14.0","text":"Add Stochastic Search Variable Selection (SSVS) models VAR VHAR (bvar_ssvs() bvhar_ssvs()) Can corresponding variable selection (summary.ssvsmod())","code":""},{"path":"/dev/news/index.html","id":"bvhar-0130","dir":"Changelog","previous_headings":"","what":"bvhar 0.13.0","title":"bvhar 0.13.0","text":"Add stochastic volatility models VAR-SV VHAR-SV (bvar_sv() bvhar_sv()).","code":""},{"path":"/dev/news/index.html","id":"bvhar-0121","dir":"Changelog","previous_headings":"","what":"bvhar 0.12.1","title":"bvhar 0.12.1","text":"Fix working Hierarchical natural conjugate MNIW function (bvar_niwhm()). Use posterior package summary.normaliw() improve processing printing.","code":""},{"path":"/dev/news/index.html","id":"bvhar-0120","dir":"Changelog","previous_headings":"","what":"bvhar 0.12.0","title":"bvhar 0.12.0","text":"Now can use heavy-tailed distribution (Multivariate t-distribution) generating VAR VHAR process (sim_var() sim_vhar()). Also provide independent MVT generation function (sim_mvt()).","code":""},{"path":"/dev/news/index.html","id":"bvhar-0110","dir":"Changelog","previous_headings":"","what":"bvhar 0.11.0","title":"bvhar 0.11.0","text":"Added method = c(\"\", \"chol\", \"qr\") option VAR VHAR fitting function use cholesky Householder QR method (var_lm() vhar_lm()). Now include_mean works internally Rcpp.","code":""},{"path":"/dev/news/index.html","id":"bvhar-0100","dir":"Changelog","previous_headings":"","what":"bvhar 0.10.0","title":"bvhar 0.10.0","text":"Add partial t-test VAR VHAR coefficient (summary.varlse() summary.vharlse()). Appropriate print method updated summary method (print.summary.varlse() print.summary.vharlse()).","code":""},{"path":"/dev/news/index.html","id":"bvhar-090","dir":"Changelog","previous_headings":"","what":"bvhar 0.9.0","title":"bvhar 0.9.0","text":"Can compute impulse response function VAR (varlse) VHAR (vharlse) models (analyze_ir()). Can draw impulse -> response plot grid panels (autoplot.bvharirf()).","code":""},{"path":"/dev/news/index.html","id":"bvhar-080","dir":"Changelog","previous_headings":"","what":"bvhar 0.8.0","title":"bvhar 0.8.0","text":"Changed way specifying lower upper bounds empirical bayes (bound_bvhar()). Added Empirical Bayes vignette.","code":""},{"path":"/dev/news/index.html","id":"bvhar-071","dir":"Changelog","previous_headings":"","what":"bvhar 0.7.1","title":"bvhar 0.7.1","text":"simulation, asymmetric covariance error caught now (sim_mgaussian()).","code":""},{"path":"/dev/news/index.html","id":"bvhar-070","dir":"Changelog","previous_headings":"","what":"bvhar 0.7.0","title":"bvhar 0.7.0","text":"Add one integrated function can empirical bayes (choose_bayes() bound_bvhar()).","code":""},{"path":"/dev/news/index.html","id":"bvhar-061","dir":"Changelog","previous_headings":"","what":"bvhar 0.6.1","title":"bvhar 0.6.1","text":"Pre-process date column oxfordman elaborately (becomes etf_vix).","code":""},{"path":"/dev/news/index.html","id":"bvhar-060","dir":"Changelog","previous_headings":"","what":"bvhar 0.6.0","title":"bvhar 0.6.0","text":"Added weekly monthly order feature VHAR family (vhar_lm() bvhar_minnesota()). functions compatible har order option (predict.vharlse(), predict.bvharmn(), choose_bvhar())","code":""},{"path":"/dev/news/index.html","id":"bvhar-052","dir":"Changelog","previous_headings":"","what":"bvhar 0.5.2","title":"bvhar 0.5.2","text":"Added parallel option empirical bayes (choose_bvar() choose_bvhar()).","code":""},{"path":"/dev/news/index.html","id":"bvhar-051","dir":"Changelog","previous_headings":"","what":"bvhar 0.5.1","title":"bvhar 0.5.1","text":"Added facet feature loss plot changed name (gg_loss()).","code":""},{"path":"/dev/news/index.html","id":"bvhar-050","dir":"Changelog","previous_headings":"","what":"bvhar 0.5.0","title":"bvhar 0.5.0","text":"Added rolling window expanding window features (forecast_roll() forecast_expand()). Can compute loss rolling expanding window method (mse.bvharcv(), mae.bvharcv(), mape.bvharcv(), mape.bvharcv()).","code":""},{"path":"/dev/news/index.html","id":"bvhar-041","dir":"Changelog","previous_headings":"","what":"bvhar 0.4.1","title":"bvhar 0.4.1","text":"Fix Marginal likelihood form (compute_logml()). Optimize empirical bayes method using stabilized marginal likelihood function (logml_stable()).","code":""},{"path":"/dev/news/index.html","id":"bvhar-040","dir":"Changelog","previous_headings":"","what":"bvhar 0.4.0","title":"bvhar 0.4.0","text":"Change way compute CI BVAR BVHAR (predict.bvarmn(), predict.bvharmn(), predict.bvarflat()) Used custom random generation function - MN, IW, MNIW based RcppEigen","code":""},{"path":"/dev/news/index.html","id":"bvhar-030","dir":"Changelog","previous_headings":"","what":"bvhar 0.3.0","title":"bvhar 0.3.0","text":"Added Bayesian model specification functions class (bvharspec). Replaced hyperparameters model specification Bayesian models (bvar_minnesota(), bvar_flat(), bvhar_minnesota()).","code":""},{"path":"/dev/news/index.html","id":"bvhar-020","dir":"Changelog","previous_headings":"","what":"bvhar 0.2.0","title":"bvhar 0.2.0","text":"Added constant term choice function (var_lm(), vhar_lm(), bvar_minnesota(), bvar_flat(), bvhar_minnesota()).","code":""},{"path":"/dev/news/index.html","id":"bvhar-010","dir":"Changelog","previous_headings":"","what":"bvhar 0.1.0","title":"bvhar 0.1.0","text":"Added NEWS.md file track changes package.","code":""}]
