[{"path":[]},{"path":"/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement [INSERT CONTACT METHOD]. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.0, available https://www.contributor-covenant.org/version/2/0/ code_of_conduct.html. Community Impact Guidelines inspired Mozilla’s code conduct enforcement ladder. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https:// www.contributor-covenant.org/translations.","code":""},{"path":"/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to bvhar","title":"Contributing to bvhar","text":"outlines propose change bvhar. detailed info contributing , tidyverse packages, please see development contributing guide.","code":""},{"path":"/CONTRIBUTING.html","id":"fixing-typos","dir":"","previous_headings":"","what":"Fixing typos","title":"Contributing to bvhar","text":"can fix typos, spelling mistakes, grammatical errors documentation directly using GitHub web interface, long changes made source file. generally means ’ll need edit roxygen2 comments .R, .Rd file. can find .R file generates .Rd reading comment first line.","code":""},{"path":"/CONTRIBUTING.html","id":"bigger-changes","dir":"","previous_headings":"","what":"Bigger changes","title":"Contributing to bvhar","text":"want make bigger change, ’s good idea first file issue make sure someone team agrees ’s needed. ’ve found bug, please file issue illustrates bug minimal reprex (also help write unit test, needed).","code":""},{"path":"/CONTRIBUTING.html","id":"pull-request-process","dir":"","previous_headings":"Bigger changes","what":"Pull request process","title":"Contributing to bvhar","text":"Fork package clone onto computer. haven’t done , recommend using usethis::create_from_github(\"ygeunkim/bvhar\", fork = TRUE). Install development dependences devtools::install_dev_deps(), make sure package passes R CMD check running devtools::check(). R CMD check doesn’t pass cleanly, ’s good idea ask help continuing. Create Git branch pull request (PR). recommend using usethis::pr_init(\"brief-description--change\"). Make changes, commit git, create PR running usethis::pr_push(), following prompts browser. title PR briefly describe change. body PR contain Fixes #issue-number. user-facing changes, add bullet top NEWS.md (.e. just first header). Follow style described https://style.tidyverse.org/news.html.","code":""},{"path":"/CONTRIBUTING.html","id":"code-style","dir":"","previous_headings":"Bigger changes","what":"Code style","title":"Contributing to bvhar","text":"New code follow tidyverse style guide. can use styler package apply styles, please don’t restyle code nothing PR. use roxygen2, Markdown syntax, documentation. use testthat unit tests. Contributions test cases included easier accept.","code":""},{"path":"/CONTRIBUTING.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Contributing to bvhar","text":"Please note bvhar project released Contributor Code Conduct. contributing project agree abide terms.","code":""},{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) 2023  Young Geun Kim  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. bvhar  Copyright (C) 2023  Young Geun Kim This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"/SUPPORT.html","id":null,"dir":"","previous_headings":"","what":"Getting help with bvhar","title":"Getting help with bvhar","text":"Thanks using bvhar! filing issue, places explore pieces put together make process smooth possible.","code":""},{"path":"/SUPPORT.html","id":"make-a-reprex","dir":"","previous_headings":"","what":"Make a reprex","title":"Getting help with bvhar","text":"Start making minimal reproducible example using reprex package. haven’t heard used reprex , ’re treat! Seriously, reprex make R-question-asking endeavors easier (pretty insane ROI five ten minutes ’ll take learn ’s ). additional reprex pointers, check Get help! section tidyverse site.","code":""},{"path":"/SUPPORT.html","id":"where-to-ask","dir":"","previous_headings":"","what":"Where to ask?","title":"Getting help with bvhar","text":"Armed reprex, next step figure ask. ’s question: start community.rstudio.com, /StackOverflow. people answer questions. ’s bug: ’re right place, file issue. ’re sure: let community help figure ! problem bug feature request, can easily return report . opening new issue, sure search issues pull requests make sure bug hasn’t reported /already fixed development version. default, search pre-populated :issue :open. can edit qualifiers (e.g. :pr, :closed) needed. example, ’d simply remove :open search issues repo, open closed.","code":""},{"path":"/SUPPORT.html","id":"what-happens-next","dir":"","previous_headings":"","what":"What happens next?","title":"Getting help with bvhar","text":"efficient possible, development tidyverse packages tends bursty, shouldn’t worry don’t get immediate response. Typically don’t look repo sufficient quantity issues accumulates, ’s burst intense activity focus efforts. makes development efficient avoids expensive context switching problems, cost taking longer get back . process makes good reprex particularly important might multiple months initial report start working . can’t reproduce bug, can’t fix !","code":""},{"path":"/articles/bvhar.html","id":"data","dir":"Articles","previous_headings":"","what":"Data","title":"Introduction to bvhar","text":"Looking VAR VHAR, can learn models work perform package.","code":""},{"path":"/articles/bvhar.html","id":"etf-dataset","dir":"Articles","previous_headings":"Data","what":"ETF Dataset","title":"Introduction to bvhar","text":"package includes datasets. Among , try CBOE ETF volatility index (etf_vix). Since just example, arbitrarily extract small number variables: Gold, crude oil, euro currency, china ETF.","code":"var_idx <- c(\"GVZCLS\", \"OVXCLS\", \"EVZCLS\", \"VXFXICLS\") etf <-    etf_vix %>%    dplyr::select(dplyr::all_of(var_idx)) etf #> # A tibble: 905 × 4 #>    GVZCLS OVXCLS EVZCLS VXFXICLS #>     <dbl>  <dbl>  <dbl>    <dbl> #>  1   21.5   36.5   13.2     30.2 #>  2   21.5   35.4   12.6     28.9 #>  3   22.3   35.5   13.1     29.1 #>  4   21.6   36.6   12.8     28.5 #>  5   21.2   35.6   13.3     29.5 #>  6   21.4   34.8   13.2     29.1 #>  7   21.6   34.0   13.2     28.7 #>  8   21.1   32.6   12.8     28.0 #>  9   20.3   33.5   12.7     28.9 #> 10   19.6   33.4   12.4     28.0 #> # ℹ 895 more rows"},{"path":"/articles/bvhar.html","id":"h-step-ahead-forecasting","dir":"Articles","previous_headings":"Data","what":"h-step ahead forecasting","title":"Introduction to bvhar","text":"evaluation, split data. last 19 observations test set. divide_ts() function splits time series train-test set. vignette, provide perform --sample forecasting. T: Total number observation p: VAR lag m: Dimension variable s = T - p k = m * p + 1 constant term, k = m * p without constant term","code":"h <- 19 etf_eval <- divide_ts(etf, h) # Try ?divide_ts etf_train <- etf_eval$train # train etf_test <- etf_eval$test # test # dimension--------- m <- ncol(etf)"},{"path":[]},{"path":"/articles/bvhar.html","id":"var","dir":"Articles","previous_headings":"Models","what":"VAR","title":"Introduction to bvhar","text":"package indentifies VAR(p) model \\[\\mathbf{Y}_t = \\mathbf{c}+ \\boldsymbol\\beta_1 \\mathbf{Y}_{t - 1} + \\ldots + \\boldsymbol\\beta_p +\\mathbf{Y}_{t - p} + \\boldsymbol\\epsilon_t\\] \\(\\boldsymbol\\epsilon_t \\sim N(\\mathbf{0}_k, \\Sigma_e)\\) package perform VAR(p = 5) based \\[Y_0 = X_0 + Z\\] \\[ Y_0 = \\begin{bmatrix}   \\mathbf{y}_{p + 1}^T \\\\   \\mathbf{y}_{p + 2}^T \\\\   \\vdots \\\\   \\mathbf{y}_n^T \\end{bmatrix}_{s \\times m} \\equiv Y_{p + 1} \\\\mathbb{R}^{s \\times m} \\] build_y0() \\[ X_0 = \\left[\\begin{array}{c|c|c|c}   \\mathbf{y}_p^T & \\cdots & \\mathbf{y}_1^T & 1 \\\\   \\mathbf{y}_{p + 1}^T & \\cdots & \\mathbf{y}_2^T & 1 \\\\   \\vdots & \\vdots & \\cdots & \\vdots \\\\   \\mathbf{y}_{T - 1}^T & \\cdots & \\mathbf{y}_{T - p}^T & 1 \\end{array}\\right]_{s \\times k} = \\begin{bmatrix}   Y_p & Y_{p - 1} & \\cdots & \\mathbf{1}_{T - p} \\end{bmatrix} \\\\mathbb{R}^{s \\times k} \\] build_design(). Coefficient matrix form \\[ = \\begin{bmatrix}   A_1^T \\\\   \\vdots \\\\   A_p^T \\\\   \\mathbf{c}^T \\end{bmatrix} \\\\mathbb{R}^{k \\times m} \\] form also corresponds model. Use var_lm(y, p) model VAR(p). can specify type = \"none\" get model without constant term. package provide S3 object.","code":"var_lag <- 5 (fit_var <- var_lm(etf_train, var_lag)) #> Call: #> var_lm(y = etf_train, p = var_lag) #>  #> VAR(5) Estimation using least squares #> ==================================================== #>  #> LSE for A1: #>           GVZCLS_1  OVXCLS_1  EVZCLS_1  VXFXICLS_1 #> GVZCLS     0.93290    0.0545    0.0659     -0.0346 #> OVXCLS    -0.02367    1.0047   -0.1447      0.0324 #> EVZCLS    -0.00789    0.0102    0.9810      0.0199 #> VXFXICLS  -0.03868    0.0109    0.0754      0.9328 #>  #>  #> LSE for A2: #>           GVZCLS_2  OVXCLS_2  EVZCLS_2  VXFXICLS_2 #> GVZCLS     -0.0781  -0.04865    0.0829      0.0561 #> OVXCLS      0.0880   0.01207    0.2729     -0.1173 #> EVZCLS      0.0195   0.00255   -0.1071     -0.0383 #> VXFXICLS    0.0896   0.04278   -0.0691      0.0419 #>  #>  #> LSE for A3: #>           GVZCLS_3  OVXCLS_3  EVZCLS_3  VXFXICLS_3 #> GVZCLS      0.0424  -0.00452  -0.03245    -0.05967 #> OVXCLS     -0.0272  -0.09144  -0.05764    -0.06255 #> EVZCLS     -0.0123   0.00864   0.08693     0.00252 #> VXFXICLS   -0.0266  -0.04810   0.00851    -0.02137 #>  #>  #> LSE for A4: #>           GVZCLS_4  OVXCLS_4  EVZCLS_4  VXFXICLS_4 #> GVZCLS    -0.00793   0.01072  -0.01513      0.0616 #> OVXCLS    -0.04343  -0.00377  -0.00694      0.1445 #> EVZCLS     0.00614  -0.02278  -0.01007      0.0200 #> VXFXICLS  -0.00755  -0.05555   0.08783     -0.1025 #>  #>  #> LSE for A5: #>           GVZCLS_5  OVXCLS_5  EVZCLS_5  VXFXICLS_5 #> GVZCLS      0.0728  -0.01745   -0.0886   -0.017273 #> OVXCLS      0.0104   0.07151   -0.0637    0.002018 #> EVZCLS     -0.0113   0.00581    0.0202    0.000498 #> VXFXICLS   -0.0155   0.04192   -0.0254    0.093984 #>  #>  #> LSE for constant: #>   GVZCLS    OVXCLS    EVZCLS  VXFXICLS   #>    0.571     0.145     0.129     0.875   #>  #>  #> -------------------------------------------------- #> *_j of the Coefficient matrix: corresponding to the j-th VAR lag # class--------------- class(fit_var) #> [1] \"varlse\"   \"bvharmod\" # inheritance--------- is.varlse(fit_var) #> [1] TRUE # names--------------- names(fit_var) #>  [1] \"coefficients\"  \"fitted.values\" \"residuals\"     \"covmat\"        #>  [5] \"df\"            \"p\"             \"m\"             \"obs\"           #>  [9] \"totobs\"        \"call\"          \"process\"       \"type\"          #> [13] \"y0\"            \"design\"        \"y\""},{"path":"/articles/bvhar.html","id":"vhar","dir":"Articles","previous_headings":"Models","what":"VHAR","title":"Introduction to bvhar","text":"Consider Vector HAR (VHAR) model. \\[\\mathbf{Y}_t = \\mathbf{c}+ \\Phi^{(d)} + \\mathbf{Y}_{t - 1} + \\Phi^{(w)} \\mathbf{Y}_{t - 1}^{(w)} + \\Phi^{(m)} \\mathbf{Y}_{t - 1}^{(m)} + \\boldsymbol\\epsilon_t\\] \\(\\mathbf{Y}_t\\) daily RV \\[\\mathbf{Y}_t^{(w)} = \\frac{1}{5} \\left( \\mathbf{Y}_t + \\cdots + \\mathbf{Y}_{t - 4} \\right)\\] weekly RV \\[\\mathbf{Y}_t^{(m)} = \\frac{1}{22} \\left( \\mathbf{Y}_t + \\cdots + \\mathbf{Y}_{t - 21} \\right)\\] monthly RV. model can expressed \\[Y_0 = X_1 \\Phi + Z\\] \\[ \\Phi = \\begin{bmatrix}   \\Phi^{(d)T} \\\\   \\Phi^{(w)T} \\\\   \\Phi^{(m)T} \\\\   \\mathbf{c}^T \\end{bmatrix} \\\\mathbb{R}^{(3m + 1) \\times m} \\] Let \\(T\\) \\[ \\mathbb{C}_0 \\mathpunct{:}=\\begin{bmatrix}   1 & 0 & \\cdots & 0 & 0 & \\cdots & 0 \\\\   1 / 5 & 1 / 5 & \\cdots & 1 / 5 & 0 & \\cdots & 0 \\\\   1 / 22 & 1 / 22 & \\cdots & 1 / 22 & 1 / 22 & \\cdots & 1 / 22 \\end{bmatrix} \\otimes I_m \\\\mathbb{R}^{3m \\times 22m} \\] let \\(\\mathbb{C}_{HAR}\\) \\[ \\mathbb{C}_{HAR} \\mathpunct{:}=\\left[\\begin{array}{c|c}   T & \\mathbf{0}_{3m} \\\\ \\hline   \\mathbf{0}_{3m}^T & 1 \\end{array}\\right] \\\\mathbb{R}^{(3m + 1) \\times (22m + 1)} \\] \\(X_0\\) VAR(p), \\[ X_1 = X_0 \\mathbb{C}_{HAR}^T = \\begin{bmatrix}   \\mathbf{y}_{22}^T & \\mathbf{y}_{22}^{(w)T} & \\mathbf{y}_{22}^{(m)T} & 1 \\\\   \\mathbf{y}_{23}^T & \\mathbf{y}_{23}^{(w)T} & \\mathbf{y}_{23}^{(m)T} & 1 \\\\   \\vdots & \\vdots & \\vdots & \\vdots \\\\   \\mathbf{y}_{T - 1}^T & \\mathbf{y}_{T - 1}^{(w)T} & \\mathbf{y}_{T - 1}^{(m)T} & 1 \\end{bmatrix} \\\\mathbb{R}^{s \\times (3m + 1)} \\] package fits VHAR scaling VAR(p) using \\(\\mathbb{C}_{HAR}\\) (scale_har(m, week = 5, month = 22)). Use vhar_lm(y) fit VHAR. can specify type = \"none\" get model without constant term.","code":"(fit_har <- vhar_lm(etf_train)) #> Call: #> vhar_lm(y = etf_train) #>  #> VHAR Estimation==================================================== #>  #> LSE for day: #>           GVZCLS_day  OVXCLS_day  EVZCLS_day  VXFXICLS_day #> GVZCLS       0.87561      0.0447      0.1623      -0.03772 #> OVXCLS       0.04147      0.9942     -0.0605      -0.09361 #> EVZCLS       0.00305      0.0281      0.9206      -0.00748 #> VXFXICLS     0.01021      0.0569      0.0440       0.91713 #>  #>  #> LSE for week: #>           GVZCLS_week  OVXCLS_week  EVZCLS_week  VXFXICLS_week #> GVZCLS        0.01622      -0.0554      -0.1608         0.0637 #> OVXCLS       -0.07093      -0.0373       0.2000         0.1034 #> EVZCLS       -0.00334      -0.0414      -0.0101         0.0239 #> VXFXICLS     -0.03756      -0.0787      -0.0135         0.0480 #>  #>  #> LSE for month: #>           GVZCLS_month  OVXCLS_month  EVZCLS_month  VXFXICLS_month #> GVZCLS        0.084981       0.00359        0.0228         -0.0299 #> OVXCLS        0.045986       0.03825       -0.1564         -0.0157 #> EVZCLS       -0.000597       0.02030        0.0501         -0.0138 #> VXFXICLS      0.041648       0.01263        0.0639         -0.0371 #>  #>  #> LSE for constant: #>   GVZCLS    OVXCLS    EVZCLS  VXFXICLS   #>    0.491     0.135     0.105     0.926   #>  #>  #> -------------------------------------------------- #> *_day, *_week, *_month of the Coefficient matrix: daily, weekly, and monthly term in the VHAR model # class---------------- class(fit_har) #> [1] \"vharlse\"  \"bvharmod\" # inheritance---------- is.varlse(fit_har) #> [1] FALSE is.vharlse(fit_har) #> [1] TRUE # complements---------- names(fit_har) #>  [1] \"coefficients\"  \"fitted.values\" \"residuals\"     \"covmat\"        #>  [5] \"df\"            \"p\"             \"week\"          \"month\"         #>  [9] \"m\"             \"obs\"           \"totobs\"        \"call\"          #> [13] \"process\"       \"type\"          \"HARtrans\"      \"y0\"            #> [17] \"design\"        \"y\""},{"path":"/articles/bvhar.html","id":"bvar","dir":"Articles","previous_headings":"Models","what":"BVAR","title":"Introduction to bvhar","text":"bvhar package provides two prior framework - Minnesota prior flat prior.","code":""},{"path":"/articles/bvhar.html","id":"minnesota-prior","dir":"Articles","previous_headings":"Models > BVAR","what":"Minnesota prior","title":"Introduction to bvhar","text":"Litterman (1986) Bańbura et al. (2010) equations centered around random walk drift. Prior mean: Recent lags provide reliable information distant ones. Prior variance: lags explain variation given variable lags variables equation. First specify prior using set_bvar(sigma, lambda, delta, eps = 1e-04). turn, bvar_minnesota(y, p, bayes_spec, include_mean = TRUE) fits BVAR(p). y: Multivariate time series data. data frame matrix, means every column numeric. column indicates variable, .e. sould wide format. p: Order BVAR bayes_spec: Output set_bvar() include_mean = TRUE: default, include constant term model. bvarmn class. Bayes computation, also class normaliw bvharmod.","code":"bvar_lag <- 5 sig <- apply(etf_train, 2, sd) # sigma vector lam <- .2 # lambda delta <- rep(0, m) # delta vector (0 vector since RV stationary) eps <- 1e-04 # very small number (bvar_spec <- set_bvar(sig, lam, delta, eps)) #> Model Specification for BVAR #>  #> Parameters: Coefficent matrice and Covariance matrix #> Prior: Minnesota #> # Type '?bvar_minnesota' in the console for some help. #> ======================================================== #>  #> Setting for 'sigma': #>   GVZCLS    OVXCLS    EVZCLS  VXFXICLS   #>     3.77     10.63      2.27      3.81   #>  #> Setting for 'lambda': #> [1]  0.2 #>  #> Setting for 'delta': #> [1]  0  0  0  0 #>  #> Setting for 'eps': #> [1]  1e-04 (fit_bvar <- bvar_minnesota(etf_train, bvar_lag, bvar_spec)) #> Call: #> bvar_minnesota(y = etf_train, p = bvar_lag, bayes_spec = bvar_spec) #>  #> BVAR(5) with Minnesota Prior #> ==================================================== #>  #> A ~ Matrix Normal (Mean, Precision, Scale = Sigma) #> ==================================================== #> Matrix Normal Mean for A1 part: #>           GVZCLS_1  OVXCLS_1  EVZCLS_1  VXFXICLS_1 #> GVZCLS      0.7771   0.00915    0.0628      0.0193 #> OVXCLS      0.0445   0.70884    0.1111      0.0167 #> EVZCLS      0.0104   0.01068    0.7036      0.0266 #> VXFXICLS    0.0214   0.00673    0.1044      0.7674 #>  #>  #> Matrix Normal Mean for A2 part: #>            GVZCLS_2   OVXCLS_2  EVZCLS_2  VXFXICLS_2 #> GVZCLS     0.082726  -0.006736  -0.01387     -0.0020 #> OVXCLS     0.000568   0.140781   0.02419     -0.0436 #> EVZCLS    -0.004778   0.000769   0.11756     -0.0114 #> VXFXICLS   0.013424  -0.003779   0.00369      0.1063 #>  #>  #> Matrix Normal Mean for A3 part: #>           GVZCLS_3   OVXCLS_3  EVZCLS_3  VXFXICLS_3 #> GVZCLS     0.03574  -0.003825  -0.01504    -0.00581 #> OVXCLS    -0.01733   0.054037   0.00196    -0.01874 #> EVZCLS    -0.00391   0.000223   0.05065    -0.00168 #> VXFXICLS  -0.00891  -0.006167  -0.00435     0.02176 #>  #>  #> Matrix Normal Mean for A4 part: #>           GVZCLS_4   OVXCLS_4   EVZCLS_4  VXFXICLS_4 #> GVZCLS     0.02474  -0.001932  -0.011546     0.00263 #> OVXCLS    -0.00987   0.030763   0.003771     0.00845 #> EVZCLS    -0.00318  -0.000206   0.027289     0.00161 #> VXFXICLS  -0.00898  -0.004378   0.000232     0.00582 #>  #>  #> Matrix Normal Mean for A5 part: #>           GVZCLS_5   OVXCLS_5  EVZCLS_5  VXFXICLS_5 #> GVZCLS     0.01986  -1.47e-03  -0.00970     0.00127 #> OVXCLS    -0.00357   2.10e-02   0.00339     0.01017 #> EVZCLS    -0.00284   1.59e-05   0.01729     0.00159 #> VXFXICLS  -0.00431  -1.70e-03   0.00263     0.01207 #>  #>  #> Matrix Normal Mean for constant part: #>   GVZCLS    OVXCLS    EVZCLS  VXFXICLS   #>   0.7271    0.3713    0.0971    1.2139   #>  #>  #> dim(Matrix Normal precision matrix): #> [1]  21  21 #>  #>  #> Sigma ~ Inverse-Wishart #> ==================================================== #> IW scale matrix: #>           GVZCLS  OVXCLS  EVZCLS  VXFXICLS #> GVZCLS      1285     375     115       287 #> OVXCLS       375    3638     131       397 #> EVZCLS       115     131     220       126 #> VXFXICLS     287     397     126      1186 #>  #> IW degrees of freedom: #> [1] 887 #>  #>  #> -------------------------------------------------- #> *_j of the Coefficient matrix: corresponding to the j-th BVAR lag # class--------------- class(fit_bvar) #> [1] \"bvarmn\"   \"normaliw\" \"bvharmod\" # inheritance--------- is.bvarmn(fit_bvar) #> [1] TRUE # names--------------- names(fit_bvar) #>  [1] \"coefficients\"    \"fitted.values\"   \"residuals\"       \"mn_prec\"         #>  [5] \"iw_scale\"        \"iw_shape\"        \"df\"              \"p\"               #>  [9] \"m\"               \"obs\"             \"totobs\"          \"call\"            #> [13] \"process\"         \"spec\"            \"type\"            \"prior_mean\"      #> [17] \"prior_precision\" \"prior_scale\"     \"prior_shape\"     \"y0\"              #> [21] \"design\"          \"y\""},{"path":"/articles/bvhar.html","id":"flat-prior","dir":"Articles","previous_headings":"Models > BVAR","what":"Flat prior","title":"Introduction to bvhar","text":"Ghosh et al. (2018) provides flat prior covariance matrix, .e. non-informative. Use set_bvar_flat(U). bvar_flat(y, p, bayes_spec, include_mean = TRUE):","code":"(flat_spec <- set_bvar_flat(U = 5000 * diag(m * bvar_lag + 1))) # c * I #> Model Specification for BVAR #>  #> Parameters: Coefficent matrice and Covariance matrix #> Prior: Flat #> # Type '?bvar_flat' in the console for some help. #> ======================================================== #>  #> Setting for 'U': #> # A matrix:  21 x 21  #>        [,1]  [,2]  [,3]  [,4]  [,5] #>  [1,]  5000     0     0     0     0 #>  [2,]     0  5000     0     0     0 #>  [3,]     0     0  5000     0     0 #>  [4,]     0     0     0  5000     0 #>  [5,]     0     0     0     0  5000 #>  [6,]     0     0     0     0     0 #>  [7,]     0     0     0     0     0 #>  [8,]     0     0     0     0     0 #>  [9,]     0     0     0     0     0 #> [10,]     0     0     0     0     0 #> # ... with 11 more rows (fit_ghosh <- bvar_flat(etf_train, bvar_lag, flat_spec)) #> Call: #> bvar_flat(y = etf_train, p = bvar_lag, bayes_spec = flat_spec) #>  #> BVAR(5) with Flat Prior #> ==================================================== #>  #> A ~ Matrix Normal (Mean, U^{-1}, Scale 2 = Sigma) #> ==================================================== #> Matrix Normal Mean for A1 part: #>           GVZCLS_1  OVXCLS_1  EVZCLS_1  VXFXICLS_1 #> GVZCLS      0.3128    0.0460    0.0205      0.0457 #> OVXCLS      0.0440    0.4128    0.0186      0.0314 #> EVZCLS      0.0174    0.0230    0.1334      0.0410 #> VXFXICLS    0.0477    0.0464    0.0481      0.3197 #>  #>  #> Matrix Normal Mean for A2 part: #>           GVZCLS_2  OVXCLS_2  EVZCLS_2  VXFXICLS_2 #> GVZCLS     0.19811   0.00287   0.00771      0.0194 #> OVXCLS     0.01595   0.23709   0.00978     -0.0111 #> EVZCLS     0.00425   0.01205   0.11715      0.0201 #> VXFXICLS   0.02725   0.01516   0.03513      0.2162 #>  #>  #> Matrix Normal Mean for A3 part: #>           GVZCLS_3  OVXCLS_3  EVZCLS_3  VXFXICLS_3 #> GVZCLS     0.13884   -0.0153  -0.00102     0.00591 #> OVXCLS    -0.00741    0.1304   0.00361    -0.02452 #> EVZCLS    -0.00353    0.0079   0.10724     0.01150 #> VXFXICLS   0.00797   -0.0146   0.02633     0.14628 #>  #>  #> Matrix Normal Mean for A4 part: #>           GVZCLS_4  OVXCLS_4  EVZCLS_4  VXFXICLS_4 #> GVZCLS     0.11392  -0.01775  -0.00653     0.00884 #> OVXCLS    -0.01626   0.09421   0.00195    -0.00572 #> EVZCLS    -0.00847   0.00565   0.10046     0.01098 #> VXFXICLS  -0.00356  -0.03067   0.02292     0.10552 #>  #>  #> Matrix Normal Mean for A5 part: #>           GVZCLS_5  OVXCLS_5  EVZCLS_5  VXFXICLS_5 #> GVZCLS     0.11282   -0.0208  -0.01028     0.01136 #> OVXCLS    -0.01507    0.1004   0.00155     0.00973 #> EVZCLS    -0.01252    0.0104   0.09667     0.01361 #> VXFXICLS  -0.00492   -0.0215   0.02342     0.10353 #>  #>  #> Matrix Normal Mean for constant part: #>   GVZCLS    OVXCLS    EVZCLS  VXFXICLS   #> 5.49e-03  7.82e-04  8.83e-05  9.82e-03   #>  #>  #> dim(Matrix Normal precision matrix): #> [1]  21  21 #>  #>  #> Sigma ~ Inverse-Wishart #> ==================================================== #> IW scale matrix: #>           GVZCLS  OVXCLS  EVZCLS  VXFXICLS #> GVZCLS      2483     595     209       535 #> OVXCLS       595    3580     216       578 #> EVZCLS       209     216     771       354 #> VXFXICLS     535     578     354      2472 #>  #>  #> -------------------------------------------------- #> *_j of the Coefficient matrix: corresponding to the j-th BVAR lag # class--------------- class(fit_ghosh) #> [1] \"bvarflat\" \"normaliw\" \"bvharmod\" # inheritance--------- is.bvarflat(fit_ghosh) #> [1] TRUE # names--------------- names(fit_ghosh) #>  [1] \"coefficients\"    \"fitted.values\"   \"residuals\"       \"mn_prec\"         #>  [5] \"iw_scale\"        \"iw_shape\"        \"df\"              \"p\"               #>  [9] \"m\"               \"obs\"             \"totobs\"          \"process\"         #> [13] \"spec\"            \"type\"            \"call\"            \"prior_mean\"      #> [17] \"prior_precision\" \"y0\"              \"design\"          \"y\""},{"path":"/articles/bvhar.html","id":"bvhar","dir":"Articles","previous_headings":"Models","what":"BVHAR","title":"Introduction to bvhar","text":"Consider VAR(22) form VHAR. \\[ \\begin{aligned}   \\mathbf{Y}_t = \\mathbf{c}& + \\left( \\Phi^{(d)} + \\frac{1}{5} \\Phi^{(w)} + \\frac{1}{22} \\Phi^{(m)} \\right) \\mathbf{Y}_{t - 1} \\\\   & + \\left( \\frac{1}{5} \\Phi^{(w)} + \\frac{1}{22} \\Phi^{(m)} \\right) \\mathbf{Y}_{t - 2} + \\cdots \\left( \\frac{1}{5} \\Phi^{(w)} + \\frac{1}{22} \\Phi^{(m)} \\right) \\mathbf{Y}_{t - 5} \\\\   & + \\frac{1}{22} \\Phi^{(m)} \\mathbf{Y}_{t - 6} + \\cdots + \\frac{1}{22} \\Phi^{(m)} \\mathbf{Y}_{t - 22} \\end{aligned} \\] Minnesota prior mean VHAR model? equations centered around \\(\\mathbf{Y}_t + \\mathbf{c}+ \\Phi^{(d)} \\mathbf{Y}_{t - 1} + \\boldsymbol\\epsilon_t\\) \\(\\Phi^{(w)}\\) \\(\\Phi^{(m)}\\) zero WN form: \\(\\delta_i = 0\\) simplicity, write coefficient matrices \\(\\Phi^{(1)}, \\Phi^{(2)}, \\Phi^{(3)}\\). apply prior way, Minnesota moment becomes \\[ E \\left[ (\\Phi^{(l)})_{ij} \\right] = \\begin{cases}   \\delta_i & j = , \\; l = 1 \\\\   0 & o/w \\end{cases} \\quad \\mathrm{Var}\\left[ (\\Phi^{(l)})_{ij} \\right] = \\begin{cases}   \\frac{\\lambda^2}{l^2} & j = \\\\   \\nu \\frac{\\lambda^2}{l^2} \\frac{\\sigma_i^2}{\\sigma_j^2} & o/w \\end{cases} \\] call VAR-type Minnesota prior BVHAR-S.","code":""},{"path":"/articles/bvhar.html","id":"bvhar-s","dir":"Articles","previous_headings":"Models > BVHAR","what":"BVHAR-S","title":"Introduction to bvhar","text":"set_bvhar(sigma, lambda, delta, eps = 1e-04) specifies VAR-type Minnesota prior. bvhar_minnesota(y, har = c(5, 22), bayes_spec, include_mean = TRUE) can fit BVHAR prior. default prior setting. model bvharmn class.","code":"(bvhar_spec_v1 <- set_bvhar(sig, lam, delta, eps)) #> Model Specification for BVHAR #>  #> Parameters: Coefficent matrice and Covariance matrix #> Prior: MN_VAR #> # Type '?bvhar_minnesota' in the console for some help. #> ======================================================== #>  #> Setting for 'sigma': #>   GVZCLS    OVXCLS    EVZCLS  VXFXICLS   #>     3.77     10.63      2.27      3.81   #>  #> Setting for 'lambda': #> [1]  0.2 #>  #> Setting for 'delta': #> [1]  0  0  0  0 #>  #> Setting for 'eps': #> [1]  1e-04 (fit_bvhar_v1 <- bvhar_minnesota(etf_train, bayes_spec = bvhar_spec_v1)) #> Call: #> bvhar_minnesota(y = etf_train, bayes_spec = bvhar_spec_v1) #>  #> BVHAR with Minnesota Prior #> ==================================================== #>  #> Phi ~ Matrix Normal (Mean, Scale 1, Scale 2 = Sigma) #> ==================================================== #> Matrix Normal Mean for day: #>           GVZCLS_day  OVXCLS_day  EVZCLS_day  VXFXICLS_day #> GVZCLS        0.7808     0.00502      0.0595        0.0181 #> OVXCLS        0.0419     0.75268      0.1293       -0.0129 #> EVZCLS        0.0109     0.00957      0.7248        0.0213 #> VXFXICLS      0.0252     0.00347      0.1003        0.8042 #>  #>  #> Matrix Normal Mean for week: #>           GVZCLS_week  OVXCLS_week  EVZCLS_week  VXFXICLS_week #> GVZCLS         0.1160    -0.007669     -0.03216       -0.00181 #> OVXCLS        -0.0211     0.152822      0.02794       -0.00136 #> EVZCLS        -0.0103    -0.000372      0.13214       -0.00158 #> VXFXICLS      -0.0177    -0.010393      0.00229        0.10274 #>  #>  #> Matrix Normal Mean for month: #>           GVZCLS_month  OVXCLS_month  EVZCLS_month  VXFXICLS_month #> GVZCLS         0.05269      -0.00345       -0.0110        -0.00302 #> OVXCLS         0.00556       0.05169       -0.0225        -0.01051 #> EVZCLS        -0.00441       0.00410        0.0502        -0.00138 #> VXFXICLS       0.00733      -0.00321        0.0109         0.00573 #>  #>  #> Matrix Normal Mean for constant part: #>   GVZCLS    OVXCLS    EVZCLS  VXFXICLS   #>   0.6107    0.1410    0.0741    1.1544   #>  #>  #> dim(Matrix Normal precision matrix): #> [1]  13  13 #>  #>  #> Sigma ~ Inverse-Wishart #> ==================================================== #> IW scale matrix: #>           GVZCLS  OVXCLS  EVZCLS  VXFXICLS #> GVZCLS      1268     366     114       286 #> OVXCLS       366    3742     131       378 #> EVZCLS       114     131     219       121 #> VXFXICLS     286     378     121      1189 # class--------------- class(fit_bvhar_v1) #> [1] \"bvharmn\"  \"normaliw\" \"bvharmod\" # inheritance--------- is.bvharmn(fit_bvhar_v1) #> [1] TRUE # names--------------- names(fit_bvhar_v1) #>  [1] \"coefficients\"    \"fitted.values\"   \"residuals\"       \"mn_prec\"         #>  [5] \"iw_scale\"        \"iw_shape\"        \"df\"              \"p\"               #>  [9] \"week\"            \"month\"           \"m\"               \"obs\"             #> [13] \"totobs\"          \"call\"            \"process\"         \"spec\"            #> [17] \"type\"            \"prior_mean\"      \"prior_precision\" \"prior_scale\"     #> [21] \"prior_shape\"     \"HARtrans\"        \"y0\"              \"design\"          #> [25] \"y\""},{"path":"/articles/bvhar.html","id":"bvhar-l","dir":"Articles","previous_headings":"Models > BVHAR","what":"BVHAR-L","title":"Introduction to bvhar","text":"Set \\(\\delta_i\\) weekly monthly coefficient matrices Minnesota moments: \\[ E \\left[ (\\Phi^{(l)})_{ij} \\right] = \\begin{cases}   d_i & j = , \\; l = 1 \\\\   w_i & j = , \\; l = 2 \\\\   m_i & j = , \\; l = 3 \\end{cases} \\] .e. instead one delta vector, set three vector daily weekly monthly called VHAR-type Minnesota prior BVHAR-L. set_weight_bvhar(sigma, lambda, eps, daily, weekly, monthly) defines BVHAR-L. bayes_spec option bvhar_minnesota() gets value, can use prior intuitively.","code":"daily <- rep(.1, m) weekly <- rep(.1, m) monthly <- rep(.1, m) (bvhar_spec_v2 <- set_weight_bvhar(sig, lam, eps, daily, weekly, monthly)) #> Model Specification for BVHAR #>  #> Parameters: Coefficent matrice and Covariance matrix #> Prior: MN_VHAR #> # Type '?bvhar_minnesota' in the console for some help. #> ======================================================== #>  #> Setting for 'sigma': #>   GVZCLS    OVXCLS    EVZCLS  VXFXICLS   #>     3.77     10.63      2.27      3.81   #>  #> Setting for 'lambda': #> [1]  0.2 #>  #> Setting for 'eps': #> [1]  1e-04 #>  #> Setting for 'daily': #> [1]  0.1  0.1  0.1  0.1 #>  #> Setting for 'weekly': #> [1]  0.1  0.1  0.1  0.1 #>  #> Setting for 'monthly': #> [1]  0.1  0.1  0.1  0.1 fit_bvhar_v2 <- bvhar_minnesota(   etf_train,    bayes_spec = bvhar_spec_v2 ) fit_bvhar_v2 #> Call: #> bvhar_minnesota(y = etf_train, bayes_spec = bvhar_spec_v2) #>  #> BVHAR with Minnesota Prior #> ==================================================== #>  #> Phi ~ Matrix Normal (Mean, Scale 1, Scale 2 = Sigma) #> ==================================================== #> Matrix Normal Mean for day: #>           GVZCLS_day  OVXCLS_day  EVZCLS_day  VXFXICLS_day #> GVZCLS        0.7780     0.00503      0.0605        0.0183 #> OVXCLS        0.0435     0.74834      0.1234       -0.0110 #> EVZCLS        0.0112     0.00947      0.7218        0.0211 #> VXFXICLS      0.0253     0.00363      0.0997        0.8021 #>  #>  #> Matrix Normal Mean for week: #>           GVZCLS_week  OVXCLS_week  EVZCLS_week  VXFXICLS_week #> GVZCLS         0.1180    -0.007746     -0.03245       -0.00215 #> OVXCLS        -0.0213     0.155999      0.02539       -0.00152 #> EVZCLS        -0.0104    -0.000477      0.13525       -0.00186 #> VXFXICLS      -0.0182    -0.010424      0.00136        0.10491 #>  #>  #> Matrix Normal Mean for month: #>           GVZCLS_month  OVXCLS_month  EVZCLS_month  VXFXICLS_month #> GVZCLS         0.05510      -0.00346      -0.01138        -0.00359 #> OVXCLS         0.00473       0.05518      -0.02463        -0.01064 #> EVZCLS        -0.00451       0.00393       0.05338        -0.00178 #> VXFXICLS       0.00681      -0.00319       0.00994         0.00823 #>  #>  #> Matrix Normal Mean for constant part: #>   GVZCLS    OVXCLS    EVZCLS  VXFXICLS   #>   0.5989    0.1195    0.0759    1.1240   #>  #>  #> dim(Matrix Normal precision matrix): #> [1]  13  13 #>  #>  #> Sigma ~ Inverse-Wishart #> ==================================================== #> IW scale matrix: #>           GVZCLS  OVXCLS  EVZCLS  VXFXICLS #> GVZCLS      1252     367     114       286 #> OVXCLS       367    3607     130       380 #> EVZCLS       114     130     214       121 #> VXFXICLS     286     380     121      1174"},{"path":"/articles/bvhar.html","id":"inference","dir":"Articles","previous_headings":"Models","what":"Inference","title":"Introduction to bvhar","text":"summary() method normaliw object performs MCMC based conjugate MNIW distribution. autoplot() gives several Bayes visualization based bayesplot package. type = \"trace\" type = \"dens\" type = \"area\"","code":"(inf_bvar <- summary(fit_bvar, num_iter = 10000, num_burn = 5000)) #> Call: #> bvar_minnesota(y = etf_train, p = bvar_lag, bayes_spec = bvar_spec) #>  #> BVAR(5) with Minnesota Prior #> ==================================================== #> Phi ~ Matrix Normal (Mean, Precision, Scale = Sigma) #> Sigma ~ Inverse-Wishart (IW Scale, IW df) #>  #>  #> Conjugate MCMC: #> ==================================================== #> Total number of iteration: 10000 #> Number of burn-in: 5000 #> ==================================================== #>  #> Parameter record: #> # A draws_df: 5000 iterations, 1 chains, and 94 variables #>     alpha[1]  alpha[2]  alpha[3]  alpha[4]  alpha[5]  alpha[6]  alpha[7] #> 1      0.782   0.01900    0.1082  -0.01713    0.0778  -0.02016  -0.04249 #> 2      0.771   0.02805    0.1741  -0.02644    0.1191  -0.00915  -0.07979 #> 3      0.792   0.00966    0.0206  -0.02666    0.0563   0.00389   0.02754 #> 4      0.810   0.00663    0.0443   0.03536    0.0687  -0.00745   0.03969 #> 5      0.755   0.01324   -0.0268   0.03741    0.1122  -0.01740   0.06798 #> 6      0.780   0.02466    0.0722  -0.00605    0.0531  -0.01612   0.02113 #> 7      0.779   0.02240    0.1136  -0.04152    0.0902  -0.01079   0.01486 #> 8      0.818   0.00400    0.0968   0.03691    0.0472  -0.00912   0.00984 #> 9      0.794   0.01312   -0.0580  -0.00267    0.0603   0.00483   0.03454 #> 10     0.793  -0.00984   -0.0313   0.03740    0.0654   0.00821   0.04095 #>      alpha[8] #> 1    0.021548 #> 2   -0.006194 #> 3   -0.001558 #> 4   -0.002852 #> 5   -0.008489 #> 6    0.012011 #> 7    0.044801 #> 8   -0.000476 #> 9    0.029307 #> 10  -0.004706 #> # ... with 4990 more draws, and 86 more variables #> # ... hidden reserved variables {'.chain', '.iteration', '.draw'} autoplot(inf_bvar, type = \"trace\", pars = c(\"alpha[1]\", \"alpha[2]\"))"},{"path":"/articles/empirical-bayes.html","id":"hyperparameters-in-normal-inverse-wishart-priors","dir":"Articles","previous_headings":"","what":"Hyperparameters in Normal-inverse-Wishart Priors","title":"Empirical Bayes","text":"vignette, discuss hyperparameters Normal-inverse-Wishart priors BVAR, BVHAR-S, BVHAR-L.","code":""},{"path":"/articles/empirical-bayes.html","id":"bvar","dir":"Articles","previous_headings":"Hyperparameters in Normal-inverse-Wishart Priors","what":"BVAR","title":"Empirical Bayes","text":"Litterman (1986) Bańbura et al. (2010), \\(\\sigma_j\\) (sigma), \\(\\lambda\\) (lambda), \\(\\delta_j\\) (delta) BVAR. \\(\\sigma_i^2 / \\sigma_j^2\\) Minnesota moments explain data scales. \\(\\forall j \\; \\delta_j = 1\\), random walk prior (Litterman (1986) setting). \\(\\forall j \\; \\delta_j = 0\\), white noise. \\(\\lambda\\) controls overall tightness prior around two prior beliefs. addition, small number \\(\\epsilon\\) (eps) matrix invertibility. set 1e-04 (default). can change number. Based properties, users subjectively choose hyperparameter. Consider four indices CBOE ETF volatility index (etf_vix): Gold, crude oil, emerging markets, gold miners, silver. split train-test set (Test = last 20 points). following BVAR Minnesota prior specification. sigma: standard error lambda: small number small dimension delta: Litterman’s setting one parameter, order \\(p\\). Set \\(p = 3\\).","code":"etf_split <-    etf_vix %>%    dplyr::select(GVZCLS, OVXCLS, VXEEMCLS, VXGDXCLS, VXSLVCLS) %>%    divide_ts(20) # split--------------------- etf_train <- etf_split$train etf_test <- etf_split$test dim_data <- ncol(etf_train) sig <- apply(etf_train, 2, sd) lam <- .2 del <- rep(1, dim_data) # bvharspec------------------ (bvar_spec <- set_bvar(   sigma = sig,   lambda = lam,   delta = del,   eps = 1e-04 )) #> Model Specification for BVAR #>  #> Parameters: Coefficent matrice and Covariance matrix #> Prior: Minnesota #> # Type '?bvar_minnesota' in the console for some help. #> ======================================================== #>  #> Setting for 'sigma': #>   GVZCLS    OVXCLS  VXEEMCLS  VXGDXCLS  VXSLVCLS   #>     3.77     10.63      4.39      7.45      5.99   #>  #> Setting for 'lambda': #> [1]  0.2 #>  #> Setting for 'delta': #> [1]  1  1  1  1  1 #>  #> Setting for 'eps': #> [1]  1e-04 bvar_cand <- bvar_minnesota(   y = etf_train,    p = 3,    bayes_spec = bvar_spec,    include_mean = TRUE )"},{"path":"/articles/empirical-bayes.html","id":"bvhar-s","dir":"Articles","previous_headings":"Hyperparameters in Normal-inverse-Wishart Priors","what":"BVHAR-S","title":"Empirical Bayes","text":"BVHAR-S (Kim et al. (n.d.)) set hyperparameters BVAR.","code":"(bvhar_short_spec <- set_bvhar(   sigma = sig,   lambda = lam,   delta = del,   eps = 1e-04 )) #> Model Specification for BVHAR #>  #> Parameters: Coefficent matrice and Covariance matrix #> Prior: MN_VAR #> # Type '?bvhar_minnesota' in the console for some help. #> ======================================================== #>  #> Setting for 'sigma': #>   GVZCLS    OVXCLS  VXEEMCLS  VXGDXCLS  VXSLVCLS   #>     3.77     10.63      4.39      7.45      5.99   #>  #> Setting for 'lambda': #> [1]  0.2 #>  #> Setting for 'delta': #> [1]  1  1  1  1  1 #>  #> Setting for 'eps': #> [1]  1e-04 bvhar_short_cand <- bvhar_minnesota(   y = etf_train,    har = c(5, 22),    bayes_spec = bvhar_short_spec,    include_mean = TRUE )"},{"path":"/articles/empirical-bayes.html","id":"bvhar-l","dir":"Articles","previous_headings":"Hyperparameters in Normal-inverse-Wishart Priors","what":"BVHAR-L","title":"Empirical Bayes","text":"two priors set prior mean zero farther coefficient (.e. \\(A_2, \\ldots, A_p\\) \\(\\Phi^{(w)}, \\Phi^{(m)}\\)), now weekly monthly coefficients also nonzero prior mean. instead \\(\\delta_j\\), \\(d_j\\) daily term. \\(w_j\\) weekly term. \\(m_j\\) monthly term.","code":"dayj <- rep(.8, dim_data) weekj <- rep(.2, dim_data) monthj <- rep(.1, dim_data) # bvharspec------------------ bvhar_long_spec <- set_weight_bvhar(   sigma = sig,   lambda = lam,   eps = 1e-04,   daily = dayj,   weekly = weekj,   monthly = monthj ) bvhar_long_cand <- bvhar_minnesota(   y = etf_train,    har = c(5, 22),    bayes_spec = bvhar_long_spec,    include_mean = TRUE )"},{"path":"/articles/empirical-bayes.html","id":"hyperparameter-selection","dir":"Articles","previous_headings":"","what":"Hyperparameter Selection","title":"Empirical Bayes","text":"Giannone et al. (2015) provides closed form marginal likelihood BVAR Minnesota prior. Based calculation, Kim et al. (n.d.) gives closed form BVHAR-S BVHAR-L. package provides hyperparameter selection function empirical bayes (Giannone et al. (2015)). Implementation simple. Provide bvharspec initial values stats::optim() structure. can either use Individual choose_bvar() choose_bvhar() function one integrated choose_bayes() function","code":""},{"path":"/articles/empirical-bayes.html","id":"individual-functions","dir":"Articles","previous_headings":"Hyperparameter Selection","what":"Individual Functions","title":"Empirical Bayes","text":"can parallelize computation optimParallel::optimParallel() specifying parallel = list() (leave empty list, function execute stats::optim()). Register cluster, pass cl = cl. details two, please see documentation optimParallel::optimParallel(). cl: Register cluster forward: Recommendation - FALSE loginfo: Recommendation - FALSE","code":"cl <- parallel::makeCluster(2)"},{"path":"/articles/empirical-bayes.html","id":"bvar-1","dir":"Articles","previous_headings":"Hyperparameter Selection > Individual Functions","what":"BVAR","title":"Empirical Bayes","text":"first try BVAR. choose_bvar(bayes_spec, lower = .01, upper = 10, eps = 1e-04, y, p, include_mean = TRUE, parallel = list()) chooses BVAR hyperparameter. Observe fixes order p (course eps, either). default, apply .01 lower bound 10 upper bound. using function, setting lower upper bounds can quite tricky. ’s bound expressed vector stats::optim() function. See following code specify bound. result class named bvharemp. chosen specification (bvharspec), fit (bvarmn), marginal likelihood value (ml).","code":"(bvar_optim <- choose_bvar(   bayes_spec = bvar_spec,   lower = c(     rep(1, dim_data), # sigma     1e-2, # lambda     rep(1e-2, dim_data) # delta   ),   upper = c(     rep(15, dim_data), # sigma     Inf, # lambda     rep(1, dim_data) # delta   ),   eps = 1e-04,   y = etf_train,   p = 3,   include_mean = TRUE,   parallel = list(cl = cl, forward = FALSE, loginfo = FALSE) )) #> Model Specification for BVAR #>  #> Parameters: Coefficent matrice and Covariance matrix #> Prior: Minnesota #> # Type '?bvar_minnesota' in the console for some help. #> ======================================================== #>  #> Setting for 'sigma': #>   GVZCLS    OVXCLS  VXEEMCLS  VXGDXCLS  VXSLVCLS   #>     2.49      3.90      3.55      4.51      3.79   #>  #> Setting for 'lambda': #>         #> 0.579   #>  #> Setting for 'delta': #>                 #> 1  1  1  1  1   #>  #> Setting for 'eps': #> [1]  1e-04 class(bvar_optim) #> [1] \"bvharemp\" names(bvar_optim) #> [1] \"par\"         \"value\"       \"counts\"      \"convergence\" \"message\"     #> [6] \"spec\"        \"fit\"         \"ml\" bvar_final <- bvar_optim$fit"},{"path":"/articles/empirical-bayes.html","id":"bvhar-s-1","dir":"Articles","previous_headings":"Hyperparameter Selection > Individual Functions","what":"BVHAR-S","title":"Empirical Bayes","text":"choose_bvhar(bayes_spec, lower = .01, upper = 10, eps = 1e-04, y, har = c(5, 22), include_mean = TRUE, parallel = list()) choses hyperparameter set BVHAR-S BVHAR-L given bayes_spec. set_bvhar(), performs BVHAR-S. set_weight_bvhar(), performs BVHAR-L. structure result .","code":"(bvhar_short_optim <- choose_bvhar(   bayes_spec = bvhar_short_spec,   lower = c(     rep(1, dim_data), # sigma     1e-2, # lambda     rep(1e-2, dim_data) # delta   ),   upper = c(     rep(15, dim_data), # sigma     Inf, # lambda     rep(1, dim_data) # delta   ),   eps = 1e-04,   y = etf_train,   har = c(5, 22),   include_mean = TRUE,   parallel = list(cl = cl, forward = FALSE, loginfo = FALSE) )) #> Model Specification for BVHAR #>  #> Parameters: Coefficent matrice and Covariance matrix #> Prior: MN_VAR #> # Type '?bvhar_minnesota' in the console for some help. #> ======================================================== #>  #> Setting for 'sigma': #>   GVZCLS    OVXCLS  VXEEMCLS  VXGDXCLS  VXSLVCLS   #>     2.54      4.08      3.67      4.43      4.05   #>  #> Setting for 'lambda': #>         #> 0.551   #>  #> Setting for 'delta': #>                 #> 1  1  1  1  1   #>  #> Setting for 'eps': #> [1]  1e-04 class(bvhar_short_optim) #> [1] \"bvharemp\" names(bvhar_short_optim) #> [1] \"par\"         \"value\"       \"counts\"      \"convergence\" \"message\"     #> [6] \"spec\"        \"fit\"         \"ml\" bvhar_short_final <- bvhar_short_optim$fit"},{"path":"/articles/empirical-bayes.html","id":"bvhar-l-1","dir":"Articles","previous_headings":"Hyperparameter Selection > Individual Functions","what":"BVHAR-L","title":"Empirical Bayes","text":"Using choose_bvhar() function, change bayes_spec length bounds vectors: Final fit:","code":"(bvhar_long_optim <- choose_bvhar(   bayes_spec = bvhar_long_spec,   lower = c(     rep(1, dim_data), # sigma     1e-2, # lambda     rep(1e-2, dim_data), # daily     rep(1e-2, dim_data), # weekly     rep(1e-2, dim_data) # monthly   ),   upper = c(     rep(15, dim_data), # sigma     Inf, # lambda     rep(1, dim_data), # daily     rep(1, dim_data), # weekly     rep(1, dim_data) # monthly   ),   eps = 1e-04,   y = etf_train,   har = c(5, 22),   include_mean = TRUE,   parallel = list(cl = cl, forward = FALSE, loginfo = FALSE) )) #> Model Specification for BVHAR #>  #> Parameters: Coefficent matrice and Covariance matrix #> Prior: MN_VHAR #> # Type '?bvhar_minnesota' in the console for some help. #> ======================================================== #>  #> Setting for 'sigma': #>   GVZCLS    OVXCLS  VXEEMCLS  VXGDXCLS  VXSLVCLS   #>     2.53      3.94      3.55      5.05      4.26   #>  #> Setting for 'lambda': #>         #> 0.519   #>  #> Setting for 'eps': #> [1]  1e-04 #>  #> Setting for 'daily': #>                 #> 1  1  1  1  1   #>  #> Setting for 'weekly': #>                                     #> 0.315  0.225  0.234  0.804  0.543   #>  #> Setting for 'monthly': #>                                          #> 0.2182  0.1444  0.0997  0.2664  0.2411 class(bvhar_long_optim) #> [1] \"bvharemp\" names(bvhar_long_optim) #> [1] \"par\"         \"value\"       \"counts\"      \"convergence\" \"message\"     #> [6] \"spec\"        \"fit\"         \"ml\" bvhar_long_final <- bvhar_long_optim$fit"},{"path":"/articles/empirical-bayes.html","id":"integrated-function","dir":"Articles","previous_headings":"Hyperparameter Selection","what":"Integrated Function","title":"Empirical Bayes","text":"mentioned, choose_bvar() choose_bvhar() still providing difficult ways bounding methods. , another function: choose_bayes(). can set Empirical Bayes bound using bound_bvhar(init_spec, lower_spec, upper_spec). Based boundbvharemp, can use choose_bayes() function. function implements choose_bvar() choose_bvhar() given inputs. bayes_bound: boundbvharemp object. order: p BVAR har BVHAR. options . forget shut cluster cl.","code":"# lower bound---------------- bvar_lower <- set_bvar(   sigma = rep(1, dim_data),   lambda = 1e-2,   delta = rep(1e-2, dim_data) ) # upper bound--------------- bvar_upper <- set_bvar(   sigma = rep(15, dim_data),   lambda = Inf,   delta = rep(1, dim_data) ) # bound-------------------- (bvar_bound <- bound_bvhar(   init_spec = bvar_spec,   lower_spec = bvar_lower,   upper_spec = bvar_upper )) #> Lower bound specification for BVAR optimization (L-BFGS-B): #> ======================================================== #> ======================================================== #> Model Specification for BVAR #>  #> Parameters: Coefficent matrice and Covariance matrix #> Prior: Minnesota #> # Type '?bvar_minnesota' in the console for some help. #> ======================================================== #>  #> Setting for 'sigma': #> [1]  1  1  1  1  1 #>  #> Setting for 'lambda': #> [1]  0.01 #>  #> Setting for 'delta': #> [1]  0.01  0.01  0.01  0.01  0.01 #>  #> Setting for 'eps': #> [1]  1e-04 #>  #>  #>  #> Upper bound specification for BVAR optimization (L-BFGS-B): #> ======================================================== #> ======================================================== #> Model Specification for BVAR #>  #> Parameters: Coefficent matrice and Covariance matrix #> Prior: Minnesota #> # Type '?bvar_minnesota' in the console for some help. #> ======================================================== #>  #> Setting for 'sigma': #> [1]  15  15  15  15  15 #>  #> Setting for 'lambda': #> [1]  Inf #>  #> Setting for 'delta': #> [1]  1  1  1  1  1 #>  #> Setting for 'eps': #> [1]  1e-04 class(bvar_bound) #> [1] \"boundbvharemp\" names(bvar_bound) #> [1] \"spec\"  \"lower\" \"upper\" (bvar_optim_v2 <- choose_bayes(   bayes_bound = bvar_bound,   eps = 1e-04,   y = etf_train,   order = 3,   include_mean = TRUE,   parallel = list(cl = cl, forward = FALSE, loginfo = FALSE) )) #> Model Specification for BVAR #>  #> Parameters: Coefficent matrice and Covariance matrix #> Prior: Minnesota #> # Type '?bvar_minnesota' in the console for some help. #> ======================================================== #>  #> Setting for 'sigma': #>   GVZCLS    OVXCLS  VXEEMCLS  VXGDXCLS  VXSLVCLS   #>     2.49      3.90      3.55      4.51      3.79   #>  #> Setting for 'lambda': #>         #> 0.579   #>  #> Setting for 'delta': #>                 #> 1  1  1  1  1   #>  #> Setting for 'eps': #> [1]  1e-04 parallel::stopCluster(cl)"},{"path":"/articles/forecasting.html","id":"simulation","dir":"Articles","previous_headings":"","what":"Simulation","title":"Forecasting","text":"Given VAR coefficient VHAR coefficient , sim_var(num_sim, num_burn, var_coef, var_lag, sig_error, init) generates VAR process sim_vhar(num_sim, num_burn, vhar_coef, sig_error, init) generates VHAR process use coefficient matrix estimated VAR(5) introduction vignette. Consider ","code":"coef(ex_fit) #>              GVZCLS   OVXCLS    EVZCLS VXFXICLS #> GVZCLS_1    0.93302 -0.02332 -0.007712 -0.03853 #> OVXCLS_1    0.05429  1.00399  0.009806  0.01062 #> EVZCLS_1    0.06794 -0.13900  0.983825  0.07783 #> VXFXICLS_1 -0.03399  0.03404  0.020719  0.93350 #> GVZCLS_2   -0.07831  0.08753  0.019302  0.08939 #> OVXCLS_2   -0.04770  0.01480  0.003888  0.04392 #> EVZCLS_2    0.08082  0.26704 -0.110017 -0.07163 #> VXFXICLS_2  0.05465 -0.12154 -0.040349  0.04012 #> GVZCLS_3    0.04332 -0.02459 -0.011041 -0.02556 #> OVXCLS_3   -0.00594 -0.09550  0.006638 -0.04981 #> EVZCLS_3   -0.02952 -0.04926  0.091056  0.01204 #> VXFXICLS_3 -0.05876 -0.05995  0.003803 -0.02027 #> GVZCLS_4   -0.00845 -0.04490  0.005415 -0.00817 #> OVXCLS_4    0.01070 -0.00383 -0.022806 -0.05557 #> EVZCLS_4   -0.01971 -0.02008 -0.016535  0.08229 #> VXFXICLS_4  0.06139  0.14403  0.019780 -0.10271 #> GVZCLS_5    0.07301  0.01093 -0.010994 -0.01526 #> OVXCLS_5   -0.01658  0.07401  0.007035  0.04297 #> EVZCLS_5   -0.08794 -0.06189  0.021082 -0.02465 #> VXFXICLS_5 -0.01739  0.00169  0.000335  0.09384 #> const       0.57370  0.15256  0.132842  0.87785 ex_fit$covmat #>          GVZCLS OVXCLS EVZCLS VXFXICLS #> GVZCLS    1.157  0.403  0.127    0.332 #> OVXCLS    0.403  1.740  0.115    0.438 #> EVZCLS    0.127  0.115  0.144    0.127 #> VXFXICLS  0.332  0.438  0.127    1.028 m <- ncol(ex_fit$coefficients) # generate VAR(5)----------------- y <- sim_var(   num_sim = 1500,    num_burn = 100,    var_coef = coef(ex_fit),    var_lag = 5L,    sig_error = ex_fit$covmat,    init = matrix(0L, nrow = 5L, ncol = m) ) # colname: y1, y2, ...------------ colnames(y) <- paste0(\"y\", 1:m) head(y) #>        y1   y2   y3   y4 #> [1,] 18.7 26.5 7.55 26.2 #> [2,] 18.2 25.8 7.39 25.6 #> [3,] 19.7 25.3 7.40 26.1 #> [4,] 20.6 24.5 7.34 26.4 #> [5,] 21.6 24.6 7.06 27.8 #> [6,] 22.5 23.7 7.02 25.8 h <- 20 y_eval <- divide_ts(y, h) y_train <- y_eval$train # train y_test <- y_eval$test # test"},{"path":[]},{"path":"/articles/forecasting.html","id":"var5-and-vhar","dir":"Articles","previous_headings":"Fitting Models","what":"VAR(5) and VHAR","title":"Forecasting","text":"","code":"# VAR(5) model_var <- var_lm(y_train, 5) # VHAR model_vhar <- vhar_lm(y_train)"},{"path":"/articles/forecasting.html","id":"bvar5","dir":"Articles","previous_headings":"Fitting Models","what":"BVAR(5)","title":"Forecasting","text":"Minnesota prior","code":"# hyper parameters--------------------------- y_sig <- apply(y_train, 2, sd) # sigma vector y_lam <- .2 # lambda y_delta <- rep(.2, m) # delta vector (0 vector since RV stationary) eps <- 1e-04 # very small number spec_bvar <- set_bvar(y_sig, y_lam, y_delta, eps) # fit--------------------------------------- model_bvar <- bvar_minnesota(y_train, 5, spec_bvar)"},{"path":"/articles/forecasting.html","id":"bvhar","dir":"Articles","previous_headings":"Fitting Models","what":"BVHAR","title":"Forecasting","text":"BVHAR-S BVHAR-L","code":"spec_bvhar_v1 <- set_bvhar(y_sig, y_lam, y_delta, eps) # fit--------------------------------------- model_bvhar_v1 <- bvhar_minnesota(y_train, bayes_spec = spec_bvhar_v1) # weights---------------------------------- y_day <- rep(.1, m) y_week <- rep(.01, m) y_month <- rep(.01, m) # spec------------------------------------- spec_bvhar_v2 <- set_weight_bvhar(   y_sig,   y_lam,   eps,   y_day,   y_week,   y_month ) # fit-------------------------------------- model_bvhar_v2 <- bvhar_minnesota(y_train, bayes_spec = spec_bvhar_v2)"},{"path":"/articles/forecasting.html","id":"splitting","dir":"Articles","previous_headings":"","what":"Splitting","title":"Forecasting","text":"can forecast using predict() method objects. set step forecasting using n_ahead argument. addition, result forecast return another class called predbvhar use methods, Plot: autoplot.predbvhar() Evaluation: mse.predbvhar(), mae.predbvhar(), mape.predbvhar(), mase.predbvhar(), mrae.predbvhar(), relmae.predbvhar() Relative error: rmape.predbvhar(), rmase.predbvhar(), rmase.predbvhar(), rmsfe.predbvhar(), rmafe.predbvhar()","code":""},{"path":"/articles/forecasting.html","id":"var","dir":"Articles","previous_headings":"Splitting","what":"VAR","title":"Forecasting","text":"package provides evaluation function mse(predbvhar, test): MSE mape(predbvhar, test): MAPE","code":"(pred_var <- predict(model_var, n_ahead = h)) #>         y1   y2   y3   y4 #>  [1,] 17.0 37.3 9.56 22.2 #>  [2,] 16.8 37.4 9.56 22.4 #>  [3,] 16.7 37.3 9.58 22.5 #>  [4,] 16.7 37.2 9.57 22.6 #>  [5,] 16.7 37.1 9.58 22.7 #>  [6,] 16.6 37.0 9.58 22.7 #>  [7,] 16.6 36.9 9.58 22.8 #>  [8,] 16.5 36.8 9.59 22.9 #>  [9,] 16.5 36.8 9.59 22.9 #> [10,] 16.4 36.7 9.59 23.0 #> [11,] 16.4 36.6 9.60 23.1 #> [12,] 16.3 36.5 9.60 23.1 #> [13,] 16.3 36.4 9.60 23.2 #> [14,] 16.3 36.3 9.60 23.3 #> [15,] 16.2 36.3 9.61 23.3 #> [16,] 16.2 36.2 9.61 23.4 #> [17,] 16.2 36.1 9.61 23.4 #> [18,] 16.1 36.0 9.61 23.5 #> [19,] 16.1 35.9 9.61 23.5 #> [20,] 16.1 35.9 9.61 23.6 class(pred_var) #> [1] \"predbvhar\" names(pred_var) #> [1] \"process\"     \"forecast\"    \"se\"          \"lower\"       \"upper\"       #> [6] \"lower_joint\" \"upper_joint\" \"y\" (mse_var <- mse(pred_var, y_test)) #>     y1     y2     y3     y4  #>  2.416 22.739  0.372  3.115"},{"path":"/articles/forecasting.html","id":"vhar","dir":"Articles","previous_headings":"Splitting","what":"VHAR","title":"Forecasting","text":"MSE:","code":"(pred_vhar <- predict(model_vhar, n_ahead = h)) #>         y1   y2   y3   y4 #>  [1,] 17.0 37.5 9.57 22.4 #>  [2,] 16.9 37.4 9.56 22.5 #>  [3,] 16.8 37.3 9.55 22.5 #>  [4,] 16.7 37.2 9.54 22.5 #>  [5,] 16.6 37.2 9.53 22.6 #>  [6,] 16.5 37.1 9.52 22.6 #>  [7,] 16.4 37.0 9.51 22.6 #>  [8,] 16.3 36.9 9.49 22.6 #>  [9,] 16.2 36.9 9.48 22.6 #> [10,] 16.2 36.8 9.46 22.6 #> [11,] 16.1 36.7 9.45 22.7 #> [12,] 16.0 36.7 9.43 22.7 #> [13,] 15.9 36.6 9.42 22.7 #> [14,] 15.9 36.6 9.41 22.7 #> [15,] 15.8 36.5 9.40 22.8 #> [16,] 15.8 36.5 9.40 22.8 #> [17,] 15.7 36.4 9.39 22.9 #> [18,] 15.7 36.4 9.39 22.9 #> [19,] 15.7 36.3 9.39 23.0 #> [20,] 15.6 36.3 9.39 23.0 (mse_vhar <- mse(pred_vhar, y_test)) #>    y1    y2    y3    y4  #>  3.29 24.46  0.27  3.05"},{"path":"/articles/forecasting.html","id":"bvar","dir":"Articles","previous_headings":"Splitting","what":"BVAR","title":"Forecasting","text":"MSE:","code":"(pred_bvar <- predict(model_bvar, n_ahead = h)) #>         y1   y2   y3   y4 #>  [1,] 17.1 37.4 9.50 22.4 #>  [2,] 17.0 37.2 9.49 22.6 #>  [3,] 16.9 37.1 9.49 22.7 #>  [4,] 16.9 37.0 9.50 22.8 #>  [5,] 16.8 36.9 9.50 22.9 #>  [6,] 16.7 36.7 9.50 22.9 #>  [7,] 16.7 36.6 9.51 23.0 #>  [8,] 16.6 36.5 9.51 23.1 #>  [9,] 16.6 36.4 9.51 23.2 #> [10,] 16.5 36.3 9.51 23.3 #> [11,] 16.5 36.2 9.51 23.3 #> [12,] 16.4 36.1 9.52 23.4 #> [13,] 16.4 36.0 9.52 23.5 #> [14,] 16.4 35.8 9.52 23.5 #> [15,] 16.3 35.7 9.52 23.6 #> [16,] 16.3 35.6 9.52 23.7 #> [17,] 16.3 35.5 9.52 23.7 #> [18,] 16.3 35.4 9.52 23.8 #> [19,] 16.2 35.3 9.53 23.8 #> [20,] 16.2 35.2 9.53 23.9 (mse_bvar <- mse(pred_bvar, y_test)) #>    y1    y2    y3    y4  #>  2.17 19.22  0.31  3.43"},{"path":[]},{"path":"/articles/forecasting.html","id":"var-type-minnesota","dir":"Articles","previous_headings":"Splitting > BVHAR","what":"VAR-type Minnesota","title":"Forecasting","text":"MSE:","code":"(pred_bvhar_v1 <- predict(model_bvhar_v1, n_ahead = h)) #>         y1   y2   y3   y4 #>  [1,] 16.9 37.4 9.53 22.4 #>  [2,] 16.9 37.2 9.49 22.5 #>  [3,] 16.8 37.0 9.47 22.5 #>  [4,] 16.8 36.9 9.45 22.6 #>  [5,] 16.7 36.8 9.45 22.7 #>  [6,] 16.6 36.7 9.44 22.7 #>  [7,] 16.5 36.5 9.43 22.8 #>  [8,] 16.5 36.4 9.42 22.8 #>  [9,] 16.4 36.3 9.41 22.8 #> [10,] 16.4 36.2 9.40 22.9 #> [11,] 16.3 36.1 9.40 22.9 #> [12,] 16.3 36.1 9.39 23.0 #> [13,] 16.2 36.0 9.39 23.0 #> [14,] 16.2 35.9 9.38 23.1 #> [15,] 16.1 35.8 9.38 23.1 #> [16,] 16.1 35.8 9.38 23.1 #> [17,] 16.0 35.7 9.38 23.2 #> [18,] 16.0 35.6 9.38 23.2 #> [19,] 16.0 35.5 9.39 23.3 #> [20,] 16.0 35.5 9.39 23.3 (mse_bvhar_v1 <- mse(pred_bvhar_v1, y_test)) #>    y1    y2    y3    y4  #>  2.62 19.34  0.25  3.10"},{"path":"/articles/forecasting.html","id":"vhar-type-minnesota","dir":"Articles","previous_headings":"Splitting > BVHAR","what":"VHAR-type Minnesota","title":"Forecasting","text":"MSE:","code":"(pred_bvhar_v2 <- predict(model_bvhar_v2, n_ahead = h)) #>         y1   y2   y3   y4 #>  [1,] 16.9 37.4 9.53 22.4 #>  [2,] 16.9 37.2 9.49 22.5 #>  [3,] 16.8 37.0 9.46 22.5 #>  [4,] 16.8 36.9 9.45 22.6 #>  [5,] 16.7 36.8 9.44 22.7 #>  [6,] 16.6 36.6 9.44 22.7 #>  [7,] 16.5 36.5 9.43 22.8 #>  [8,] 16.5 36.4 9.42 22.8 #>  [9,] 16.4 36.3 9.41 22.8 #> [10,] 16.4 36.2 9.40 22.9 #> [11,] 16.3 36.1 9.40 22.9 #> [12,] 16.3 36.0 9.39 23.0 #> [13,] 16.2 36.0 9.39 23.0 #> [14,] 16.2 35.9 9.38 23.0 #> [15,] 16.1 35.8 9.38 23.1 #> [16,] 16.1 35.7 9.38 23.1 #> [17,] 16.1 35.7 9.38 23.2 #> [18,] 16.0 35.6 9.38 23.2 #> [19,] 16.0 35.5 9.38 23.3 #> [20,] 16.0 35.5 9.39 23.3 (mse_bvhar_v2 <- mse(pred_bvhar_v2, y_test)) #>     y1     y2     y3     y4  #>  2.614 19.300  0.249  3.103"},{"path":[]},{"path":"/articles/forecasting.html","id":"region","dir":"Articles","previous_headings":"Splitting > Compare","what":"Region","title":"Forecasting","text":"autoplot(predbvhar) autolayer(predbvhar) draws results forecasting.","code":"autoplot(pred_var, x_cut = 1470, ci_alpha = .7, type = \"wrap\") +   autolayer(pred_vhar, ci_alpha = .5) +   autolayer(pred_bvar, ci_alpha = .4) +   autolayer(pred_bvhar_v1, ci_alpha = .2) +   autolayer(pred_bvhar_v2, ci_alpha = .1) +   geom_eval(y_test, colour = \"#000000\", alpha = .5)"},{"path":"/articles/forecasting.html","id":"error","dir":"Articles","previous_headings":"Splitting > Compare","what":"Error","title":"Forecasting","text":"Mean MSE variable, can see error plot.  Relative MAPE (MAPE), benchmark model: VAR","code":"list(   VAR = mse_var,   VHAR = mse_vhar,   BVAR = mse_bvar,   BVHAR1 = mse_bvhar_v1,   BVHAR2 = mse_bvhar_v2 ) %>%    lapply(mean) %>%    unlist() %>%    sort() #>   BVAR BVHAR2 BVHAR1    VAR   VHAR  #>   6.28   6.32   6.33   7.16   7.77 list(   pred_var,   pred_vhar,   pred_bvar,   pred_bvhar_v1,   pred_bvhar_v2 ) %>%    gg_loss(y = y_test, \"mse\") list(   VAR = pred_var,   VHAR = pred_vhar,   BVAR = pred_bvar,   BVHAR1 = pred_bvhar_v1,   BVHAR2 = pred_bvhar_v2 ) %>%    lapply(rmape, pred_bench = pred_var, y = y_test) %>%    unlist() #>    VAR   VHAR   BVAR BVHAR1 BVHAR2  #>  1.000  1.020  0.956  0.944  0.943"},{"path":"/articles/forecasting.html","id":"out-of-sample-forecasting","dir":"Articles","previous_headings":"","what":"Out-of-Sample Forecasting","title":"Forecasting","text":"time series research, --sample forecasting plays key role. , provide --sample forecasting function based Rolling window: forecast_roll(object, n_ahead, y_test) Expanding window: forecast_expand(object, n_ahead, y_test)","code":""},{"path":"/articles/forecasting.html","id":"rolling-windows","dir":"Articles","previous_headings":"Out-of-Sample Forecasting","what":"Rolling windows","title":"Forecasting","text":"forecast_roll(object, n_ahead, y_test) conducts h >= 1 step rolling windows forecasting. fixes window size moves window. window training set. package, set window size = original input data. Iterating step model fitted training set. fitted model, researcher forecast next h >= 1 step ahead. longest forecast horizon num_test - h + 1. window, move window process. Get forecasted values possible (longest forecast horizon). 5-step --sample: Denote nrow longest forecast horizon. apply evaluation methods, class named bvharcv defined. can use functions . Relative MAPE, benchmark model: VAR","code":"(var_roll <- forecast_roll(model_var, 5, y_test)) #>         y1   y2   y3   y4 #>  [1,] 16.7 37.1 9.58 22.7 #>  [2,] 17.6 34.9 9.48 23.4 #>  [3,] 16.7 35.0 9.73 22.5 #>  [4,] 16.6 32.5 8.98 21.7 #>  [5,] 16.0 31.6 8.83 22.3 #>  [6,] 16.5 32.9 8.64 22.6 #>  [7,] 17.1 32.9 9.12 22.8 #>  [8,] 17.5 32.2 9.27 22.5 #>  [9,] 17.5 30.7 9.57 22.1 #> [10,] 18.5 32.8 9.93 22.2 #> [11,] 18.2 31.6 9.67 21.5 #> [12,] 18.2 30.5 9.47 22.6 #> [13,] 18.1 30.9 9.19 21.5 #> [14,] 17.3 30.7 8.83 21.0 #> [15,] 19.0 31.3 9.18 23.2 #> [16,] 17.6 31.1 8.71 22.9 class(var_roll) #> [1] \"predbvhar_roll\" \"bvharcv\" names(var_roll) #> [1] \"process\"  \"forecast\" \"eval_id\"  \"y\" vhar_roll <- forecast_roll(model_vhar, 5, y_test) bvar_roll <- forecast_roll(model_bvar, 5, y_test) bvhar_roll_v1 <- forecast_roll(model_bvhar_v1, 5, y_test) bvhar_roll_v2 <- forecast_roll(model_bvhar_v2, 5, y_test) list(   VAR = var_roll,   VHAR = vhar_roll,   BVAR = bvar_roll,   BVHAR1 = bvhar_roll_v1,   BVHAR2 = bvhar_roll_v2 ) %>%    lapply(rmape, pred_bench = var_roll, y = y_test) %>%    unlist() #>    VAR   VHAR   BVAR BVHAR1 BVHAR2  #>  1.000  0.989  0.980  0.972  0.972"},{"path":"/articles/forecasting.html","id":"expanding-windows","dir":"Articles","previous_headings":"Out-of-Sample Forecasting","what":"Expanding Windows","title":"Forecasting","text":"forecast_expand(object, n_ahead, y_test) conducts h >= 1 step expanding window forecasting. Different rolling windows, expanding windows method fixes starting point. . class bvharcv. Relative MAPE, benchmark model: VAR","code":"(var_expand <- forecast_expand(model_var, 5, y_test)) #>         y1   y2   y3   y4 #>  [1,] 16.7 37.1 9.58 22.7 #>  [2,] 17.6 34.9 9.48 23.4 #>  [3,] 16.7 35.0 9.73 22.5 #>  [4,] 16.6 32.4 8.97 21.7 #>  [5,] 16.0 31.6 8.82 22.3 #>  [6,] 16.5 32.9 8.63 22.6 #>  [7,] 17.1 32.9 9.12 22.8 #>  [8,] 17.5 32.2 9.27 22.5 #>  [9,] 17.5 30.7 9.58 22.1 #> [10,] 18.5 32.8 9.95 22.2 #> [11,] 18.2 31.6 9.68 21.5 #> [12,] 18.2 30.5 9.48 22.6 #> [13,] 18.1 30.9 9.19 21.5 #> [14,] 17.3 30.7 8.84 21.0 #> [15,] 19.0 31.3 9.17 23.2 #> [16,] 17.6 31.1 8.70 22.9 class(var_expand) #> [1] \"predbvhar_expand\" \"bvharcv\" names(var_expand) #> [1] \"process\"  \"forecast\" \"eval_id\"  \"y\" vhar_expand <- forecast_expand(model_vhar, 5, y_test) bvar_expand <- forecast_expand(model_bvar, 5, y_test) bvhar_expand_v1 <- forecast_expand(model_bvhar_v1, 5, y_test) bvhar_expand_v2 <- forecast_expand(model_bvhar_v2, 5, y_test) list(   VAR = var_expand,   VHAR = vhar_expand,   BVAR = bvar_expand,   BVHAR1 = bvhar_expand_v1,   BVHAR2 = bvhar_expand_v2 ) %>%    lapply(rmape, pred_bench = var_expand, y = y_test) %>%    unlist() #>    VAR   VHAR   BVAR BVHAR1 BVHAR2  #>  1.000  0.985  0.980  0.968  0.968"},{"path":"/articles/minnesota.html","id":"normal-inverse-wishart-matrix","dir":"Articles","previous_headings":"","what":"Normal-inverse-Wishart Matrix","title":"Minnesota Prior","text":"provide functions generate matrix-variate Normal inverse-Wishart. sim_mnormal(num_sim, mu, sig): num_sim \\(\\mathbf{X}_i \\stackrel{iid}{\\sim} N(\\boldsymbol{\\mu}, \\Sigma)\\). sim_matgaussian(mat_mean, mat_scale_u, mat_scale_v): One \\(X_{m \\times n} \\sim MN(M_{m \\times n}, U_{m \\times m}, V_{n \\times n})\\) means \\(vec(X) \\sim N(vec(M), V \\otimes U)\\). sim_iw(mat_scale, shape): One \\(\\Sigma \\sim IW(\\Psi, \\nu)\\). sim_mniw(num_sim, mat_mean, mat_scale_u, mat_scale, shape): num_sim \\((X_i, \\Sigma_i) \\stackrel{iid}{\\sim} MNIW(M, U, V, \\nu)\\). Multivariate Normal generation gives num_sim x dim matrix. example, generating 3 vector Normal(\\(\\boldsymbol{\\mu} = \\mathbf{0}_2\\), \\(\\Sigma = diag(\\mathbf{1}_2)\\)): output sim_matgaussian() matrix. generating IW, violating \\(\\nu > dim - 1\\) gives error. ignore \\(\\nu > dim + 1\\) (condition mean existence) function. Nonetheless, recommend keep \\(\\nu > dim + 1\\) condition. mentioned, guarantees existence mean. case sim_mniw(), returns list mn (stacked MN matrices) iw (stacked IW matrices): Since matrix stacked rowwise, actually readable practical. function defined next simulation functions.","code":"sim_mnormal(3, rep(0, 2), diag(2)) #>        [,1]   [,2] #> [1,] -0.626  0.184 #> [2,] -0.836  1.595 #> [3,]  0.330 -0.820 sim_matgaussian(matrix(1:20, nrow = 4), diag(4), diag(5)) #>      [,1] [,2]  [,3] [,4] [,5] #> [1,] 1.49 5.74  9.58 12.7 18.5 #> [2,] 2.39 5.38  7.79 15.1 18.0 #> [3,] 2.98 7.94 11.82 15.6 19.9 #> [4,] 4.78 8.07 10.01 16.6 19.9 sim_iw(diag(5), 7) #>         [,1]    [,2]    [,3]    [,4]    [,5] #> [1,]  0.1827  0.0894 -0.0411 -0.0924 -0.1305 #> [2,]  0.0894  0.6110  0.0860 -0.3754 -0.1015 #> [3,] -0.0411  0.0860  0.2189 -0.1649 -0.0988 #> [4,] -0.0924 -0.3754 -0.1649  0.4577  0.2136 #> [5,] -0.1305 -0.1015 -0.0988  0.2136  0.7444 sim_mniw(2, matrix(1:20, nrow = 4), diag(4), diag(5), 7) #> $mn #>      [,1] [,2]  [,3] [,4] [,5]  [,6] [,7]  [,8] [,9] [,10] #> [1,] 1.19 4.96  8.03 12.7 14.6 0.323 5.07  8.24 13.1  17.4 #> [2,] 2.13 5.17 10.41 14.1 19.3 2.022 5.56  9.96 13.9  19.4 #> [3,] 3.01 7.15 10.29 14.9 18.1 3.380 7.24 11.34 15.5  17.9 #> [4,] 4.59 7.99 12.12 15.0 18.5 3.755 8.79 11.84 15.6  19.6 #>  #> $iw #>         [,1]     [,2]     [,3]    [,4]   [,5]     [,6]    [,7]     [,8]    [,9] #> [1,]  0.2887 -0.04393  0.11892 -0.2959  0.110  0.28118 -0.1397  0.00529  0.0283 #> [2,] -0.0439  0.33357  0.00197  0.0106 -0.167 -0.13965  0.2876  0.06156 -0.1575 #> [3,]  0.1189  0.00197  1.30074 -0.0291  2.210  0.00529  0.0616  0.31282 -0.1372 #> [4,] -0.2959  0.01061 -0.02913  0.5072  0.250  0.02831 -0.1575 -0.13724  0.3441 #> [5,]  0.1104 -0.16736  2.20957  0.2504  4.623  0.03803 -0.1856 -0.29860  0.1217 #>       [,10] #> [1,]  0.038 #> [2,] -0.186 #> [3,] -0.299 #> [4,]  0.122 #> [5,]  0.738"},{"path":[]},{"path":"/articles/minnesota.html","id":"bvar","dir":"Articles","previous_headings":"Minnesota Prior","what":"BVAR","title":"Minnesota Prior","text":"Consider BVAR Minnesota prior setting, \\[\\sim MN(A_0, \\Omega_0, \\Sigma_e)\\] \\[\\Sigma_e \\sim IW(S_0, \\alpha_0)\\] Litterman (1986) Bańbura et al. (2010) build_xdummy() build_ydummy() \\(\\Sigma_e = diag(\\sigma_1^2, \\ldots, \\sigma_m^2)\\) \\(\\sigma_i^2 / \\sigma_j^2\\): different scale variability data Controls overall tightness prior distribution around RW WN \\(\\lambda = 0\\), posterior = prior data influence estimates. \\(\\lambda = \\infty\\), posterior expectations = OLS. m increases, \\(\\lambda\\) smaller avoid overfitting (De Mol et al. (2008)) Litterman (1986) originally sets high persistence \\(\\delta_i = 1\\) Non-stationary variables: random walk prior \\(\\delta_i = 1\\) stationary variables: white noise prior \\(\\delta_i = 0\\) eps: small number make matrix invertible sim_mncoef(p, bayes_spec, full = TRUE) can generate \\(\\) \\(\\Sigma\\) matrices. bayes_spec, set_bvar() works. full = FALSE, \\(\\Sigma\\) random. diag(sigma) bayes_spec. full = TRUE default.","code":"bvar_lag <- 5 (spec_to_sim <- set_bvar(   sigma = c(3.25, 11.1, 2.2, 6.8), # sigma vector   lambda = .2, # lambda   delta = rep(1, 4), # 4-dim delta vector   eps = 1e-04 # very small number )) #> Model Specification for BVAR #>  #> Parameters: Coefficent matrice and Covariance matrix #> Prior: Minnesota #> # Type '?bvar_minnesota' in the console for some help. #> ======================================================== #>  #> Setting for 'sigma': #> [1]   3.25  11.10   2.20   6.80 #>  #> Setting for 'lambda': #> [1]  0.2 #>  #> Setting for 'delta': #> [1]  1  1  1  1 #>  #> Setting for 'eps': #> [1]  1e-04 (sim_mncoef(bvar_lag, spec_to_sim)) #> $coefficients #>            [,1]     [,2]      [,3]     [,4] #>  [1,]  0.196255 -0.19084 -0.026363  0.07600 #>  [2,] -0.017158  0.27873 -0.033404 -0.00816 #>  [3,] -0.225869  0.31165  0.127705 -0.48148 #>  [4,] -0.002706 -0.26068  0.038566  0.04105 #>  [5,] -0.023064 -0.11717 -0.030881  0.35496 #>  [6,]  0.000253 -0.05523 -0.018351  0.03580 #>  [7,] -0.001364 -0.06563 -0.051615 -0.33330 #>  [8,] -0.025569  0.11938 -0.011720 -0.15248 #>  [9,]  0.062006 -0.07985 -0.001830  0.15440 #> [10,]  0.008609 -0.03437  0.016242  0.00866 #> [11,] -0.069804  0.11559  0.003275  0.30043 #> [12,]  0.001677  0.01789 -0.000582 -0.02224 #> [13,] -0.000864  0.05893  0.038960  0.06788 #> [14,]  0.008799 -0.04337  0.005557  0.02273 #> [15,] -0.053924  0.16120 -0.006870  0.10085 #> [16,] -0.009109  0.00284 -0.008880 -0.01168 #> [17,]  0.008001 -0.05816  0.012293 -0.05256 #> [18,] -0.006107  0.03645 -0.004491 -0.00687 #> [19,] -0.011204  0.05703  0.036651  0.13185 #> [20,] -0.003148 -0.05735  0.016794  0.04086 #>  #> $covmat #>        [,1]     [,2]    [,3]   [,4] #> [1,]  2.615  -5.1044  0.1522   2.44 #> [2,] -5.104  32.2768 -0.0549 -12.04 #> [3,]  0.152  -0.0549  1.4573   0.31 #> [4,]  2.440 -12.0446  0.3101  30.83"},{"path":"/articles/minnesota.html","id":"bvhar","dir":"Articles","previous_headings":"Minnesota Prior","what":"BVHAR","title":"Minnesota Prior","text":"sim_mnvhar_coef(bayes_spec, full = TRUE) generates BVHAR model setting: \\[\\Phi \\mid \\Sigma_e \\sim MN(M_0, \\Omega_0, \\Sigma_e)\\] \\[\\Sigma_e \\sim IW(\\Psi_0, \\nu_0)\\] set_bvhar() set_weight_bvhar() full = TRUE, .","code":""},{"path":"/articles/minnesota.html","id":"bvhar-s","dir":"Articles","previous_headings":"Minnesota Prior > BVHAR","what":"BVHAR-S","title":"Minnesota Prior","text":"","code":"(bvhar_var_spec <- set_bvhar(   sigma = c(1.2, 2.3), # sigma vector   lambda = .2, # lambda   delta = c(.3, 1), # 2-dim delta vector   eps = 1e-04 # very small number )) #> Model Specification for BVHAR #>  #> Parameters: Coefficent matrice and Covariance matrix #> Prior: MN_VAR #> # Type '?bvhar_minnesota' in the console for some help. #> ======================================================== #>  #> Setting for 'sigma': #> [1]  1.2  2.3 #>  #> Setting for 'lambda': #> [1]  0.2 #>  #> Setting for 'delta': #> [1]  0.3  1.0 #>  #> Setting for 'eps': #> [1]  1e-04 (sim_mnvhar_coef(bvhar_var_spec)) #> $coefficients #>          [,1]    [,2] #> [1,]  0.06349 -0.2954 #> [2,] -0.01177  0.4277 #> [3,]  0.05543 -0.2689 #> [4,]  0.00235  0.0574 #> [5,] -0.05121  0.1928 #> [6,] -0.00891  0.0245 #>  #> $covmat #>        [,1]   [,2] #> [1,]  0.322 -0.407 #> [2,] -0.407  3.195"},{"path":"/articles/minnesota.html","id":"bvhar-l","dir":"Articles","previous_headings":"Minnesota Prior > BVHAR","what":"BVHAR-L","title":"Minnesota Prior","text":"","code":"(bvhar_vhar_spec <- set_weight_bvhar(   sigma = c(1.2, 2.3), # sigma vector   lambda = .2, # lambda   eps = 1e-04, # very small number   daily = c(.5, 1), # 2-dim daily weight vector   weekly = c(.2, .3), # 2-dim weekly weight vector   monthly = c(.1, .1) # 2-dim monthly weight vector )) #> Model Specification for BVHAR #>  #> Parameters: Coefficent matrice and Covariance matrix #> Prior: MN_VHAR #> # Type '?bvhar_minnesota' in the console for some help. #> ======================================================== #>  #> Setting for 'sigma': #> [1]  1.2  2.3 #>  #> Setting for 'lambda': #> [1]  0.2 #>  #> Setting for 'eps': #> [1]  1e-04 #>  #> Setting for 'daily': #> [1]  0.5  1.0 #>  #> Setting for 'weekly': #> [1]  0.2  0.3 #>  #> Setting for 'monthly': #> [1]  0.1  0.1 (sim_mnvhar_coef(bvhar_vhar_spec)) #> $coefficients #>          [,1]    [,2] #> [1,] -0.01953  0.2058 #> [2,]  0.14585 -0.2401 #> [3,]  0.01613 -0.0491 #> [4,]  0.05043 -0.1112 #> [5,]  0.02742  0.3732 #> [6,] -0.00569 -0.0749 #>  #> $covmat #>       [,1]   [,2] #> [1,] 0.566  0.263 #> [2,] 0.263 14.995"},{"path":"/articles/shrinkage.html","id":"stochastic-search-variable-selection-ssvs-prior","dir":"Articles","previous_headings":"","what":"Stochastic Search Variable Selection (SSVS) Prior","title":"Shrinkage Priors","text":"y: Multivariate time series data. data frame matrix, means every column numeric. column indicates variable, .e. sould wide format. har: Order VHAR num_iter: Total number iterations num_burn: Number burn-thinning: Thinning default, use default semi-automatic approach using choose_ssvs(). default, init_ssvs(type = \"auto\") uses OLS. include_mean = TRUE: default, include constant term model. minnesota = c(\"\", \"short\", \"longrun\"): Minnesota-type shrinkage. verbose = FALSE: Progress bar autoplot() fit (bvharsp object) provides coefficients heatmap. type argument, default type = \"coef\" draws heatmap.  type = \"trace\" gives MCMC trace plot.","code":"(fit_ssvs <- bvhar_ssvs(etf_train, num_iter = 50, include_mean = FALSE, minnesota = \"longrun\")) #> Call: #> bvhar_ssvs(y = etf_train, num_iter = 50, include_mean = FALSE,  #>     minnesota = \"longrun\") #>  #> BVHAR with SSVS Prior #> Fitted by Gibbs sampling #> Total number of iteration: 50 #> Number of burn-in: 25 #> ==================================================== #>  #> Parameter Record: #> # A draws_df: 25 iterations, 1 chains, and 112 variables #>     phi[1]    phi[2]   phi[3]     phi[4]    phi[5]    phi[6]    phi[7]   phi[8] #> 1    0.698  -0.00226  -0.0123   0.037430   0.02887   0.03234   0.04147  0.00751 #> 2    0.873   0.02821   0.0360   0.010323   0.04918   0.01284   0.03641  0.00163 #> 3    0.763   0.01056  -0.0212  -0.000826  -0.02758   0.01102   0.05360  0.04717 #> 4    0.889   0.00357  -0.0204   0.034986  -0.00416  -0.02446  -0.03122  0.02264 #> 5    0.859   0.01599   0.0599   0.029510   0.01150   0.00536   0.00188  0.00865 #> 6    0.956  -0.01873   0.0263   0.003166   0.02746   0.05086  -0.00259  0.00709 #> 7    0.782   0.00567   0.0208   0.009171   0.01129   0.03717  -0.07532  0.00518 #> 8    0.817   0.03570   0.0362   0.003582   0.03489  -0.00423   0.03803  0.02531 #> 9    0.932   0.00745  -0.0411   0.010844   0.01799   0.01914   0.10273  0.01348 #> 10   0.740   0.04380   0.0326   0.016294  -0.01817   0.02164   0.02196  0.00779 #> # ... with 15 more draws, and 104 more variables #> # ... hidden reserved variables {'.chain', '.iteration', '.draw'} autoplot(fit_ssvs) autoplot(fit_ssvs, type = \"trace\", regex_pars = \"psi\")"},{"path":"/articles/shrinkage.html","id":"horseshoe-prior","dir":"Articles","previous_headings":"","what":"Horseshoe Prior","title":"Shrinkage Priors","text":"type = \"dens\" draws MCMC density plot.","code":"(fit_hs <- bvhar_horseshoe(etf_train, num_iter = 50, include_mean = FALSE, minnesota = \"longrun\", verbose = TRUE)) #>  #                                                  2% ##                                                 4% ###                                                6% ####                                               8% #####                                              10% ######                                             12% #######                                            14% ########                                           16% #########                                          18% ##########                                         20% ###########                                        22% ############                                       24% #############                                      26% ##############                                     28% ###############                                    30% ################                                   32% #################                                  34% ##################                                 36% ###################                                38% ####################                               40% #####################                              42% ######################                             44% #######################                            46% ########################                           48% #########################                          50% ##########################                         52% ###########################                        54% ############################                       56% #############################                      58% ##############################                     60% ###############################                    62% ################################                   64% #################################                  66% ##################################                 68% ###################################                70% ####################################               72% #####################################              74% ######################################             76% #######################################            78% ########################################           80% #########################################          82% ##########################################         84% ###########################################        86% ############################################       88% #############################################      90% ##############################################     92% ###############################################    94% ################################################   96% #################################################  98% ################################################## 100% #> Call: #> bvhar_horseshoe(y = etf_train, num_iter = 50, include_mean = FALSE,  #>     minnesota = \"longrun\", verbose = TRUE) #>  #> BVHAR with Horseshoe Prior #> Fitted by blocked sampling #> Total number of iteration: 50 #> Number of burn-in: 25 #> ==================================================== #>  #> # A draws_df: 25 iterations, 1 chains, and 103 variables #>     phi[1]  phi[2]  phi[3]  phi[4]  phi[5]   phi[6]  phi[7]    phi[8] #> 1    0.541   0.117  0.1022  0.0879   0.164  -0.0480  0.0431  -0.01197 #> 2    0.543   0.119  0.0983  0.0885   0.158  -0.0497  0.0587  -0.01417 #> 3    0.543   0.118  0.0992  0.0867   0.160  -0.0485  0.0502  -0.01051 #> 4    0.542   0.119  0.1020  0.0875   0.160  -0.0483  0.0427  -0.01106 #> 5    0.542   0.117  0.1058  0.0858   0.163  -0.0479  0.0427  -0.00992 #> 6    0.544   0.116  0.0949  0.0916   0.158  -0.0462  0.0488  -0.01830 #> 7    0.541   0.119  0.0966  0.0875   0.164  -0.0489  0.0497  -0.01049 #> 8    0.542   0.116  0.1020  0.0894   0.159  -0.0454  0.0485  -0.01446 #> 9    0.542   0.118  0.0954  0.0903   0.157  -0.0475  0.0556  -0.01525 #> 10   0.541   0.118  0.1012  0.0889   0.159  -0.0496  0.0491  -0.01307 #> # ... with 15 more draws, and 95 more variables #> # ... hidden reserved variables {'.chain', '.iteration', '.draw'} autoplot(fit_hs) autoplot(fit_hs, type = \"dens\", regex_pars = \"tau\")"},{"path":[]},{"path":"/articles/shrinkage.html","id":"ssvs","dir":"Articles","previous_headings":"Models with Stochastic Volatilities","what":"SSVS","title":"Shrinkage Priors","text":"","code":"(fit_ssvs_sv <- bvhar_sv(etf_train, num_iter = 50, bayes_spec = set_ssvs(), include_mean = FALSE, minnesota = \"longrun\")) #> Call: #> bvhar_sv(y = etf_train, num_iter = 50, bayes_spec = set_ssvs(),  #>     include_mean = FALSE, minnesota = \"longrun\") #>  #> BVHAR with Stochastic Volatility #> Fitted by Gibbs sampling #> Total number of iteration: 50 #> Number of burn-in: 25 #> ==================================================== #>  #> Parameter Record: #> # A draws_df: 25 iterations, 1 chains, and 354 variables #>     phi[1]  phi[2]    phi[3]  phi[4]  phi[5]   phi[6]    phi[7]   phi[8] #> 1    0.785  0.0793  -0.15126  0.2043   0.120   0.0907  -0.00864  -0.1397 #> 2    0.801  0.0824   0.04322  0.1067   0.125   0.0681  -0.06809  -0.0667 #> 3    0.770  0.0605  -0.00129  0.1077   0.125   0.0998  -0.11264  -0.0318 #> 4    0.739  0.0604  -0.03785  0.1134   0.176   0.0667  -0.08694  -0.0227 #> 5    0.789  0.0128  -0.01029  0.0443   0.174   0.1075  -0.02040   0.0418 #> 6    0.501  0.1494  -0.23357  0.3354   0.332  -0.0470   0.18223  -0.2315 #> 7    0.629  0.0438  -0.15867  0.2159   0.254   0.0901   0.15882  -0.0991 #> 8    0.522  0.1171  -0.26260  0.3145   0.361  -0.0327   0.12431  -0.2004 #> 9    0.493  0.1000  -0.29624  0.3133   0.271  -0.0120   0.21763  -0.0935 #> 10   0.461  0.1733  -0.42657  0.3467   0.108  -0.1280   0.30065   0.0165 #> # ... with 15 more draws, and 346 more variables #> # ... hidden reserved variables {'.chain', '.iteration', '.draw'} autoplot(fit_ssvs_sv)"},{"path":"/articles/shrinkage.html","id":"horseshoe","dir":"Articles","previous_headings":"Models with Stochastic Volatilities","what":"Horseshoe","title":"Shrinkage Priors","text":"","code":"(fit_hs_sv <- bvhar_sv(etf_train, num_iter = 50, bayes_spec = set_horseshoe(), include_mean = FALSE, minnesota = \"longrun\")) #> Call: #> bvhar_sv(y = etf_train, num_iter = 50, bayes_spec = set_horseshoe(),  #>     include_mean = FALSE, minnesota = \"longrun\") #>  #> BVHAR with Stochastic Volatility #> Fitted by Gibbs sampling #> Total number of iteration: 50 #> Number of burn-in: 25 #> ==================================================== #>  #> Parameter Record: #> # A draws_df: 25 iterations, 1 chains, and 354 variables #>     phi[1]  phi[2]     phi[3]  phi[4]     phi[5]   phi[6]   phi[7]   phi[8] #> 1    0.433  0.0461  -6.93e-02   0.258   0.033938   0.0102   0.2708  0.00212 #> 2    0.431  0.0699   2.67e-02   0.263  -0.008923   0.0148   0.0480  0.04576 #> 3    0.490  0.0749  -2.72e-02   0.258  -0.060934   0.0119   0.1199  0.03617 #> 4    0.520  0.0476   1.77e-03   0.253   0.007058   0.0120   0.1069  0.04747 #> 5    0.516  0.0466   9.22e-05   0.214  -0.060572   0.0136   0.1859  0.12563 #> 6    0.527  0.0230   5.12e-02   0.219  -0.127866   0.0650  -0.0279  0.15157 #> 7    0.515  0.0455   1.52e-01   0.163   0.003174  -0.0635   0.2009  0.20966 #> 8    0.489  0.0640   1.70e-01   0.188  -0.050664  -0.0444   0.0661  0.17885 #> 9    0.498  0.0609   6.21e-02   0.232  -0.017296  -0.0285   0.2176  0.08531 #> 10   0.490  0.0705   2.49e-01   0.208   0.000344  -0.0650   0.0610  0.14936 #> # ... with 15 more draws, and 346 more variables #> # ... hidden reserved variables {'.chain', '.iteration', '.draw'} autoplot(fit_hs_sv)"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Young Geun Kim. Author, maintainer, copyright holder. Changryong Baek. Contributor.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Kim Y, Baek C (2023). bvhar: Bayesian Vector Heterogeneous Autoregressive Modeling. R package version 1.2.0, https://cran.r-project.org/package=bvhar. Kim Y, Baek C (2023). “Bayesian Vector Heterogeneous Autoregressive Modeling.” Journal Statistical Computation Simulation. doi:10.1080/00949655.2023.2281644.","code":"@Manual{,   title = {{bvhar}: Bayesian Vector Heterogeneous Autoregressive Modeling},   author = {Young Geun Kim and Changryong Baek},   year = {2023},   note = {R package version 1.2.0},   url = {https://cran.r-project.org/package=bvhar}, } @Article{,   title = {Bayesian Vector Heterogeneous Autoregressive Modeling},   author = {Young Geun Kim and Changryong Baek},   journal = {Journal of Statistical Computation and Simulation},   year = {2023},   doi = {10.1080/00949655.2023.2281644}, }"},{"path":[]},{"path":"/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Bayesian Vector Heterogeneous Autoregressive Modeling","text":"bvhar provides functions analyze multivariate time series time series using VAR VHAR (Vector HAR) BVAR (Bayesian VAR) BVHAR (Bayesian VHAR) Basically, package focuses research forecasting.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Bayesian Vector Heterogeneous Autoregressive Modeling","text":"","code":"install.packages(\"bvhar\")"},{"path":"/index.html","id":"development-version","dir":"","previous_headings":"Installation","what":"Development version","title":"Bayesian Vector Heterogeneous Autoregressive Modeling","text":"can install development version repository.","code":"# install.packages(\"remotes\") remotes::install_github(\"ygeunkim/bvhar\")"},{"path":"/index.html","id":"models","dir":"","previous_headings":"","what":"Models","title":"Bayesian Vector Heterogeneous Autoregressive Modeling","text":"Repeatedly, bvhar research tool analyze multivariate time series model readme document shows forecasting procedure briefly. Details function vignettes help documents. h-step ahead forecasting:","code":"library(bvhar) # this package library(dplyr) h <- 19 etf_split <- divide_ts(etf_vix, h) # Try ?divide_ts etf_tr <- etf_split$train etf_te <- etf_split$test"},{"path":"/index.html","id":"var","dir":"","previous_headings":"Models","what":"VAR","title":"Bayesian Vector Heterogeneous Autoregressive Modeling","text":"VAR(5): Forecasting: MSE:","code":"mod_var <- var_lm(y = etf_tr, p = 5) forecast_var <- predict(mod_var, h) (msevar <- mse(forecast_var, etf_te)) #>   GVZCLS   OVXCLS VXFXICLS VXEEMCLS VXSLVCLS   EVZCLS VXXLECLS VXGDXCLS  #>    5.381   14.689    2.838    9.451   10.078    0.654   22.436    9.992  #> VXEWZCLS  #>   10.647"},{"path":"/index.html","id":"vhar","dir":"","previous_headings":"Models","what":"VHAR","title":"Bayesian Vector Heterogeneous Autoregressive Modeling","text":"MSE:","code":"mod_vhar <- vhar_lm(y = etf_tr) forecast_vhar <- predict(mod_vhar, h) (msevhar <- mse(forecast_vhar, etf_te)) #>   GVZCLS   OVXCLS VXFXICLS VXEEMCLS VXSLVCLS   EVZCLS VXXLECLS VXGDXCLS  #>     6.15     2.49     1.52     1.58    10.55     1.35     8.79     4.43  #> VXEWZCLS  #>     3.84"},{"path":"/index.html","id":"bvar","dir":"","previous_headings":"Models","what":"BVAR","title":"Bayesian Vector Heterogeneous Autoregressive Modeling","text":"Minnesota prior: MSE:","code":"lam <- .3 delta <- rep(1, ncol(etf_vix)) # litterman sig <- apply(etf_tr, 2, sd) eps <- 1e-04 (bvar_spec <- set_bvar(sig, lam, delta, eps)) #> Model Specification for BVAR #>  #> Parameters: Coefficent matrice and Covariance matrix #> Prior: Minnesota #> # Type '?bvar_minnesota' in the console for some help. #> ======================================================== #>  #> Setting for 'sigma': #>   GVZCLS    OVXCLS  VXFXICLS  VXEEMCLS  VXSLVCLS    EVZCLS  VXXLECLS  VXGDXCLS   #>     3.77     10.63      3.81      4.39      5.99      2.27      4.88      7.45   #> VXEWZCLS   #>     7.03   #>  #> Setting for 'lambda': #> [1]  0.3 #>  #> Setting for 'delta': #> [1]  1  1  1  1  1  1  1  1  1 #>  #> Setting for 'eps': #> [1]  1e-04 mod_bvar <- bvar_minnesota(y = etf_tr, p = 5, bayes_spec = bvar_spec) forecast_bvar <- predict(mod_bvar, h) (msebvar <- mse(forecast_bvar, etf_te)) #>   GVZCLS   OVXCLS VXFXICLS VXEEMCLS VXSLVCLS   EVZCLS VXXLECLS VXGDXCLS  #>    4.463   13.510    1.336   11.267    9.802    0.862   21.929    5.418  #> VXEWZCLS  #>    7.362"},{"path":"/index.html","id":"bvhar","dir":"","previous_headings":"Models","what":"BVHAR","title":"Bayesian Vector Heterogeneous Autoregressive Modeling","text":"BVHAR-S: MSE: BVHAR-L: MSE:","code":"(bvhar_spec_v1 <- set_bvhar(sig, lam, delta, eps)) #> Model Specification for BVHAR #>  #> Parameters: Coefficent matrice and Covariance matrix #> Prior: MN_VAR #> # Type '?bvhar_minnesota' in the console for some help. #> ======================================================== #>  #> Setting for 'sigma': #>   GVZCLS    OVXCLS  VXFXICLS  VXEEMCLS  VXSLVCLS    EVZCLS  VXXLECLS  VXGDXCLS   #>     3.77     10.63      3.81      4.39      5.99      2.27      4.88      7.45   #> VXEWZCLS   #>     7.03   #>  #> Setting for 'lambda': #> [1]  0.3 #>  #> Setting for 'delta': #> [1]  1  1  1  1  1  1  1  1  1 #>  #> Setting for 'eps': #> [1]  1e-04 mod_bvhar_v1 <- bvhar_minnesota(y = etf_tr, bayes_spec = bvhar_spec_v1) forecast_bvhar_v1 <- predict(mod_bvhar_v1, h) (msebvhar_v1 <- mse(forecast_bvhar_v1, etf_te)) #>   GVZCLS   OVXCLS VXFXICLS VXEEMCLS VXSLVCLS   EVZCLS VXXLECLS VXGDXCLS  #>     3.58     4.76     1.32     5.71     6.29     1.15    14.03     2.52  #> VXEWZCLS  #>     5.41 day <- rep(.1, ncol(etf_vix)) week <- rep(.1, ncol(etf_vix)) month <- rep(.1, ncol(etf_vix)) #---------------------------------- (bvhar_spec_v2 <- set_weight_bvhar(sig, lam, eps, day, week, month)) #> Model Specification for BVHAR #>  #> Parameters: Coefficent matrice and Covariance matrix #> Prior: MN_VHAR #> # Type '?bvhar_minnesota' in the console for some help. #> ======================================================== #>  #> Setting for 'sigma': #>   GVZCLS    OVXCLS  VXFXICLS  VXEEMCLS  VXSLVCLS    EVZCLS  VXXLECLS  VXGDXCLS   #>     3.77     10.63      3.81      4.39      5.99      2.27      4.88      7.45   #> VXEWZCLS   #>     7.03   #>  #> Setting for 'lambda': #> [1]  0.3 #>  #> Setting for 'eps': #> [1]  1e-04 #>  #> Setting for 'daily': #> [1]  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1 #>  #> Setting for 'weekly': #> [1]  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1 #>  #> Setting for 'monthly': #> [1]  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1 mod_bvhar_v2 <- bvhar_minnesota(y = etf_tr, bayes_spec = bvhar_spec_v2) forecast_bvhar_v2 <- predict(mod_bvhar_v2, h) (msebvhar_v2 <- mse(forecast_bvhar_v2, etf_te)) #>   GVZCLS   OVXCLS VXFXICLS VXEEMCLS VXSLVCLS   EVZCLS VXXLECLS VXGDXCLS  #>     3.63     4.39     1.37     5.63     6.16     1.19    14.18     2.52  #> VXEWZCLS  #>     5.23"},{"path":"/index.html","id":"plots","dir":"","previous_headings":"","what":"Plots","title":"Bayesian Vector Heterogeneous Autoregressive Modeling","text":"","code":"autoplot(forecast_var, x_cut = 870, ci_alpha = .7, type = \"wrap\") +   autolayer(forecast_vhar, ci_alpha = .6) +   autolayer(forecast_bvar, ci_alpha = .4) +   autolayer(forecast_bvhar_v1, ci_alpha = .2) +   autolayer(forecast_bvhar_v2, ci_alpha = .1)"},{"path":"/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Bayesian Vector Heterogeneous Autoregressive Modeling","text":"Please cite package following BibTeX:","code":"@Manual{,   title = {{bvhar}: Bayesian Vector Heterogeneous Autoregressive Modeling},   author = {Young Geun Kim and Changryong Baek},   year = {2023},   note = {R package version 1.2.0},   url = {https://cran.r-project.org/package=bvhar}, }  @Article{,   title = {Bayesian Vector Heterogeneous Autoregressive Modeling},   author = {Young Geun Kim and Changryong Baek},   journal = {Journal of Statistical Computation and Simulation},   year = {2023},   doi = {10.1080/00949655.2023.2281644}, }"},{"path":"/index.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Bayesian Vector Heterogeneous Autoregressive Modeling","text":"Please note bvhar project released Contributor Code Conduct. contributing project, agree abide terms.","code":""},{"path":"/reference/AIC.varlse.html","id":null,"dir":"Reference","previous_headings":"","what":"Akaike's Information Criterion of Multivariate Time Series Model — AIC.varlse","title":"Akaike's Information Criterion of Multivariate Time Series Model — AIC.varlse","text":"Compute AIC VAR(p), VHAR, BVAR(p), BVHAR","code":""},{"path":"/reference/AIC.varlse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Akaike's Information Criterion of Multivariate Time Series Model — AIC.varlse","text":"","code":"# S3 method for varlse AIC(object, ...)  # S3 method for vharlse AIC(object, ...)  # S3 method for bvarmn AIC(object, ...)  # S3 method for bvarflat AIC(object, ...)  # S3 method for bvharmn AIC(object, ...)"},{"path":"/reference/AIC.varlse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Akaike's Information Criterion of Multivariate Time Series Model — AIC.varlse","text":"object Model fit ... used","code":""},{"path":"/reference/AIC.varlse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Akaike's Information Criterion of Multivariate Time Series Model — AIC.varlse","text":"AIC value.","code":""},{"path":"/reference/AIC.varlse.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Akaike's Information Criterion of Multivariate Time Series Model — AIC.varlse","text":"Let \\(\\tilde{\\Sigma}_e\\) MLE let \\(\\hat{\\Sigma}_e\\) unbiased estimator (covmat) \\(\\Sigma_e\\). Note $$\\tilde{\\Sigma}_e = \\frac{s - k}{s} \\hat{\\Sigma}_e$$ $$AIC(p) = \\log \\det \\Sigma_e + \\frac{2}{s}(\\text{number freely estimated parameters})$$ number freely estimated parameters \\(mk\\), .e. \\(pm^2\\) \\(pm^2 + m\\).","code":""},{"path":"/reference/AIC.varlse.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Akaike's Information Criterion of Multivariate Time Series Model — AIC.varlse","text":"Akaike, H. (1969). Fitting autoregressive models prediction. Ann Inst Stat Math 21, 243–247. Akaike, H. (1971). Autoregressive model fitting control. Ann Inst Stat Math 23, 163–180. Akaike H. (1974). new look statistical model identification. IEEE Transactions Automatic Control, vol. 19, . 6, pp. 716-723. Akaike H. (1998). Information Theory Extension Maximum Likelihood Principle. : Parzen E., Tanabe K., Kitagawa G. (eds) Selected Papers Hirotugu Akaike. Springer Series Statistics (Perspectives Statistics). Springer, New York, NY. Lütkepohl, H. (2007). New Introduction Multiple Time Series Analysis. Springer Publishing.","code":""},{"path":"/reference/BIC.varlse.html","id":null,"dir":"Reference","previous_headings":"","what":"Bayesian Information Criterion of Multivariate Time Series Model — BIC.varlse","title":"Bayesian Information Criterion of Multivariate Time Series Model — BIC.varlse","text":"Compute BIC VAR(p), VHAR, BVAR(p), BVHAR","code":""},{"path":"/reference/BIC.varlse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bayesian Information Criterion of Multivariate Time Series Model — BIC.varlse","text":"","code":"# S3 method for varlse BIC(object, ...)  # S3 method for vharlse BIC(object, ...)  # S3 method for bvarmn BIC(object, ...)  # S3 method for bvarflat BIC(object, ...)  # S3 method for bvharmn BIC(object, ...)"},{"path":"/reference/BIC.varlse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bayesian Information Criterion of Multivariate Time Series Model — BIC.varlse","text":"object Model fit ... used","code":""},{"path":"/reference/BIC.varlse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bayesian Information Criterion of Multivariate Time Series Model — BIC.varlse","text":"BIC value.","code":""},{"path":"/reference/BIC.varlse.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bayesian Information Criterion of Multivariate Time Series Model — BIC.varlse","text":"Let \\(\\tilde{\\Sigma}_e\\) MLE let \\(\\hat{\\Sigma}_e\\) unbiased estimator (covmat) \\(\\Sigma_e\\). Note $$\\tilde{\\Sigma}_e = \\frac{s - k}{n} \\hat{\\Sigma}_e$$ $$BIC(p) = \\log \\det \\Sigma_e + \\frac{\\log s}{s}(\\text{number freely estimated parameters})$$ number freely estimated parameters \\(pm^2\\).","code":""},{"path":"/reference/BIC.varlse.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Bayesian Information Criterion of Multivariate Time Series Model — BIC.varlse","text":"Gideon Schwarz. (1978). Estimating Dimension Model. Ann. Statist. 6 (2) 461 - 464. Lütkepohl, H. (2007). New Introduction Multiple Time Series Analysis. Springer Publishing.","code":""},{"path":"/reference/FPE.html","id":null,"dir":"Reference","previous_headings":"","what":"Final Prediction Error Criterion — FPE","title":"Final Prediction Error Criterion — FPE","text":"Generic function computes FPE criterion.","code":""},{"path":"/reference/FPE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Final Prediction Error Criterion — FPE","text":"","code":"FPE(object, ...)"},{"path":"/reference/FPE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Final Prediction Error Criterion — FPE","text":"object Model fit ... used","code":""},{"path":"/reference/FPE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Final Prediction Error Criterion — FPE","text":"FPE value.","code":""},{"path":"/reference/FPE.varlse.html","id":null,"dir":"Reference","previous_headings":"","what":"Final Prediction Error Criterion of Multivariate Time Series Model — FPE.varlse","title":"Final Prediction Error Criterion of Multivariate Time Series Model — FPE.varlse","text":"Compute FPE VAR(p), VHAR, BVAR(p), BVHAR","code":""},{"path":"/reference/FPE.varlse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Final Prediction Error Criterion of Multivariate Time Series Model — FPE.varlse","text":"","code":"# S3 method for varlse FPE(object, ...)  # S3 method for vharlse FPE(object, ...)"},{"path":"/reference/FPE.varlse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Final Prediction Error Criterion of Multivariate Time Series Model — FPE.varlse","text":"object Model fit ... used","code":""},{"path":"/reference/FPE.varlse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Final Prediction Error Criterion of Multivariate Time Series Model — FPE.varlse","text":"FPE value.","code":""},{"path":"/reference/FPE.varlse.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Final Prediction Error Criterion of Multivariate Time Series Model — FPE.varlse","text":"Let \\(\\tilde{\\Sigma}_e\\) MLE let \\(\\hat{\\Sigma}_e\\) unbiased estimator (covmat) \\(\\Sigma_e\\). Note $$\\tilde{\\Sigma}_e = \\frac{s - k}{n} \\hat{\\Sigma}_e$$ $$FPE(p) = (\\frac{s + k}{s - k})^m \\det \\tilde{\\Sigma}_e$$","code":""},{"path":"/reference/FPE.varlse.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Final Prediction Error Criterion of Multivariate Time Series Model — FPE.varlse","text":"Lütkepohl, H. (2007). New Introduction Multiple Time Series Analysis. Springer Publishing.","code":""},{"path":"/reference/HQ.html","id":null,"dir":"Reference","previous_headings":"","what":"Hannan-Quinn Criterion — HQ","title":"Hannan-Quinn Criterion — HQ","text":"Generic function computes HQ criterion.","code":""},{"path":"/reference/HQ.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hannan-Quinn Criterion — HQ","text":"","code":"HQ(object, ...)  # S3 method for logLik HQ(object, ...)"},{"path":"/reference/HQ.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hannan-Quinn Criterion — HQ","text":"object Model fit ... used","code":""},{"path":"/reference/HQ.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hannan-Quinn Criterion — HQ","text":"HQ value.","code":""},{"path":"/reference/HQ.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Hannan-Quinn Criterion — HQ","text":"formula $$HQ = -2 \\log p(y \\mid \\hat\\theta) + k \\log\\log(n)$$ whic can computed AIC(object, ..., k = 2 * log(log(nobs(object)))) stats::AIC().","code":""},{"path":"/reference/HQ.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Hannan-Quinn Criterion — HQ","text":"Hannan, E.J. Quinn, B.G. (1979). Determination Order Autoregression. Journal Royal Statistical Society: Series B (Methodological), 41: 190-195.","code":""},{"path":"/reference/HQ.varlse.html","id":null,"dir":"Reference","previous_headings":"","what":"Hannan-Quinn Criterion of Multivariate Time Series Model — HQ.varlse","title":"Hannan-Quinn Criterion of Multivariate Time Series Model — HQ.varlse","text":"Compute HQ VAR(p), VHAR, BVAR(p), BVHAR","code":""},{"path":"/reference/HQ.varlse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hannan-Quinn Criterion of Multivariate Time Series Model — HQ.varlse","text":"","code":"# S3 method for varlse HQ(object, ...)  # S3 method for vharlse HQ(object, ...)  # S3 method for bvarmn HQ(object, ...)  # S3 method for bvarflat HQ(object, ...)  # S3 method for bvharmn HQ(object, ...)"},{"path":"/reference/HQ.varlse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hannan-Quinn Criterion of Multivariate Time Series Model — HQ.varlse","text":"object Model fit ... used","code":""},{"path":"/reference/HQ.varlse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hannan-Quinn Criterion of Multivariate Time Series Model — HQ.varlse","text":"HQ value.","code":""},{"path":"/reference/HQ.varlse.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Hannan-Quinn Criterion of Multivariate Time Series Model — HQ.varlse","text":"Let \\(\\tilde{\\Sigma}_e\\) MLE let \\(\\hat{\\Sigma}_e\\) unbiased estimator (covmat) \\(\\Sigma_e\\). Note $$\\tilde{\\Sigma}_e = \\frac{s - k}{n} \\hat{\\Sigma}_e$$ $$HQ(p) = \\log \\det \\Sigma_e + \\frac{2 \\log \\log s}{s}(\\text{number freely estimated parameters})$$ number freely estimated parameters \\(pm^2\\).","code":""},{"path":"/reference/HQ.varlse.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Hannan-Quinn Criterion of Multivariate Time Series Model — HQ.varlse","text":"Hannan, E.J. Quinn, B.G. (1979). Determination Order Autoregression. Journal Royal Statistical Society: Series B (Methodological), 41: 190-195. Lütkepohl, H. (2007). New Introduction Multiple Time Series Analysis. Springer Publishing. Quinn, B.G. (1980). Order Determination Multivariate Autoregression. Journal Royal Statistical Society: Series B (Methodological), 42: 182-185.","code":""},{"path":"/reference/VARtoVMA.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert VAR to VMA(infinite) — VARtoVMA","title":"Convert VAR to VMA(infinite) — VARtoVMA","text":"Convert VAR process infinite vector MA process","code":""},{"path":"/reference/VARtoVMA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert VAR to VMA(infinite) — VARtoVMA","text":"","code":"VARtoVMA(object, lag_max)"},{"path":"/reference/VARtoVMA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert VAR to VMA(infinite) — VARtoVMA","text":"object varlse object lag_max Maximum lag VMA","code":""},{"path":"/reference/VARtoVMA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert VAR to VMA(infinite) — VARtoVMA","text":"VMA coefficient k(lag-max + 1) x k dimension","code":""},{"path":"/reference/VARtoVMA.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert VAR to VMA(infinite) — VARtoVMA","text":"Let VAR(p) stable. $$Y_t = c + \\sum_{j = 0} W_j Z_{t - j}$$ VAR coefficient \\(B_1, B_2, \\ldots, B_p\\), $$= (W_0 + W_1 L + W_2 L^2 + \\cdots + ) (- B_1 L - B_2 L^2 - \\cdots - B_p L^p)$$ Recursively, $$W_0 = $$ $$W_1 = W_0 B_1 (W_1^T = B_1^T W_0^T)$$ $$W_2 = W_1 B_1 + W_0 B_2 (W_2^T = B_1^T W_1^T + B_2^T W_0^T)$$ $$W_j = \\sum_{j = 1}^k W_{k - j} B_j (W_j^T = \\sum_{j = 1}^k B_j^T W_{k - j}^T)$$","code":""},{"path":"/reference/VARtoVMA.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Convert VAR to VMA(infinite) — VARtoVMA","text":"Lütkepohl, H. (2007). New Introduction Multiple Time Series Analysis. Springer Publishing.","code":""},{"path":"/reference/VHARtoVMA.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert VHAR to VMA(infinite) — VHARtoVMA","title":"Convert VHAR to VMA(infinite) — VHARtoVMA","text":"Convert VHAR process infinite vector MA process","code":""},{"path":"/reference/VHARtoVMA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert VHAR to VMA(infinite) — VHARtoVMA","text":"","code":"VHARtoVMA(object, lag_max)"},{"path":"/reference/VHARtoVMA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert VHAR to VMA(infinite) — VHARtoVMA","text":"object vharlse object lag_max Maximum lag VMA","code":""},{"path":"/reference/VHARtoVMA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert VHAR to VMA(infinite) — VHARtoVMA","text":"VMA coefficient k(lag-max + 1) x k dimension","code":""},{"path":"/reference/VHARtoVMA.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert VHAR to VMA(infinite) — VHARtoVMA","text":"Let VAR(p) stable let VAR(p) \\(Y_0 = X_0 B + Z\\) VHAR VAR(22) $$Y_0 = X_1 B + Z = ((X_0 \\tilde{T}^T)) \\Phi + Z$$ Observe $$B = \\tilde{T}^T \\Phi$$","code":""},{"path":"/reference/VHARtoVMA.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Convert VHAR to VMA(infinite) — VHARtoVMA","text":"Lütkepohl, H. (2007). New Introduction Multiple Time Series Analysis. Springer Publishing.","code":""},{"path":"/reference/analyze_ir.html","id":null,"dir":"Reference","previous_headings":"","what":"Impulse Response Analysis — analyze_ir.varlse","title":"Impulse Response Analysis — analyze_ir.varlse","text":"Computes responses impulses orthogonal impulses","code":""},{"path":"/reference/analyze_ir.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Impulse Response Analysis — analyze_ir.varlse","text":"","code":"# S3 method for varlse analyze_ir(   object,   lag_max = 10,   orthogonal = TRUE,   impulse_var,   response_var,   ... )  # S3 method for vharlse analyze_ir(   object,   lag_max = 10,   orthogonal = TRUE,   impulse_var,   response_var,   ... )  # S3 method for bvharirf print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  analyze_ir(object, lag_max, orthogonal, impulse_var, response_var, ...)  knit_print.bvharirf(x, ...)"},{"path":"/reference/analyze_ir.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Impulse Response Analysis — analyze_ir.varlse","text":"object Model object lag_max Maximum lag investigate impulse responses (default, 10) orthogonal Orthogonal impulses (TRUE) just impulses (FALSE) impulse_var Impulse variables character vector. specified, use every variable. response_var Response variables character vector. specified, use every variable. ... used x bvharirf object digits digit option print","code":""},{"path":"/reference/analyze_ir.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Impulse Response Analysis — analyze_ir.varlse","text":"bvharirf  class","code":""},{"path":"/reference/analyze_ir.html","id":"responses-to-forecast-errors","dir":"Reference","previous_headings":"","what":"Responses to forecast errors","title":"Impulse Response Analysis — analyze_ir.varlse","text":"orthogonal = FALSE, function gives \\(W_j\\) VMA representation process $$Y_t = \\sum_{j = 0}^\\infty W_j \\epsilon_{t - j}$$","code":""},{"path":"/reference/analyze_ir.html","id":"responses-to-orthogonal-impulses","dir":"Reference","previous_headings":"","what":"Responses to orthogonal impulses","title":"Impulse Response Analysis — analyze_ir.varlse","text":"orthogonal = TRUE, gives orthogonalized VMA representation $$\\Theta$$. Based variance decomposition (Cholesky decomposition) $$\\Sigma = P P^T$$ \\(P\\) lower triangular matrix, impulse response analysis performed MA representation $$y_t = \\sum_{= 0}^\\infty \\Theta_i v_{t - }$$ , $$\\Theta_i = W_i P$$ \\(v_t = P^{-1} \\epsilon_t\\) orthogonal.","code":""},{"path":"/reference/analyze_ir.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Impulse Response Analysis — analyze_ir.varlse","text":"Lütkepohl, H. (2007). New Introduction Multiple Time Series Analysis. Springer Publishing.","code":""},{"path":[]},{"path":"/reference/autoplot.bvharirf.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Impulse Responses — autoplot.bvharirf","title":"Plot Impulse Responses — autoplot.bvharirf","text":"Draw impulse responses response ~ impulse facet.","code":""},{"path":"/reference/autoplot.bvharirf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Impulse Responses — autoplot.bvharirf","text":"","code":"# S3 method for bvharirf autoplot(object, ...)"},{"path":"/reference/autoplot.bvharirf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Impulse Responses — autoplot.bvharirf","text":"object bvharirf object ... arguments passed ggplot2::geom_path().","code":""},{"path":"/reference/autoplot.bvharirf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Impulse Responses — autoplot.bvharirf","text":"ggplot object","code":""},{"path":[]},{"path":"/reference/autoplot.bvharsp.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the Result of BVAR and BVHAR MCMC — autoplot.bvharsp","title":"Plot the Result of BVAR and BVHAR MCMC — autoplot.bvharsp","text":"Draw BVAR BVHAR MCMC plots.","code":""},{"path":"/reference/autoplot.bvharsp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the Result of BVAR and BVHAR MCMC — autoplot.bvharsp","text":"","code":"# S3 method for bvharsp autoplot(   object,   type = c(\"coef\", \"trace\", \"dens\", \"area\"),   pars = character(),   regex_pars = character(),   ... )"},{"path":"/reference/autoplot.bvharsp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the Result of BVAR and BVHAR MCMC — autoplot.bvharsp","text":"object bvharsp object type type plot. Posterior coefficient (\"coef\"), Trace plot (\"trace\"), kernel density plot (\"dens\"), interval estimates plot (\"area\"). pars Parameter names draw. regex_pars Regular expression parameter names draw. ... options bayesplot::mcmc_trace(), bayesplot::mcmc_dens(), bayesplot::mcmc_areas().","code":""},{"path":"/reference/autoplot.bvharsp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot the Result of BVAR and BVHAR MCMC — autoplot.bvharsp","text":"ggplot object","code":""},{"path":"/reference/autoplot.normaliw.html","id":null,"dir":"Reference","previous_headings":"","what":"Residual Plot for Minnesota Prior VAR Model — autoplot.normaliw","title":"Residual Plot for Minnesota Prior VAR Model — autoplot.normaliw","text":"function draws residual plot covariance matrix Minnesota prior VAR model.","code":""},{"path":"/reference/autoplot.normaliw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Residual Plot for Minnesota Prior VAR Model — autoplot.normaliw","text":"","code":"# S3 method for normaliw autoplot(object, hcol = \"grey\", hsize = 1.5, ...)"},{"path":"/reference/autoplot.normaliw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Residual Plot for Minnesota Prior VAR Model — autoplot.normaliw","text":"object normaliw object hcol color horizontal line = 0 (default, grey) hsize size horizontal line = 0 (default, 1.5) ... additional options geom_point","code":""},{"path":"/reference/autoplot.normaliw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Residual Plot for Minnesota Prior VAR Model — autoplot.normaliw","text":"ggplot object","code":""},{"path":"/reference/autoplot.predbvhar.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Forecast Result — autoplot.predbvhar","title":"Plot Forecast Result — autoplot.predbvhar","text":"Plots forecasting result forecast regions.","code":""},{"path":"/reference/autoplot.predbvhar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Forecast Result — autoplot.predbvhar","text":"","code":"# S3 method for predbvhar autoplot(   object,   type = c(\"grid\", \"wrap\"),   ci_alpha = 0.7,   alpha_scale = 0.3,   x_cut = 1,   viridis = FALSE,   viridis_option = \"D\",   NROW = NULL,   NCOL = NULL,   ... )  # S3 method for predbvhar autolayer(object, ci_fill = \"grey70\", ci_alpha = 0.5, alpha_scale = 0.3, ...)"},{"path":"/reference/autoplot.predbvhar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Forecast Result — autoplot.predbvhar","text":"object predbvhar object type Divide variables using ggplot2::facet_grid() (\"grid\": default) ggplot2::facet_wrap() (\"wrap\") ci_alpha Transparency CI alpha_scale Scale transparency parameter (alpha) two layers. alpha CI ribbon = alpha_scale * alpha path (default, .5) x_cut plot x axes x_cut visibility viridis TRUE, scale CI forecast line using ggplot2::scale_fill_viridis_d() ggplot2::scale_colour_viridis_d, respectively. viridis_option Option viridis string. See option ggplot2::scale_colour_viridis_d. Choose one c(\"\", \"B\", \"C\", \"D\", \"E\"). default, \"D\". NROW nrow ggplot2::facet_wrap() NCOL ncol ggplot2::facet_wrap() ... additional option ggplot2::geom_path() ci_fill color CI","code":""},{"path":"/reference/autoplot.predbvhar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Forecast Result — autoplot.predbvhar","text":"ggplot object ggplot layer","code":""},{"path":"/reference/autoplot.summary.bvharsp.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the Heatmap of SSVS Coefficients — autoplot.summary.bvharsp","title":"Plot the Heatmap of SSVS Coefficients — autoplot.summary.bvharsp","text":"Draw heatmap SSVS prior coefficients.","code":""},{"path":"/reference/autoplot.summary.bvharsp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the Heatmap of SSVS Coefficients — autoplot.summary.bvharsp","text":"","code":"# S3 method for summary.bvharsp autoplot(object, point = FALSE, ...)"},{"path":"/reference/autoplot.summary.bvharsp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the Heatmap of SSVS Coefficients — autoplot.summary.bvharsp","text":"object summary.bvharsp object point Use point sparsity representation ... arguments passed ggplot2::geom_tile().","code":""},{"path":"/reference/autoplot.summary.bvharsp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot the Heatmap of SSVS Coefficients — autoplot.summary.bvharsp","text":"ggplot object","code":""},{"path":"/reference/autoplot.summary.normaliw.html","id":null,"dir":"Reference","previous_headings":"","what":"Density Plot for Minnesota Prior VAR Model — autoplot.summary.normaliw","title":"Density Plot for Minnesota Prior VAR Model — autoplot.summary.normaliw","text":"function draws density plot coefficient matrices Minnesota prior VAR model.","code":""},{"path":"/reference/autoplot.summary.normaliw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Density Plot for Minnesota Prior VAR Model — autoplot.summary.normaliw","text":"","code":"# S3 method for summary.normaliw autoplot(   object,   type = c(\"trace\", \"dens\", \"area\"),   pars = character(),   regex_pars = character(),   ... )"},{"path":"/reference/autoplot.summary.normaliw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Density Plot for Minnesota Prior VAR Model — autoplot.summary.normaliw","text":"object summary.normaliw object type type plot. Trace plot (\"trace\"), kernel density plot (\"dens\"), interval estimates plot (\"area\"). pars Parameter names draw. regex_pars Regular expression parameter names draw. ... options bayesplot::mcmc_trace(), bayesplot::mcmc_dens(), bayesplot::mcmc_areas().","code":""},{"path":"/reference/autoplot.summary.normaliw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Density Plot for Minnesota Prior VAR Model — autoplot.summary.normaliw","text":"ggplot object","code":""},{"path":"/reference/bound_bvhar.html","id":null,"dir":"Reference","previous_headings":"","what":"Setting Empirical Bayes Optimization Bounds — bound_bvhar","title":"Setting Empirical Bayes Optimization Bounds — bound_bvhar","text":"function sets lower upper bounds set_bvar(), set_bvhar(), set_weight_bvhar().","code":""},{"path":"/reference/bound_bvhar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Setting Empirical Bayes Optimization Bounds — bound_bvhar","text":"","code":"bound_bvhar(   init_spec = set_bvhar(),   lower_spec = set_bvhar(),   upper_spec = set_bvhar() )  # S3 method for boundbvharemp print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  knit_print.boundbvharemp(x, ...)"},{"path":"/reference/bound_bvhar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Setting Empirical Bayes Optimization Bounds — bound_bvhar","text":"init_spec Initial Bayes model specification lower_spec Lower bound Bayes model specification upper_spec Upper bound Bayes model specification x boundbvharemp object digits digit option print ... used","code":""},{"path":"/reference/bound_bvhar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Setting Empirical Bayes Optimization Bounds — bound_bvhar","text":"boundbvharemp  class","code":""},{"path":"/reference/bvar_adding_dummy.html","id":null,"dir":"Reference","previous_headings":"","what":"Adding Dummy Observations — bvar_adding_dummy","title":"Adding Dummy Observations — bvar_adding_dummy","text":"page notes define dummy observation matrices Bayesian VAR VHAR models.","code":""},{"path":"/reference/bvar_adding_dummy.html","id":"bayesian-var","dir":"Reference","previous_headings":"","what":"Bayesian VAR","title":"Adding Dummy Observations — bvar_adding_dummy","text":"Consider BVAR hyperparameters set_bvar(). sigma: \\(\\sigma_1, \\ldots, \\sigma_m\\) lambda: \\(\\lambda\\) delta: \\(\\delta_1, \\ldots, \\delta_m\\) eps: \\(\\epsilon\\) package implements adding-dummy-observations approach Bańbura et al. (2010). Let \\(J_p = diag(1, 2, \\ldots, p)\\). response design matrix \\(Y_0\\) \\(X_0\\), define dummy observation named \\(Y_p\\) \\(X_p\\). Response dummy matrix \\(Y_p\\) (m + k) x m matrix: $$   Y_p = \\left[\\begin{array}{c} diag\\left( \\delta_1 \\sigma_1, \\ldots, \\delta_m \\sigma_m \\right) / \\lambda \\\\ 0_{m(p - 1) \\times m} \\\\ \\hline diag\\left( \\sigma_1, \\ldots, \\sigma_m \\right) \\\\ \\hline 0_m^\\intercal \\end{array}\\right] $$ Design dummy matrix \\(X_p\\) (m + k) x k matrix: $$   X_p = \\left[\\begin{array}{c|c} J_p \\otimes diag\\left( \\sigma_1, \\ldots, \\sigma_m \\right) / \\lambda & 0_{mp} \\\\ \\hline 0_{m \\times mp} & 0_m \\\\ \\hline 0_{mp}^\\intercal & \\epsilon \\end{array}\\right] $$ two matrices define Minnesota prior distribution BVAR.","code":""},{"path":"/reference/bvar_adding_dummy.html","id":"bayesian-vhar","dir":"Reference","previous_headings":"","what":"Bayesian VHAR","title":"Adding Dummy Observations — bvar_adding_dummy","text":"Consider BVHAR hyperparameter set_bvhar(). First, VAR-type minnesota prior: sigma: \\(\\sigma_1, \\ldots, \\sigma_m\\) lambda: \\(\\lambda\\) delta: \\(\\delta_1, \\ldots, \\delta_m\\) eps: \\(\\epsilon\\) response matrix \\(Y_0\\), define (m + h) x m matrix \\(Y_{HAR}\\) $$   Y_{HAR} = \\left[\\begin{array}{c}   diag\\left( \\delta_1 \\sigma_1, \\ldots, \\delta_m \\sigma_m \\right) / \\lambda \\\\   0_{2m \\times m} \\\\ \\hline   diag\\left( \\sigma_1, \\ldots, \\sigma_m \\right) \\\\ \\hline   0_m^\\intercal \\end{array}\\right] $$ design matrix \\(X_0\\), define (m + h) x h matrix \\(X_{HAR}\\) $$   X_{HAR} = \\left[\\begin{array}{c|c}   J_3 \\otimes diag\\left( \\sigma_1, \\ldots, \\sigma_m \\right) / \\lambda & 0_{3m} \\\\ \\hline   0_{m \\times 3m} & 0_m \\\\ \\hline   0_{3m}^\\intercal & \\epsilon \\end{array}\\right] $$ case VHAR-type minnesota prior, delta replaced following three: daily: \\(d_1, \\ldots, d_m\\) weekly: \\(w_1, \\ldots, w_m\\) monthly: \\(m_1, \\ldots, m_m\\) \\(Y_{HAR}\\) changed. $$   Y_{HAR} = \\left[\\begin{array}{c}   diag\\left( d_1 \\sigma_1, \\ldots, d_m \\sigma_m \\right) / \\lambda \\\\   diag\\left( w_1 \\sigma_1, \\ldots, w_m \\sigma_m \\right) / \\lambda \\\\   diag\\left( m_1 \\sigma_1, \\ldots, m_m \\sigma_m \\right) / \\lambda \\\\ \\hline   diag\\left( \\sigma_1, \\ldots, \\sigma_m \\right) \\\\ \\hline   0_m^\\intercal \\end{array}\\right] $$ two dummy matrices define minnesota prior distribution BVHAR.","code":""},{"path":"/reference/bvar_adding_dummy.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Adding Dummy Observations — bvar_adding_dummy","text":"Bańbura, M., Giannone, D., & Reichlin, L. (2010). Large Bayesian vector auto regressions. Journal Applied Econometrics, 25(1).","code":""},{"path":"/reference/bvar_flat.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting Bayesian VAR(p) of Flat Prior — bvar_flat","title":"Fitting Bayesian VAR(p) of Flat Prior — bvar_flat","text":"function fits BVAR(p) flat prior.","code":""},{"path":"/reference/bvar_flat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting Bayesian VAR(p) of Flat Prior — bvar_flat","text":"","code":"bvar_flat(y, p, bayes_spec = set_bvar_flat(), include_mean = TRUE)  # S3 method for bvarflat print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  knit_print.bvarflat(x, ...)"},{"path":"/reference/bvar_flat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting Bayesian VAR(p) of Flat Prior — bvar_flat","text":"y Time series data columns indicate variables p VAR lag bayes_spec BVAR model specification set_bvar_flat(). include_mean Add constant term (Default: TRUE) (FALSE) x bvarflat object digits digit option print ... used","code":""},{"path":"/reference/bvar_flat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting Bayesian VAR(p) of Flat Prior — bvar_flat","text":"bvar_flat() returns object bvarflat  class. list following components: coefficients Posterior Mean matrix Matrix Normal distribution fitted.values Fitted values residuals Residuals mn_prec Posterior precision matrix Matrix Normal distribution iw_scale Posterior scale matrix posterior inverse-wishart distribution iw_shape Posterior shape inverse-wishart distribution df Numer Coefficients: mp + 1 mp p Lag VAR m Dimension time series obs Sample size used training = totobs - p totobs Total number observation process Process string bayes_spec: \"BVAR_Flat\" spec Model specification (bvharspec) type include constant term (\"const\") (\"none\") call Matched call prior_mean Prior mean matrix Matrix Normal distribution: zero matrix prior_precision Prior precision matrix Matrix Normal distribution: \\(U^{-1}\\) y0 \\(Y_0\\) design \\(X_0\\) y Raw input (matrix)","code":""},{"path":"/reference/bvar_flat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting Bayesian VAR(p) of Flat Prior — bvar_flat","text":"Ghosh et al. (2018) gives flat prior residual matrix BVAR. setting, many models hierarchical non-hierarchical. function chooses simple non-hierarchical matrix normal prior Section 3.1. $$\\mid \\Sigma_e \\sim MN(0, U^{-1}, \\Sigma_e)$$ U: precision matrix (MN: matrix normal). $$p (\\Sigma_e) \\propto 1$$","code":""},{"path":"/reference/bvar_flat.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting Bayesian VAR(p) of Flat Prior — bvar_flat","text":"Ghosh, S., Khare, K., & Michailidis, G. (2018). High-Dimensional Posterior Consistency Bayesian Vector Autoregressive Models. Journal American Statistical Association, 114(526). Litterman, R. B. (1986). Forecasting Bayesian Vector Autoregressions: Five Years Experience. Journal Business & Economic Statistics, 4(1), 25.","code":""},{"path":[]},{"path":"/reference/bvar_horseshoe.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting Bayesian VAR(p) of Horseshoe Prior — bvar_horseshoe","title":"Fitting Bayesian VAR(p) of Horseshoe Prior — bvar_horseshoe","text":"function fits BVAR(p) horseshoe prior.","code":""},{"path":"/reference/bvar_horseshoe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting Bayesian VAR(p) of Horseshoe Prior — bvar_horseshoe","text":"","code":"bvar_horseshoe(   y,   p,   num_iter = 1000,   num_burn = floor(num_iter/2),   thinning = 1,   bayes_spec = set_horseshoe(),   include_mean = TRUE,   minnesota = FALSE,   algo = c(\"block\", \"gibbs\"),   verbose = FALSE )  # S3 method for bvarhs print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  knit_print.bvarhs(x, ...)"},{"path":"/reference/bvar_horseshoe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting Bayesian VAR(p) of Horseshoe Prior — bvar_horseshoe","text":"y Time series data columns indicate variables p VAR lag num_iter MCMC iteration number num_burn Number burn-(warm-). Half iteration default choice. thinning Thinning every thinning-th iteration bayes_spec Horseshoe initialization specification set_horseshoe(). include_mean Add constant term (Default: TRUE) (FALSE) minnesota Minnesota type algo Ordinary gibbs sampling (\"gibbs\") blocked gibbs (Default: \"block\"). verbose Print progress bar console. default, FALSE. x bvarhs object digits digit option print ... used","code":""},{"path":"/reference/bvar_horseshoe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting Bayesian VAR(p) of Horseshoe Prior — bvar_horseshoe","text":"bvar_horseshoe returns object named bvarhs  class. list following components: alpha_record MCMC trace vectorized coefficients (alpha \\(\\alpha\\)) posterior::draws_df format. lambda_record MCMC trace local shrinkage level (lambda \\(\\lambda\\)) posterior::draws_df format. tau_record MCMC trace global shrinkage level (tau \\(\\tau\\)) posterior::draws_df format. psi_record MCMC trace precision matrix (psi \\(\\Psi\\)) list format. chain numer chains coefficients Posterior mean VAR coefficients. psi_posterior Posterior mean precision matrix \\(\\Psi\\) covmat Posterior mean covariance matrix omega_record MCMC trace diagonal element \\(\\Psi\\) (omega) posterior::draws_df format. eta_record MCMC trace upper triangular element \\(\\Psi\\) (eta) posterior::draws_df format. param posterior::draws_df every variable: alpha, lambda, tau, omega, eta df Numer Coefficients: mp + 1 mp p Lag VAR m Dimension data obs Sample size used training = totobs - p totobs Total number observation call Matched call process Description model, e.g. \"VAR_Horseshoe\" type include constant term (\"const\") (\"none\") algo Usual Gibbs sampling (\"gibbs\") fast sampling (\"fast\") spec Horseshoe specification defined set_horseshoe() iter Total iterations burn Burn-thin Thinning y0 \\(Y_0\\) design \\(X_0\\) y Raw input","code":""},{"path":"/reference/bvar_horseshoe.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting Bayesian VAR(p) of Horseshoe Prior — bvar_horseshoe","text":"Carvalho, C. M., Polson, N. G., & Scott, J. G. (2010). horseshoe estimator sparse signals. Biometrika, 97(2), 465–480. Makalic, E., & Schmidt, D. F. (2016). Simple Sampler Horseshoe Estimator. IEEE Signal Processing Letters, 23(1), 179–182.","code":""},{"path":"/reference/bvar_minnesota.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting Bayesian VAR(p) of Minnesota Prior — bvar_minnesota","title":"Fitting Bayesian VAR(p) of Minnesota Prior — bvar_minnesota","text":"function fits BVAR(p) Minnesota prior.","code":""},{"path":"/reference/bvar_minnesota.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting Bayesian VAR(p) of Minnesota Prior — bvar_minnesota","text":"","code":"bvar_minnesota(y, p = 1, bayes_spec = set_bvar(), include_mean = TRUE)  # S3 method for bvarmn print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  knit_print.bvarmn(x, ...)"},{"path":"/reference/bvar_minnesota.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting Bayesian VAR(p) of Minnesota Prior — bvar_minnesota","text":"y Time series data columns indicate variables p VAR lag (Default: 1) bayes_spec BVAR model specification set_bvar(). include_mean Add constant term (Default: TRUE) (FALSE) x bvarmn object digits digit option print ... used","code":""},{"path":"/reference/bvar_minnesota.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting Bayesian VAR(p) of Minnesota Prior — bvar_minnesota","text":"bvar_minnesota() returns object bvarmn  class. list following components: coefficients Posterior Mean matrix Matrix Normal distribution fitted.values Fitted values residuals Residuals mn_prec Posterior precision matrix Matrix Normal distribution iw_scale Posterior scale matrix posterior inverse-Wishart distribution iw_shape Posterior shape inverse-Wishart distribution (\\(alpha_0\\) - obs + 2). \\(\\alpha_0\\): nrow(Dummy observation) - k df Numer Coefficients: mp + 1 mp p Lag VAR m Dimension time series obs Sample size used training = totobs - p totobs Total number observation call Matched call process Process string bayes_spec: \"BVAR_Minnesota\" spec Model specification (bvharspec) type include constant term (\"const\") (\"none\") prior_mean Prior mean matrix Matrix Normal distribution: \\(A_0\\) prior_precision Prior precision matrix Matrix Normal distribution: \\(\\Omega_0^{-1}\\) prior_scale Prior scale matrix inverse-Wishart distribution: \\(S_0\\) prior_shape Prior shape inverse-Wishart distribution: \\(\\alpha_0\\) y0 \\(Y_0\\) design \\(X_0\\) y Raw input (matrix) also normaliw bvharmod class.","code":""},{"path":"/reference/bvar_minnesota.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting Bayesian VAR(p) of Minnesota Prior — bvar_minnesota","text":"Minnesota prior gives prior parameters \\(\\) (VAR matrices) \\(\\Sigma_e\\) (residual covariance). $$\\mid \\Sigma_e \\sim MN(A_0, \\Omega_0, \\Sigma_e)$$ $$\\Sigma_e \\sim IW(S_0, \\alpha_0)$$ (MN: matrix normal, IW: inverse-wishart)","code":""},{"path":"/reference/bvar_minnesota.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting Bayesian VAR(p) of Minnesota Prior — bvar_minnesota","text":"Bańbura, M., Giannone, D., & Reichlin, L. (2010). Large Bayesian vector auto regressions. Journal Applied Econometrics, 25(1). Giannone, D., Lenza, M., & Primiceri, G. E. (2015). Prior Selection Vector Autoregressions. Review Economics Statistics, 97(2). Litterman, R. B. (1986). Forecasting Bayesian Vector Autoregressions: Five Years Experience. Journal Business & Economic Statistics, 4(1), 25. KADIYALA, K.R. KARLSSON, S. (1997), NUMERICAL METHODS ESTIMATION INFERENCE BAYESIAN VAR-MODELS. J. Appl. Econ., 12: 99-132. Karlsson, S. (2013). Chapter 15 Forecasting Bayesian Vector Autoregression. Handbook Economic Forecasting, 2, 791–897. Sims, C. ., & Zha, T. (1998). Bayesian Methods Dynamic Multivariate Models. International Economic Review, 39(4), 949–968.","code":""},{"path":[]},{"path":"/reference/bvar_minnesota.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting Bayesian VAR(p) of Minnesota Prior — bvar_minnesota","text":"","code":"# Perform the function using etf_vix dataset fit <- bvar_minnesota(y = etf_vix[,1:3], p = 2) class(fit) #> [1] \"bvarmn\"   \"normaliw\" \"bvharmod\"  # Extract coef, fitted values, and residuals coef(fit) #>                  GVZCLS      OVXCLS     VXFXICLS #> GVZCLS_1    0.748002362 0.016660371 0.0292009699 #> OVXCLS_1    0.001065823 0.756433551 0.0095768264 #> VXFXICLS_1  0.030593805 0.047149733 0.7394653446 #> GVZCLS_2    0.131161556 0.001676923 0.0070667088 #> OVXCLS_2   -0.002739948 0.156961310 0.0007335284 #> VXFXICLS_2  0.004802996 0.002851055 0.1348365830 #> const       1.364048215 0.892319013 2.1678666754 head(residuals(fit)) #>            [,1]       [,2]       [,3] #> [1,]  1.1038151  0.2448516  0.3122368 #> [2,] -0.2642748  1.4056509 -0.2626782 #> [3,] -0.2029986 -0.3475479  1.2435163 #> [4,]  0.3670679 -0.6480620  0.1162101 #> [5,]  0.4762747 -0.6819821 -0.1371471 #> [6,] -0.1455416 -1.2903485 -0.4655733 head(fitted(fit)) #>        GVZCLS   OVXCLS VXFXICLS #> [1,] 21.23618 35.27515 28.74776 #> [2,] 21.86427 35.18435 28.72268 #> [3,] 21.40300 35.96755 28.29648 #> [4,] 21.03293 35.44306 28.98879 #> [5,] 21.12373 34.65198 28.80715 #> [6,] 21.28554 33.88035 28.42557"},{"path":"/reference/bvar_niwhm.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting Hierarchical Bayesian VAR(p) — bvar_niwhm","title":"Fitting Hierarchical Bayesian VAR(p) — bvar_niwhm","text":"function fits hierarchical BVAR(p) general Minnesota prior.","code":""},{"path":"/reference/bvar_niwhm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting Hierarchical Bayesian VAR(p) — bvar_niwhm","text":"","code":"bvar_niwhm(   y,   p,   num_iter = 1000,   num_burn = floor(num_iter/2),   thinning = 1,   bayes_spec = set_bvar(sigma = set_psi(), lambda = set_lambda()),   scale_variance = 0.05,   include_mean = TRUE,   parallel = list(),   verbose = FALSE )  # S3 method for bvarhm print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  knit_print.bvarhm(x, ...)"},{"path":"/reference/bvar_niwhm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting Hierarchical Bayesian VAR(p) — bvar_niwhm","text":"y Time series data columns indicate variables p VAR lag num_iter MCMC iteration number num_burn Number burn-(warm-). Half iteration default choice. thinning Thinning every thinning-th iteration bayes_spec BVAR model specification set_ssvs(). scale_variance Proposal distribution scaling constant adjust acceptance rate include_mean Add constant term (Default: TRUE) (FALSE) parallel List argument optimParallel::optimParallel(). default, empty, function execute parallel computation. verbose Print progress bar console. default, FALSE. x bvarhm object digits digit option print ... used","code":""},{"path":"/reference/bvar_niwhm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting Hierarchical Bayesian VAR(p) — bvar_niwhm","text":"bvar_niwhm returns object named bvarhm  class. list following components: coefficients Coefficient Matrix p Lag VAR m Dimension data obs Sample size used training = totobs - p totobs Total number observation call Matched call type include constant term (\"const\") (\"none\") y0 \\(Y_0\\) design \\(X_0\\) y Raw input","code":""},{"path":"/reference/bvar_niwhm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting Hierarchical Bayesian VAR(p) — bvar_niwhm","text":"SSVS prior gives prior parameters \\(\\alpha = vec()\\) (VAR coefficient) \\(\\Sigma_e^{-1} = \\Psi \\Psi^T\\) (residual covariance). $$\\alpha_j \\mid \\gamma_j \\sim (1 - \\gamma_j) N(0, \\kappa_{0j}^2) + \\gamma_j N(0, \\kappa_{1j}^2)$$ $$\\gamma_j \\sim Bernoulli(q_j)$$ upper triangular matrix \\(\\Psi\\), $$\\psi_{jj}^2 \\sim Gamma(shape = a_j, rate = b_j)$$ $$\\psi_{ij} \\mid w_{ij} \\sim (1 - w_{ij}) N(0, \\kappa_{0,ij}^2) + w_{ij} N(0, \\kappa_{1,ij}^2)$$ $$w_{ij} \\sim Bernoulli(q_{ij})$$ Gibbs sampler used estimation. See ssvs_bvar_algo works.","code":""},{"path":"/reference/bvar_niwhm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting Hierarchical Bayesian VAR(p) — bvar_niwhm","text":"Bańbura, M., Giannone, D., & Reichlin, L. (2010). Large Bayesian vector auto regressions. Journal Applied Econometrics, 25(1). Giannone, D., Lenza, M., & Primiceri, G. E. (2015). Prior Selection Vector Autoregressions. Review Economics Statistics, 97(2). Litterman, R. B. (1986). Forecasting Bayesian Vector Autoregressions: Five Years Experience. Journal Business & Economic Statistics, 4(1), 25.","code":""},{"path":"/reference/bvar_predictive_density.html","id":null,"dir":"Reference","previous_headings":"","what":"Predictive Density of Bayesian Models — bvar_predictive_density","title":"Predictive Density of Bayesian Models — bvar_predictive_density","text":"page explains simulation algorithm predictive distribution BVAR BVHAR.","code":""},{"path":"/reference/bvar_predictive_density.html","id":"simulating-predictive-distribution-of-bvar","dir":"Reference","previous_headings":"","what":"Simulating predictive distribution of BVAR","title":"Predictive Density of Bayesian Models — bvar_predictive_density","text":"simulation process required know closed form h-step ahead forecasting density. given number simulation (n_iter), Generate \\((^{(b)}, \\Sigma_e^{(b)}) \\sim MIW\\) (posterior) Recursively, \\(j = 1, \\ldots, h\\) (n_ahead) Point forecast: Use \\(\\hat{}\\) Predictive distribution: generate \\(\\tilde{Y}_{n + j}^{(b)} \\sim ^{(b)}, \\Sigma_e^{(b)} \\sim MN\\) tilde notation indicates simulated ones Simulating predictive distribution BVHAR extend similar procedure BVAR BVHAR. given number simulation (n_iter), Generate \\((\\Phi^{(b)}, \\Sigma_e^{(b)}) \\sim MIW\\) (posterior) Recursively, \\(j = 1, \\ldots, h\\) (n_ahead) Point forecast: Use \\(\\hat\\Phi\\) Predictive distribution: generate \\(\\tilde{Y}_{n + j}^{(b)} \\sim \\Phi^{(b)}, \\Sigma_e^{(b)} \\sim MN\\) tilde notation indicates simulated ones","code":""},{"path":"/reference/bvar_predictive_density.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Predictive Density of Bayesian Models — bvar_predictive_density","text":"Giannone, D., Lenza, M., & Primiceri, G. E. (2015). Prior Selection Vector Autoregressions. Review Economics Statistics, 97(2). Karlsson, S. (2013). Chapter 15 Forecasting Bayesian Vector Autoregression. Handbook Economic Forecasting, 2, 791–897.","code":""},{"path":"/reference/bvar_ssvs.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting Bayesian VAR(p) of SSVS Prior — bvar_ssvs","title":"Fitting Bayesian VAR(p) of SSVS Prior — bvar_ssvs","text":"function fits BVAR(p) stochastic search variable selection (SSVS) prior.","code":""},{"path":"/reference/bvar_ssvs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting Bayesian VAR(p) of SSVS Prior — bvar_ssvs","text":"","code":"bvar_ssvs(   y,   p,   num_iter = 1000,   num_burn = floor(num_iter/2),   thinning = 1,   bayes_spec = choose_ssvs(y = y, ord = p, type = \"VAR\", param = c(0.1, 10), include_mean     = include_mean, gamma_param = c(0.01, 0.01), mean_non = 0, sd_non = 0.1),   init_spec = init_ssvs(type = \"auto\"),   include_mean = TRUE,   minnesota = FALSE,   verbose = FALSE )  # S3 method for bvarssvs print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  knit_print.bvarssvs(x, ...)"},{"path":"/reference/bvar_ssvs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting Bayesian VAR(p) of SSVS Prior — bvar_ssvs","text":"y Time series data columns indicate variables p VAR lag num_iter MCMC iteration number num_burn Number burn-(warm-). Half iteration default choice. thinning Thinning every thinning-th iteration bayes_spec SSVS model specification set_ssvs(). default, use default semiautomatic approach choose_ssvs(). init_spec SSVS initialization specification init_ssvs(). default, use OLS coefficient cholesky factor 1 dummies. include_mean Add constant term (Default: TRUE) (FALSE) minnesota Apply cross-variable shrinkage structure (Minnesota-way). default, FALSE. verbose Print progress bar console. default, FALSE. x bvarssvs object digits digit option print ... used","code":""},{"path":"/reference/bvar_ssvs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting Bayesian VAR(p) of SSVS Prior — bvar_ssvs","text":"bvar_ssvs returns object named bvarssvs  class. list following components: alpha_record MCMC trace vectorized coefficients (alpha \\(\\alpha\\)) posterior::draws_df format. eta_record MCMC trace upper triangular element cholesky factor (eta \\(\\eta\\)) posterior::draws_df format. psi_record MCMC trace diagonal element cholesky factor (psi \\(\\psi\\)) posterior::draws_df format. omega_record MCMC trace indicator variable \\(eta\\) (omega \\(\\omega\\)) posterior::draws_df format. gamma_record MCMC trace indicator variable \\(alpha\\) (gamma \\(\\gamma\\)) posterior::draws_df format. chol_record MCMC trace cholesky factor matrix \\(\\Psi\\) list format. ols_coef OLS estimates VAR coefficients. ols_cholesky OLS estimates cholesky factor coefficients Posterior mean VAR coefficients. omega_posterior Posterior mean omega pip Posterior inclusion probability param posterior::draws_df every variable: alpha, eta, psi, omega, gamma chol_posterior Posterior mean cholesky factor matrix covmat Posterior mean covariance matrix df Numer Coefficients: mp + 1 mp p Lag VAR m Dimension data obs Sample size used training = totobs - p totobs Total number observation call Matched call process Description model, e.g. \"VAR_SSVS\" type include constant term (\"const\") (\"none\") spec SSVS specification defined set_ssvs() init Initial specification defined init_ssvs() iter Total iterations burn Burn-thin Thinning chain numer chains y0 \\(Y_0\\) design \\(X_0\\) y Raw input","code":""},{"path":"/reference/bvar_ssvs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting Bayesian VAR(p) of SSVS Prior — bvar_ssvs","text":"SSVS prior gives prior parameters \\(\\alpha = vec()\\) (VAR coefficient) \\(\\Sigma_e^{-1} = \\Psi \\Psi^T\\) (residual covariance). $$\\alpha_j \\mid \\gamma_j \\sim (1 - \\gamma_j) N(0, \\kappa_{0j}^2) + \\gamma_j N(0, \\kappa_{1j}^2)$$ $$\\gamma_j \\sim Bernoulli(q_j)$$ upper triangular matrix \\(\\Psi\\), $$\\psi_{jj}^2 \\sim Gamma(shape = a_j, rate = b_j)$$ $$\\psi_{ij} \\mid w_{ij} \\sim (1 - w_{ij}) N(0, \\kappa_{0,ij}^2) + w_{ij} N(0, \\kappa_{1,ij}^2)$$ $$w_{ij} \\sim Bernoulli(q_{ij})$$ Gibbs sampler used estimation. See ssvs_bvar_algo works.","code":""},{"path":"/reference/bvar_ssvs.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting Bayesian VAR(p) of SSVS Prior — bvar_ssvs","text":"George, E. ., & McCulloch, R. E. (1993). Variable Selection via Gibbs Sampling. Journal American Statistical Association, 88(423), 881–889. George, E. ., Sun, D., & Ni, S. (2008). Bayesian stochastic search VAR model restrictions. Journal Econometrics, 142(1), 553–580. Koop, G., & Korobilis, D. (2009). Bayesian Multivariate Time Series Methods Empirical Macroeconomics. Foundations Trends® Econometrics, 3(4), 267–358.","code":""},{"path":[]},{"path":"/reference/bvar_sv.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting Bayesian VAR-SV — bvar_sv","title":"Fitting Bayesian VAR-SV — bvar_sv","text":"function fits VAR-SV. can Minnesota, SSVS, Horseshoe prior.","code":""},{"path":"/reference/bvar_sv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting Bayesian VAR-SV — bvar_sv","text":"","code":"bvar_sv(   y,   p,   num_iter = 1000,   num_burn = floor(num_iter/2),   thinning = 1,   bayes_spec = set_bvar(),   include_mean = TRUE,   minnesota = FALSE,   verbose = FALSE,   num_thread = 1 )  # S3 method for bvarsv print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  knit_print.bvarsv(x, ...)"},{"path":"/reference/bvar_sv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting Bayesian VAR-SV — bvar_sv","text":"y Time series data columns indicate variables p VAR lag num_iter MCMC iteration number num_burn Number burn-(warm-). Half iteration default choice. thinning Thinning every thinning-th iteration bayes_spec BVAR model specification set_bvar(). include_mean Add constant term (Default: TRUE) (FALSE) minnesota Apply cross-variable shrinkage structure (Minnesota-way). default, FALSE. verbose Print progress bar console. default, FALSE. num_thread Number threads x bvarsv object digits digit option print ... used","code":""},{"path":"/reference/bvar_sv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting Bayesian VAR-SV — bvar_sv","text":"bvar_sv() returns object named bvarsv  class.","code":""},{"path":"/reference/bvar_sv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting Bayesian VAR-SV — bvar_sv","text":"Cholesky stochastic volatility modeling VAR based $$\\Sigma_t = L^T D_t^{-1} L$$","code":""},{"path":"/reference/bvar_sv.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting Bayesian VAR-SV — bvar_sv","text":"Carriero, ., Chan, J., Clark, T. E., & Marcellino, M. (2022). Corrigendum “Large Bayesian vector autoregressions stochastic volatility non-conjugate priors” [J. Econometrics 212 (1)(2019) 137–154]. Journal Econometrics, 227(2), 506-512. Chan, J., Koop, G., Poirier, D., & Tobias, J. (2019). Bayesian Econometric Methods (2nd ed., Econometric Exercises). Cambridge: Cambridge University Press. Cogley, T., & Sargent, T. J. (2005). Drifts volatilities: monetary policies outcomes post WWII US. Review Economic Dynamics, 8(2), 262–302. Gruber, L., & Kastner, G. (2022). Forecasting macroeconomic data Bayesian VARs: Sparse dense? depends! arXiv.","code":""},{"path":"/reference/bvhar-package.html","id":null,"dir":"Reference","previous_headings":"","what":"bvhar: Bayesian Vector Heterogeneous Autoregressive Modeling — bvhar-package","title":"bvhar: Bayesian Vector Heterogeneous Autoregressive Modeling — bvhar-package","text":"Tools research Bayesian Vector heterogeneous autoregressive (VHAR) model, referring Kim & Baek (2023) (doi:10.1080/00949655.2023.2281644 ). 'bvhar' can model Vector Autoregressive (VAR), VHAR, Bayesian VAR (BVAR), Bayesian VHAR (BVHAR) models.","code":""},{"path":"/reference/bvhar-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"bvhar: Bayesian Vector Heterogeneous Autoregressive Modeling — bvhar-package","text":"bvhar package provides function analyze forecast multivariate time series data via vector autoregressive modelling. , vector autoregressive modelling includes: Vector autoregressive (VAR) model: var_lm() Vector heterogeneous autoregressive (VHAR) model: vhar_lm() Bayesian VAR (BVAR) model: bvar_minnesota(), bvar_flat() Bayesian VHAR (BVHAR) model: bvhar_minnesota()","code":""},{"path":"/reference/bvhar-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"bvhar: Bayesian Vector Heterogeneous Autoregressive Modeling — bvhar-package","text":"Kim, Y. G., Baek, C. (2023). Bayesian vector heterogeneous autoregressive modeling. Journal Statistical Computation Simulation.","code":""},{"path":[]},{"path":"/reference/bvhar-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"bvhar: Bayesian Vector Heterogeneous Autoregressive Modeling — bvhar-package","text":"Maintainer: Young Geun Kim ygeunkimstat@gmail.com (ORCID) [copyright holder] contributors: Changryong Baek [contributor]","code":""},{"path":"/reference/bvhar_horseshoe.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting Bayesian VHAR of Horseshoe Prior — bvhar_horseshoe","title":"Fitting Bayesian VHAR of Horseshoe Prior — bvhar_horseshoe","text":"function fits VHAR horseshoe prior.","code":""},{"path":"/reference/bvhar_horseshoe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting Bayesian VHAR of Horseshoe Prior — bvhar_horseshoe","text":"","code":"bvhar_horseshoe(   y,   har = c(5, 22),   num_iter = 1000,   num_burn = floor(num_iter/2),   thinning = 1,   bayes_spec = set_horseshoe(),   include_mean = TRUE,   minnesota = c(\"no\", \"short\", \"longrun\"),   algo = c(\"block\", \"gibbs\"),   verbose = FALSE )  # S3 method for bvharhs print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  knit_print.bvharhs(x, ...)"},{"path":"/reference/bvhar_horseshoe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting Bayesian VHAR of Horseshoe Prior — bvhar_horseshoe","text":"y Time series data columns indicate variables har Numeric vector weekly monthly order. default, c(5, 22). num_iter MCMC iteration number num_burn Number burn-(warm-). Half iteration default choice. thinning Thinning every thinning-th iteration bayes_spec Horseshoe initialization specification set_horseshoe(). include_mean Add constant term (Default: TRUE) (FALSE) minnesota Minnesota type algo Ordinary gibbs sampling (\"gibbs\") blocked gibbs (Default: \"block\"). verbose Print progress bar console. default, FALSE. x bvharhs object digits digit option print ... used","code":""},{"path":"/reference/bvhar_horseshoe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting Bayesian VHAR of Horseshoe Prior — bvhar_horseshoe","text":"bvhar_horseshoe returns object named bvarhs  class. list following components: phi_record MCMC trace vectorized coefficients (alpha \\(\\phi\\)) posterior::draws_df format. lambda_record MCMC trace local shrinkage level (lambda \\(\\lambda\\)) posterior::draws_df format. tau_record MCMC trace global shrinkage level (tau \\(\\tau\\)) posterior::draws_df format. psi_record MCMC trace precision matrix (psi \\(\\Psi\\)) list format. chain numer chains coefficients Posterior mean VHAR coefficients. psi_posterior Posterior mean precision matrix \\(\\Psi\\) covmat Posterior mean covariance matrix omega_record MCMC trace diagonal element \\(\\Psi\\) (omega) posterior::draws_df format. eta_record MCMC trace upper triangular element \\(\\Psi\\) (eta) posterior::draws_df format. param posterior::draws_df every variable: alpha, lambda, tau, omega, eta df Numer Coefficients: 3m + 1 3m p 3 (number terms. contains element usage functions.) m Dimension data obs Sample size used training = totobs - p totobs Total number observation call Matched call process Description model, e.g. \"VHAR_Horseshoe\" type include constant term (\"const\") (\"none\") algo Usual Gibbs sampling (\"gibbs\") fast sampling (\"fast\") spec Horseshoe specification defined set_horseshoe() iter Total iterations burn Burn-thin Thinning HARtrans VHAR linear transformation matrix y0 \\(Y_0\\) design \\(X_0\\) y Raw input","code":""},{"path":"/reference/bvhar_horseshoe.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting Bayesian VHAR of Horseshoe Prior — bvhar_horseshoe","text":"Kim, Y. G., Baek, C. (2023). Bayesian vector heterogeneous autoregressive modeling. Journal Statistical Computation Simulation. Kim, Y. G., Baek, C. (n.d.). Working paper.","code":""},{"path":"/reference/bvhar_minnesota.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting Bayesian VHAR of Minnesota Prior — bvhar_minnesota","title":"Fitting Bayesian VHAR of Minnesota Prior — bvhar_minnesota","text":"function fits BVHAR Minnesota prior.","code":""},{"path":"/reference/bvhar_minnesota.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting Bayesian VHAR of Minnesota Prior — bvhar_minnesota","text":"","code":"bvhar_minnesota(   y,   har = c(5, 22),   bayes_spec = set_bvhar(),   include_mean = TRUE )  # S3 method for bvharmn print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  knit_print.bvharmn(x, ...)"},{"path":"/reference/bvhar_minnesota.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting Bayesian VHAR of Minnesota Prior — bvhar_minnesota","text":"y Time series data columns indicate variables har Numeric vector weekly monthly order. default, c(5, 22). bayes_spec BVHAR model specification set_bvhar() (default) set_weight_bvhar(). include_mean Add constant term (Default: TRUE) (FALSE) x bvarmn object digits digit option print ... used","code":""},{"path":"/reference/bvhar_minnesota.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting Bayesian VHAR of Minnesota Prior — bvhar_minnesota","text":"bvhar_minnesota() returns object bvharmn  class. list following components: coefficients Posterior Mean matrix Matrix Normal distribution fitted.values Fitted values residuals Residuals mn_prec Posterior precision matrix Matrix Normal distribution iw_scale Posterior scale matrix posterior inverse-wishart distribution iw_shape Posterior shape inverse-Wishart distribution (\\(\\nu_0\\) - obs + 2). \\(\\nu_0\\): nrow(Dummy observation) - k df Numer Coefficients: 3m + 1 3m p 3, element exists run functions week Order weekly term month Order monthly term m Dimension time series obs Sample size used training = totobs - 22 totobs Total number observation call Matched call process Process string bayes_spec: \"BVHAR_MN_VAR\" (BVHAR-S) \"BVHAR_MN_VHAR\" (BVHAR-L) spec Model specification (bvharspec) type include constant term (\"const\") (\"none\") prior_mean Prior mean matrix Matrix Normal distribution: \\(M_0\\) prior_precision Prior precision matrix Matrix Normal distribution: \\(\\Omega_0^{-1}\\) prior_scale Prior scale matrix inverse-Wishart distribution: \\(\\Psi_0\\) prior_shape Prior shape inverse-Wishart distribution: \\(\\nu_0\\) HARtrans VHAR linear transformation matrix: \\(C_{HAR}\\) y0 \\(Y_0\\) design \\(X_0\\) y Raw input (matrix) also normaliw bvharmod class.","code":""},{"path":"/reference/bvhar_minnesota.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting Bayesian VHAR of Minnesota Prior — bvhar_minnesota","text":"Apply Minnesota prior Vector HAR: \\(\\Phi\\) (VHAR matrices) \\(\\Sigma_e\\) (residual covariance). $$\\Phi \\mid \\Sigma_e \\sim MN(M_0, \\Omega_0, \\Sigma_e)$$ $$\\Sigma_e \\sim IW(\\Psi_0, \\nu_0)$$ (MN: matrix normal, IW: inverse-wishart) two types Minnesota priors BVHAR: VAR-type Minnesota prior specified set_bvhar(), -called BVHAR-S model. VHAR-type Minnesota prior specified set_weight_bvhar(), -called BVHAR-L model. Two types Minnesota priors builds different dummy variables Y0. See var_design_formulation.","code":""},{"path":"/reference/bvhar_minnesota.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting Bayesian VHAR of Minnesota Prior — bvhar_minnesota","text":"Kim, Y. G., Baek, C. (2023). Bayesian vector heterogeneous autoregressive modeling. Journal Statistical Computation Simulation.","code":""},{"path":[]},{"path":"/reference/bvhar_minnesota.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting Bayesian VHAR of Minnesota Prior — bvhar_minnesota","text":"","code":"# Perform the function using etf_vix dataset fit <- bvhar_minnesota(y = etf_vix[,1:3]) class(fit) #> [1] \"bvharmn\"  \"normaliw\" \"bvharmod\"  # Extract coef, fitted values, and residuals coef(fit) #>                       GVZCLS       OVXCLS      VXFXICLS #> GVZCLS_day      0.7239591235  0.030141906  0.0334224930 #> OVXCLS_day      0.0021163564  0.718324835  0.0094789827 #> VXFXICLS_day    0.0294772930  0.035320583  0.7377164885 #> GVZCLS_week     0.1251766305 -0.002704810 -0.0024006869 #> OVXCLS_week    -0.0030211395  0.144436818 -0.0010429118 #> VXFXICLS_week   0.0028666589  0.009321449  0.1206325735 #> GVZCLS_month    0.0482747164  0.005220543  0.0008392191 #> OVXCLS_month   -0.0022599110  0.058987040  0.0007463012 #> VXFXICLS_month  0.0007727524  0.005768089  0.0298913283 #> const           1.1216988711  0.382866382  1.9279431742 head(residuals(fit)) #>            [,1]        [,2]       [,3] #> [1,]  0.2011463 -0.03569196  0.2373614 #> [2,] -0.5979335  0.15122959 -0.2782346 #> [3,] -0.3466428  0.50804209  3.3657096 #> [4,] -0.8431968  0.52911348 -0.2492212 #> [5,] -0.1001249  0.54094522  0.3884998 #> [6,] -0.1407253  1.48033862  0.8978522 head(fitted(fit)) #>        GVZCLS   OVXCLS VXFXICLS #> [1,] 20.48885 32.35569 29.22264 #> [2,] 20.62793 32.27877 28.94823 #> [3,] 20.07664 32.32196 28.36429 #> [4,] 19.91320 32.77089 30.71922 #> [5,] 19.34012 33.09905 29.80150 #> [6,] 19.42073 33.36966 29.61215"},{"path":"/reference/bvhar_ssvs.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting Bayesian VHAR of SSVS Prior — bvhar_ssvs","title":"Fitting Bayesian VHAR of SSVS Prior — bvhar_ssvs","text":"function fits BVAR(p) stochastic search variable selection (SSVS) prior.","code":""},{"path":"/reference/bvhar_ssvs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting Bayesian VHAR of SSVS Prior — bvhar_ssvs","text":"","code":"bvhar_ssvs(   y,   har = c(5, 22),   num_iter = 1000,   num_burn = floor(num_iter/2),   thinning = 1,   bayes_spec = choose_ssvs(y = y, ord = har, type = \"VHAR\", param = c(0.1, 10),     include_mean = include_mean, gamma_param = c(0.01, 0.01), mean_non = 0, sd_non = 0.1),   init_spec = init_ssvs(type = \"auto\"),   include_mean = TRUE,   minnesota = c(\"no\", \"short\", \"longrun\"),   verbose = FALSE )  # S3 method for bvharssvs print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  knit_print.bvharssvs(x, ...)"},{"path":"/reference/bvhar_ssvs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting Bayesian VHAR of SSVS Prior — bvhar_ssvs","text":"y Time series data columns indicate variables har Numeric vector weekly monthly order. default, c(5, 22). num_iter MCMC iteration number num_burn Number warm-(burn-). Half iteration default choice. thinning Thinning every thinning-th iteration bayes_spec SSVS model specification set_ssvs(). default, use default semiautomatic approach choose_ssvs(). init_spec SSVS initialization specification init_ssvs(). default, use OLS coefficient cholesky factor 1 dummies. include_mean Add constant term (Default: TRUE) (FALSE) minnesota Apply cross-variable shrinkage structure (Minnesota-way). Two type: \"short\" type \"longrun\" type. default, \"\". verbose Print progress bar console. default, FALSE. x bvharssvs object digits digit option print ... used","code":""},{"path":"/reference/bvhar_ssvs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting Bayesian VHAR of SSVS Prior — bvhar_ssvs","text":"bvhar_ssvs returns object named bvharssvs  class. list following components: phi_record MCMC trace vectorized coefficients (phi \\(\\phi\\)) posterior::draws_df format. eta_record MCMC trace upper triangular element cholesky factor (eta \\(\\eta\\)) posterior::draws_df format. psi_record MCMC trace diagonal element cholesky factor (psi \\(\\psi\\)) posterior::draws_df format. omega_record MCMC trace indicator variable \\(eta\\) (omega \\(\\omega\\)) posterior::draws_df format. gamma_record MCMC trace indicator variable \\(alpha\\) (gamma \\(\\gamma\\)) posterior::draws_df format. chol_record MCMC trace cholesky factor matrix \\(\\Psi\\) list format. ols_coef OLS estimates VAR coefficients. ols_cholesky OLS estimates cholesky factor coefficients Posterior mean VAR coefficients. omega_posterior Posterior mean omega pip Posterior inclusion probability param posterior::draws_df every variable: alpha, eta, psi, omega, gamma chol_posterior Posterior mean cholesky factor matrix covmat Posterior mean covariance matrix df Numer Coefficients: 3m + 1 3m p 3 (number terms. contains element usage functions.) week Order weekly term month Order monthly term m Dimension data obs Sample size used training = totobs - p totobs Total number observation call Matched call process Description model, e.g. \"VHAR_SSVS\" type include constant term (\"const\") (\"none\") spec SSVS specification defined set_ssvs() init Initial specification defined init_ssvs() iter Total iterations burn Burn-thin Thinning chain numer chains HARtrans VHAR linear transformation matrix y0 \\(Y_0\\) design \\(X_0\\) y Raw input","code":""},{"path":"/reference/bvhar_ssvs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting Bayesian VHAR of SSVS Prior — bvhar_ssvs","text":"SSVS prior gives prior parameters \\(\\alpha = vec()\\) (VAR coefficient) \\(\\Sigma_e^{-1} = \\Psi \\Psi^T\\) (residual covariance). $$\\alpha_j \\mid \\gamma_j \\sim (1 - \\gamma_j) N(0, \\kappa_{0j}^2) + \\gamma_j N(0, \\kappa_{1j}^2)$$ $$\\gamma_j \\sim Bernoulli(q_j)$$ upper triangular matrix \\(\\Psi\\), $$\\psi_{jj}^2 \\sim Gamma(shape = a_j, rate = b_j)$$ $$\\psi_{ij} \\mid w_{ij} \\sim (1 - w_{ij}) N(0, \\kappa_{0,ij}^2) + w_{ij} N(0, \\kappa_{1,ij}^2)$$ $$w_{ij} \\sim Bernoulli(q_{ij})$$ Gibbs sampler used estimation. See ssvs_bvar_algo works.","code":""},{"path":"/reference/bvhar_ssvs.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting Bayesian VHAR of SSVS Prior — bvhar_ssvs","text":"Kim, Y. G., Baek, C. (2023). Bayesian vector heterogeneous autoregressive modeling. Journal Statistical Computation Simulation. Kim, Y. G., Baek, C. (n.d.). Working paper.","code":""},{"path":[]},{"path":"/reference/bvhar_sv.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting Bayesian VHAR-SV — bvhar_sv","title":"Fitting Bayesian VHAR-SV — bvhar_sv","text":"function fits VHAR-SV. can Minnesota, SSVS, Horseshoe prior.","code":""},{"path":"/reference/bvhar_sv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting Bayesian VHAR-SV — bvhar_sv","text":"","code":"bvhar_sv(   y,   har = c(5, 22),   num_iter = 1000,   num_burn = floor(num_iter/2),   thinning = 1,   bayes_spec = set_bvhar(),   include_mean = TRUE,   minnesota = c(\"no\", \"short\", \"longrun\"),   verbose = FALSE,   num_thread = 1 )  # S3 method for bvharsv print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  knit_print.bvharsv(x, ...)"},{"path":"/reference/bvhar_sv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting Bayesian VHAR-SV — bvhar_sv","text":"y Time series data columns indicate variables har Numeric vector weekly monthly order. default, c(5, 22). num_iter MCMC iteration number num_burn Number burn-(warm-). Half iteration default choice. thinning Thinning every thinning-th iteration bayes_spec BVHAR model specification set_bvhar() (default) set_weight_bvhar(). include_mean Add constant term (Default: TRUE) (FALSE) minnesota Apply cross-variable shrinkage structure (Minnesota-way). Two type: \"short\" type \"longrun\" type. default, \"\". verbose Print progress bar console. default, FALSE. num_thread Number threads x bvarsv object digits digit option print ... used","code":""},{"path":"/reference/bvhar_sv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting Bayesian VHAR-SV — bvhar_sv","text":"bvhar_sv() returns object named bvharsv  class. list following components: phi_record MCMC trace vectorized coefficients (phi \\(\\phi\\)) posterior::draws_df format. h_record MCMC trace log-volatilities. a_record MCMC trace contemporaneous coefficients. h0_record MCMC trace initial log-volatilities. sigh_record MCMC trace log-volatilities variance. coefficients Posterior mean coefficients. chol_posterior Posterior mean contemporaneous effects. pip Posterior inclusion probabilities. param Every set MCMC trace. group Indicators group. df Numer Coefficients: 3m + 1 3m p 3 (number terms. contains element usage functions.) week Order weekly term month Order monthly term m Dimension data obs Sample size used training = totobs - p totobs Total number observation call Matched call process Description model, e.g. \"VHAR_SSVS_SV\", \"VHAR_Horseshoe_SV\", \"VHAR_minnesota-part_SV\"} \\item{type}{include constant term (\"const\") (\"none\"`) spec SSVS specification defined set_ssvs() init Initial specification defined init_ssvs() iter Total iterations burn Burn-thin Thinning chain numer chains HARtrans VHAR linear transformation matrix y0 \\(Y_0\\) design \\(X_0\\) y Raw input Different members added according priors. SSVS: gamma_record MCMC trace dummy variable. Horseshoe: lambda_record MCMC trace local shrinkage level. tau_record MCMC trace global shrinkage level. kappa_record MCMC trace shrinkage factor.","code":""},{"path":"/reference/bvhar_sv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting Bayesian VHAR-SV — bvhar_sv","text":"Cholesky stochastic volatility modeling VHAR based $$\\Sigma_t = L^T D_t^{-1} L$$","code":""},{"path":"/reference/bvhar_sv.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting Bayesian VHAR-SV — bvhar_sv","text":"Kim, Y. G., Baek, C. (2023+). Bayesian vector heterogeneous autoregressive modeling. Journal Statistical Computation Simulation. Kim, Y. G., Baek, C. (n.d.). Working paper.","code":""},{"path":"/reference/choose_bayes.html","id":null,"dir":"Reference","previous_headings":"","what":"Finding the Set of Hyperparameters of Bayesian Model — choose_bayes","title":"Finding the Set of Hyperparameters of Bayesian Model — choose_bayes","text":"function chooses set hyperparameters Bayesian model using stats::optim() function.","code":""},{"path":"/reference/choose_bayes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Finding the Set of Hyperparameters of Bayesian Model — choose_bayes","text":"","code":"choose_bayes(   bayes_bound = bound_bvhar(),   ...,   eps = 1e-04,   y,   order = c(5, 22),   include_mean = TRUE,   parallel = list() )"},{"path":"/reference/choose_bayes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Finding the Set of Hyperparameters of Bayesian Model — choose_bayes","text":"bayes_bound Empirical Bayes optimization bound specification defined bound_bvhar(). ... Additional arguments stats::optim(). eps Hyperparameter eps fixed. default, 1e-04. y Time series data order Order BVAR BVHAR. p bvar_minnesota() har bvhar_minnesota(). default, c(5, 22) har. include_mean Add constant term (Default: TRUE) (FALSE) parallel List argument optimParallel::optimParallel(). default, empty, function execute parallel computation.","code":""},{"path":"/reference/choose_bayes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Finding the Set of Hyperparameters of Bayesian Model — choose_bayes","text":"bvharemp  class list ... Many components stats::optim() optimParallel::optimParallel() spec Corresponding bvharspec fit Chosen Bayesian model ml Marginal likelihood final model","code":""},{"path":"/reference/choose_bayes.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Finding the Set of Hyperparameters of Bayesian Model — choose_bayes","text":"Giannone, D., Lenza, M., & Primiceri, G. E. (2015). Prior Selection Vector Autoregressions. Review Economics Statistics, 97(2). Kim, Y. G., Baek, C. (n.d.). Bayesian vector heterogeneous autoregressive modeling. submitted.","code":""},{"path":[]},{"path":"/reference/choose_bvar.html","id":null,"dir":"Reference","previous_headings":"","what":"Finding the Set of Hyperparameters of Individual Bayesian Model — choose_bvar","title":"Finding the Set of Hyperparameters of Individual Bayesian Model — choose_bvar","text":"Instead functions, can use choose_bayes().","code":""},{"path":"/reference/choose_bvar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Finding the Set of Hyperparameters of Individual Bayesian Model — choose_bvar","text":"","code":"choose_bvar(   bayes_spec = set_bvar(),   lower = 0.01,   upper = 10,   ...,   eps = 1e-04,   y,   p,   include_mean = TRUE,   parallel = list() )  choose_bvhar(   bayes_spec = set_bvhar(),   lower = 0.01,   upper = 10,   ...,   eps = 1e-04,   y,   har = c(5, 22),   include_mean = TRUE,   parallel = list() )  # S3 method for bvharemp print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  knit_print.bvharemp(x, ...)"},{"path":"/reference/choose_bvar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Finding the Set of Hyperparameters of Individual Bayesian Model — choose_bvar","text":"bayes_spec Initial Bayes model specification. lower Lower bound. default, .01. upper Upper bound. default, 10. ... used eps Hyperparameter eps fixed. default, 1e-04. y Time series data p BVAR lag include_mean Add constant term (Default: TRUE) (FALSE) parallel List argument optimParallel::optimParallel(). default, empty, function execute parallel computation. har Numeric vector weekly monthly order. default, c(5, 22). x bvharemp object digits digit option print","code":""},{"path":"/reference/choose_bvar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Finding the Set of Hyperparameters of Individual Bayesian Model — choose_bvar","text":"bvharemp  class list stats::optim() optimParallel::optimParallel() chosen bvharspec set Bayesian model fit result chosen specification ... Many components stats::optim() optimParallel::optimParallel() spec Corresponding bvharspec fit Chosen Bayesian model ml Marginal likelihood final model","code":""},{"path":"/reference/choose_bvar.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Finding the Set of Hyperparameters of Individual Bayesian Model — choose_bvar","text":"Empirical Bayes method maximizes marginal likelihood selects set hyperparameters. functions implement \"L-BFGS-B\" method stats::optim() find maximum marginal likelihood. want set lower upper option carefully, deal like stats::optim() order set_bvar(), set_bvhar(), set_weight_bvhar()'s argument (except eps). words, just arrange vector.","code":""},{"path":"/reference/choose_bvar.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Finding the Set of Hyperparameters of Individual Bayesian Model — choose_bvar","text":"Byrd, R. H., Lu, P., Nocedal, J., & Zhu, C. (1995). limited memory algorithm bound constrained optimization. SIAM Journal scientific computing, 16(5), 1190-1208. Gelman, ., Carlin, J. B., Stern, H. S., & Rubin, D. B. (2013). Bayesian data analysis. Chapman Hall/CRC. Giannone, D., Lenza, M., & Primiceri, G. E. (2015). Prior Selection Vector Autoregressions. Review Economics Statistics, 97(2). Kim, Y. G., Baek, C. (2023+). Bayesian vector heterogeneous autoregressive modeling. Journal Statistical Computation Simulation.","code":""},{"path":"/reference/choose_ssvs.html","id":null,"dir":"Reference","previous_headings":"","what":"Choose the Hyperparameters Set of SSVS-VAR using a Default Semiautomatic Approach — choose_ssvs","title":"Choose the Hyperparameters Set of SSVS-VAR using a Default Semiautomatic Approach — choose_ssvs","text":"function chooses \\((\\tau_{0i}, \\tau_{1i})\\) \\((\\kappa_{0i}, \\kappa_{1i})\\) using default semiautomatic approach.","code":""},{"path":"/reference/choose_ssvs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Choose the Hyperparameters Set of SSVS-VAR using a Default Semiautomatic Approach — choose_ssvs","text":"","code":"choose_ssvs(   y,   ord,   type = c(\"VAR\", \"VHAR\"),   param = c(0.1, 10),   include_mean = TRUE,   gamma_param = c(0.01, 0.01),   mean_non = 0,   sd_non = 0.1 )"},{"path":"/reference/choose_ssvs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Choose the Hyperparameters Set of SSVS-VAR using a Default Semiautomatic Approach — choose_ssvs","text":"y Time series data columns indicate variables. ord Order VAR VHAR. type Model type (Default: \"VAR\" \"VHAR\"). param Preselected constants \\(c_0 << c_1\\). default, 0.1 10 (See Details). include_mean Add constant term (Default: TRUE) (FALSE). gamma_param Parameters (shape, rate) Gamma distribution. output. mean_non Prior mean unrestricted coefficients. output. sd_non Standard deviance unrestricted coefficients. output.","code":""},{"path":"/reference/choose_ssvs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Choose the Hyperparameters Set of SSVS-VAR using a Default Semiautomatic Approach — choose_ssvs","text":"ssvsinput object","code":""},{"path":"/reference/choose_ssvs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Choose the Hyperparameters Set of SSVS-VAR using a Default Semiautomatic Approach — choose_ssvs","text":"Instead using subjective values \\((\\tau_{0i}, \\tau_{1i})\\), can use $$\\tau_{ki} = c_k \\hat{VAR(OLS)}$$ must \\(c_0 << c_1\\). case \\((\\omega_{0ij}, \\omega_{1ij})\\), $$\\omega_{kij} = c_k = \\hat{VAR(OLS)}$$ similarly.","code":""},{"path":"/reference/choose_ssvs.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Choose the Hyperparameters Set of SSVS-VAR using a Default Semiautomatic Approach — choose_ssvs","text":"George, E. ., & McCulloch, R. E. (1993). Variable Selection via Gibbs Sampling. Journal American Statistical Association, 88(423), 881–889. George, E. ., Sun, D., & Ni, S. (2008). Bayesian stochastic search VAR model restrictions. Journal Econometrics, 142(1), 553–580. Koop, G., & Korobilis, D. (2009). Bayesian Multivariate Time Series Methods Empirical Macroeconomics. Foundations Trends® Econometrics, 3(4), 267–358.","code":""},{"path":"/reference/choose_var.html","id":null,"dir":"Reference","previous_headings":"","what":"Choose the Best VAR based on Information Criteria — choose_var","title":"Choose the Best VAR based on Information Criteria — choose_var","text":"function computes AIC, FPE, BIC, HQ p = lag_max VAR model.","code":""},{"path":"/reference/choose_var.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Choose the Best VAR based on Information Criteria — choose_var","text":"","code":"choose_var(y, lag_max = 5, include_mean = TRUE, parallel = FALSE)"},{"path":"/reference/choose_var.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Choose the Best VAR based on Information Criteria — choose_var","text":"y Time series data columns indicate variables lag_max Maximum Var lag explore (default = 5) include_mean Add constant term (Default: TRUE) (FALSE) parallel Parallel computation using foreach::foreach()? default, FALSE.","code":""},{"path":"/reference/choose_var.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Choose the Best VAR based on Information Criteria — choose_var","text":"Minimum order information criteria values","code":""},{"path":"/reference/coef.varlse.html","id":null,"dir":"Reference","previous_headings":"","what":"Coefficient Matrix of Multivariate Time Series Models — coef.varlse","title":"Coefficient Matrix of Multivariate Time Series Models — coef.varlse","text":"defining stats::coef() model, function returns coefficient matrix estimates.","code":""},{"path":"/reference/coef.varlse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coefficient Matrix of Multivariate Time Series Models — coef.varlse","text":"","code":"# S3 method for varlse coef(object, ...)  # S3 method for vharlse coef(object, ...)  # S3 method for bvarmn coef(object, ...)  # S3 method for bvarflat coef(object, ...)  # S3 method for bvharmn coef(object, ...)  # S3 method for bvharsp coef(object, ...)  # S3 method for summary.bvharsp coef(object, ...)"},{"path":"/reference/coef.varlse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coefficient Matrix of Multivariate Time Series Models — coef.varlse","text":"object Model object ... used","code":""},{"path":"/reference/coef.varlse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coefficient Matrix of Multivariate Time Series Models — coef.varlse","text":"matrix object appropriate dimension.","code":""},{"path":"/reference/compute_dic.html","id":null,"dir":"Reference","previous_headings":"","what":"Deviance Information Criterion of Multivariate Time Series Model — compute_dic","title":"Deviance Information Criterion of Multivariate Time Series Model — compute_dic","text":"Compute DIC BVAR BVHAR.","code":""},{"path":"/reference/compute_dic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Deviance Information Criterion of Multivariate Time Series Model — compute_dic","text":"","code":"compute_dic(object, ...)  # S3 method for bvarmn compute_dic(object, n_iter = 100L, ...)"},{"path":"/reference/compute_dic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Deviance Information Criterion of Multivariate Time Series Model — compute_dic","text":"object Model fit ... used n_iter Number sample","code":""},{"path":"/reference/compute_dic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Deviance Information Criterion of Multivariate Time Series Model — compute_dic","text":"DIC value.","code":""},{"path":"/reference/compute_dic.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Deviance Information Criterion of Multivariate Time Series Model — compute_dic","text":"Deviance information criteria (DIC) $$- 2 \\log p(y \\mid \\hat\\theta_{bayes}) + 2 p_{DIC}$$ \\(p_{DIC}\\) effective number parameters defined $$p_{DIC} = 2 ( \\log p(y \\mid \\hat\\theta_{bayes}) - E_{post} \\log p(y \\mid \\theta) )$$ Random sampling posterior distribution gives computation, \\(\\theta_i \\sim \\theta \\mid y, = 1, \\ldots, M\\) $$p_{DIC}^{computed} = 2 ( \\log p(y \\mid \\hat\\theta_{bayes}) - \\frac{1}{M} \\sum_i \\log p(y \\mid \\theta_i) )$$","code":""},{"path":"/reference/compute_dic.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Deviance Information Criterion of Multivariate Time Series Model — compute_dic","text":"Gelman, ., Carlin, J. B., Stern, H. S., & Rubin, D. B. (2013). Bayesian data analysis. Chapman Hall/CRC. Spiegelhalter, D.J., Best, N.G., Carlin, B.P. Van Der Linde, . (2002). Bayesian measures model complexity fit. Journal Royal Statistical Society: Series B (Statistical Methodology), 64: 583-639.","code":""},{"path":"/reference/compute_logml.html","id":null,"dir":"Reference","previous_headings":"","what":"Extracting Log of Marginal Likelihood — compute_logml","title":"Extracting Log of Marginal Likelihood — compute_logml","text":"Compute log marginal likelihood Bayesian Fit","code":""},{"path":"/reference/compute_logml.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extracting Log of Marginal Likelihood — compute_logml","text":"","code":"compute_logml(object, ...)  # S3 method for bvarmn compute_logml(object, ...)  # S3 method for bvharmn compute_logml(object, ...)"},{"path":"/reference/compute_logml.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extracting Log of Marginal Likelihood — compute_logml","text":"object Model fit ... used","code":""},{"path":"/reference/compute_logml.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extracting Log of Marginal Likelihood — compute_logml","text":"log likelihood Minnesota prior model.","code":""},{"path":"/reference/compute_logml.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extracting Log of Marginal Likelihood — compute_logml","text":"Closed form Marginal Likelihood BVAR can derived $$p(Y_0) = \\pi^{-ms / 2} \\frac{\\Gamma_m ((\\alpha_0 + s) / 2)}{\\Gamma_m (\\alpha_0 / 2)} \\det(\\Omega_0)^{-m / 2} \\det(S_0)^{\\alpha_0 / 2} \\det(\\hat{V})^{- m / 2} \\det(\\hat{\\Sigma}_e)^{-(\\alpha_0 + s) / 2}$$ Closed form Marginal Likelihood BVHAR can derived $$p(Y_0) = \\pi^{-ms_0 / 2} \\frac{\\Gamma_m ((d_0 + s) / 2)}{\\Gamma_m (d_0 / 2)} \\det(P_0)^{-m / 2} \\det(U_0)^{d_0 / 2} \\det(\\hat{V}_{HAR})^{- m / 2} \\det(\\hat{\\Sigma}_e)^{-(d_0 + s) / 2}$$","code":""},{"path":"/reference/compute_logml.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extracting Log of Marginal Likelihood — compute_logml","text":"Giannone, D., Lenza, M., & Primiceri, G. E. (2015). Prior Selection Vector Autoregressions. Review Economics Statistics, 97(2).","code":""},{"path":"/reference/conf_fdr.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Sparsity Estimation Based on FDR — conf_fdr","title":"Evaluate the Sparsity Estimation Based on FDR — conf_fdr","text":"function computes false discovery rate (FDR) sparse element true coefficients given threshold.","code":""},{"path":"/reference/conf_fdr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Sparsity Estimation Based on FDR — conf_fdr","text":"","code":"conf_fdr(x, y, ...)  # S3 method for summary.bvharsp conf_fdr(x, y, truth_thr = 0, ...)"},{"path":"/reference/conf_fdr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Sparsity Estimation Based on FDR — conf_fdr","text":"x summary.bvharsp object. y True inclusion variable. ... used truth_thr Threshold value using non-sparse true coefficient matrix. default, 0 sparse matrix.","code":""},{"path":"/reference/conf_fdr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Sparsity Estimation Based on FDR — conf_fdr","text":"FDR value confusion table","code":""},{"path":"/reference/conf_fdr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Sparsity Estimation Based on FDR — conf_fdr","text":"using function, true coefficient matrix \\(\\Phi\\) sparse. False discovery rate (FDR) computed $$FDR = \\frac{FP}{TP + FP}$$ TP true positive, FP false positive.","code":""},{"path":"/reference/conf_fdr.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Sparsity Estimation Based on FDR — conf_fdr","text":"Bai, R., & Ghosh, M. (2018). High-dimensional multivariate posterior consistency global–local shrinkage priors. Journal Multivariate Analysis, 167, 157–170.","code":""},{"path":[]},{"path":"/reference/conf_fnr.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Sparsity Estimation Based on FNR — conf_fnr","title":"Evaluate the Sparsity Estimation Based on FNR — conf_fnr","text":"function computes false negative rate (FNR) sparse element true coefficients given threshold.","code":""},{"path":"/reference/conf_fnr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Sparsity Estimation Based on FNR — conf_fnr","text":"","code":"conf_fnr(x, y, ...)  # S3 method for summary.bvharsp conf_fnr(x, y, truth_thr = 0, ...)"},{"path":"/reference/conf_fnr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Sparsity Estimation Based on FNR — conf_fnr","text":"x summary.bvharsp object. y True inclusion variable. ... used truth_thr Threshold value using non-sparse true coefficient matrix. default, 0 sparse matrix.","code":""},{"path":"/reference/conf_fnr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Sparsity Estimation Based on FNR — conf_fnr","text":"FNR value confusion table","code":""},{"path":"/reference/conf_fnr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Sparsity Estimation Based on FNR — conf_fnr","text":"False negative rate (FNR) computed $$FNR = \\frac{FN}{TP + FN}$$ TP true positive, FN false negative.","code":""},{"path":"/reference/conf_fnr.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Sparsity Estimation Based on FNR — conf_fnr","text":"Bai, R., & Ghosh, M. (2018). High-dimensional multivariate posterior consistency global–local shrinkage priors. Journal Multivariate Analysis, 167, 157–170.","code":""},{"path":[]},{"path":"/reference/conf_fscore.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Sparsity Estimation Based on F1 Score — conf_fscore","title":"Evaluate the Sparsity Estimation Based on F1 Score — conf_fscore","text":"function computes F1 score sparse element true coefficients given threshold.","code":""},{"path":"/reference/conf_fscore.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Sparsity Estimation Based on F1 Score — conf_fscore","text":"","code":"conf_fscore(x, y, ...)  # S3 method for summary.bvharsp conf_fscore(x, y, truth_thr = 0, ...)"},{"path":"/reference/conf_fscore.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Sparsity Estimation Based on F1 Score — conf_fscore","text":"x summary.bvharsp object. y True inclusion variable. ... used truth_thr Threshold value using non-sparse true coefficient matrix. default, 0 sparse matrix.","code":""},{"path":"/reference/conf_fscore.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Sparsity Estimation Based on F1 Score — conf_fscore","text":"F1 score confusion table","code":""},{"path":"/reference/conf_fscore.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Sparsity Estimation Based on F1 Score — conf_fscore","text":"F1 score computed $$F_1 = \\frac{2 precision \\times recall}{precision + recall}$$","code":""},{"path":[]},{"path":"/reference/conf_prec.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Sparsity Estimation Based on Precision — conf_prec","title":"Evaluate the Sparsity Estimation Based on Precision — conf_prec","text":"function computes precision sparse element true coefficients given threshold.","code":""},{"path":"/reference/conf_prec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Sparsity Estimation Based on Precision — conf_prec","text":"","code":"conf_prec(x, y, ...)  # S3 method for summary.bvharsp conf_prec(x, y, truth_thr = 0, ...)"},{"path":"/reference/conf_prec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Sparsity Estimation Based on Precision — conf_prec","text":"x summary.bvharsp object. y True inclusion variable. ... used truth_thr Threshold value using non-sparse true coefficient matrix. default, 0 sparse matrix.","code":""},{"path":"/reference/conf_prec.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Sparsity Estimation Based on Precision — conf_prec","text":"Precision value confusion table","code":""},{"path":"/reference/conf_prec.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Sparsity Estimation Based on Precision — conf_prec","text":"element estimate \\(\\hat\\Phi\\) smaller threshold, treated zero. precision computed $$precision = \\frac{TP}{TP + FP}$$ TP true positive, FP false positive.","code":""},{"path":"/reference/conf_prec.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Sparsity Estimation Based on Precision — conf_prec","text":"Bai, R., & Ghosh, M. (2018). High-dimensional multivariate posterior consistency global–local shrinkage priors. Journal Multivariate Analysis, 167, 157–170.","code":""},{"path":[]},{"path":"/reference/conf_recall.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Sparsity Estimation Based on Recall — conf_recall","title":"Evaluate the Sparsity Estimation Based on Recall — conf_recall","text":"function computes recall sparse element true coefficients given threshold.","code":""},{"path":"/reference/conf_recall.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Sparsity Estimation Based on Recall — conf_recall","text":"","code":"conf_recall(x, y, ...)  # S3 method for summary.bvharsp conf_recall(x, y, truth_thr = 0L, ...)"},{"path":"/reference/conf_recall.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Sparsity Estimation Based on Recall — conf_recall","text":"x summary.bvharsp object. y True inclusion variable. ... used truth_thr Threshold value using non-sparse true coefficient matrix. default, 0 sparse matrix.","code":""},{"path":"/reference/conf_recall.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Sparsity Estimation Based on Recall — conf_recall","text":"Recall value confusion table","code":""},{"path":"/reference/conf_recall.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Sparsity Estimation Based on Recall — conf_recall","text":"Precision computed $$recall = \\frac{TP}{TP + FN}$$ TP true positive, FN false negative.","code":""},{"path":"/reference/conf_recall.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Sparsity Estimation Based on Recall — conf_recall","text":"Bai, R., & Ghosh, M. (2018). High-dimensional multivariate posterior consistency global–local shrinkage priors. Journal Multivariate Analysis, 167, 157–170.","code":""},{"path":[]},{"path":"/reference/confusion.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Sparsity Estimation Based on Confusion Matrix — confusion","title":"Evaluate the Sparsity Estimation Based on Confusion Matrix — confusion","text":"function computes FDR (false discovery rate) FNR (false negative rate) sparse element true coefficients given threshold.","code":""},{"path":"/reference/confusion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Sparsity Estimation Based on Confusion Matrix — confusion","text":"","code":"confusion(x, y, ...)  # S3 method for summary.bvharsp confusion(x, y, truth_thr = 0, ...)"},{"path":"/reference/confusion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Sparsity Estimation Based on Confusion Matrix — confusion","text":"x summary.bvharsp object. y True inclusion variable. ... used truth_thr Threshold value using non-sparse true coefficient matrix. default, 0 sparse matrix.","code":""},{"path":"/reference/confusion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Sparsity Estimation Based on Confusion Matrix — confusion","text":"Confusion table following.","code":""},{"path":"/reference/confusion.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Sparsity Estimation Based on Confusion Matrix — confusion","text":"using function, true coefficient matrix \\(\\Phi\\) sparse. confusion matrix, positive (0) means sparsity. FP false positive, TP true positive. FN false negative, FN false negative.","code":""},{"path":"/reference/confusion.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Sparsity Estimation Based on Confusion Matrix — confusion","text":"Bai, R., & Ghosh, M. (2018). High-dimensional multivariate posterior consistency global–local shrinkage priors. Journal Multivariate Analysis, 167, 157–170.","code":""},{"path":"/reference/divide_ts.html","id":null,"dir":"Reference","previous_headings":"","what":"Split a Time Series Dataset into Train-Test Set — divide_ts","title":"Split a Time Series Dataset into Train-Test Set — divide_ts","text":"Split given time series dataset train test set evaluation.","code":""},{"path":"/reference/divide_ts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split a Time Series Dataset into Train-Test Set — divide_ts","text":"","code":"divide_ts(y, n_ahead)"},{"path":"/reference/divide_ts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split a Time Series Dataset into Train-Test Set — divide_ts","text":"y Time series data columns indicate variables n_ahead step evaluate","code":""},{"path":"/reference/divide_ts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split a Time Series Dataset into Train-Test Set — divide_ts","text":"List two datasets, train test.","code":""},{"path":"/reference/etf_vix.html","id":null,"dir":"Reference","previous_headings":"","what":"CBOE ETF Volatility Index Dataset — etf_vix","title":"CBOE ETF Volatility Index Dataset — etf_vix","text":"Chicago Board Options Exchage (CBOE) Exchange Traded Funds (ETFs) volatility index FRED.","code":""},{"path":"/reference/etf_vix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CBOE ETF Volatility Index Dataset — etf_vix","text":"","code":"etf_vix"},{"path":"/reference/etf_vix.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"CBOE ETF Volatility Index Dataset — etf_vix","text":"data frame 1006 row 9 columns: 2012-01-09 2015-06-27, 33 missing observations interpolated stats::approx() linear. GVZCLS Gold ETF volatility index VXFXICLS China ETF volatility index OVXCLS Crude Oil ETF volatility index VXEEMCLS Emerging Markets ETF volatility index EVZCLS EuroCurrency ETF volatility index VXSLVCLS Silver ETF volatility index VXGDXCLS Gold Miners ETF volatility index VXXLECLS Energy Sector ETF volatility index VXEWZCLS Brazil ETF volatility index","code":""},{"path":"/reference/etf_vix.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"CBOE ETF Volatility Index Dataset — etf_vix","text":"Source: https://www.cboe.com Release: https://www.cboe.com/us/options/market_statistics/daily/","code":""},{"path":"/reference/etf_vix.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"CBOE ETF Volatility Index Dataset — etf_vix","text":"Copyright, 2016, Chicago Board Options Exchange, Inc. Note , data frame, dates column removed. dataset interpolated 36 missing observations (nontrading dates) using imputeTS::na_interpolation().","code":""},{"path":"/reference/etf_vix.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"CBOE ETF Volatility Index Dataset — etf_vix","text":"Chicago Board Options Exchange, CBOE Gold ETF Volatility Index (GVZCLS), retrieved FRED, Federal Reserve Bank St. Louis; https://fred.stlouisfed.org/series/GVZCLS, July 31, 2021. Chicago Board Options Exchange, CBOE China ETF Volatility Index (VXFXICLS), retrieved FRED, Federal Reserve Bank St. Louis; https://fred.stlouisfed.org/series/VXFXICLS, August 1, 2021. Chicago Board Options Exchange, CBOE Crude Oil ETF Volatility Index (OVXCLS), retrieved FRED, Federal Reserve Bank St. Louis; https://fred.stlouisfed.org/series/OVXCLS, August 1, 2021. Chicago Board Options Exchange, CBOE Emerging Markets ETF Volatility Index (VXEEMCLS), retrieved FRED, Federal Reserve Bank St. Louis; https://fred.stlouisfed.org/series/VXEEMCLS, August 1, 2021. Chicago Board Options Exchange, CBOE EuroCurrency ETF Volatility Index (EVZCLS), retrieved FRED, Federal Reserve Bank St. Louis; https://fred.stlouisfed.org/series/EVZCLS, August 2, 2021. Chicago Board Options Exchange, CBOE Silver ETF Volatility Index (VXSLVCLS), retrieved FRED, Federal Reserve Bank St. Louis; https://fred.stlouisfed.org/series/VXSLVCLS, August 1, 2021. Chicago Board Options Exchange, CBOE Gold Miners ETF Volatility Index (VXGDXCLS), retrieved FRED, Federal Reserve Bank St. Louis; https://fred.stlouisfed.org/series/VXGDXCLS, August 1, 2021. Chicago Board Options Exchange, CBOE Energy Sector ETF Volatility Index (VXXLECLS), retrieved FRED, Federal Reserve Bank St. Louis; https://fred.stlouisfed.org/series/VXXLECLS, August 1, 2021. Chicago Board Options Exchange, CBOE Brazil ETF Volatility Index (VXEWZCLS), retrieved FRED, Federal Reserve Bank St. Louis; https://fred.stlouisfed.org/series/VXEWZCLS, August 2, 2021.","code":""},{"path":"/reference/financial_history_appendix.html","id":null,"dir":"Reference","previous_headings":"","what":"Time points and Financial Events — financial_history_appendix","title":"Time points and Financial Events — financial_history_appendix","text":"page describes important financial events 20th century. might give hint cutting data provides datasets limited period.","code":""},{"path":"/reference/financial_history_appendix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Time points and Financial Events — financial_history_appendix","text":"","code":"trading_day"},{"path":"/reference/financial_history_appendix.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Time points and Financial Events — financial_history_appendix","text":"vector trading_day saves dates etf_vix oxfordman.","code":""},{"path":"/reference/financial_history_appendix.html","id":"outline","dir":"Reference","previous_headings":"","what":"Outline","title":"Time points and Financial Events — financial_history_appendix","text":"2000: Dot-com bubble 2001: September 11 terror Enron scandal 2003: Iraq war (2011) 2007 2008: Financial crisis (US) 2007: Subprime morgage crisis 2008: Bankrupcy Lehman Brothers 2010 2016: European sovereign dept crisis 2010: Greek debt crisis 2011: Italian default 2015: Greek default 2016: Brexit 2018: US-China trade war 2019: Brexit 2020: COVID-19","code":""},{"path":"/reference/financial_history_appendix.html","id":"about-datasets-in-this-package","dir":"Reference","previous_headings":"","what":"About Datasets in this package","title":"Time points and Financial Events — financial_history_appendix","text":"etf_vix oxfordman range 2012-01-09 2015-06-27 (weekdays). year corresponds Italian default Grexit. wonder exact vector date, see trading_day vector.","code":""},{"path":"/reference/financial_history_appendix.html","id":"notice","dir":"Reference","previous_headings":"","what":"Notice","title":"Time points and Financial Events — financial_history_appendix","text":"want time period, see codes Github repo dataset. etf_vix: ygeunkim/bvhar/data-raw/etf_vix.R oxfordman: ygeunkim/bvhar/data-raw/oxfordman_long.R can download want changing lines.","code":""},{"path":"/reference/fitted.varlse.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitted Matrix from Multivariate Time Series Models — fitted.varlse","title":"Fitted Matrix from Multivariate Time Series Models — fitted.varlse","text":"defining stats::fitted() model, function returns fitted matrix.","code":""},{"path":"/reference/fitted.varlse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitted Matrix from Multivariate Time Series Models — fitted.varlse","text":"","code":"# S3 method for varlse fitted(object, ...)  # S3 method for vharlse fitted(object, ...)  # S3 method for bvarmn fitted(object, ...)  # S3 method for bvarflat fitted(object, ...)  # S3 method for bvharmn fitted(object, ...)"},{"path":"/reference/fitted.varlse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitted Matrix from Multivariate Time Series Models — fitted.varlse","text":"object Model object ... used","code":""},{"path":"/reference/fitted.varlse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitted Matrix from Multivariate Time Series Models — fitted.varlse","text":"matrix object.","code":""},{"path":"/reference/forecast_expand.html","id":null,"dir":"Reference","previous_headings":"","what":"Out-of-sample Forecasting based on Expanding Window — forecast_expand","title":"Out-of-sample Forecasting based on Expanding Window — forecast_expand","text":"function conducts expanding window forecasting.","code":""},{"path":"/reference/forecast_expand.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Out-of-sample Forecasting based on Expanding Window — forecast_expand","text":"","code":"forecast_expand(object, n_ahead, y_test)"},{"path":"/reference/forecast_expand.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Out-of-sample Forecasting based on Expanding Window — forecast_expand","text":"object Model object n_ahead Step forecast rolling window scheme y_test Test data compared. Use divide_ts() separate evaluation dataset.","code":""},{"path":"/reference/forecast_expand.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Out-of-sample Forecasting based on Expanding Window — forecast_expand","text":"predbvhar_expand  class","code":""},{"path":"/reference/forecast_expand.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Out-of-sample Forecasting based on Expanding Window — forecast_expand","text":"Expanding windows forecasting fixes starting period. moves window ahead forecast h-ahead y_test set.","code":""},{"path":"/reference/forecast_expand.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Out-of-sample Forecasting based on Expanding Window — forecast_expand","text":"Hyndman, R. J., & Athanasopoulos, G. (2021). Forecasting: Principles practice (3rd ed.). OTEXTS. https://otexts.com/fpp3/","code":""},{"path":[]},{"path":"/reference/forecast_roll.html","id":null,"dir":"Reference","previous_headings":"","what":"Out-of-sample Forecasting based on Rolling Window — forecast_roll","title":"Out-of-sample Forecasting based on Rolling Window — forecast_roll","text":"function conducts rolling window forecasting.","code":""},{"path":"/reference/forecast_roll.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Out-of-sample Forecasting based on Rolling Window — forecast_roll","text":"","code":"forecast_roll(object, n_ahead, y_test, roll_thread = 1, mod_thread = 1)  # S3 method for bvharcv print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  knit_print.bvharcv(x, ...)"},{"path":"/reference/forecast_roll.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Out-of-sample Forecasting based on Rolling Window — forecast_roll","text":"object Model object n_ahead Step forecast rolling window scheme y_test Test data compared. Use divide_ts() separate evaluation dataset. roll_thread Number threads rolling window mod_thread Number threads fitting models x bvharcv object digits digit option print ... used","code":""},{"path":"/reference/forecast_roll.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Out-of-sample Forecasting based on Rolling Window — forecast_roll","text":"predbvhar_roll  class","code":""},{"path":"/reference/forecast_roll.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Out-of-sample Forecasting based on Rolling Window — forecast_roll","text":"Rolling windows forecasting fixes window size. moves window ahead forecast h-ahead y_test set.","code":""},{"path":"/reference/forecast_roll.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Out-of-sample Forecasting based on Rolling Window — forecast_roll","text":"Hyndman, R. J., & Athanasopoulos, G. (2021). Forecasting: Principles practice (3rd ed.). OTEXTS.","code":""},{"path":[]},{"path":"/reference/fromse.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Estimation Based on Frobenius Norm — fromse","title":"Evaluate the Estimation Based on Frobenius Norm — fromse","text":"function computes estimation error given estimated model true coefficient.","code":""},{"path":"/reference/fromse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Estimation Based on Frobenius Norm — fromse","text":"","code":"fromse(x, y, ...)  # S3 method for bvharsp fromse(x, y, ...)"},{"path":"/reference/fromse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Estimation Based on Frobenius Norm — fromse","text":"x Estimated model. y Coefficient matrix compared. ... used","code":""},{"path":"/reference/fromse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Estimation Based on Frobenius Norm — fromse","text":"Frobenius norm value","code":""},{"path":"/reference/fromse.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Estimation Based on Frobenius Norm — fromse","text":"Consider Frobenius Norm \\(\\lVert \\cdot \\rVert_F\\). let \\(\\hat{\\Phi}\\) nrow x k estimates, let \\(\\Phi\\) true coefficients matrix. function computes estimation error $$MSE = 100 \\frac{\\lVert \\hat{\\Phi} - \\Phi \\rVert_F}{nrow \\times k}$$","code":""},{"path":"/reference/fromse.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Estimation Based on Frobenius Norm — fromse","text":"Bai, R., & Ghosh, M. (2018). High-dimensional multivariate posterior consistency global–local shrinkage priors. Journal Multivariate Analysis, 167, 157–170.","code":""},{"path":"/reference/geom_eval.html","id":null,"dir":"Reference","previous_headings":"","what":"Adding Test Data Layer — geom_eval","title":"Adding Test Data Layer — geom_eval","text":"function adds layer test dataset.","code":""},{"path":"/reference/geom_eval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adding Test Data Layer — geom_eval","text":"","code":"geom_eval(data, colour = \"red\", ...)"},{"path":"/reference/geom_eval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adding Test Data Layer — geom_eval","text":"data Test data draw, format train data. colour Color line (default, \"red\"). ... arguments passed ggplot2::geom_path().","code":""},{"path":"/reference/geom_eval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adding Test Data Layer — geom_eval","text":"ggplot layer","code":""},{"path":"/reference/gg_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare Lists of Models — gg_loss","title":"Compare Lists of Models — gg_loss","text":"Draw plot test error given models","code":""},{"path":"/reference/gg_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare Lists of Models — gg_loss","text":"","code":"gg_loss(   mod_list,   y,   type = c(\"mse\", \"mae\", \"mape\", \"mase\"),   mean_line = FALSE,   line_param = list(),   mean_param = list(),   viridis = FALSE,   viridis_option = \"D\",   NROW = NULL,   NCOL = NULL,   ... )"},{"path":"/reference/gg_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare Lists of Models — gg_loss","text":"mod_list Lists forecast results (predbvhar objects) y Test data compared. format train data predict$forecast. type Loss function used (\"mse\": MSE, \"mae\": MAE, mape: MAPE, \"mase\": MASE) mean_line Whether draw average loss. default, FALSE. line_param Parameter lists ggplot2::geom_path(). mean_param Parameter lists average loss ggplot2::geom_hline(). viridis TRUE, scale CI forecast line using ggplot2::scale_fill_viridis_d() ggplot2::scale_colour_viridis_d, respectively. viridis_option Option viridis string. See option ggplot2::scale_colour_viridis_d. Choose one c(\"\", \"B\", \"C\", \"D\", \"E\"). default, \"D\". NROW nrow ggplot2::facet_wrap() NCOL ncol ggplot2::facet_wrap() ... Additional options geom_loss (inherit.aes show.legend)","code":""},{"path":"/reference/gg_loss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare Lists of Models — gg_loss","text":"ggplot object","code":""},{"path":[]},{"path":"/reference/horseshoe_bvar_algo.html","id":null,"dir":"Reference","previous_headings":"","what":"Horseshoe Prior in BVAR — horseshoe_bvar_algo","title":"Horseshoe Prior in BVAR — horseshoe_bvar_algo","text":"page describes Horseshoe prior Gibbs sampler VAR model.","code":""},{"path":"/reference/horseshoe_bvar_algo.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Horseshoe Prior in BVAR — horseshoe_bvar_algo","text":"Carvalho, C. M., Polson, N. G., & Scott, J. G. (2010). horseshoe estimator sparse signals. Biometrika, 97(2), 465–480. Makalic, E., & Schmidt, D. F. (2016). Simple Sampler Horseshoe Estimator. IEEE Signal Processing Letters, 23(1), 179–182.","code":""},{"path":"/reference/init_ssvs.html","id":null,"dir":"Reference","previous_headings":"","what":"Initial Parameters of Stochastic Search Variable Selection (SSVS) Model — init_ssvs","title":"Initial Parameters of Stochastic Search Variable Selection (SSVS) Model — init_ssvs","text":"Set initial parameters starting Gibbs sampler SSVS.","code":""},{"path":"/reference/init_ssvs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initial Parameters of Stochastic Search Variable Selection (SSVS) Model — init_ssvs","text":"","code":"init_ssvs(   init_coef,   init_coef_dummy,   init_chol,   init_chol_dummy,   type = c(\"user\", \"auto\") )  # S3 method for ssvsinit print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  knit_print.ssvsinit(x, ...)"},{"path":"/reference/init_ssvs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initial Parameters of Stochastic Search Variable Selection (SSVS) Model — init_ssvs","text":"init_coef Initial coefficient matrix. Initialize array list multiple chains. init_coef_dummy Initial indicator matrix (1-0) corresponding component coefficient. Initialize array list multiple chains. init_chol Initial cholesky factor (upper triangular). Initialize array list multiple chains. init_chol_dummy Initial indicator matrix (1-0) corresponding component cholesky factor. Initialize array list multiple chains. type Type choose initial values. One \"user\" (User-given) \"auto\" (OLS coefficients 1 dummy). x ssvsinit digits digit option print ... used","code":""},{"path":"/reference/init_ssvs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initial Parameters of Stochastic Search Variable Selection (SSVS) Model — init_ssvs","text":"ssvsinit object","code":""},{"path":"/reference/init_ssvs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Initial Parameters of Stochastic Search Variable Selection (SSVS) Model — init_ssvs","text":"Set SSVS initialization VAR model. init_coef: (kp + 1) x m \\(\\) coefficient matrix. init_coef_dummy: kp x m \\(\\Gamma\\) dummy matrix restrict coefficients. init_chol: k x k \\(\\Psi\\) upper triangular cholesky factor, \\(\\Psi \\Psi^\\intercal = \\Sigma_e^{-1}\\). init_chol_dummy: k x k \\(\\Omega\\) upper triangular dummy matrix restrict cholesky factor. Denote init_chol init_chol_dummy upper_triangular function gives error. parallel chain initialization, assign three-dimensional array three-length list.","code":""},{"path":"/reference/init_ssvs.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Initial Parameters of Stochastic Search Variable Selection (SSVS) Model — init_ssvs","text":"George, E. ., & McCulloch, R. E. (1993). Variable Selection via Gibbs Sampling. Journal American Statistical Association, 88(423), 881–889. George, E. ., Sun, D., & Ni, S. (2008). Bayesian stochastic search VAR model restrictions. Journal Econometrics, 142(1), 553–580. Koop, G., & Korobilis, D. (2009). Bayesian Multivariate Time Series Methods Empirical Macroeconomics. Foundations Trends® Econometrics, 3(4), 267–358.","code":""},{"path":"/reference/is.stable.html","id":null,"dir":"Reference","previous_headings":"","what":"Stability of the process — is.stable","title":"Stability of the process — is.stable","text":"Stability process","code":""},{"path":"/reference/is.stable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stability of the process — is.stable","text":"","code":"is.stable(x, ...)"},{"path":"/reference/is.stable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stability of the process — is.stable","text":"x object ... used","code":""},{"path":"/reference/is.stable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stability of the process — is.stable","text":"logical class","code":""},{"path":"/reference/is.stable.varlse.html","id":null,"dir":"Reference","previous_headings":"","what":"Stability of VAR Coefficient Matrix — is.stable.varlse","title":"Stability of VAR Coefficient Matrix — is.stable.varlse","text":"Check stability condition VAR(p) coefficient matrix.","code":""},{"path":"/reference/is.stable.varlse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stability of VAR Coefficient Matrix — is.stable.varlse","text":"","code":"# S3 method for varlse is.stable(x, ...)  # S3 method for vharlse is.stable(x, ...)  # S3 method for bvarmn is.stable(x, ...)  # S3 method for bvarflat is.stable(x, ...)  # S3 method for bvharmn is.stable(x, ...)"},{"path":"/reference/is.stable.varlse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stability of VAR Coefficient Matrix — is.stable.varlse","text":"x Model fit ... used","code":""},{"path":"/reference/is.stable.varlse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stability of VAR Coefficient Matrix — is.stable.varlse","text":"logical class","code":""},{"path":"/reference/is.stable.varlse.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Stability of VAR Coefficient Matrix — is.stable.varlse","text":"VAR(p) stable $$\\det(I_m - z) \\neq 0$$ \\(\\lvert z \\rvert \\le 1\\).","code":""},{"path":"/reference/is.stable.varlse.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Stability of VAR Coefficient Matrix — is.stable.varlse","text":"Lütkepohl, H. (2007). New Introduction Multiple Time Series Analysis. Springer Publishing.","code":""},{"path":"/reference/is.varlse.html","id":null,"dir":"Reference","previous_headings":"","what":"See if the Object a class in this package — is.varlse","title":"See if the Object a class in this package — is.varlse","text":"function returns TRUE input class defined package.","code":""},{"path":"/reference/is.varlse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"See if the Object a class in this package — is.varlse","text":"","code":"is.varlse(x)  is.vharlse(x)  is.bvarmn(x)  is.bvarflat(x)  is.bvharmn(x)  is.predbvhar(x)  is.bvharcv(x)  is.bvharspec(x)  is.bvharpriorspec(x)  is.bvharemp(x)  is.boundbvharemp(x)  is.ssvsinput(x)  is.ssvsinit(x)  is.bvharpriorspec(x)  is.horseshoespec(x)"},{"path":"/reference/is.varlse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"See if the Object a class in this package — is.varlse","text":"x Object","code":""},{"path":"/reference/is.varlse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"See if the Object a class in this package — is.varlse","text":"logical class","code":""},{"path":"/reference/logLik.varlse.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Log-Likelihood of Multivariate Time Series Model — logLik.varlse","title":"Extract Log-Likelihood of Multivariate Time Series Model — logLik.varlse","text":"Compute log-likelihood function value VAR(p), VHAR, BVAR(p), BVHAR","code":""},{"path":"/reference/logLik.varlse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Log-Likelihood of Multivariate Time Series Model — logLik.varlse","text":"","code":"# S3 method for varlse logLik(object, ...)  # S3 method for vharlse logLik(object, ...)  # S3 method for bvarmn logLik(object, ...)  # S3 method for bvarflat logLik(object, ...)  # S3 method for bvharmn logLik(object, ...)"},{"path":"/reference/logLik.varlse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Log-Likelihood of Multivariate Time Series Model — logLik.varlse","text":"object Model fit ... used","code":""},{"path":"/reference/logLik.varlse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Log-Likelihood of Multivariate Time Series Model — logLik.varlse","text":"logLik object.","code":""},{"path":"/reference/logLik.varlse.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract Log-Likelihood of Multivariate Time Series Model — logLik.varlse","text":"Consider response matrix \\(Y_0\\). Let \\(n\\) total number sample, let \\(m\\) dimension time series, let \\(p\\) order model, let \\(s = n - p\\). Likelihood VAR(p) $$Y_0 \\mid B, \\Sigma_e \\sim MN(X_0 B, I_s, \\Sigma_e)$$ \\(X_0\\) design matrix, MN matrix normal distribution. log-likelihood vector autoregressive model family specified $$\\log p(Y_0 \\mid B, \\Sigma_e) = - \\frac{sm}{2} \\log 2\\pi - \\frac{s}{2} \\log \\det \\Sigma_e - \\frac{1}{2} tr( (Y_0 - X_0 B) \\Sigma_e^{-1} (Y_0 - X_0 B)^T )$$ addition, recall OLS estimator matrix coefficient matrix MLE Gaussian assumption. MLE \\(\\Sigma_e\\) different denominator, \\(s\\). $$\\hat{B} = \\hat{B}^{LS} = \\hat{B}^{ML} = (X_0^T X_0)^{-1} X_0^T Y_0$$ $$\\hat\\Sigma_e = \\frac{1}{s - k} (Y_0 - X_0 \\hat{B})^T (Y_0 - X_0 \\hat{B})$$ $$\\tilde\\Sigma_e = \\frac{1}{s} (Y_0 - X_0 \\hat{B})^T (Y_0 - X_0 \\hat{B}) = \\frac{s - k}{s} \\hat\\Sigma_e$$ case VHAR, just consider linear relationship. frequentist models use OLS MLE coefficient covariance matrices, Bayesian models implement posterior means.","code":""},{"path":"/reference/logLik.varlse.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extract Log-Likelihood of Multivariate Time Series Model — logLik.varlse","text":"Lütkepohl, H. (2007). New Introduction Multiple Time Series Analysis. Springer Publishing. Corsi, F. (2008). Simple Approximate Long-Memory Model Realized Volatility. Journal Financial Econometrics, 7(2), 174–196. Bańbura, M., Giannone, D., & Reichlin, L. (2010). Large Bayesian vector auto regressions. Journal Applied Econometrics, 25(1). Litterman, R. B. (1986). Forecasting Bayesian Vector Autoregressions: Five Years Experience. Journal Business & Economic Statistics, 4(1), 25. Ghosh, S., Khare, K., & Michailidis, G. (2018). High-Dimensional Posterior Consistency Bayesian Vector Autoregressive Models. Journal American Statistical Association, 114(526).","code":""},{"path":[]},{"path":"/reference/lpl.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Model Based on Log Predictive Likelihood — lpl","title":"Evaluate the Model Based on Log Predictive Likelihood — lpl","text":"function computes LPL given prediction result versus evaluation set.","code":""},{"path":"/reference/lpl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Model Based on Log Predictive Likelihood — lpl","text":"","code":"lpl(x, y, ...)  # S3 method for predsv lpl(x, y, ...)"},{"path":"/reference/lpl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Model Based on Log Predictive Likelihood — lpl","text":"x Forecasting object y Test data compared. format train data. ... used","code":""},{"path":"/reference/lpl.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Model Based on Log Predictive Likelihood — lpl","text":"Cross, J. L., Hou, C., & Poon, . (2020). Macroeconomic forecasting large Bayesian VARs: Global-local priors illusion sparsity. International Journal Forecasting, 36(3), 899–915. Gruber, L., & Kastner, G. (2022). Forecasting macroeconomic data Bayesian VARs: Sparse dense? depends! arXiv.","code":""},{"path":"/reference/mae.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Model Based on MAE (Mean Absolute Error) — mae","title":"Evaluate the Model Based on MAE (Mean Absolute Error) — mae","text":"function computes MAE given prediction result versus evaluation set.","code":""},{"path":"/reference/mae.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Model Based on MAE (Mean Absolute Error) — mae","text":"","code":"mae(x, y, ...)  # S3 method for predbvhar mae(x, y, ...)  # S3 method for bvharcv mae(x, y, ...)"},{"path":"/reference/mae.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Model Based on MAE (Mean Absolute Error) — mae","text":"x Forecasting object y Test data compared. format train data. ... used","code":""},{"path":"/reference/mae.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Model Based on MAE (Mean Absolute Error) — mae","text":"MAE vector corressponding variable.","code":""},{"path":"/reference/mae.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Model Based on MAE (Mean Absolute Error) — mae","text":"Let \\(e_t = y_t - \\hat{y}_t\\). MAE defined $$MSE = mean(\\lvert e_t \\rvert)$$ researchers prefer MAE MSE less sensitive outliers.","code":""},{"path":"/reference/mae.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Model Based on MAE (Mean Absolute Error) — mae","text":"Hyndman, R. J., & Koehler, . B. (2006). Another look measures forecast accuracy. International Journal Forecasting, 22(4), 679–688.","code":""},{"path":"/reference/mape.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Model Based on MAPE (Mean Absolute Percentage Error) — mape","title":"Evaluate the Model Based on MAPE (Mean Absolute Percentage Error) — mape","text":"function computes MAPE given prediction result versus evaluation set.","code":""},{"path":"/reference/mape.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Model Based on MAPE (Mean Absolute Percentage Error) — mape","text":"","code":"mape(x, y, ...)  # S3 method for predbvhar mape(x, y, ...)  # S3 method for bvharcv mape(x, y, ...)"},{"path":"/reference/mape.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Model Based on MAPE (Mean Absolute Percentage Error) — mape","text":"x Forecasting object y Test data compared. format train data. ... used","code":""},{"path":"/reference/mape.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Model Based on MAPE (Mean Absolute Percentage Error) — mape","text":"MAPE vector corresponding variable.","code":""},{"path":"/reference/mape.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Model Based on MAPE (Mean Absolute Percentage Error) — mape","text":"Let \\(e_t = y_t - \\hat{y}_t\\). Percentage error defined \\(p_t = 100 e_t / Y_t\\) (100 can omitted since comparison focus). $$MAPE = mean(\\lvert p_t \\rvert)$$","code":""},{"path":"/reference/mape.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Model Based on MAPE (Mean Absolute Percentage Error) — mape","text":"Hyndman, R. J., & Koehler, . B. (2006). Another look measures forecast accuracy. International Journal Forecasting, 22(4), 679–688.","code":""},{"path":"/reference/mase.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Model Based on MASE (Mean Absolute Scaled Error) — mase","title":"Evaluate the Model Based on MASE (Mean Absolute Scaled Error) — mase","text":"function computes MASE given prediction result versus evaluation set.","code":""},{"path":"/reference/mase.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Model Based on MASE (Mean Absolute Scaled Error) — mase","text":"","code":"mase(x, y, ...)  # S3 method for predbvhar mase(x, y, ...)  # S3 method for bvharcv mase(x, y, ...)"},{"path":"/reference/mase.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Model Based on MASE (Mean Absolute Scaled Error) — mase","text":"x Forecasting object y Test data compared. format train data. ... used","code":""},{"path":"/reference/mase.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Model Based on MASE (Mean Absolute Scaled Error) — mase","text":"MASE vector corresponding variable.","code":""},{"path":"/reference/mase.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Model Based on MASE (Mean Absolute Scaled Error) — mase","text":"Let \\(e_t = y_t - \\hat{y}_t\\). Scaled error defined $$q_t = \\frac{e_t}{\\sum_{= 2}^{n} \\lvert Y_i - Y_{- 1} \\rvert / (n - 1)}$$ error can free data scale. $$MASE = mean(\\lvert q_t \\rvert)$$ , \\(Y_i\\) points sample, .e. errors scaled -sample mean absolute error (\\(mean(\\lvert e_t \\rvert)\\)) naive random walk forecasting.","code":""},{"path":"/reference/mase.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Model Based on MASE (Mean Absolute Scaled Error) — mase","text":"Hyndman, R. J., & Koehler, . B. (2006). Another look measures forecast accuracy. International Journal Forecasting, 22(4), 679–688.","code":""},{"path":"/reference/mrae.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Model Based on MRAE (Mean Relative Absolute Error) — mrae","title":"Evaluate the Model Based on MRAE (Mean Relative Absolute Error) — mrae","text":"function computes MRAE given prediction result versus evaluation set.","code":""},{"path":"/reference/mrae.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Model Based on MRAE (Mean Relative Absolute Error) — mrae","text":"","code":"mrae(x, pred_bench, y, ...)  # S3 method for predbvhar mrae(x, pred_bench, y, ...)  # S3 method for bvharcv mrae(x, pred_bench, y, ...)"},{"path":"/reference/mrae.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Model Based on MRAE (Mean Relative Absolute Error) — mrae","text":"x Forecasting object use pred_bench forecasting object benchmark model y Test data compared. format train data. ... used","code":""},{"path":"/reference/mrae.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Model Based on MRAE (Mean Relative Absolute Error) — mrae","text":"MRAE vector corresponding variable.","code":""},{"path":"/reference/mrae.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Model Based on MRAE (Mean Relative Absolute Error) — mrae","text":"Let \\(e_t = y_t - \\hat{y}_t\\). MRAE implements benchmark model scaling method. Relative error defined $$r_t = \\frac{e_t}{e_t^{\\ast}}$$ \\(e_t^\\ast\\) error benchmark method. $$MRAE = mean(\\lvert r_t \\rvert)$$","code":""},{"path":"/reference/mrae.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Model Based on MRAE (Mean Relative Absolute Error) — mrae","text":"Hyndman, R. J., & Koehler, . B. (2006). Another look measures forecast accuracy. International Journal Forecasting, 22(4), 679–688.","code":""},{"path":"/reference/mse.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Model Based on MSE (Mean Square Error) — mse","title":"Evaluate the Model Based on MSE (Mean Square Error) — mse","text":"function computes MSE given prediction result versus evaluation set.","code":""},{"path":"/reference/mse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Model Based on MSE (Mean Square Error) — mse","text":"","code":"mse(x, y, ...)  # S3 method for predbvhar mse(x, y, ...)  # S3 method for bvharcv mse(x, y, ...)"},{"path":"/reference/mse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Model Based on MSE (Mean Square Error) — mse","text":"x Forecasting object y Test data compared. format train data. ... used","code":""},{"path":"/reference/mse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Model Based on MSE (Mean Square Error) — mse","text":"MSE vector corresponding variable.","code":""},{"path":"/reference/mse.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Model Based on MSE (Mean Square Error) — mse","text":"Let \\(e_t = y_t - \\hat{y}_t\\). $$MSE = mean(e_t^2)$$ MSE used accuracy measure.","code":""},{"path":"/reference/mse.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Model Based on MSE (Mean Square Error) — mse","text":"Hyndman, R. J., & Koehler, . B. (2006). Another look measures forecast accuracy. International Journal Forecasting, 22(4), 679–688.","code":""},{"path":"/reference/oxfordman.html","id":null,"dir":"Reference","previous_headings":"","what":"Oxford-Man Institute Realized Library — oxfordman","title":"Oxford-Man Institute Realized Library — oxfordman","text":"realized measure financial assets dataset provided Oxford-man Institute Quantitative Finance.","code":""},{"path":"/reference/oxfordman.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Oxford-Man Institute Realized Library — oxfordman","text":"","code":"oxfordman_rv  oxfordman_rk"},{"path":"/reference/oxfordman.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Oxford-Man Institute Realized Library — oxfordman","text":"oxfordman_long raw data frame 53507 rows 20 columns (call dataset.): date Date - 2012-01-09 2015-06-27 Symbol Name Assets - See name nobs Number observations by_ss Bipower Variation (5-min Sub-sampled) rsv Realized Semi-variance (5-min) rk_parzen Realized Kernel Variance (Non-Flat Parzen) rv10 Realized Variance (10-min) rv5_ss Realized Variance (5-min Sub-sampled) rv5 Realized Variance (5-min) rv10_ss Realized Variance (10-min Sub-sampled) rk_twoscale Realized Kernel Variance (Two-Scale/Bartlett) close_price Closing (Last) Price rsv_ss Realized Semi-variance (5-min Sub-sampled) rk_th2 Realized Kernel Variance (Tukey-Hanning(2)) open_time Opening Time medrv Median Realized Variance (5-min) open_price Opening (First) Price bv Bipower Variation (5-min) open_to_close Open Close Return close_time Closing Time oxfordman_rv data frame interpolates NA values oxfordman_wide_rv. Also, date column fitting. number rows 905 number columns 30 (except date). date Date - 2012-01-09 2015-06-27 AEX AEX index AORD Ordinaries BFX Bell 20 Index BSESN S&P BSE Sensex BVLG PSI -Share Index (excluded index observed 2012-10-15) BVSP BVSP BOVESPA Index DJI Dow Jones Industrial Average FCHI CAC 40 FTMIB FTSE MIB FTSE FTSE 100 GDAXI DAX GSPTSE S&P/TSX Composite index HSI HANG SENG Index IBEX IBEX 35 Index IXIC Nasdaq 100 KS11 Korea Composite Stock Price Index (KOSPI) KSE Karachi SE 100 Index MXX IPC Mexico N225 Nikkei 225 NSEI NIFTY 50 OMXC20 OMX Copenhagen 20 Index OMXHPI OMX Helsinki Share Index OMXSPI OMX Stockholm Share Index OSEAX Oslo Exchange -share Index RUT Russel 2000 SMSI Madrid General Index SPX S&P 500 Index SSEC Shanghai Composite Index SSMI Swiss Stock Market Index STI Straits Times Index (excluded index NA period) STOXX50E EURO STOXX 50 oxfordman_rk data frame interpolates NA values oxfordman_wide_rk. Also, DATE column fitting. number rows 1826 number columns 31.","code":""},{"path":"/reference/oxfordman.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Oxford-Man Institute Realized Library — oxfordman","text":"Realized library oxford-man discontinued, source listed.","code":""},{"path":"/reference/oxfordman.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Oxford-Man Institute Realized Library — oxfordman","text":"raw dataset, internal dataset long format oxfordman_long. contains every realized measure. Denote non-trading dates excluded oxfordman_long, NA. careful dealing set directly. analysis, widened data 5-min realized volatility (rv5) realized kernel variance (rk_parzen), respectively. oxfordman_wide_rv oxfordman_wide_rk oxford_rv oxford_rk sets whose NA values interpolated using imputeTS::na_interpolation(). First three datasets called using data() function: data(..., package = \"bvhar\"). oxford_rv oxford_rk lazy loaded.","code":""},{"path":"/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"/reference/predict.varlse.html","id":null,"dir":"Reference","previous_headings":"","what":"Forecasting Multivariate Time Series — predict.varlse","title":"Forecasting Multivariate Time Series — predict.varlse","text":"Forecasts multivariate time series using given model.","code":""},{"path":"/reference/predict.varlse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forecasting Multivariate Time Series — predict.varlse","text":"","code":"# S3 method for varlse predict(object, n_ahead, level = 0.05, ...)  # S3 method for vharlse predict(object, n_ahead, level = 0.05, ...)  # S3 method for bvarmn predict(object, n_ahead, n_iter = 100L, level = 0.05, ...)  # S3 method for bvharmn predict(object, n_ahead, n_iter = 100L, level = 0.05, ...)  # S3 method for bvarflat predict(object, n_ahead, n_iter = 100L, level = 0.05, ...)  # S3 method for bvarssvs predict(object, n_ahead, level = 0.05, ...)  # S3 method for bvharssvs predict(object, n_ahead, level = 0.05, ...)  # S3 method for bvarhs predict(object, n_ahead, level = 0.05, ...)  # S3 method for bvharhs predict(object, n_ahead, level = 0.05, ...)  # S3 method for bvarsv predict(object, n_ahead, level = 0.05, ...)  # S3 method for bvharsv predict(object, n_ahead, level = 0.05, ...)  # S3 method for predbvhar print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  knit_print.predbvhar(x, ...)"},{"path":"/reference/predict.varlse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forecasting Multivariate Time Series — predict.varlse","text":"object Model object n_ahead step forecast level Specify alpha confidence interval level 100(1 - alpha) percentage. default, .05. ... used n_iter Number sample residual matrix inverse-wishart distribution. default, 100. x predbvhar object digits digit option print","code":""},{"path":"/reference/predict.varlse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Forecasting Multivariate Time Series — predict.varlse","text":"predbvhar  class following components: process object$process forecast forecast matrix se standard error matrix lower lower confidence interval upper upper confidence interval lower_joint lower CI adjusted (Bonferroni) upper_joint upper CI adjusted (Bonferroni) y object$y","code":""},{"path":"/reference/predict.varlse.html","id":"n-step-ahead-forecasting-var-p-","dir":"Reference","previous_headings":"","what":"n-step ahead forecasting VAR(p)","title":"Forecasting Multivariate Time Series — predict.varlse","text":"See pp35 Lütkepohl (2007). Consider h-step ahead forecasting (e.g. n + 1, ... n + h). Let \\(y_{(n)}^T = (y_n^T, ..., y_{n - p + 1}^T, 1)\\). one-step ahead (point) forecasting: $$\\hat{y}_{n + 1}^T = y_{(n)}^T \\hat{B}$$ Recursively, let \\(\\hat{y}_{(n + 1)}^T = (\\hat{y}_{n + 1}^T, y_n^T, ..., y_{n - p + 2}^T, 1)\\). two-step ahead (point) forecasting: $$\\hat{y}_{n + 2}^T = \\hat{y}_{(n + 1)}^T \\hat{B}$$ Similarly, h-step ahead (point) forecasting: $$\\hat{y}_{n + h}^T = \\hat{y}_{(n + h - 1)}^T \\hat{B}$$ confident region? Confidence interval h-period $$y_{k,t}(h) \\pm z_(\\alpha / 2) \\sigma_k (h)$$ Joint forecast region \\(100(1-\\alpha)\\)% can computed $$\\{ (y_{k, 1}, y_{k, h}) \\mid y_{k, n}() - z_{(\\alpha / 2h)} \\sigma_n() \\le y_{n, } \\le y_{k, n}() + z_{(\\alpha / 2h)} \\sigma_k(), = 1, \\ldots, h \\}$$ See pp41 Lütkepohl (2007). compute covariance matrix, needs VMA representation: $$Y_{t}(h) = c + \\sum_{= h}^{\\infty} W_{} \\epsilon_{t + h - } = c + \\sum_{= 0}^{\\infty} W_{h + } \\epsilon_{t - }$$ $$\\Sigma_y(h) = MSE [ y_t(h) ] = \\sum_{= 0}^{h - 1} W_i \\Sigma_{\\epsilon} W_i^T = \\Sigma_y(h - 1) + W_{h - 1} \\Sigma_{\\epsilon} W_{h - 1}^T$$","code":""},{"path":"/reference/predict.varlse.html","id":"n-step-ahead-forecasting-vhar","dir":"Reference","previous_headings":"","what":"n-step ahead forecasting VHAR","title":"Forecasting Multivariate Time Series — predict.varlse","text":"Let \\(T_{HAR}\\) VHAR linear transformation matrix (See var_design_formulation). Since VHAR linearly transformed VAR(22), let \\(y_{(n)}^T = (y_n^T, y_{n - 1}^T, ..., y_{n - 21}^T, 1)\\). one-step ahead (point) forecasting: $$\\hat{y}_{n + 1}^T = y_{(n)}^T T_{HAR} \\hat{\\Phi}$$ Recursively, let \\(\\hat{y}_{(n + 1)}^T = (\\hat{y}_{n + 1}^T, y_n^T, ..., y_{n - 20}^T, 1)\\). two-step ahead (point) forecasting: $$\\hat{y}_{n + 2}^T = \\hat{y}_{(n + 1)}^T T_{HAR} \\hat{\\Phi}$$ h-step ahead (point) forecasting: $$\\hat{y}_{n + h}^T = \\hat{y}_{(n + h - 1)}^T T_{HAR} \\hat{\\Phi}$$","code":""},{"path":"/reference/predict.varlse.html","id":"n-step-ahead-forecasting-bvar-p-with-minnesota-prior","dir":"Reference","previous_headings":"","what":"n-step ahead forecasting BVAR(p) with minnesota prior","title":"Forecasting Multivariate Time Series — predict.varlse","text":"Point forecasts computed posterior mean parameters. See Section 3 Bańbura et al. (2010). Let \\(\\hat{B}\\) posterior MN mean let \\(\\hat{V}\\) posterior MN precision. predictive posterior step $$y_{n + 1} \\mid \\Sigma_e, y \\sim N( vec(y_{(n)}^T ), \\Sigma_e \\otimes (1 + y_{(n)}^T \\hat{V}^{-1} y_{(n)}) )$$ $$y_{n + 2} \\mid \\Sigma_e, y \\sim N( vec(\\hat{y}_{(n + 1)}^T ), \\Sigma_e \\otimes (1 + \\hat{y}_{(n + 1)}^T \\hat{V}^{-1} \\hat{y}_{(n + 1)}) )$$ recursively, $$y_{n + h} \\mid \\Sigma_e, y \\sim N( vec(\\hat{y}_{(n + h - 1)}^T ), \\Sigma_e \\otimes (1 + \\hat{y}_{(n + h - 1)}^T \\hat{V}^{-1} \\hat{y}_{(n + h - 1)}) )$$ See bvar_predictive_density generate predictive distribution.","code":""},{"path":"/reference/predict.varlse.html","id":"n-step-ahead-forecasting-bvhar","dir":"Reference","previous_headings":"","what":"n-step ahead forecasting BVHAR","title":"Forecasting Multivariate Time Series — predict.varlse","text":"Let \\(\\hat\\Phi\\) posterior MN mean let \\(\\hat\\Psi\\) posterior MN precision. predictive posterior step $$y_{n + 1} \\mid \\Sigma_e, y \\sim N( vec(y_{(n)}^T \\tilde{T}^T \\Phi), \\Sigma_e \\otimes (1 + y_{(n)}^T \\tilde{T} \\hat\\Psi^{-1} \\tilde{T} y_{(n)}) )$$ $$y_{n + 2} \\mid \\Sigma_e, y \\sim N( vec(y_{(n + 1)}^T \\tilde{T}^T \\Phi), \\Sigma_e \\otimes (1 + y_{(n + 1)}^T \\tilde{T} \\hat\\Psi^{-1} \\tilde{T} y_{(n + 1)}) )$$ recursively, $$y_{n + h} \\mid \\Sigma_e, y \\sim N( vec(y_{(n + h - 1)}^T \\tilde{T}^T \\Phi), \\Sigma_e \\otimes (1 + y_{(n + h - 1)}^T \\tilde{T} \\hat\\Psi^{-1} \\tilde{T} y_{(n + h - 1)}) )$$ See bvar_predictive_density generate predictive distribution.","code":""},{"path":"/reference/predict.varlse.html","id":"n-step-ahead-forecasting-var-p-with-ssvs-and-horseshoe","dir":"Reference","previous_headings":"","what":"n-step ahead forecasting VAR(p) with SSVS and Horseshoe","title":"Forecasting Multivariate Time Series — predict.varlse","text":"process computing point estimate . However, predictive interval achieved Gibbs sampler sample. $$y_{n + 1} \\mid , \\Sigma_e, y \\sim N( vec(y_{(n)}^T ), \\Sigma_e )$$ $$y_{n + h} \\mid , \\Sigma_e, y \\sim N( vec(\\hat{y}_{(n + h - 1)}^T ), \\Sigma_e )$$","code":""},{"path":"/reference/predict.varlse.html","id":"n-step-ahead-forecasting-vhar-with-ssvs-and-horseshoe","dir":"Reference","previous_headings":"","what":"n-step ahead forecasting VHAR with SSVS and Horseshoe","title":"Forecasting Multivariate Time Series — predict.varlse","text":"process computing point estimate . However, predictive interval achieved Gibbs sampler sample. $$y_{n + 1} \\mid \\Sigma_e, y \\sim N( vec(y_{(n)}^T \\tilde{T}^T \\Phi), \\Sigma_e \\otimes (1 + y_{(n)}^T \\tilde{T} \\hat\\Psi^{-1} \\tilde{T} y_{(n)}) )$$ $$y_{n + h} \\mid \\Sigma_e, y \\sim N( vec(y_{(n + h - 1)}^T \\tilde{T}^T \\Phi), \\Sigma_e \\otimes (1 + y_{(n + h - 1)}^T \\tilde{T} \\hat\\Psi^{-1} \\tilde{T} y_{(n + h - 1)}) )$$","code":""},{"path":"/reference/predict.varlse.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Forecasting Multivariate Time Series — predict.varlse","text":"Lütkepohl, H. (2007). New Introduction Multiple Time Series Analysis. Springer Publishing. Corsi, F. (2008). Simple Approximate Long-Memory Model Realized Volatility. Journal Financial Econometrics, 7(2), 174–196. Baek, C. Park, M. (2021). Sparse vector heterogeneous autoregressive modeling realized volatility. J. Korean Stat. Soc. 50, 495–510. Bańbura, M., Giannone, D., & Reichlin, L. (2010). Large Bayesian vector auto regressions. Journal Applied Econometrics, 25(1). Gelman, ., Carlin, J. B., Stern, H. S., & Rubin, D. B. (2013). Bayesian data analysis. Chapman Hall/CRC. Karlsson, S. (2013). Chapter 15 Forecasting Bayesian Vector Autoregression. Handbook Economic Forecasting, 2, 791–897. Litterman, R. B. (1986). Forecasting Bayesian Vector Autoregressions: Five Years Experience. Journal Business & Economic Statistics, 4(1), 25. Ghosh, S., Khare, K., & Michailidis, G. (2018). High-Dimensional Posterior Consistency Bayesian Vector Autoregressive Models. Journal American Statistical Association, 114(526). George, E. ., Sun, D., & Ni, S. (2008). Bayesian stochastic search VAR model restrictions. Journal Econometrics, 142(1), 553–580. George, E. ., Sun, D., & Ni, S. (2008). Bayesian stochastic search VAR model restrictions. Journal Econometrics, 142(1), 553–580.","code":""},{"path":"/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. ggplot2 autolayer, autoplot","code":""},{"path":"/reference/relmae.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Model Based on RelMAE (Relative MAE) — relmae","title":"Evaluate the Model Based on RelMAE (Relative MAE) — relmae","text":"function computes RelMAE given prediction result versus evaluation set.","code":""},{"path":"/reference/relmae.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Model Based on RelMAE (Relative MAE) — relmae","text":"","code":"relmae(x, pred_bench, y, ...)  # S3 method for predbvhar relmae(x, pred_bench, y, ...)  # S3 method for bvharcv relmae(x, pred_bench, y, ...)"},{"path":"/reference/relmae.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Model Based on RelMAE (Relative MAE) — relmae","text":"x Forecasting object use pred_bench forecasting object benchmark model y Test data compared. format train data. ... used","code":""},{"path":"/reference/relmae.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Model Based on RelMAE (Relative MAE) — relmae","text":"RelMAE vector corresponding variable.","code":""},{"path":"/reference/relmae.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Model Based on RelMAE (Relative MAE) — relmae","text":"Let \\(e_t = y_t - \\hat{y}_t\\). RelMAE implements MAE benchmark model relative measures. Let \\(MAE_b\\) MAE benchmark model. $$RelMAE = \\frac{MAE}{MAE_b}$$ \\(MAE\\) MAE model.","code":""},{"path":"/reference/relmae.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Model Based on RelMAE (Relative MAE) — relmae","text":"Hyndman, R. J., & Koehler, . B. (2006). Another look measures forecast accuracy. International Journal Forecasting, 22(4), 679–688.","code":""},{"path":"/reference/relspne.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Estimation Based on Relative Spectral Norm Error — relspne","title":"Evaluate the Estimation Based on Relative Spectral Norm Error — relspne","text":"function computes relative estimation error given estimated model true coefficient.","code":""},{"path":"/reference/relspne.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Estimation Based on Relative Spectral Norm Error — relspne","text":"","code":"relspne(x, y, ...)  # S3 method for bvharsp relspne(x, y, ...)"},{"path":"/reference/relspne.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Estimation Based on Relative Spectral Norm Error — relspne","text":"x Estimated model. y Coefficient matrix compared. ... used","code":""},{"path":"/reference/relspne.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Estimation Based on Relative Spectral Norm Error — relspne","text":"Spectral norm value","code":""},{"path":"/reference/relspne.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Estimation Based on Relative Spectral Norm Error — relspne","text":"Let \\(\\lVert \\cdot \\rVert_2\\) spectral norm matrix, let \\(\\hat{\\Phi}\\) estimates, let \\(\\Phi\\) true coefficients matrix. function computes relative estimation error $$\\frac{\\lVert \\hat{\\Phi} - \\Phi \\rVert_2}{\\lVert \\Phi \\rVert_2}$$","code":""},{"path":"/reference/relspne.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Estimation Based on Relative Spectral Norm Error — relspne","text":"Ghosh, S., Khare, K., & Michailidis, G. (2018). High-Dimensional Posterior Consistency Bayesian Vector Autoregressive Models. Journal American Statistical Association, 114(526).","code":""},{"path":"/reference/residuals.varlse.html","id":null,"dir":"Reference","previous_headings":"","what":"Residual Matrix from Multivariate Time Series Models — residuals.varlse","title":"Residual Matrix from Multivariate Time Series Models — residuals.varlse","text":"defining stats::residuals() model, function returns residual.","code":""},{"path":"/reference/residuals.varlse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Residual Matrix from Multivariate Time Series Models — residuals.varlse","text":"","code":"# S3 method for varlse residuals(object, ...)  # S3 method for vharlse residuals(object, ...)  # S3 method for bvarmn residuals(object, ...)  # S3 method for bvarflat residuals(object, ...)  # S3 method for bvharmn residuals(object, ...)"},{"path":"/reference/residuals.varlse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Residual Matrix from Multivariate Time Series Models — residuals.varlse","text":"object Model object ... used","code":""},{"path":"/reference/residuals.varlse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Residual Matrix from Multivariate Time Series Models — residuals.varlse","text":"matrix object.","code":""},{"path":"/reference/rmafe.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Model Based on RMAFE — rmafe","title":"Evaluate the Model Based on RMAFE — rmafe","text":"function computes RMAFE (Mean Absolute Forecast Error Relative Benchmark)","code":""},{"path":"/reference/rmafe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Model Based on RMAFE — rmafe","text":"","code":"rmafe(x, pred_bench, y, ...)  # S3 method for predbvhar rmafe(x, pred_bench, y, ...)  # S3 method for bvharcv rmafe(x, pred_bench, y, ...)"},{"path":"/reference/rmafe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Model Based on RMAFE — rmafe","text":"x Forecasting object use pred_bench forecasting object benchmark model y Test data compared. format train data. ... used","code":""},{"path":"/reference/rmafe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Model Based on RMAFE — rmafe","text":"RMAFE vector corresponding variable.","code":""},{"path":"/reference/rmafe.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Model Based on RMAFE — rmafe","text":"Let \\(e_t = y_t - \\hat{y}_t\\). RMAFE ratio L1 norm \\(e_t\\) forecasting object benchmark model. $$RMAFE = \\frac{sum(\\lVert e_t \\rVert)}{sum(\\lVert e_t^{(b)} \\rVert)}$$ \\(e_t^{(b)}\\) error benchmark model.","code":""},{"path":"/reference/rmafe.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Model Based on RMAFE — rmafe","text":"Hyndman, R. J., & Koehler, . B. (2006). Another look measures forecast accuracy. International Journal Forecasting, 22(4), 679–688. Bańbura, M., Giannone, D., & Reichlin, L. (2010). Large Bayesian vector auto regressions. Journal Applied Econometrics, 25(1). Ghosh, S., Khare, K., & Michailidis, G. (2018). High-Dimensional Posterior Consistency Bayesian Vector Autoregressive Models. Journal American Statistical Association, 114(526).","code":""},{"path":"/reference/rmape.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Model Based on RMAPE (Relative MAPE) — rmape","title":"Evaluate the Model Based on RMAPE (Relative MAPE) — rmape","text":"function computes RMAPE given prediction result versus evaluation set.","code":""},{"path":"/reference/rmape.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Model Based on RMAPE (Relative MAPE) — rmape","text":"","code":"rmape(x, pred_bench, y, ...)  # S3 method for predbvhar rmape(x, pred_bench, y, ...)  # S3 method for bvharcv rmape(x, pred_bench, y, ...)"},{"path":"/reference/rmape.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Model Based on RMAPE (Relative MAPE) — rmape","text":"x Forecasting object use pred_bench forecasting object benchmark model y Test data compared. format train data. ... used","code":""},{"path":"/reference/rmape.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Model Based on RMAPE (Relative MAPE) — rmape","text":"RMAPE vector corresponding variable.","code":""},{"path":"/reference/rmape.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Model Based on RMAPE (Relative MAPE) — rmape","text":"RMAPE ratio MAPE given model benchmark one. Let \\(MAPE_b\\) MAPE benchmark model. $$RMAPE = \\frac{mean(MAPE)}{mean(MAPE_b)}$$ \\(MAPE\\) MAPE model.","code":""},{"path":"/reference/rmape.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Model Based on RMAPE (Relative MAPE) — rmape","text":"Hyndman, R. J., & Koehler, . B. (2006). Another look measures forecast accuracy. International Journal Forecasting, 22(4), 679–688.","code":""},{"path":"/reference/rmase.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Model Based on RMASE (Relative MASE) — rmase","title":"Evaluate the Model Based on RMASE (Relative MASE) — rmase","text":"function computes RMASE given prediction result versus evaluation set.","code":""},{"path":"/reference/rmase.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Model Based on RMASE (Relative MASE) — rmase","text":"","code":"rmase(x, pred_bench, y, ...)  # S3 method for predbvhar rmase(x, pred_bench, y, ...)  # S3 method for bvharcv rmase(x, pred_bench, y, ...)"},{"path":"/reference/rmase.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Model Based on RMASE (Relative MASE) — rmase","text":"x Forecasting object use pred_bench forecasting object benchmark model y Test data compared. format train data. ... used","code":""},{"path":"/reference/rmase.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Model Based on RMASE (Relative MASE) — rmase","text":"RMASE vector corresponding variable.","code":""},{"path":"/reference/rmase.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Model Based on RMASE (Relative MASE) — rmase","text":"RMASE ratio MAPE given model benchmark one. Let \\(MASE_b\\) MAPE benchmark model. $$RMASE = \\frac{mean(MASE)}{mean(MASE_b)}$$ \\(MASE\\) MASE model.","code":""},{"path":"/reference/rmase.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Model Based on RMASE (Relative MASE) — rmase","text":"Hyndman, R. J., & Koehler, . B. (2006). Another look measures forecast accuracy. International Journal Forecasting, 22(4), 679–688.","code":""},{"path":"/reference/rmsfe.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Model Based on RMSFE — rmsfe","title":"Evaluate the Model Based on RMSFE — rmsfe","text":"function computes RMSFE (Mean Squared Forecast Error Relative Benchmark)","code":""},{"path":"/reference/rmsfe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Model Based on RMSFE — rmsfe","text":"","code":"rmsfe(x, pred_bench, y, ...)  # S3 method for predbvhar rmsfe(x, pred_bench, y, ...)  # S3 method for bvharcv rmsfe(x, pred_bench, y, ...)"},{"path":"/reference/rmsfe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Model Based on RMSFE — rmsfe","text":"x Forecasting object use pred_bench forecasting object benchmark model y Test data compared. format train data. ... used","code":""},{"path":"/reference/rmsfe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Model Based on RMSFE — rmsfe","text":"RMSFE vector corresponding variable.","code":""},{"path":"/reference/rmsfe.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Model Based on RMSFE — rmsfe","text":"Let \\(e_t = y_t - \\hat{y}_t\\). RMSFE ratio L2 norm \\(e_t\\) forecasting object benchmark model. $$RMSFE = \\frac{sum(\\lVert e_t \\rVert)}{sum(\\lVert e_t^{(b)} \\rVert)}$$ \\(e_t^{(b)}\\) error benchmark model.","code":""},{"path":"/reference/rmsfe.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Model Based on RMSFE — rmsfe","text":"Hyndman, R. J., & Koehler, . B. (2006). Another look measures forecast accuracy. International Journal Forecasting, 22(4), 679–688. Bańbura, M., Giannone, D., & Reichlin, L. (2010). Large Bayesian vector auto regressions. Journal Applied Econometrics, 25(1). Ghosh, S., Khare, K., & Michailidis, G. (2018). High-Dimensional Posterior Consistency Bayesian Vector Autoregressive Models. Journal American Statistical Association, 114(526).","code":""},{"path":"/reference/set_bvar.html","id":null,"dir":"Reference","previous_headings":"","what":"Hyperparameters for Bayesian Models — set_bvar","title":"Hyperparameters for Bayesian Models — set_bvar","text":"Set hyperparameters Bayesian VAR VHAR models.","code":""},{"path":"/reference/set_bvar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hyperparameters for Bayesian Models — set_bvar","text":"","code":"set_bvar(sigma, lambda = 0.1, delta, eps = 1e-04)  set_bvar_flat(U)  set_bvhar(sigma, lambda = 0.1, delta, eps = 1e-04)  set_weight_bvhar(sigma, lambda = 0.1, eps = 1e-04, daily, weekly, monthly)  # S3 method for bvharspec print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  knit_print.bvharspec(x, ...)"},{"path":"/reference/set_bvar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hyperparameters for Bayesian Models — set_bvar","text":"sigma Standard error vector variable (Default: sd) lambda Tightness prior around random walk white noise (Default: .1) delta Persistence (Default: Litterman sets 1 = random walk prior, White noise prior = 0) eps small number (Default: 1e-04) U Positive definite matrix. default, identity matrix dimension ncol(X0) daily delta VHAR type (Default: 1 Litterman) weekly Fill second part first block (Default: 1) monthly Fill third part first block (Default: 1) x bvharspec object digits digit option print ... used","code":""},{"path":"/reference/set_bvar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hyperparameters for Bayesian Models — set_bvar","text":"Every function returns bvharspec  class. list components arguments provided. argument specified, NULL assigned . default values mentioned considered fitting function. process Model name: BVAR, BVHAR prior Prior name: Minnesota (Minnesota prior BVAR), Hierarchical (Hierarchical prior BVAR), MN_VAR (BVHAR-S), MN_VHAR (BVHAR-L), Flat (Flat prior BVAR) sigma Vector value (bvharpriorspec class) assigned sigma lambda Value (bvharpriorspec class) assigned lambda delta Vector value assigned delta eps Value assigned epsilon set_weight_bvhar() different component delta due different construction. daily Vector value assigned daily weight weekly Vector value assigned weekly weight monthly Vector value assigned monthly weight","code":""},{"path":"/reference/set_bvar.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Hyperparameters for Bayesian Models — set_bvar","text":"Missing arguments set default values model function mentioned . set_bvar() sets hyperparameters bvar_minnesota(). delta (vector), lambda (length 1), sigma (vector), eps (vector) corresponds \\(\\delta_j\\), \\(\\lambda\\), \\(\\delta_j\\), \\(\\epsilon\\). \\(\\delta_i\\) related belief random walk. \\(\\delta_i = 1\\) , random walk prior \\(\\delta_i = 0\\) , white noise prior \\(\\lambda\\) controls overall tightness prior around two prior beliefs. \\(\\lambda = 0\\), posterior equivalent prior data influence estimates. \\(\\lambda = \\infty\\), posterior mean becomes OLS estimates (VAR). \\(\\sigma_i^2 / \\sigma_j^2\\) Minnesota moments explain data scales. set_bvar_flat sets hyperparameters bvar_flat(). set_bvhar() sets hyperparameters bvhar_minnesota() VAR-type Minnesota prior, .e. BVHAR-S model. set_weight_bvhar() sets hyperparameters bvhar_minnesota() VHAR-type Minnesota prior, .e. BVHAR-L model.","code":""},{"path":"/reference/set_bvar.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Hyperparameters for Bayesian Models — set_bvar","text":"using set_psi() set_lambda() , hierarchical modeling available.","code":""},{"path":"/reference/set_bvar.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Hyperparameters for Bayesian Models — set_bvar","text":"Bańbura, M., Giannone, D., & Reichlin, L. (2010). Large Bayesian vector auto regressions. Journal Applied Econometrics, 25(1). Litterman, R. B. (1986). Forecasting Bayesian Vector Autoregressions: Five Years Experience. Journal Business & Economic Statistics, 4(1), 25. Ghosh, S., Khare, K., & Michailidis, G. (2018). High-Dimensional Posterior Consistency Bayesian Vector Autoregressive Models. Journal American Statistical Association, 114(526). Kim, Y. G., Baek, C. (2023+). Bayesian vector heterogeneous autoregressive modeling. Journal Statistical Computation Simulation. Kim, Y. G., Baek, C. (2023+). Bayesian vector heterogeneous autoregressive modeling. Journal Statistical Computation Simulation.","code":""},{"path":[]},{"path":"/reference/set_bvar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hyperparameters for Bayesian Models — set_bvar","text":"","code":"# Minnesota BVAR specification------------------------ bvar_spec <- set_bvar(   sigma = c(.03, .02, .01), # Sigma = diag(.03^2, .02^2, .01^2)   lambda = .2, # lambda = .2   delta = rep(.1, 3), # delta1 = .1, delta2 = .1, delta3 = .1   eps = 1e-04 # eps = 1e-04 ) class(bvar_spec) #> [1] \"bvharspec\" str(bvar_spec) #> List of 6 #>  $ process: chr \"BVAR\" #>  $ prior  : chr \"Minnesota\" #>  $ sigma  : num [1:3] 0.03 0.02 0.01 #>  $ lambda : num 0.2 #>  $ delta  : num [1:3] 0.1 0.1 0.1 #>  $ eps    : num 1e-04 #>  - attr(*, \"class\")= chr \"bvharspec\" # Flat BVAR specification------------------------- # 3-dim # p = 5 with constant term # U = 500 * I(mp + 1) bvar_flat_spec <- set_bvar_flat(U = 500 * diag(16)) class(bvar_flat_spec) #> [1] \"bvharspec\" str(bvar_flat_spec) #> List of 3 #>  $ process: chr \"BVAR\" #>  $ prior  : chr \"Flat\" #>  $ U      : num [1:16, 1:16] 500 0 0 0 0 0 0 0 0 0 ... #>  - attr(*, \"class\")= chr \"bvharspec\" # BVHAR-S specification----------------------- bvhar_var_spec <- set_bvhar(   sigma = c(.03, .02, .01), # Sigma = diag(.03^2, .02^2, .01^2)   lambda = .2, # lambda = .2   delta = rep(.1, 3), # delta1 = .1, delta2 = .1, delta3 = .1   eps = 1e-04 # eps = 1e-04 ) class(bvhar_var_spec) #> [1] \"bvharspec\" str(bvhar_var_spec) #> List of 6 #>  $ process: chr \"BVHAR\" #>  $ prior  : chr \"MN_VAR\" #>  $ sigma  : num [1:3] 0.03 0.02 0.01 #>  $ lambda : num 0.2 #>  $ delta  : num [1:3] 0.1 0.1 0.1 #>  $ eps    : num 1e-04 #>  - attr(*, \"class\")= chr \"bvharspec\" # BVHAR-L specification--------------------------- bvhar_vhar_spec <- set_weight_bvhar(   sigma = c(.03, .02, .01), # Sigma = diag(.03^2, .02^2, .01^2)   lambda = .2, # lambda = .2   eps = 1e-04, # eps = 1e-04   daily = rep(.2, 3), # daily1 = .2, daily2 = .2, daily3 = .2   weekly = rep(.1, 3), # weekly1 = .1, weekly2 = .1, weekly3 = .1   monthly = rep(.05, 3) # monthly1 = .05, monthly2 = .05, monthly3 = .05 ) class(bvhar_vhar_spec) #> [1] \"bvharspec\" str(bvhar_vhar_spec) #> List of 8 #>  $ process: chr \"BVHAR\" #>  $ prior  : chr \"MN_VHAR\" #>  $ sigma  : num [1:3] 0.03 0.02 0.01 #>  $ lambda : num 0.2 #>  $ eps    : num 1e-04 #>  $ daily  : num [1:3] 0.2 0.2 0.2 #>  $ weekly : num [1:3] 0.1 0.1 0.1 #>  $ monthly: num [1:3] 0.05 0.05 0.05 #>  - attr(*, \"class\")= chr \"bvharspec\""},{"path":"/reference/set_horseshoe.html","id":null,"dir":"Reference","previous_headings":"","what":"Horseshoe Prior Specification — set_horseshoe","title":"Horseshoe Prior Specification — set_horseshoe","text":"Set initial hyperparameters parameter starting Gibbs sampler Horseshoe prior.","code":""},{"path":"/reference/set_horseshoe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Horseshoe Prior Specification — set_horseshoe","text":"","code":"set_horseshoe(local_sparsity = 1, global_sparsity = 1)  # S3 method for horseshoespec print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  knit_print.horseshoespec(x, ...)"},{"path":"/reference/set_horseshoe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Horseshoe Prior Specification — set_horseshoe","text":"local_sparsity Initial local shrinkage hyperparameters global_sparsity Initial global shrinkage hyperparameter x horseshoespec digits digit option print ... used","code":""},{"path":"/reference/set_horseshoe.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Horseshoe Prior Specification — set_horseshoe","text":"Set horseshoe prior initialization VAR family. local_sparsity: Local shrinkage row coefficients matrix. global_sparsity: (Initial) global shrinkage. init_cov: Initial covariance matrix. package, horseshoe prior model estimated Gibbs sampling, initial means initial values gibbs sampler.","code":""},{"path":"/reference/set_horseshoe.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Horseshoe Prior Specification — set_horseshoe","text":"Carvalho, C. M., Polson, N. G., & Scott, J. G. (2010). horseshoe estimator sparse signals. Biometrika, 97(2), 465–480. Makalic, E., & Schmidt, D. F. (2016). Simple Sampler Horseshoe Estimator. IEEE Signal Processing Letters, 23(1), 179–182.","code":""},{"path":"/reference/set_lambda.html","id":null,"dir":"Reference","previous_headings":"","what":"Hyperpriors for Bayesian Models — set_lambda","title":"Hyperpriors for Bayesian Models — set_lambda","text":"Set hyperpriors Bayesian VAR VHAR models.","code":""},{"path":"/reference/set_lambda.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hyperpriors for Bayesian Models — set_lambda","text":"","code":"set_lambda(mode = 0.2, sd = 0.4, lower = 1e-05, upper = 3)  set_psi(shape = 4e-04, scale = 4e-04, lower = 1e-05, upper = 3)  # S3 method for bvharpriorspec print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  knit_print.bvharpriorspec(x, ...)"},{"path":"/reference/set_lambda.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hyperpriors for Bayesian Models — set_lambda","text":"mode Mode Gamma distribution. default, .2. sd Standard deviation Gamma distribution. default, .4. lower Lower bound stats::optim(). default, 1e-5. upper Upper bound stats::optim(). default, 3. shape Shape Inverse Gamma distribution. default, (.02)^2. scale Scale Inverse Gamma distribution. default, (.02)^2. x bvharpriorspec object digits digit option print ... used","code":""},{"path":"/reference/set_lambda.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hyperpriors for Bayesian Models — set_lambda","text":"bvharpriorspec object","code":""},{"path":"/reference/set_lambda.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Hyperpriors for Bayesian Models — set_lambda","text":"addition Normal-IW priors set_bvar(), set_bvhar(), set_weight_bvhar(), functions give hierarchical structure model. set_lambda() specifies hyperprior \\(\\lambda\\) (lambda), Gamma distribution. set_psi() specifies hyperprior \\(\\psi / (\\nu_0 - k - 1) = \\sigma^2\\) (sigma), Inverse gamma distribution. following set (mode, sd) recommended Sims Zha (1998) set_lambda(). (mode = .2, sd = .4): default (mode = 1, sd = 1) Giannone et al. (2015) suggested data-based selection set_psi(). chooses (0.02)^2 based empirical data set.","code":""},{"path":"/reference/set_lambda.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Hyperpriors for Bayesian Models — set_lambda","text":"Giannone, D., Lenza, M., & Primiceri, G. E. (2015). Prior Selection Vector Autoregressions. Review Economics Statistics, 97(2).","code":""},{"path":"/reference/set_lambda.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hyperpriors for Bayesian Models — set_lambda","text":"","code":"# Hirearchical BVAR specification------------------------ set_bvar(   sigma = set_psi(shape = 4e-4, scale = 4e-4),   lambda = set_lambda(mode = .2, sd = .4),   delta = rep(1, 3),   eps = 1e-04 # eps = 1e-04 ) #> Model Specification for BVAR #>  #> Parameters: Coefficent matrice and Covariance matrix #> Prior: MN_Hierarchical #> # Type '?bvar_' in the console for some help. #> ======================================================== #>  #> Setting for 'sigma': #> Hyperprior specification for psi #>  #> [1]  psi ~ Inv-Gamma(shape = 4e-04, scale =4e-04) #> with mode: 0.000 #> Setting for 'lambda': #> Hyperprior specification for lambda #>  #> [1]  lambda ~ Gamma(shape = 1.64038820320221, rate =3.20194101601104) #> with mode: 0.200 #> Setting for 'delta': #> [1]  1  1  1 #>  #> Setting for 'eps': #> [1]  1e-04 #>"},{"path":"/reference/set_ssvs.html","id":null,"dir":"Reference","previous_headings":"","what":"Stochastic Search Variable Selection (SSVS) Hyperparameter for Coefficients Matrix and Cholesky Factor — set_ssvs","title":"Stochastic Search Variable Selection (SSVS) Hyperparameter for Coefficients Matrix and Cholesky Factor — set_ssvs","text":"Set SSVS hyperparameters VAR VHAR coefficient matrix Cholesky factor.","code":""},{"path":"/reference/set_ssvs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stochastic Search Variable Selection (SSVS) Hyperparameter for Coefficients Matrix and Cholesky Factor — set_ssvs","text":"","code":"set_ssvs(   coef_spike = 0.1,   coef_slab = 5,   coef_mixture = 0.5,   mean_non = 0,   sd_non = 0.1,   shape = 0.01,   rate = 0.01,   chol_spike = 0.1,   chol_slab = 5,   chol_mixture = 0.5 )  # S3 method for ssvsinput print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  knit_print.ssvsinput(x, ...)"},{"path":"/reference/set_ssvs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stochastic Search Variable Selection (SSVS) Hyperparameter for Coefficients Matrix and Cholesky Factor — set_ssvs","text":"coef_spike Standard deviance Spike normal distribution (See Details). coef_slab Standard deviance Slab normal distribution (See Details). coef_mixture Bernoulli parameter sparsity proportion (See Details). mean_non Prior mean unrestricted coefficients sd_non Standard deviance unrestricted coefficients shape Gamma shape parameters precision matrix (See Details). rate Gamma rate parameters precision matrix (See Details). chol_spike Standard deviance Spike normal distribution, cholesky factor (See Details). chol_slab Standard deviance Slab normal distribution, cholesky factor (See Details). chol_mixture Bernoulli parameter sparsity proportion, cholesky factor (See Details). x ssvsinput digits digit option print ... used","code":""},{"path":"/reference/set_ssvs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stochastic Search Variable Selection (SSVS) Hyperparameter for Coefficients Matrix and Cholesky Factor — set_ssvs","text":"ssvsinput object","code":""},{"path":"/reference/set_ssvs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Stochastic Search Variable Selection (SSVS) Hyperparameter for Coefficients Matrix and Cholesky Factor — set_ssvs","text":"Let \\(\\alpha\\) vectorized coefficient, \\(\\alpha = vec()\\). Spike-slab prior given using two normal distributions. $$\\alpha_j \\mid \\gamma_j \\sim (1 - \\gamma_j) N(0, \\tau_{0j}^2) + \\gamma_j N(0, \\tau_{1j}^2)$$ spike-slab prior suggests, set \\(\\tau_{0j}\\) small (point mass zero: spike distribution) set \\(\\tau_{1j}\\) large (symmetric zero: slab distribution). \\(\\gamma_j\\) proportion nonzero coefficients follows $$\\gamma_j \\sim Bernoulli(p_j)$$ coef_spike: \\(\\tau_{0j}\\) coef_slab: \\(\\tau_{1j}\\) coef_mixture: \\(p_j\\) \\(j = 1, \\ldots, mk\\): vectorized format corresponding coefficient matrix one value provided, model function read replicated value. coef_non: vectorized constant term given prior Normal distribution variance \\(cI\\). , coef_non \\(\\sqrt{c}\\). Next precision matrix \\(\\Sigma_e^{-1}\\), SSVS applies Cholesky decomposition. $$\\Sigma_e^{-1} = \\Psi \\Psi^T$$ \\(\\Psi = \\{\\psi_{ij}\\}\\) upper triangular. Diagonal components follow gamma distribution. $$\\psi_{jj}^2 \\sim Gamma(shape = a_j, rate = b_j)$$ row -diagonal (upper-triangular) components, apply spike-slab prior . $$\\psi_{ij} \\mid w_{ij} \\sim (1 - w_{ij}) N(0, \\kappa_{0,ij}^2) + w_{ij} N(0, \\kappa_{1,ij}^2)$$ $$w_{ij} \\sim Bernoulli(q_{ij})$$ shape: \\(a_j\\) rate: \\(b_j\\) chol_spike: \\(\\kappa_{0,ij}\\) chol_slab: \\(\\kappa_{1,ij}\\) chol_mixture: \\(q_{ij}\\) \\(j = 1, \\ldots, mk\\): vectorized format corresponding coefficient matrix \\(= 1, \\ldots, j - 1\\) \\(j = 2, \\ldots, m\\): \\(\\eta = (\\psi_{12}, \\psi_{13}, \\psi_{23}, \\psi_{14}, \\ldots, \\psi_{34}, \\ldots, \\psi_{1m}, \\ldots, \\psi_{m - 1, m})^T\\) chol_ arguments can one value replication, vector, upper triangular matrix.","code":""},{"path":"/reference/set_ssvs.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Stochastic Search Variable Selection (SSVS) Hyperparameter for Coefficients Matrix and Cholesky Factor — set_ssvs","text":"George, E. ., & McCulloch, R. E. (1993). Variable Selection via Gibbs Sampling. Journal American Statistical Association, 88(423), 881–889. George, E. ., Sun, D., & Ni, S. (2008). Bayesian stochastic search VAR model restrictions. Journal Econometrics, 142(1), 553–580. Koop, G., & Korobilis, D. (2009). Bayesian Multivariate Time Series Methods Empirical Macroeconomics. Foundations Trends® Econometrics, 3(4), 267–358.","code":""},{"path":"/reference/sim_horseshoe_var.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Horseshoe Parameters — sim_horseshoe_var","title":"Generate Horseshoe Parameters — sim_horseshoe_var","text":"function generates parameters VAR Horseshoe prior.","code":""},{"path":"/reference/sim_horseshoe_var.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Horseshoe Parameters — sim_horseshoe_var","text":"","code":"sim_horseshoe_var(   p,   dim_data = NULL,   include_mean = TRUE,   minnesota = FALSE,   method = c(\"eigen\", \"chol\") )  sim_horseshoe_vhar(   har = c(5, 22),   dim_data = NULL,   include_mean = TRUE,   minnesota = c(\"no\", \"short\", \"longrun\"),   method = c(\"eigen\", \"chol\") )"},{"path":"/reference/sim_horseshoe_var.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Horseshoe Parameters — sim_horseshoe_var","text":"p VAR lag dim_data Specify dimension data hyperparameters bayes_spec constant values. include_mean Add constant term (Default: TRUE) (FALSE) minnesota use -diagonal terms coefficient matrices restriction. sim_horseshoe_var() function, use TRUE FALSE (default). sim_horseshoe_vhar() function, \"\" (default), \"short\" type, \"longrun\" type. method Method compute \\(\\Sigma^{1/2}\\). har Numeric vector weekly monthly order. default, c(5, 22).","code":""},{"path":"/reference/sim_iw.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Inverse-Wishart Random Matrix — sim_iw","title":"Generate Inverse-Wishart Random Matrix — sim_iw","text":"function samples one matrix IW matrix.","code":""},{"path":"/reference/sim_iw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Inverse-Wishart Random Matrix — sim_iw","text":"","code":"sim_iw(mat_scale, shape)"},{"path":"/reference/sim_iw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Inverse-Wishart Random Matrix — sim_iw","text":"mat_scale Scale matrix shape Shape","code":""},{"path":"/reference/sim_iw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Inverse-Wishart Random Matrix — sim_iw","text":"One k x k matrix following IW distribution","code":""},{"path":"/reference/sim_iw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate Inverse-Wishart Random Matrix — sim_iw","text":"Consider \\(\\Sigma \\sim IW(\\Psi, \\nu)\\). Upper triangular Bartlett decomposition: k x k matrix \\(Q = [q_{ij}]\\) upper triangular \\(q_{ii}^2 \\chi_{\\nu - + 1}^2\\) \\(q_{ij} \\sim N(0, 1)\\) < j (upper triangular) Lower triangular Cholesky decomposition: \\(\\Psi = L L^T\\) \\(= L (Q^{-1})^T\\) \\(\\Sigma = ^T \\sim IW(\\Psi, \\nu)\\)","code":""},{"path":"/reference/sim_matgaussian.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Matrix Normal Random Matrix — sim_matgaussian","title":"Generate Matrix Normal Random Matrix — sim_matgaussian","text":"function samples one matrix gaussian matrix.","code":""},{"path":"/reference/sim_matgaussian.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Matrix Normal Random Matrix — sim_matgaussian","text":"","code":"sim_matgaussian(mat_mean, mat_scale_u, mat_scale_v)"},{"path":"/reference/sim_matgaussian.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Matrix Normal Random Matrix — sim_matgaussian","text":"mat_mean Mean matrix mat_scale_u First scale matrix mat_scale_v Second scale matrix","code":""},{"path":"/reference/sim_matgaussian.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Matrix Normal Random Matrix — sim_matgaussian","text":"One n x k matrix following MN distribution.","code":""},{"path":"/reference/sim_matgaussian.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate Matrix Normal Random Matrix — sim_matgaussian","text":"Consider n x k matrix \\(Y_1, \\ldots, Y_n \\sim MN(M, U, V)\\) M n x k, U n x n, V k x k. Lower triangular Cholesky decomposition: \\(U = P P^T\\) \\(V = L L^T\\) Standard normal generation: s x m matrix \\(Z_i = [z_{ij} \\sim N(0, 1)]\\) row-wise direction. \\(Y_i = M + P Z_i L^T\\) function generates one matrix, .e. \\(Y_1\\).","code":""},{"path":"/reference/sim_mncoef.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Minnesota BVAR Parameters — sim_mncoef","title":"Generate Minnesota BVAR Parameters — sim_mncoef","text":"function generates parameters BVAR Minnesota prior.","code":""},{"path":"/reference/sim_mncoef.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Minnesota BVAR Parameters — sim_mncoef","text":"","code":"sim_mncoef(p, bayes_spec = set_bvar(), full = TRUE)"},{"path":"/reference/sim_mncoef.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Minnesota BVAR Parameters — sim_mncoef","text":"p VAR lag bayes_spec BVAR model specification set_bvar(). full Generate variance matrix IW (default: TRUE) (FALSE)?","code":""},{"path":"/reference/sim_mncoef.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Minnesota BVAR Parameters — sim_mncoef","text":"List following component. coefficients BVAR coefficient (MN) covmat BVAR variance (IW diagonal matrix sigma bayes_spec)","code":""},{"path":"/reference/sim_mncoef.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate Minnesota BVAR Parameters — sim_mncoef","text":"Implementing dummy observation constructions, Bańbura et al. (2010) sets Normal-IW prior. $$\\mid \\Sigma_e \\sim MN(A_0, \\Omega_0, \\Sigma_e)$$ $$\\Sigma_e \\sim IW(S_0, \\alpha_0)$$ full = FALSE, result \\(\\Sigma_e\\) input (diag(sigma)).","code":""},{"path":"/reference/sim_mncoef.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generate Minnesota BVAR Parameters — sim_mncoef","text":"Bańbura, M., Giannone, D., & Reichlin, L. (2010). Large Bayesian vector auto regressions. Journal Applied Econometrics, 25(1). Karlsson, S. (2013). Chapter 15 Forecasting Bayesian Vector Autoregression. Handbook Economic Forecasting, 2, 791–897. Litterman, R. B. (1986). Forecasting Bayesian Vector Autoregressions: Five Years Experience. Journal Business & Economic Statistics, 4(1), 25.","code":""},{"path":[]},{"path":"/reference/sim_mncoef.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Minnesota BVAR Parameters — sim_mncoef","text":"","code":"# Generate (A, Sigma) # BVAR(p = 2) # sigma: 1, 1, 1 # lambda: .1 # delta: .1, .1, .1 # epsilon: 1e-04 set.seed(1) sim_mncoef(   p = 2,   bayes_spec = set_bvar(     sigma = rep(1, 3),     lambda = .1,     delta = rep(.1, 3),     eps = 1e-04   ),   full = TRUE ) #> $coefficients #>              [,1]         [,2]         [,3] #> [1,] -0.008928370  0.002721103  0.092414563 #> [2,]  0.049041658 -0.027508268 -0.032011373 #> [3,] -0.018590620 -0.008312152 -0.023491591 #> [4,]  0.008099504 -0.017944600  0.007603526 #> [5,] -0.039740346  0.001970018 -0.017502085 #> [6,]  0.004281752  0.014382071  0.007386941 #>  #> $covmat #>             [,1]        [,2]       [,3] #> [1,]  0.41248285 -0.06400052 0.24882667 #> [2,] -0.06400052  0.14995663 0.01758338 #> [3,]  0.24882667  0.01758338 0.35941383 #>"},{"path":"/reference/sim_mniw.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Normal-IW Random Family — sim_mniw","title":"Generate Normal-IW Random Family — sim_mniw","text":"function samples normal inverse-wishart matrices.","code":""},{"path":"/reference/sim_mniw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Normal-IW Random Family — sim_mniw","text":"","code":"sim_mniw(num_sim, mat_mean, mat_scale_u, mat_scale, shape)"},{"path":"/reference/sim_mniw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Normal-IW Random Family — sim_mniw","text":"num_sim Number generate mat_mean Mean matrix MN mat_scale_u First scale matrix MN mat_scale Scale matrix IW shape Shape IW","code":""},{"path":"/reference/sim_mniw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Normal-IW Random Family — sim_mniw","text":"List MN IW matrices. Multiple samples column-stacked.","code":""},{"path":"/reference/sim_mniw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate Normal-IW Random Family — sim_mniw","text":"Consider \\((Y_i, \\Sigma_i) \\sim MIW(M, U, \\Psi, \\nu)\\). Generate upper triangular factor \\(\\Sigma_i = C_i C_i^T\\) upper triangular Bartlett decomposition. Standard normal generation: n x k matrix \\(Z_i = [z_{ij} \\sim N(0, 1)]\\) row-wise direction. Lower triangular Cholesky decomposition: \\(U = P P^T\\) \\(A_i = M + P Z_i C_i^T\\)","code":""},{"path":"/reference/sim_mnormal.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Multivariate Normal Random Vector — sim_mnormal","title":"Generate Multivariate Normal Random Vector — sim_mnormal","text":"function samples n x muti-dimensional normal random matrix.","code":""},{"path":"/reference/sim_mnormal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Multivariate Normal Random Vector — sim_mnormal","text":"","code":"sim_mnormal(   num_sim,   mu = rep(0, 5),   sig = diag(5),   method = c(\"eigen\", \"chol\") )"},{"path":"/reference/sim_mnormal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Multivariate Normal Random Vector — sim_mnormal","text":"num_sim Number generate process mu Mean vector sig Variance matrix method Method compute \\(\\Sigma^{1/2}\\). Choose \"eigen\" (spectral decomposition) \"chol\" (cholesky decomposition). default, \"eigen\".","code":""},{"path":"/reference/sim_mnormal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Multivariate Normal Random Vector — sim_mnormal","text":"T x k matrix","code":""},{"path":"/reference/sim_mnormal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate Multivariate Normal Random Vector — sim_mnormal","text":"Consider \\(x_1, \\ldots, x_n \\sim N_m (\\mu, \\Sigma)\\). Lower triangular Cholesky decomposition: \\(\\Sigma = L L^T\\) Standard normal generation: \\(Z_{i1}, Z_{} \\stackrel{iid}{\\sim} N(0, 1)\\) \\(Z_i = (Z_{i1}, \\ldots, Z_{})^T\\) \\(X_i = L Z_i + \\mu\\)","code":""},{"path":"/reference/sim_mnvhar_coef.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Minnesota BVAR Parameters — sim_mnvhar_coef","title":"Generate Minnesota BVAR Parameters — sim_mnvhar_coef","text":"function generates parameters BVAR Minnesota prior.","code":""},{"path":"/reference/sim_mnvhar_coef.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Minnesota BVAR Parameters — sim_mnvhar_coef","text":"","code":"sim_mnvhar_coef(bayes_spec = set_bvhar(), full = TRUE)"},{"path":"/reference/sim_mnvhar_coef.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Minnesota BVAR Parameters — sim_mnvhar_coef","text":"bayes_spec BVHAR model specification set_bvhar() (default) set_weight_bvhar(). full Generate variance matrix IW (default: TRUE) (FALSE)?","code":""},{"path":"/reference/sim_mnvhar_coef.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Minnesota BVAR Parameters — sim_mnvhar_coef","text":"List following component. coefficients BVHAR coefficient (MN) covmat BVHAR variance (IW diagonal matrix sigma bayes_spec)","code":""},{"path":"/reference/sim_mnvhar_coef.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate Minnesota BVAR Parameters — sim_mnvhar_coef","text":"Normal-IW family vector HAR model: $$\\Phi \\mid \\Sigma_e \\sim MN(M_0, \\Omega_0, \\Sigma_e)$$ $$\\Sigma_e \\sim IW(\\Psi_0, \\nu_0)$$","code":""},{"path":"/reference/sim_mnvhar_coef.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generate Minnesota BVAR Parameters — sim_mnvhar_coef","text":"Kim, Y. G., Baek, C. (n.d.). Bayesian vector heterogeneous autoregressive modeling. submitted.","code":""},{"path":[]},{"path":"/reference/sim_mnvhar_coef.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Minnesota BVAR Parameters — sim_mnvhar_coef","text":"","code":"# Generate (Phi, Sigma) # BVHAR-S # sigma: 1, 1, 1 # lambda: .1 # delta: .1, .1, .1 # epsilon: 1e-04 set.seed(1) sim_mnvhar_coef(   bayes_spec = set_bvhar(     sigma = rep(1, 3),     lambda = .1,     delta = rep(.1, 3),     eps = 1e-04   ),   full = TRUE ) #> $coefficients #>               [,1]         [,2]         [,3] #>  [1,] -0.008928370  0.002721103  0.092414563 #>  [2,]  0.049041658 -0.027508268 -0.032011373 #>  [3,] -0.018590620 -0.008312152 -0.023491591 #>  [4,]  0.008099504 -0.017944600  0.007603526 #>  [5,] -0.039740346  0.001970018 -0.017502085 #>  [6,]  0.004281752  0.014382071  0.007386941 #>  [7,]  0.010781378  0.011870368  0.001985094 #>  [8,] -0.027501057  0.004849875 -0.019751320 #>  [9,] -0.011622302 -0.003601531 -0.018535816 #>  #> $covmat #>             [,1]        [,2]       [,3] #> [1,]  0.41248285 -0.06400052 0.24882667 #> [2,] -0.06400052  0.14995663 0.01758338 #> [3,]  0.24882667  0.01758338 0.35941383 #>"},{"path":"/reference/sim_mvt.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Multivariate t Random Vector — sim_mvt","title":"Generate Multivariate t Random Vector — sim_mvt","text":"function samples n x multi-dimensional t-random matrix.","code":""},{"path":"/reference/sim_mvt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Multivariate t Random Vector — sim_mvt","text":"","code":"sim_mvt(num_sim, df, mu, sig, method = c(\"eigen\", \"chol\"))"},{"path":"/reference/sim_mvt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Multivariate t Random Vector — sim_mvt","text":"num_sim Number generate process. df Degrees freedom. mu Location vector sig Scale matrix. method Method compute \\(\\Sigma^{1/2}\\). Choose \"eigen\" (spectral decomposition) \"chol\" (cholesky decomposition). default, \"eigen\".","code":""},{"path":"/reference/sim_mvt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Multivariate t Random Vector — sim_mvt","text":"T x k matrix","code":""},{"path":"/reference/sim_ssvs_var.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate SSVS Parameters — sim_ssvs_var","title":"Generate SSVS Parameters — sim_ssvs_var","text":"function generates parameters VAR SSVS prior.","code":""},{"path":"/reference/sim_ssvs_var.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate SSVS Parameters — sim_ssvs_var","text":"","code":"sim_ssvs_var(   bayes_spec,   p,   dim_data = NULL,   include_mean = TRUE,   minnesota = FALSE,   mn_prob = 1,   method = c(\"eigen\", \"chol\") )  sim_ssvs_vhar(   bayes_spec,   har = c(5, 22),   dim_data = NULL,   include_mean = TRUE,   minnesota = c(\"no\", \"short\", \"longrun\"),   mn_prob = 1,   method = c(\"eigen\", \"chol\") )"},{"path":"/reference/sim_ssvs_var.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate SSVS Parameters — sim_ssvs_var","text":"bayes_spec SSVS model specification set_ssvs(). p VAR lag dim_data Specify dimension data hyperparameters bayes_spec constant values. include_mean Add constant term (Default: TRUE) (FALSE) minnesota use -diagonal terms coefficient matrices restriction. sim_ssvs_var() function, use TRUE FALSE (default). sim_ssvs_vhar() function, \"\" (default), \"short\" type, \"longrun\" type. mn_prob Probability -lags. method Method compute \\(\\Sigma^{1/2}\\). har Numeric vector weekly monthly order. default, c(5, 22).","code":""},{"path":"/reference/sim_ssvs_var.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate SSVS Parameters — sim_ssvs_var","text":"List including coefficients.","code":""},{"path":"/reference/sim_ssvs_var.html","id":"var-p-with-ssvs-prior","dir":"Reference","previous_headings":"","what":"VAR(p) with SSVS prior","title":"Generate SSVS Parameters — sim_ssvs_var","text":"Let \\(\\alpha\\) vectorized coefficient VAR(p). $$(\\alpha \\mid \\gamma)$$ $$(\\gamma_i)$$ $$(\\eta_j \\mid \\omega_j)$$ $$(\\omega_{ij})$$ $$(\\psi_{ii}^2)$$","code":""},{"path":"/reference/sim_ssvs_var.html","id":"vhar-with-ssvs-prior","dir":"Reference","previous_headings":"","what":"VHAR with SSVS prior","title":"Generate SSVS Parameters — sim_ssvs_var","text":"Let \\(\\phi\\) vectorized coefficient VHAR. $$(\\phi \\mid \\gamma)$$ $$(\\gamma_i)$$ $$(\\eta_j \\mid \\omega_j)$$ $$(\\omega_{ij})$$ $$(\\psi_{ii}^2)$$","code":""},{"path":"/reference/sim_ssvs_var.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generate SSVS Parameters — sim_ssvs_var","text":"George, E. ., & McCulloch, R. E. (1993). Variable Selection via Gibbs Sampling. Journal American Statistical Association, 88(423), 881–889. George, E. ., Sun, D., & Ni, S. (2008). Bayesian stochastic search VAR model restrictions. Journal Econometrics, 142(1), 553–580. Ghosh, S., Khare, K., & Michailidis, G. (2018). High-Dimensional Posterior Consistency Bayesian Vector Autoregressive Models. Journal American Statistical Association, 114(526). Koop, G., & Korobilis, D. (2009). Bayesian Multivariate Time Series Methods Empirical Macroeconomics. Foundations Trends® Econometrics, 3(4), 267–358.","code":""},{"path":"/reference/sim_var.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Multivariate Time Series Process Following VAR(p) — sim_var","title":"Generate Multivariate Time Series Process Following VAR(p) — sim_var","text":"function generates multivariate time series dataset follows VAR(p).","code":""},{"path":"/reference/sim_var.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Multivariate Time Series Process Following VAR(p) — sim_var","text":"","code":"sim_var(   num_sim,   num_burn,   var_coef,   var_lag,   sig_error = diag(ncol(var_coef)),   init = matrix(0L, nrow = var_lag, ncol = ncol(var_coef)),   method = c(\"eigen\", \"chol\"),   process = c(\"gaussian\", \"student\"),   t_param = 5 )"},{"path":"/reference/sim_var.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Multivariate Time Series Process Following VAR(p) — sim_var","text":"num_sim Number generated process num_burn Number burn-var_coef VAR coefficient. format output coef.varlse() var_lm() var_lag Lag VAR sig_error Variance matrix error term. default, diag(dim). init Initial y1, ..., yp matrix simulate VAR model. Try matrix(0L, nrow = var_lag, ncol = dim). method Method compute \\(\\Sigma^{1/2}\\). Choose \"eigen\" (spectral decomposition) \"chol\" (cholesky decomposition). default, \"eigen\". process Process generate error term. \"gaussian\": Normal distribution (default) \"student\": Multivariate t-distribution. t_param argument MVT, e.g. DF: 5.","code":""},{"path":"/reference/sim_var.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Multivariate Time Series Process Following VAR(p) — sim_var","text":"T x k matrix","code":""},{"path":"/reference/sim_var.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate Multivariate Time Series Process Following VAR(p) — sim_var","text":"Generate \\(\\epsilon_1, \\epsilon_n \\sim N(0, \\Sigma)\\) = 1, ... n, $$y_{p + } = (y_{p + - 1}^T, \\ldots, y_i^T, 1)^T B + \\epsilon_i$$ output \\((y_{p + 1}, \\ldots, y_{n + p})^T\\) Initial values might set zero vector \\((I_m - A_1 - \\cdots - A_p)^{-1} c\\).","code":""},{"path":"/reference/sim_var.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generate Multivariate Time Series Process Following VAR(p) — sim_var","text":"Lütkepohl, H. (2007). New Introduction Multiple Time Series Analysis. Springer Publishing.","code":""},{"path":"/reference/sim_vhar.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Multivariate Time Series Process Following VAR(p) — sim_vhar","title":"Generate Multivariate Time Series Process Following VAR(p) — sim_vhar","text":"function generates multivariate time series dataset follows VAR(p).","code":""},{"path":"/reference/sim_vhar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Multivariate Time Series Process Following VAR(p) — sim_vhar","text":"","code":"sim_vhar(   num_sim,   num_burn,   vhar_coef,   week = 5L,   month = 22L,   sig_error = diag(ncol(vhar_coef)),   init = matrix(0L, nrow = month, ncol = ncol(vhar_coef)),   method = c(\"eigen\", \"chol\"),   process = c(\"gaussian\", \"student\"),   t_param = 5 )"},{"path":"/reference/sim_vhar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Multivariate Time Series Process Following VAR(p) — sim_vhar","text":"num_sim Number generated process num_burn Number burn-vhar_coef VAR coefficient. format output coef.varlse() var_lm() week Weekly order VHAR. default, 5. month Weekly order VHAR. default, 22. sig_error Variance matrix error term. default, diag(dim). init Initial y1, ..., yp matrix simulate VAR model. Try matrix(0L, nrow = month, ncol = dim). method Method compute \\(\\Sigma^{1/2}\\). Choose \"eigen\" (spectral decomposition) \"chol\" (cholesky decomposition). default, \"eigen\". process Process generate error term. \"gaussian\": Normal distribution (default) \"student\": Multivariate t-distribution. t_param argument MVT, e.g. DF: 5.","code":""},{"path":"/reference/sim_vhar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Multivariate Time Series Process Following VAR(p) — sim_vhar","text":"T x k matrix","code":""},{"path":"/reference/sim_vhar.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate Multivariate Time Series Process Following VAR(p) — sim_vhar","text":"Let \\(M\\) month order, e.g. \\(M = 22\\). Generate \\(\\epsilon_1, \\epsilon_n \\sim N(0, \\Sigma)\\) = 1, ... n, $$y_{M + } = (y_{M + - 1}^T, \\ldots, y_i^T, 1)^T C_{HAR}^T \\Phi + \\epsilon_i$$ output \\((y_{M + 1}, \\ldots, y_{n + M})^T\\) = 1, ... n, $$y_{p + } = (y_{p + - 1}^T, \\ldots, y_i^T, 1)^T B + \\epsilon_i$$ output \\((y_{p + 1}, \\ldots, y_{n + p})^T\\) Initial values might set zero vector \\((I_m - A_1 - \\cdots - A_p)^{-1} c\\).","code":""},{"path":"/reference/sim_vhar.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generate Multivariate Time Series Process Following VAR(p) — sim_vhar","text":"Lütkepohl, H. (2007). New Introduction Multiple Time Series Analysis. Springer Publishing.","code":""},{"path":"/reference/split_coef.html","id":null,"dir":"Reference","previous_headings":"","what":"Splitting Coefficient Matrix into List — split_coef","title":"Splitting Coefficient Matrix into List — split_coef","text":"Split coefficients matrix list.","code":""},{"path":"/reference/split_coef.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Splitting Coefficient Matrix into List — split_coef","text":"","code":"split_coef(object, ...)  # S3 method for bvharmod split_coef(object, ...)  # S3 method for bvharirf split_coef(object, ...)"},{"path":"/reference/split_coef.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Splitting Coefficient Matrix into List — split_coef","text":"object bvharmod object ... used","code":""},{"path":"/reference/split_coef.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Splitting Coefficient Matrix into List — split_coef","text":"list object","code":""},{"path":"/reference/split_coef.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Splitting Coefficient Matrix into List — split_coef","text":"result var_lm(), vhar_lm(), bvar_minnesota(), bvar_flat(), bvhar_minnesota() subclass bvharmod. example, c(\"varlse\", \"bvharmod\").","code":""},{"path":"/reference/spne.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the Estimation Based on Spectral Norm Error — spne","title":"Evaluate the Estimation Based on Spectral Norm Error — spne","text":"function computes estimation error given estimated model true coefficient.","code":""},{"path":"/reference/spne.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the Estimation Based on Spectral Norm Error — spne","text":"","code":"spne(x, y, ...)  # S3 method for bvharsp spne(x, y, ...)"},{"path":"/reference/spne.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the Estimation Based on Spectral Norm Error — spne","text":"x Estimated model. y Coefficient matrix compared. ... used","code":""},{"path":"/reference/spne.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the Estimation Based on Spectral Norm Error — spne","text":"Spectral norm value","code":""},{"path":"/reference/spne.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the Estimation Based on Spectral Norm Error — spne","text":"Let \\(\\lVert \\cdot \\rVert_2\\) spectral norm matrix, let \\(\\hat{\\Phi}\\) estimates, let \\(\\Phi\\) true coefficients matrix. function computes estimation error $$\\lVert \\hat{\\Phi} - \\Phi \\rVert_2$$","code":""},{"path":"/reference/spne.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the Estimation Based on Spectral Norm Error — spne","text":"Ghosh, S., Khare, K., & Michailidis, G. (2018). High-Dimensional Posterior Consistency Bayesian Vector Autoregressive Models. Journal American Statistical Association, 114(526).","code":""},{"path":"/reference/ssvs_bvar_algo.html","id":null,"dir":"Reference","previous_headings":"","what":"Stochastic Search Variable Selection in VAR — ssvs_bvar_algo","title":"Stochastic Search Variable Selection in VAR — ssvs_bvar_algo","text":"page describes stochastic search variable selection (SSVS) MCMC algorithm VAR model.","code":""},{"path":"/reference/ssvs_bvar_algo.html","id":"ssvs-prior","dir":"Reference","previous_headings":"","what":"SSVS Prior","title":"Stochastic Search Variable Selection in VAR — ssvs_bvar_algo","text":"Consider vectorized formulation \\(vec(Y_0) = (I_k \\otimes X_0) vec() + vec(Z_0)\\). Bayesian VAR model, model handles coefficients \\(\\) variance matrix \\(\\Sigma_e\\). shrink \\(\\Sigma_e^{-1}\\), however, upper cholesky factor used alternative \\(\\Sigma_e^{-1} = \\Psi \\Psi^\\intercal\\) context.","code":""},{"path":"/reference/ssvs_bvar_algo.html","id":"prior-of-coefficients","dir":"Reference","previous_headings":"","what":"Prior of coefficients","title":"Stochastic Search Variable Selection in VAR — ssvs_bvar_algo","text":"\\(vec() = \\alpha = (\\alpha_1, \\ldots, \\alpha_{k^2 p + k})\\) except constant-corresponding term restricted \\(\\gamma = (\\gamma_1, \\ldots, \\gamma_{k^2 p})^\\intercal\\), dummy vector. $$   h_i = \\begin{cases}     \\tau_{0i} & \\text{} \\gamma_i = 0 \\\\     \\tau_{1i} & \\text{} \\gamma_i = 1   \\end{cases} $$ small \\(\\tau_{0j}\\) large \\(\\tau_{1j}\\). turn, \\(D = diag(h_1, \\ldots, h_{k^2 p})\\). Let \\(\\alpha_{coef}\\) restricted coefficients vector let \\(\\alpha_{non}\\) -restricted coefficients vector, .e. vectorized constant term. term prior. $$   \\alpha_{coef} \\mid \\gamma \\sim N(0_{k^2 p}, DD),   \\quad   \\alpha_{non} \\sim N(0_k, c I_k) $$ \\(c\\) large, prior influence \\(\\alpha_{non}\\) decreases. combining term appropriate order, $$\\alpha \\mid \\gamma \\sim N(0_{k^2 p + k}, M)$$ acquired $$   M_0 = I_{k p + 1} \\otimes \\begin{bmatrix}     DD & 0_{k^2 p} \\\\     0_{k^2 p}^\\intercal & c   \\end{bmatrix} $$ Sometimes nonzero prior mean \\(\\alpha_0\\) also considered.","code":""},{"path":"/reference/ssvs_bvar_algo.html","id":"prior-of-coefficients-restrictions","dir":"Reference","previous_headings":"","what":"Prior of Coefficients Restrictions","title":"Stochastic Search Variable Selection in VAR — ssvs_bvar_algo","text":"natural 0-1 \\(\\gamma_{j}\\) Bernoulli distribution. $$\\gamma_j \\sim Bernoulli(p_j)$$ information, set \\(p_j = 0.5\\).","code":""},{"path":"/reference/ssvs_bvar_algo.html","id":"prior-of-cholesky-factor","dir":"Reference","previous_headings":"","what":"Prior of Cholesky Factor","title":"Stochastic Search Variable Selection in VAR — ssvs_bvar_algo","text":"Let \\(\\Psi = [\\psi_{ij}] \\\\mathbb{R}^{k \\times k}\\). Recall \\(\\Psi\\) upper triangular matrix \\(\\Sigma_e^{-1} = \\Psi \\Psi^\\intercal\\). define prior distribution, George et al. (2008) divide matrix two parts Diagnonal element: \\(\\psi = (\\psi_{11}, \\ldots, \\psi_{kk})^\\intercal\\) -diagonal element: \\(\\eta_j = (\\psi_{1j}, \\ldots, \\psi_{j-1, j})^\\intercal, j = 2, \\ldots, k\\)","code":""},{"path":"/reference/ssvs_bvar_algo.html","id":"prior-of-off-diagonal-element","dir":"Reference","previous_headings":"","what":"Prior of off-diagonal element","title":"Stochastic Search Variable Selection in VAR — ssvs_bvar_algo","text":"restrict cholesky factor, dummy vector \\(\\omega_j = (\\omega_{1j}, \\ldots, \\omega_{j - 1, j})^\\intercal\\) corresponding -diagonal elements defined. matrix \\(D_j = diag(h_{1j}, \\ldots, h_{j-1, j})\\) defined $$   h_{ij} = \\begin{cases}     \\kappa_{0ij} & \\text{} \\omega_{ij} = 0 \\\\     \\kappa_{1ij} & \\text{} \\omega_{ij} = 1   \\end{cases} $$ small \\(\\kappa_{0ij}\\) large \\(\\kappa_{1ij}\\). coefficients vector, \\(\\eta_j\\) normal distribution $$\\eta_j \\mid \\omega_j \\sim N(0_{j - 1}, D_j D_j), j = 2, \\ldots, k$$","code":""},{"path":"/reference/ssvs_bvar_algo.html","id":"prior-of-off-diagonal-element-restrictions","dir":"Reference","previous_headings":"","what":"Prior of off-diagonal element restrictions","title":"Stochastic Search Variable Selection in VAR — ssvs_bvar_algo","text":"\\(\\gamma_j\\), \\(\\omega_{ij}\\) Bernoulli distribution. $$\\omega_{ij} \\sim Bernoulli(q_{ij})$$ \\(q_{ij} = 0.5\\) common choice.","code":""},{"path":"/reference/ssvs_bvar_algo.html","id":"prior-of-diagonal-element","dir":"Reference","previous_headings":"","what":"Prior of diagonal element","title":"Stochastic Search Variable Selection in VAR — ssvs_bvar_algo","text":"Since cholesky factor positive definite, diagonal element matrix given Gamma distribution. $$\\psi_{jj}^2 \\sim Gamma(shape = a_j, rate = b_j)$$","code":""},{"path":[]},{"path":"/reference/ssvs_bvar_algo.html","id":"full-conditional","dir":"Reference","previous_headings":"","what":"Full Conditional","title":"Stochastic Search Variable Selection in VAR — ssvs_bvar_algo","text":"George et al. (2008) presents every full conditionals. Let SSE matrix \\(S(\\hat{}) = (Y_0 - X_0 \\hat{})^\\intercal (Y_0 - X_0 \\hat{}) \\\\mathbb{R}^{k \\times k}\\), let \\(S_j\\) upper-left j x j block matrix \\(S()\\), let \\(s_j = (s_{1j}, \\ldots, s_{j - 1, j})^\\intercal\\) \\(S()\\). specified shape rate Gamma distribution \\(a_j\\) \\(b_j\\), $$   \\psi_{jj}^2 \\mid \\alpha, \\gamma, \\omega, Y_0 \\sim \\gamma(a_i + n / 2, B_i) $$ $$   B_i = \\begin{cases}     b_1 + s_{11} / 2 & \\text{} = 1 \\\\     b_i + (s_{ii} - s_i^\\intercal ( S_{- 1} + (D_i R_i D_i)^(-1) )^(-1) s_i) & \\text{} = 2, \\ldots, k   \\end{cases} $$ , \\(D_i = diag(h_{1j}, \\ldots, h_{- 1, }) \\\\mathbb{R}^{(j - 1) \\times (j - 1)}\\). every \\(j = 1, \\ldots, k\\), $$   \\eta_j \\mid \\alpha, \\gamma, \\omega, \\psi, Y_0 \\sim N (\\mu_j, \\Delta_j) $$ $$   \\mu_j = -\\psi_{jj} (S_{j - 1} + (D_j R_j D_j)^{-1})^{-1} s_j \\\\mathbb{R}^{j - 1},   \\Delta_j = (S_{j - 1} + (D_j R_j D_j)^{-1})^{-1} \\\\mathbb{R}^{(j - 1) \\times (j - 1)} $$ Consider restriction dummy vectors. $$   \\omega_{ij} \\mid \\eta_j, \\psi_j, \\alpha, \\gamma, \\omega_{j}^{(previous)} \\sim Bernoulli(\\frac{u_{ij1}}{u_{ij1} + u_{ij2}}) $$ $$   u_{ij1} = \\frac{1}{\\kappa_{1ij}} \\exp(- \\frac{\\psi_{ij}^2}{2 \\kappa_{1ij}^2}) q_{ij},   u_{ij2} = \\frac{1}{\\kappa_{0ij}} \\exp(- \\frac{\\psi_{ij}^2}{2 \\kappa_{0ij}^2}) (1 - q_{ij}) $$ Also, $$   \\gamma_j \\mid \\alpha, \\psi, \\eta, \\omega, Y_0 \\sim Bernoulli(\\frac{u_{i1}}{u_{j1} + u_{j2}}) $$ $$   u_{j1} = \\frac{1}{\\tau_{1j}} \\exp(- \\frac{\\alpha_j^2}{2 \\tau_{1j}^2})p_i,   u_{j2} = \\frac{1}{\\tau_{0j}} \\exp(- \\frac{\\alpha_j^2}{2 \\tau_{0j}^2})(1 - p_i) $$ case coefficients vector, $$\\alpha \\mid \\gamma, \\eta, \\omega, \\psi, Y_0 \\sim N (\\mu, \\Delta)$$ $$   \\mu = ( '     (\\Psi \\Psi^\\intercal) \\otimes (X_0 X_0^\\intercal) + M^{-1}   )^{-1} ( '     ( (\\Psi \\Psi^\\intercal) \\otimes (X_0 X_0^\\intercal) ) \\hat{\\alpha} + M^{-1} \\alpha_0   ) $$ \\(\\alpha_0\\) prior mean \\(\\alpha \\mid \\gamma\\), \\(\\hat{\\alpha}\\) MLE (equivalently, OLS). $$   \\Delta = ((\\Psi \\Psi^\\intercal) \\otimes (X_0 X_0^\\intercal) + M^{-1})^{-1} $$","code":""},{"path":"/reference/ssvs_bvar_algo.html","id":"gibbs-sampling-1","dir":"Reference","previous_headings":"","what":"Gibbs Sampling","title":"Stochastic Search Variable Selection in VAR — ssvs_bvar_algo","text":"Data: \\(X_0\\), \\(Y_0\\) Input: VAR order p MCMC iteration number Weight slab: Bernoulli distribution parameters \\(p_j\\): coefficients \\(q_{ij}\\): cholesky factor Gamma distribution parameters cholesky factor diagonal elements \\(\\psi_{jj}\\) \\(a_j\\): shape \\(b_j\\): rate Correlation matrix coefficient vector: \\(R = I_{k^2p}\\) Correlation matrix restrict cholesky factor (\\(\\eta_j\\)): \\(R_j = I_{j - 1}\\) Tuning parameters spike--slab sd semi-automatic approach \\(c_0\\): small value (0.1) \\(c_1\\): large value (10) Constant reduce prior influence constant term: \\(c\\) Algorithm: Initialize \\(\\Psi\\), \\(\\omega\\), \\(\\alpha\\), \\(\\gamma\\) Iterate Diagonal elements cholesky factor: \\(\\psi^{(t)} \\mid \\alpha^{(t - 1)}, \\gamma^{(t - 1)}, \\omega^{(t - 1)}, Y_0\\) -diagonal elements cholesky factor: \\(\\eta^{(t)} \\mid \\psi^{(t)} \\alpha^{(t - 1)}, \\gamma^{(t - 1)}, \\omega^{(t - 1)}, Y_0\\) Dummy vector cholesky factor: \\(\\omega^{(t)} \\mid \\eta^{(t)}, \\psi^{(t)} \\alpha^{(t - 1)}, \\gamma^{(t - 1)}, \\omega^{(t - 1)}, Y_0\\) Coefficient vector: \\(\\alpha^{(t)} \\mid \\gamma^{(t - 1)}, \\Sigma^{(t)}, \\omega^{(t)}, Y_0\\) Dummy vector coefficient vector: \\(\\gamma^{(t)} \\mid \\alpha^{(t)}, \\psi^{(t)}, \\eta^{(t)}, \\omega^{(t)}, Y_0\\) Output: Parameter trace Update results OLS","code":""},{"path":"/reference/ssvs_bvar_algo.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Stochastic Search Variable Selection in VAR — ssvs_bvar_algo","text":"George, E. ., Sun, D., & Ni, S. (2008). Bayesian stochastic search VAR model restrictions. Journal Econometrics, 142(1), 553–580. Koop, G., & Korobilis, D. (2009). Bayesian Multivariate Time Series Methods Empirical Macroeconomics. Foundations Trends® Econometrics, 3(4), 267–358.","code":""},{"path":"/reference/ssvs_bvhar_algo.html","id":null,"dir":"Reference","previous_headings":"","what":"Stochastic Search Variable Selection in VHAR — ssvs_bvhar_algo","title":"Stochastic Search Variable Selection in VHAR — ssvs_bvhar_algo","text":"page describes stochastic search variable selection (SSVS) MCMC algorithm VHAR model. Recall \\(\\Sigma_e = \\Psi \\Psi^\\intercal\\).","code":""},{"path":[]},{"path":"/reference/ssvs_bvhar_algo.html","id":"prior-of-coefficients","dir":"Reference","previous_headings":"","what":"Prior of coefficients","title":"Stochastic Search Variable Selection in VHAR — ssvs_bvhar_algo","text":"Among \\(vec(\\Phi) = \\phi = (\\phi_1, \\ldots, \\phi_{3 k^2 + k})\\), non-constant terms restricted dummy vector \\(\\gamma = (\\gamma_1, \\ldots, \\gamma_{3 k^2})^\\intercal\\). defines diagonal matrix \\(D = diag(h_1, \\ldots, h_{k^2 p})\\) $$   h_i = \\begin{cases}     \\tau_{0i} & \\text{} \\gamma_i = 0 \\\\     \\tau_{1i} & \\text{} \\gamma_i = 1   \\end{cases} $$ small \\(\\tau_{0j}\\) large \\(\\tau_{1j}\\). Let \\(\\phi_{coef}\\) restricted coefficients vector let \\(\\phi_{non}\\) -restricted coefficients vector, .e. vectorized constant term. term prior. $$   \\phi_{coef} \\mid \\gamma \\sim N(\\phi_{0, coef}, DD),   \\quad   \\alpha_{non} \\sim N(\\phi_{0, non}, c I_k) $$ \\(c\\) large, prior influence \\(\\phi_{non}\\) decreases. combining term appropriate order, $$\\phi \\mid \\gamma \\sim N(0_{3 k^2 + k}, M)$$ $$   M = I_{k p + 1} \\otimes \\begin{bmatrix}     DD & 0_{k^2 p} \\\\     0_{k^2 p}^\\intercal & c   \\end{bmatrix} $$ \\(\\phi_0\\) combined way.","code":""},{"path":"/reference/ssvs_bvhar_algo.html","id":"prior-of-other-parameters","dir":"Reference","previous_headings":"","what":"Prior of Other Parameters","title":"Stochastic Search Variable Selection in VHAR — ssvs_bvhar_algo","text":"using notations parameters, see ssvs_bvar_algo.","code":""},{"path":"/reference/ssvs_bvhar_algo.html","id":"gibbs-sampling","dir":"Reference","previous_headings":"","what":"Gibbs Sampling","title":"Stochastic Search Variable Selection in VHAR — ssvs_bvhar_algo","text":"Data: \\(X_0\\), \\(Y_0\\), VAR linear transformation Input: VHAR order (week, month) MCMC iteration number Weight slab: Bernoulli distribution parameters \\(p_j\\): coefficients \\(q_{ij}\\): cholesky factor Gamma distribution parameters cholesky factor diagonal elements \\(\\psi_{jj}\\) \\(a_j\\): shape \\(b_j\\): rate Correlation matrix coefficient vector: \\(R = I_{k^2p}\\) Correlation matrix restrict cholesky factor (\\(\\eta_j\\)): \\(R_j = I_{j - 1}\\) Tuning parameters spike--slab sd semi-automatic approach \\(c_0\\): small value (0.1) \\(c_1\\): large value (10) Constant reduce prior influence constant term: \\(c\\) Algorithm: Initialize \\(\\Psi\\), \\(\\omega\\), \\(\\phi\\), \\(\\gamma\\) Iterate Diagonal elements cholesky factor: \\(\\psi^{(t)} \\mid \\phi^{(t - 1)}, \\gamma^{(t - 1)}, \\omega^{(t - 1)}, Y_0\\) -diagonal elements cholesky factor: \\(\\eta^{(t)} \\mid \\psi^{(t)} \\phi^{(t - 1)}, \\gamma^{(t - 1)}, \\omega^{(t - 1)}, Y_0\\) Dummy vector cholesky factor: \\(\\omega^{(t)} \\mid \\eta^{(t)}, \\psi^{(t)} \\phi^{(t - 1)}, \\gamma^{(t - 1)}, \\omega^{(t - 1)}, Y_0\\) Coefficient vector: \\(\\phi^{(t)} \\mid \\gamma^{(t - 1)}, \\Sigma^{(t)}, \\omega^{(t)}, Y_0 \\sim \\mu, \\Delta)\\) \\(\\mu = ((\\Psi \\Psi^\\intercal) \\otimes (X_1 X_1^\\intercal) + M^{-1})^{-1} (( (\\Psi \\Psi^\\intercal) \\otimes (X_1 X_1^\\intercal) ) \\hat{\\phi} + M^{-1} \\phi_0)\\) \\(\\Delta = ((\\Psi \\Psi^\\intercal) \\otimes (X_1 X_1^\\intercal) + M^{-1})^{-1}\\) Dummy vector coefficient vector: \\(\\gamma^{(t)} \\mid \\phi^{(t)}, \\psi^{(t)}, \\eta^{(t)}, \\omega^{(t)}, Y_0\\) Output: Parameter trace Update results OLS","code":""},{"path":"/reference/ssvs_bvhar_algo.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Stochastic Search Variable Selection in VHAR — ssvs_bvhar_algo","text":"George, E. ., Sun, D., & Ni, S. (2008). Bayesian stochastic search VAR model restrictions. Journal Econometrics, 142(1), 553–580. Koop, G., & Korobilis, D. (2009). Bayesian Multivariate Time Series Methods Empirical Macroeconomics. Foundations Trends® Econometrics, 3(4), 267–358.","code":""},{"path":"/reference/stableroot.html","id":null,"dir":"Reference","previous_headings":"","what":"Roots of characteristic polynomial — stableroot","title":"Roots of characteristic polynomial — stableroot","text":"Roots characteristic polynomial","code":""},{"path":"/reference/stableroot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Roots of characteristic polynomial — stableroot","text":"","code":"stableroot(x, ...)"},{"path":"/reference/stableroot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Roots of characteristic polynomial — stableroot","text":"x object ... used","code":""},{"path":"/reference/stableroot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Roots of characteristic polynomial — stableroot","text":"Numeric vector.","code":""},{"path":"/reference/stableroot.varlse.html","id":null,"dir":"Reference","previous_headings":"","what":"Characteristic polynomial roots for VAR Coefficient Matrix — stableroot.varlse","title":"Characteristic polynomial roots for VAR Coefficient Matrix — stableroot.varlse","text":"Compute character polynomial VAR(p) coefficient matrix.","code":""},{"path":"/reference/stableroot.varlse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Characteristic polynomial roots for VAR Coefficient Matrix — stableroot.varlse","text":"","code":"# S3 method for varlse stableroot(x, ...)  # S3 method for vharlse stableroot(x, ...)  # S3 method for bvarmn stableroot(x, ...)  # S3 method for bvarflat stableroot(x, ...)  # S3 method for bvharmn stableroot(x, ...)"},{"path":"/reference/stableroot.varlse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Characteristic polynomial roots for VAR Coefficient Matrix — stableroot.varlse","text":"x Model fit ... used","code":""},{"path":"/reference/stableroot.varlse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Characteristic polynomial roots for VAR Coefficient Matrix — stableroot.varlse","text":"Numeric vector.","code":""},{"path":"/reference/stableroot.varlse.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Characteristic polynomial roots for VAR Coefficient Matrix — stableroot.varlse","text":"know whether process stable , make characteristic polynomial. $$\\det(I_m - z) = 0$$ \\(\\) VAR(1) coefficient matrix representation.","code":""},{"path":"/reference/stableroot.varlse.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Characteristic polynomial roots for VAR Coefficient Matrix — stableroot.varlse","text":"Lütkepohl, H. (2007). New Introduction Multiple Time Series Analysis. Springer Publishing.","code":""},{"path":"/reference/summary.normaliw.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarizing Bayesian Multivariate Time Series Model — summary.normaliw","title":"Summarizing Bayesian Multivariate Time Series Model — summary.normaliw","text":"summary method normaliw class.","code":""},{"path":"/reference/summary.normaliw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarizing Bayesian Multivariate Time Series Model — summary.normaliw","text":"","code":"# S3 method for normaliw summary(   object,   num_iter = 10000L,   num_burn = floor(num_iter/2),   thinning = 1L,   ... )  # S3 method for summary.normaliw print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  knit_print.summary.normaliw(x, ...)"},{"path":"/reference/summary.normaliw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarizing Bayesian Multivariate Time Series Model — summary.normaliw","text":"object normaliw object num_iter Number sample MNIW distribution num_burn Number burn-thinning Thinning every thinning-th iteration ... used x summary.normaliw object digits digit option print","code":""},{"path":"/reference/summary.normaliw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarizing Bayesian Multivariate Time Series Model — summary.normaliw","text":"summary.normaliw  class following components: names Variable names totobs Total number observation obs Sample size used training = totobs - p p Lag VAR m Dimension data call Matched call spec Model specification (bvharspec) mn_mean MN Mean posterior distribution (MN-IW) mn_prec MN Precision posterior distribution (MN-IW) iw_scale IW scale posterior distribution (MN-IW) iw_shape IW df posterior distribution (MN-IW) iter Number MCMC iterations burn Number MCMC burn-thin MCMC thinning alpha_record (BVAR) phi_record (BVHAR) MCMC record coefficients vector psi_record MCMC record upper cholesky factor omega_record MCMC record diagonal cholesky factor eta_record MCMC record upper part cholesky factor param MCMC record every parameter coefficients Posterior mean coefficients covmat Posterior mean covariance","code":""},{"path":"/reference/summary.normaliw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarizing Bayesian Multivariate Time Series Model — summary.normaliw","text":"Minnesota prior, set coefficient matrices residual covariance matrix matrix Normal Inverse-Wishart distribution. BVAR: $$(, \\Sigma_e) \\sim MNIW(\\hat{}, \\hat{V}^{-1}, \\hat\\Sigma_e, \\alpha_0 + n)$$ \\(\\hat{V} = X_\\ast^T X_\\ast\\) posterior precision MN. BVHAR: $$(\\Phi, \\Sigma_e) \\sim MNIW(\\hat\\Phi, \\hat{V}_H^{-1}, \\hat\\Sigma_e, \\nu + n)$$ \\(\\hat{V}_H = X_{+}^T X_{+}\\) posterior precision MN.","code":""},{"path":"/reference/summary.normaliw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Summarizing Bayesian Multivariate Time Series Model — summary.normaliw","text":"Litterman, R. B. (1986). Forecasting Bayesian Vector Autoregressions: Five Years Experience. Journal Business & Economic Statistics, 4(1), 25. Bańbura, M., Giannone, D., & Reichlin, L. (2010). Large Bayesian vector auto regressions. Journal Applied Econometrics, 25(1).","code":""},{"path":"/reference/summary.ssvsmod.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarizing BVAR and BVHAR with Shrinkage Priors — print.summary.bvharsp","title":"Summarizing BVAR and BVHAR with Shrinkage Priors — print.summary.bvharsp","text":"Conduct variable selection.","code":""},{"path":"/reference/summary.ssvsmod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarizing BVAR and BVHAR with Shrinkage Priors — print.summary.bvharsp","text":"","code":"# S3 method for summary.bvharsp print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  knit_print.summary.ssvsmod(x, ...)  # S3 method for ssvsmod summary(object, method = c(\"pip\", \"ci\"), threshold = 0.5, level = 0.05, ...)  # S3 method for hsmod summary(object, method = c(\"ci\", \"pip\"), threshold = 0.5, level = 0.05, ...)"},{"path":"/reference/summary.ssvsmod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarizing BVAR and BVHAR with Shrinkage Priors — print.summary.bvharsp","text":"x summary.ssvsmod object digits digit option print ... used object ssvsmod object method Use PIP (\"pip\") credible interval (\"ci\"). threshold Threshold posterior inclusion probability level Specify alpha credible interval level 100(1 - alpha) percentage. default, .05.","code":""},{"path":"/reference/summary.ssvsmod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarizing BVAR and BVHAR with Shrinkage Priors — print.summary.bvharsp","text":"summary.ssvsmod object summary.hsmod object","code":""},{"path":"/reference/summary.ssvsmod.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Summarizing BVAR and BVHAR with Shrinkage Priors — print.summary.bvharsp","text":"George, E. ., & McCulloch, R. E. (1993). Variable Selection via Gibbs Sampling. Journal American Statistical Association, 88(423), 881–889. George, E. ., Sun, D., & Ni, S. (2008). Bayesian stochastic search VAR model restrictions. Journal Econometrics, 142(1), 553–580. Koop, G., & Korobilis, D. (2009). Bayesian Multivariate Time Series Methods Empirical Macroeconomics. Foundations Trends® Econometrics, 3(4), 267–358. O’Hara, R. B., & Sillanpää, M. J. (2009). review Bayesian variable selection methods: , . Bayesian Analysis, 4(1), 85–117.","code":""},{"path":"/reference/summary.varlse.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarizing Vector Autoregressive Model — summary.varlse","title":"Summarizing Vector Autoregressive Model — summary.varlse","text":"summary method varlse class.","code":""},{"path":"/reference/summary.varlse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarizing Vector Autoregressive Model — summary.varlse","text":"","code":"# S3 method for varlse summary(object, ...)  # S3 method for summary.varlse print(x, digits = max(3L, getOption(\"digits\") - 3L), signif_code = TRUE, ...)  knit_print.summary.varlse(x, ...)"},{"path":"/reference/summary.varlse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarizing Vector Autoregressive Model — summary.varlse","text":"object varlse object ... used x summary.varlse object digits digit option print signif_code Check significant rows (Default: TRUE)","code":""},{"path":"/reference/summary.varlse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarizing Vector Autoregressive Model — summary.varlse","text":"summary.varlse  class additionally computes following names Variable names totobs Total number observation obs Sample size used training = totobs - p p Lag VAR coefficients Coefficient Matrix call Matched call process Process: VAR covmat Covariance matrix residuals corrmat Correlation matrix residuals roots Roots characteristic polynomials is_stable Whether process stable based roots log_lik log-likelihood ic Information criteria vector AIC - AIC BIC - BIC HQ - HQ FPE - FPE","code":""},{"path":"/reference/summary.varlse.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Summarizing Vector Autoregressive Model — summary.varlse","text":"Lütkepohl, H. (2007). New Introduction Multiple Time Series Analysis. Springer Publishing.","code":""},{"path":"/reference/summary.vharlse.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarizing Vector HAR Model — summary.vharlse","title":"Summarizing Vector HAR Model — summary.vharlse","text":"summary method vharlse class.","code":""},{"path":"/reference/summary.vharlse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarizing Vector HAR Model — summary.vharlse","text":"","code":"# S3 method for vharlse summary(object, ...)  # S3 method for summary.vharlse print(x, digits = max(3L, getOption(\"digits\") - 3L), signif_code = TRUE, ...)  knit_print.summary.vharlse(x, ...)"},{"path":"/reference/summary.vharlse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarizing Vector HAR Model — summary.vharlse","text":"object vharlse object ... used x summary.vharlse object digits digit option print signif_code Check significant rows (Default: TRUE)","code":""},{"path":"/reference/summary.vharlse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarizing Vector HAR Model — summary.vharlse","text":"summary.vharlse  class additionally computes following names Variable names totobs Total number observation obs Sample size used training = totobs - p p 3 week Order weekly term month Order monthly term coefficients Coefficient Matrix call Matched call process Process: VAR covmat Covariance matrix residuals corrmat Correlation matrix residuals roots Roots characteristic polynomials is_stable Whether process stable based roots log_lik log-likelihood ic Information criteria vector AIC - AIC BIC - BIC HQ - HQ FPE - FPE","code":""},{"path":"/reference/summary.vharlse.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Summarizing Vector HAR Model — summary.vharlse","text":"Lütkepohl, H. (2007). New Introduction Multiple Time Series Analysis. Springer Publishing. Corsi, F. (2008). Simple Approximate Long-Memory Model Realized Volatility. Journal Financial Econometrics, 7(2), 174–196. Baek, C. Park, M. (2021). Sparse vector heterogeneous autoregressive modeling realized volatility. J. Korean Stat. Soc. 50, 495–510.","code":""},{"path":"/reference/ts_forecasting_cv.html","id":null,"dir":"Reference","previous_headings":"","what":"Time Series Cross-Validation — ts_forecasting_cv","title":"Time Series Cross-Validation — ts_forecasting_cv","text":"page describes --sample forecasting method time series scheme. simple way compute test error splitting training-test set, popular approach time series literature --sample forecasting.","code":""},{"path":"/reference/ts_forecasting_cv.html","id":"rolling-window-forecasting","dir":"Reference","previous_headings":"","what":"Rolling Window Forecasting","title":"Time Series Cross-Validation — ts_forecasting_cv","text":"Rolling window forecasting fixes window size. window used training set. window moved end possible can . step set step ahead forecasting every iteration, saying one-step h-step. fitting model window, researcher forecast next one-step h-step ahead. longest forecast horizon (final_period - window_size) - h + 1. window, move window one step ahead process. Get forecasted values possible (longest forecast horizon).","code":""},{"path":"/reference/ts_forecasting_cv.html","id":"expanding-windows","dir":"Reference","previous_headings":"","what":"Expanding Windows","title":"Time Series Cross-Validation — ts_forecasting_cv","text":"Expanding window forecasting fixes starting period. Rolling window method moves window constant size, expanding window method just literally expands window window fixing starting period. procedure .","code":""},{"path":"/reference/ts_forecasting_cv.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Time Series Cross-Validation — ts_forecasting_cv","text":"Hyndman, R. J., & Athanasopoulos, G. (2021). Forecasting: Principles practice (3rd ed.). OTEXTS. https://otexts.com/fpp3/","code":""},{"path":"/reference/var_design_formulation.html","id":null,"dir":"Reference","previous_headings":"","what":"Ordinary Least Squares Model Formulation — var_design_formulation","title":"Ordinary Least Squares Model Formulation — var_design_formulation","text":"page specifies formulation ordinary least squares (OLS) VAR-family model. Notation format used entire package document.","code":""},{"path":"/reference/var_design_formulation.html","id":"vector-autoregressive-model","dir":"Reference","previous_headings":"","what":"Vector Autoregressive Model","title":"Ordinary Least Squares Model Formulation — var_design_formulation","text":"mentioned var_lm(), specify VAR(p) model $$Y_t = A_1 Y_{t - 1} + \\cdots + A_p Y_{t - p} + c + \\epsilon_t$$ Consider sample T size, \\(y_1, \\ldots, y_n\\). Let \\(n = T - p\\). \\(y_1, \\ldots, y_T\\) data rearranged follows. $$Y_j = (y_j, y_{j + 1}, \\ldots, y_{j + n - 1})^\\intercal$$ \\(Z_j = (\\epsilon_j, \\epsilon_{j + 1}, \\ldots, \\epsilon_{j + n - 1})^\\intercal\\) ordinary least squares (OLS) estimation, define response matrix design matrix multivariate OLS follows. First, response matrix: $$Y_0 = Y_{p + 1}$$ Next, design matrix: $$X_0 = [Y_p, \\ldots, Y_1, 1]$$ now OLS model $$Y_0 = X_0 + Z_0$$ \\(Z_0 = Z_{p + 1}\\) , $$= [A_1, A_2, \\ldots, A_p, c]^T$$ gives $$\\hat{} = (X_0^\\intercal X_0)^{-1} X_0^\\intercal Y_0$$","code":""},{"path":"/reference/var_design_formulation.html","id":"vector-heterogeneous-autoregressive-model","dir":"Reference","previous_headings":"","what":"Vector Heterogeneous Autoregressive Model","title":"Ordinary Least Squares Model Formulation — var_design_formulation","text":"VHAR model linearly restricted VAR(22). Let \\(Y_0 = X_1 \\Phi + Z_0\\) OLS formula VHAR. Let \\(T_0\\) 3m x 22m matrix. $$   C_0 = \\begin{bmatrix}   1 & 0 & 0 & 0 & 0 & 0 & \\cdots & 0 \\\\   1 / 5 & 1 / 5 & 1 / 5 & 1 / 5 & 1 / 5 & 0 & \\cdots & 0 \\\\   1 / 22 & 1 / 22 & 1 / 22 & 1 / 22 & 1 / 22 & 1 / 22 & \\cdots & 1 / 22 \\end{bmatrix} \\otimes I_m $$ Define (3m + 1) x (22m + 1) matrix \\(C_{HAR}\\) $$   C_{HAR} = \\begin{bmatrix}   C_0 & 0_{3m} \\\\   0_{3m}^\\intercal & 1 \\end{bmatrix} $$ construction, $$Y_0 = X_1 \\Phi + Z_0 = (X_0 C_{HAR}^\\intercal) \\Phi + Z_0$$ .e. $$X_1 = X_0 C_{HAR}^\\intercal$$ follows $$\\hat\\Phi = (X_1^\\intercal X_1)^{-1} X_1^\\intercal Y_0$$","code":""},{"path":"/reference/var_design_formulation.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Ordinary Least Squares Model Formulation — var_design_formulation","text":"Baek, C. Park, M. (2021). Sparse vector heterogeneous autoregressive modeling realized volatility. J. Korean Stat. Soc. 50, 495–510. Bubák, V., Kočenda, E., & Žikeš, F. (2011). Volatility transmission emerging European foreign exchange markets. Journal Banking & Finance, 35(11), 2829–2841. Corsi, F. (2008). Simple Approximate Long-Memory Model Realized Volatility. Journal Financial Econometrics, 7(2), 174–196. Lütkepohl, H. (2007). New Introduction Multiple Time Series Analysis. Springer Publishing.","code":""},{"path":"/reference/var_lm.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting Vector Autoregressive Model of Order p Model — var_lm","title":"Fitting Vector Autoregressive Model of Order p Model — var_lm","text":"function fits VAR(p) using OLS method.","code":""},{"path":"/reference/var_lm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting Vector Autoregressive Model of Order p Model — var_lm","text":"","code":"var_lm(y, p = 1, include_mean = TRUE, method = c(\"nor\", \"chol\", \"qr\"))  # S3 method for varlse print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  knit_print.varlse(x, ...)"},{"path":"/reference/var_lm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting Vector Autoregressive Model of Order p Model — var_lm","text":"y Time series data columns indicate variables p Lag VAR (Default: 1) include_mean Add constant term (Default: TRUE) (FALSE) method Method solve linear equation system. (\"\": normal equation (default), \"chol\": Cholesky, \"qr\": HouseholderQR) x varlse object digits digit option print ... used","code":""},{"path":"/reference/var_lm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting Vector Autoregressive Model of Order p Model — var_lm","text":"var_lm() returns object named varlse  class. list following components: coefficients Coefficient Matrix fitted.values Fitted response values residuals Residuals covmat LS estimate covariance matrix df Numer Coefficients: mp + 1 mp p Lag VAR m Dimension data obs Sample size used training = totobs - p totobs Total number observation call Matched call process Process: VAR type include constant term (\"const\") (\"none\") y0 \\(Y_0\\) design \\(X_0\\) y Raw input also bvharmod class.","code":""},{"path":"/reference/var_lm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting Vector Autoregressive Model of Order p Model — var_lm","text":"package specifies VAR(p) model $$Y_{t} = A_1 Y_{t - 1} + \\cdots + A_p Y_{t - p} + c + \\epsilon_t$$ include_type = TRUE, \\(c\\) term. Otherwise (include_type = FALSE), \\(c\\) term. function estimates every coefficient matrix \\(A_1, \\ldots, A_p, c\\). Response matrix, \\(Y_0\\) var_design_formulation Design matrix, \\(X_0\\) var_design_formulation Coefficient matrix form \\(= [A_1, A_2, \\ldots, A_p, c]^T\\). perform least squares following multivariate regression model $$Y_0 = X_0 + error$$ gives $$\\hat{} = (X_0^T X_0)^{-1} X_0^T Y_0$$","code":""},{"path":"/reference/var_lm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting Vector Autoregressive Model of Order p Model — var_lm","text":"Lütkepohl, H. (2007). New Introduction Multiple Time Series Analysis. Springer Publishing.","code":""},{"path":[]},{"path":"/reference/var_lm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting Vector Autoregressive Model of Order p Model — var_lm","text":"","code":"# Perform the function using etf_vix dataset fit <- var_lm(y = etf_vix, p = 2) class(fit) #> [1] \"varlse\"   \"bvharmod\" str(fit) #> List of 15 #>  $ coefficients : num [1:19, 1:9] 0.9588 0.0313 -0.0235 -0.0944 -0.0048 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:19] \"GVZCLS_1\" \"OVXCLS_1\" \"VXFXICLS_1\" \"VXEEMCLS_1\" ... #>   .. ..$ : chr [1:9] \"GVZCLS\" \"OVXCLS\" \"VXFXICLS\" \"VXEEMCLS\" ... #>  $ fitted.values: num [1:903, 1:9] 21.3 22.2 21.5 21.1 21.3 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : NULL #>   .. ..$ : chr [1:9] \"GVZCLS\" \"OVXCLS\" \"VXFXICLS\" \"VXEEMCLS\" ... #>  $ residuals    : num [1:903, 1:9] 1.008 -0.639 -0.284 0.298 0.308 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : NULL #>   .. ..$ : chr [1:9] \"GVZCLS\" \"OVXCLS\" \"VXFXICLS\" \"VXEEMCLS\" ... #>  $ covmat       : num [1:9, 1:9] 1.113 0.373 0.304 0.445 1.366 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:9] \"GVZCLS\" \"OVXCLS\" \"VXFXICLS\" \"VXEEMCLS\" ... #>   .. ..$ : chr [1:9] \"GVZCLS\" \"OVXCLS\" \"VXFXICLS\" \"VXEEMCLS\" ... #>  $ df           : int 19 #>  $ p            : num 2 #>  $ m            : int 9 #>  $ obs          : int 903 #>  $ totobs       : int 905 #>  $ call         : language var_lm(y = etf_vix, p = 2) #>  $ process      : chr \"VAR\" #>  $ type         : chr \"const\" #>  $ y0           : num [1:903, 1:9] 22.3 21.6 21.2 21.4 21.6 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : NULL #>   .. ..$ : chr [1:9] \"GVZCLS\" \"OVXCLS\" \"VXFXICLS\" \"VXEEMCLS\" ... #>  $ design       : num [1:903, 1:19] 21.5 22.3 21.6 21.2 21.4 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : NULL #>   .. ..$ : chr [1:19] \"GVZCLS_1\" \"OVXCLS_1\" \"VXFXICLS_1\" \"VXEEMCLS_1\" ... #>  $ y            : num [1:905, 1:9] 21.5 21.5 22.3 21.6 21.2 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : NULL #>   .. ..$ : chr [1:9] \"GVZCLS\" \"OVXCLS\" \"VXFXICLS\" \"VXEEMCLS\" ... #>  - attr(*, \"class\")= chr [1:2] \"varlse\" \"bvharmod\"  # Extract coef, fitted values, and residuals coef(fit) #>                  GVZCLS       OVXCLS     VXFXICLS    VXEEMCLS     VXSLVCLS #> GVZCLS_1    0.958839561 -0.062827385 -0.019710690  0.01257027  0.291868669 #> OVXCLS_1    0.031306519  0.946200622 -0.006632872 -0.03089072  0.005701801 #> VXFXICLS_1 -0.023546344 -0.052053167  0.853672620 -0.06031077 -0.096749298 #> VXEEMCLS_1 -0.094354618 -0.073106564  0.074752695  0.86705288 -0.048927384 #> VXSLVCLS_1 -0.004803889  0.011100124 -0.028180528 -0.00787754  0.741225547 #> EVZCLS_1    0.125516130 -0.138276981  0.077667943 -0.05620528  0.213417413 #> VXXLECLS_1  0.077038206  0.116602536  0.049019313  0.19068844  0.123664057 #> VXGDXCLS_1 -0.041364201  0.022893379 -0.012790918 -0.02444514 -0.051351386 #> VXEWZCLS_1  0.032078312  0.081017743  0.002689773  0.02421098  0.011793646 #> GVZCLS_2   -0.104834812 -0.017750378 -0.063640299 -0.06563731 -0.284901251 #> OVXCLS_2   -0.057264753  0.000198619 -0.012230807  0.01529842 -0.021755404 #> VXFXICLS_2 -0.010770464  0.007308545  0.070962129  0.06532811  0.035457057 #> VXEEMCLS_2  0.109941832  0.031515218 -0.087805109  0.05027743  0.106490192 #> VXSLVCLS_2  0.031836190  0.026261295  0.084884303  0.07330380  0.165164782 #> EVZCLS_2   -0.039927065  0.240594601  0.018595199  0.07171981 -0.095041473 #> VXXLECLS_2 -0.063856767 -0.045562528 -0.052978615 -0.18149299 -0.106494854 #> VXGDXCLS_2  0.084605713  0.007572189  0.029414253  0.02242848  0.085005069 #> VXEWZCLS_2 -0.033916295 -0.071267512  0.007601670 -0.02085634 -0.019106806 #> const       0.484435224  0.071858917  0.764593553  0.73643928  0.993267584 #>                   EVZCLS     VXXLECLS     VXGDXCLS     VXEWZCLS #> GVZCLS_1   -0.0070051856  0.010258469  0.186062079  0.016397003 #> OVXCLS_1    0.0057743474 -0.055730279 -0.008620592 -0.017425642 #> VXFXICLS_1 -0.0013000787 -0.071102522 -0.019267681 -0.093669606 #> VXEEMCLS_1  0.0082641013  0.043573682  0.052515700  0.111449434 #> VXSLVCLS_1  0.0048970514 -0.010365439 -0.037485186 -0.035578884 #> EVZCLS_1    0.9530755788 -0.159179164 -0.029104883 -0.109896535 #> VXXLECLS_1  0.0073924911  1.090977549  0.173739155  0.097903592 #> VXGDXCLS_1 -0.0170045623 -0.002534079  0.717661085  0.014081721 #> VXEWZCLS_1  0.0295958720  0.039727624  0.029208637  0.919861136 #> GVZCLS_2    0.0011140822 -0.064661782 -0.129207944 -0.025690608 #> OVXCLS_2   -0.0013553534  0.045540919  0.007661278  0.007209753 #> VXFXICLS_2  0.0193175978  0.067148832  0.057541033  0.120471274 #> VXEEMCLS_2 -0.0273314378 -0.088654468 -0.128280935 -0.177756749 #> VXSLVCLS_2  0.0074048747  0.057079506  0.076151265  0.072552465 #> EVZCLS_2   -0.0026576824  0.171823659 -0.062484101  0.077971334 #> VXXLECLS_2 -0.0007146444 -0.109371143 -0.146653392 -0.060460831 #> VXGDXCLS_2  0.0111059419  0.007634580  0.222052920 -0.026452775 #> VXEWZCLS_2 -0.0304841577 -0.030496662 -0.018978557  0.055930225 #> const       0.1341878224  0.742494021  0.705738212  0.796582789 head(residuals(fit)) #>          GVZCLS      OVXCLS   VXFXICLS    VXEEMCLS   VXSLVCLS      EVZCLS #> [1,]  1.0084235 -0.01665024 -0.1189584  0.18259423  1.0345739  0.54161189 #> [2,] -0.6393271  1.07781122 -0.7889172  0.06023516 -0.2598844 -0.30429270 #> [3,] -0.2841251 -1.13853760  0.8285284  1.09281272  1.3066535  0.53399638 #> [4,]  0.2975186 -0.89689641 -0.5797484 -0.31164787  1.3474286 -0.09610840 #> [5,]  0.3075188 -0.98987446 -0.6230728 -0.46134610  1.2499047  0.01799667 #> [6,] -0.4052045 -1.62792068 -0.9718923 -2.26508501 -1.1137253 -0.25997035 #>         VXXLECLS   VXGDXCLS   VXEWZCLS #> [1,]  0.97639374  0.3811097 -0.2513162 #> [2,]  0.08960441 -0.6696317  0.4110768 #> [3,]  0.24450709 -0.9864375  1.7865058 #> [4,] -0.20575733  0.6892149 -0.3931113 #> [5,] -0.21831258  1.3123282 -0.5570114 #> [6,] -0.18371357 -1.1068942 -1.1856081 head(fitted(fit)) #>        GVZCLS   OVXCLS VXFXICLS VXEEMCLS VXSLVCLS   EVZCLS VXXLECLS VXGDXCLS #> [1,] 21.33158 35.53665 29.17896 29.63741 42.47543 12.57839 26.67361 33.37889 #> [2,] 22.23933 35.51219 29.24892 29.94976 43.08988 13.07429 27.55040 34.16963 #> [3,] 21.48413 36.75854 28.71147 30.03719 42.17335 12.77600 27.55549 33.79644 #> [4,] 21.10248 35.69190 29.68475 30.97165 42.64257 13.32611 27.66076 33.26579 #> [5,] 21.29248 34.95987 29.29307 30.65135 43.25010 13.13200 27.32831 33.78767 #> [6,] 21.54520 34.21792 28.93189 30.24509 43.75373 13.04997 27.03371 34.90689 #>      VXEWZCLS #> [1,] 30.43132 #> [2,] 30.33892 #> [3,] 30.91349 #> [4,] 32.54811 #> [5,] 32.16701 #> [6,] 31.65561"},{"path":"/reference/var_vec_formulation.html","id":null,"dir":"Reference","previous_headings":"","what":"Vectorized OLS Formulation — var_vec_formulation","title":"Vectorized OLS Formulation — var_vec_formulation","text":"page specifies OLS formulation, vectorized var_design_formulation. Notation format used entire package document.","code":""},{"path":"/reference/var_vec_formulation.html","id":"vector-autoregressive-model","dir":"Reference","previous_headings":"","what":"Vector Autoregressive Model","title":"Vectorized OLS Formulation — var_vec_formulation","text":"Recall k-dim VAR model \\(Y_0 = X_0 + Z_0\\). Applying \\(vec\\) operation, $$vec(Y_0) = (I_k \\otimes X_0) vec() + vec(Z_0)$$ Estimating \\(\\alpha = vec()\\) equivalent estimating usual OLS.","code":""},{"path":"/reference/var_vec_formulation.html","id":"vector-heterogeneous-autoregressive-model","dir":"Reference","previous_headings":"","what":"Vector Heterogeneous Autoregressive Model","title":"Vectorized OLS Formulation — var_vec_formulation","text":"Recall k-dim VHAR model $$Y_0 = X_1 \\Phi + Z_0 = (X_0 C_{HAR}^\\intercal) \\Phi + Z_0$$. $$vec(Y_0) = (I_k \\otimes X_0 C_{HAR}^\\intercal) vec(\\Phi) + vec(Z_0) = (I_k \\otimes X_1) vec(\\Phi) + vec(Z_0)$$","code":""},{"path":"/reference/var_vec_formulation.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Vectorized OLS Formulation — var_vec_formulation","text":"Lütkepohl, H. (2007). New Introduction Multiple Time Series Analysis. Springer Publishing.","code":""},{"path":"/reference/vhar_lm.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting Vector Heterogeneous Autoregressive Model — vhar_lm","title":"Fitting Vector Heterogeneous Autoregressive Model — vhar_lm","text":"function fits VHAR using OLS method.","code":""},{"path":"/reference/vhar_lm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting Vector Heterogeneous Autoregressive Model — vhar_lm","text":"","code":"vhar_lm(   y,   har = c(5, 22),   include_mean = TRUE,   method = c(\"nor\", \"chol\", \"qr\") )  # S3 method for vharlse print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)  knit_print.vharlse(x, ...)"},{"path":"/reference/vhar_lm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting Vector Heterogeneous Autoregressive Model — vhar_lm","text":"y Time series data columns indicate variables har Numeric vector weekly monthly order. default, c(5, 22). include_mean Add constant term (Default: TRUE) (FALSE) method Method solve linear equation system. (\"\": normal equation (default), \"chol\": Cholesky, \"qr\": HouseholderQR) x vharlse object digits digit option print ... used","code":""},{"path":"/reference/vhar_lm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting Vector Heterogeneous Autoregressive Model — vhar_lm","text":"vhar_lm() returns object named vharlse  class. list following components: coefficients Coefficient Matrix fitted.values Fitted response values residuals Residuals covmat LS estimate covariance matrix df Numer Coefficients: 3m + 1 3m p 3 (number terms. vharlse contains element usage functions.) week Order weekly term month Order monthly term m Dimension data obs Sample size used training = totobs - 22 totobs Total number observation call Matched call process Process: VHAR type include constant term (\"const\") (\"none\") HARtrans VHAR linear transformation matrix: \\(C_{HAR}\\) y0 \\(Y_0\\) design \\(X_0\\) y Raw input also bvharmod class.","code":""},{"path":"/reference/vhar_lm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting Vector Heterogeneous Autoregressive Model — vhar_lm","text":"VHAR model $$Y_{t} = \\Phi^{(d)} Y_{t - 1} + \\Phi^{(w)} Y_{t - 1}^{(w)} + \\Phi^{(m)} Y_{t - 1}^{(m)} + \\epsilon_t$$ function gives basic values.","code":""},{"path":"/reference/vhar_lm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting Vector Heterogeneous Autoregressive Model — vhar_lm","text":"Baek, C. Park, M. (2021). Sparse vector heterogeneous autoregressive modeling realized volatility. J. Korean Stat. Soc. 50, 495–510. Bubák, V., Kočenda, E., & Žikeš, F. (2011). Volatility transmission emerging European foreign exchange markets. Journal Banking & Finance, 35(11), 2829–2841. Corsi, F. (2008). Simple Approximate Long-Memory Model Realized Volatility. Journal Financial Econometrics, 7(2), 174–196.","code":""},{"path":[]},{"path":"/reference/vhar_lm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting Vector Heterogeneous Autoregressive Model — vhar_lm","text":"","code":"# Perform the function using etf_vix dataset fit <- vhar_lm(y = etf_vix) class(fit) #> [1] \"vharlse\"  \"bvharmod\" str(fit) #> List of 18 #>  $ coefficients : num [1:28, 1:9] 0.8698 0.02988 -0.01632 -0.10078 0.00306 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:28] \"GVZCLS_day\" \"OVXCLS_day\" \"VXFXICLS_day\" \"VXEEMCLS_day\" ... #>   .. ..$ : chr [1:9] \"GVZCLS\" \"OVXCLS\" \"VXFXICLS\" \"VXEEMCLS\" ... #>  $ fitted.values: num [1:883, 1:9] 20.4 20.6 20.1 19.9 19.3 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : NULL #>   .. ..$ : chr [1:9] \"GVZCLS\" \"OVXCLS\" \"VXFXICLS\" \"VXEEMCLS\" ... #>  $ residuals    : num [1:883, 1:9] 0.3176 -0.5873 -0.3752 -0.8374 -0.0281 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : NULL #>   .. ..$ : chr [1:9] \"GVZCLS\" \"OVXCLS\" \"VXFXICLS\" \"VXEEMCLS\" ... #>  $ covmat       : num [1:9, 1:9] 1.119 0.375 0.299 0.437 1.37 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:9] \"GVZCLS\" \"OVXCLS\" \"VXFXICLS\" \"VXEEMCLS\" ... #>   .. ..$ : chr [1:9] \"GVZCLS\" \"OVXCLS\" \"VXFXICLS\" \"VXEEMCLS\" ... #>  $ df           : int 28 #>  $ p            : num 3 #>  $ week         : num 5 #>  $ month        : num 22 #>  $ m            : int 9 #>  $ obs          : int 883 #>  $ totobs       : int 905 #>  $ call         : language vhar_lm(y = etf_vix) #>  $ process      : chr \"VHAR\" #>  $ type         : chr \"const\" #>  $ HARtrans     : num [1:28, 1:199] 1 0 0 0 0 0 0 0 0 0.2 ... #>  $ y0           : num [1:883, 1:9] 20.7 20 19.7 19.1 19.2 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : NULL #>   .. ..$ : chr [1:9] \"GVZCLS\" \"OVXCLS\" \"VXFXICLS\" \"VXEEMCLS\" ... #>  $ design       : num [1:883, 1:199] 20.4 20.7 20 19.7 19.1 ... #>  $ y            : num [1:905, 1:9] 21.5 21.5 22.3 21.6 21.2 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : NULL #>   .. ..$ : chr [1:9] \"GVZCLS\" \"OVXCLS\" \"VXFXICLS\" \"VXEEMCLS\" ... #>  - attr(*, \"class\")= chr [1:2] \"vharlse\" \"bvharmod\"  # Extract coef, fitted values, and residuals coef(fit) #>                      GVZCLS      OVXCLS      VXFXICLS     VXEEMCLS #> GVZCLS_day      0.869796005 -0.04681230 -0.0172897224  0.049002224 #> OVXCLS_day      0.029877159  0.91358257  0.0350799026  0.010047707 #> VXFXICLS_day   -0.016319909 -0.13959548  0.8575034005 -0.033709406 #> VXEEMCLS_day   -0.100780743 -0.08210474  0.0121290737  0.655662834 #> VXSLVCLS_day    0.003060357  0.03668387  0.0282158214  0.013830263 #> EVZCLS_day      0.186426595 -0.17282244  0.0494563262 -0.062064078 #> VXXLECLS_day    0.078818472  0.10515479  0.0728823779  0.279901357 #> VXGDXCLS_day   -0.039080303  0.04925811 -0.0428945531 -0.033003536 #> VXEWZCLS_day    0.032080106  0.07853175  0.0131343314  0.069517084 #> GVZCLS_week    -0.040418408 -0.07188231 -0.0938952991 -0.157648897 #> OVXCLS_week    -0.085524289 -0.06406862 -0.0701989801 -0.038293713 #> VXFXICLS_week  -0.029907441  0.12562086  0.0749857892  0.139908054 #> VXEEMCLS_week   0.230258633  0.05761231  0.0006402918  0.126209971 #> VXSLVCLS_week   0.027500102  0.02993123  0.0442818765  0.042748861 #> EVZCLS_week    -0.236308396  0.28602174 -0.0005685013  0.140233072 #> VXXLECLS_week  -0.120360477 -0.05095917 -0.1126391194 -0.332190330 #> VXGDXCLS_week   0.054947386 -0.06808223  0.0506682953  0.025319297 #> VXEWZCLS_week  -0.043554254 -0.05055300  0.0078698375 -0.007277838 #> GVZCLS_month    0.023458944  0.01754305 -0.0253911426  0.003596504 #> OVXCLS_month    0.001541434  0.07383772 -0.0059125573 -0.012132076 #> VXFXICLS_month -0.011772882 -0.02021036 -0.0587438676 -0.128208430 #> VXEEMCLS_month -0.134015581 -0.03842329 -0.0059768395  0.135807907 #> VXSLVCLS_month -0.002659358 -0.01415388 -0.0158012078  0.038533007 #> EVZCLS_month    0.185251113 -0.05458701  0.1512782039 -0.012040779 #> VXXLECLS_month  0.105997340  0.09819774  0.0508482758  0.101087018 #> VXGDXCLS_month  0.033825430  0.05583194  0.0377451676  0.024847951 #> VXEWZCLS_month  0.020348604 -0.01547358 -0.0074385193 -0.065668936 #> const           0.257508640 -0.75244225  0.7874223172  0.329901821 #>                     VXSLVCLS        EVZCLS     VXXLECLS    VXGDXCLS #> GVZCLS_day      0.2171686933 -8.528593e-04 -0.006316449  0.14468642 #> OVXCLS_day     -0.0038224358  1.317614e-02  0.023484352  0.06339221 #> VXFXICLS_day   -0.0821022074 -2.145593e-02 -0.074931174 -0.05632922 #> VXEEMCLS_day   -0.0951773758 -1.278904e-02 -0.111052628 -0.05281887 #> VXSLVCLS_day    0.6911996371  4.988352e-03  0.009943586  0.07416401 #> EVZCLS_day      0.2247289953  8.908482e-01 -0.164489289 -0.02651442 #> VXXLECLS_day    0.1848839755  2.688135e-02  1.110417850  0.20178781 #> VXGDXCLS_day   -0.0326865958 -1.097720e-02  0.015583137  0.65845387 #> VXEWZCLS_day    0.0086576066  2.741950e-02  0.057451312  0.06060228 #> GVZCLS_week    -0.1717505332  5.820058e-03 -0.062671994 -0.07765708 #> OVXCLS_week     0.0013998157 -3.043820e-02 -0.081955633 -0.06014147 #> VXFXICLS_week   0.0351147921  4.615955e-02  0.148110845  0.14285833 #> VXEEMCLS_week   0.2351233848  5.680828e-03  0.007968589  0.02454380 #> VXSLVCLS_week   0.1788828526 -8.453363e-05  0.023363480 -0.06368503 #> EVZCLS_week    -0.4461793985  1.019828e-02  0.182684876 -0.09790030 #> VXXLECLS_week  -0.2019441922 -2.813833e-02 -0.236461970 -0.21181825 #> VXGDXCLS_week   0.0003105573 -7.379189e-03 -0.011074423  0.20755785 #> VXEWZCLS_week  -0.0240538695 -2.495159e-02  0.001237576 -0.08368461 #> GVZCLS_month   -0.0834085916 -2.856799e-02 -0.047705620 -0.12266095 #> OVXCLS_month   -0.0657907568  1.107681e-02  0.017294294 -0.05920651 #> VXFXICLS_month -0.1051804654 -1.719717e-02 -0.087376926 -0.15744156 #> VXEEMCLS_month -0.0829087351 -1.492401e-02  0.038494367 -0.02320949 #> VXSLVCLS_month  0.0325418895  1.020723e-02  0.048603609  0.05950528 #> EVZCLS_month    0.5392049317  7.115211e-02  0.002772821  0.24304619 #> VXXLECLS_month  0.0824108862  2.585456e-02  0.176619398  0.06498108 #> VXGDXCLS_month  0.1042356427  2.218512e-02  0.016276608  0.11878639 #> VXEWZCLS_month  0.0298234196 -1.661517e-05 -0.049185431  0.06065243 #> const           0.8310348716 -2.382650e-02  0.258939806  0.60556631 #>                    VXEWZCLS #> GVZCLS_day      0.060810440 #> OVXCLS_day     -0.021328545 #> VXFXICLS_day   -0.103241781 #> VXEEMCLS_day   -0.050810494 #> VXSLVCLS_day   -0.041214628 #> EVZCLS_day     -0.044510366 #> VXXLECLS_day    0.286415660 #> VXGDXCLS_day   -0.004629846 #> VXEWZCLS_day    0.952152534 #> GVZCLS_week    -0.232659033 #> OVXCLS_week     0.029438686 #> VXFXICLS_week   0.233415007 #> VXEEMCLS_week  -0.104629279 #> VXSLVCLS_week   0.174714784 #> EVZCLS_week     0.123320940 #> VXXLECLS_week  -0.239829609 #> VXGDXCLS_week  -0.012408245 #> VXEWZCLS_week   0.018610770 #> GVZCLS_month    0.334911077 #> OVXCLS_month    0.012987518 #> VXFXICLS_month -0.111977668 #> VXEEMCLS_month  0.133305259 #> VXSLVCLS_month -0.181258940 #> EVZCLS_month   -0.129656359 #> VXXLECLS_month -0.041980863 #> VXGDXCLS_month -0.027342181 #> VXEWZCLS_month -0.009420411 #> const           1.047643911 head(residuals(fit)) #>           GVZCLS      OVXCLS   VXFXICLS    VXEEMCLS   VXSLVCLS     EVZCLS #> [1,]  0.31758364 -0.11022615 -0.5296023  0.04716717 -0.5378020 -0.4659005 #> [2,] -0.58729937 -0.02977095 -0.9556970 -0.70126942 -1.4850409 -0.5500010 #> [3,] -0.37519058  0.15466899  2.8092305  1.54460103 -0.4209523  0.4631326 #> [4,] -0.83743454  0.32276054 -1.2472184 -1.66328320 -2.0118629 -0.4732741 #> [5,] -0.02811876  0.29432487 -0.2286953  0.48869052  0.5149326  0.3606493 #> [6,] -0.14617138  1.20662142  0.3416573  1.34978100 -0.7638851  0.6622565 #>         VXXLECLS   VXGDXCLS   VXEWZCLS #> [1,] -0.03896889 -0.8878031  0.8547725 #> [2,] -0.01517932 -1.2314864 -0.6129635 #> [3,]  2.49685115  0.9469600  2.3957692 #> [4,] -2.00237189 -1.4008812 -1.1284324 #> [5,] -0.26141669  0.4395067  1.5021262 #> [6,]  0.71563874  0.7208909  1.7436068 head(fitted(fit)) #>        GVZCLS   OVXCLS VXFXICLS VXEEMCLS VXSLVCLS   EVZCLS VXXLECLS VXGDXCLS #> [1,] 20.37242 32.43023 29.98960 28.28283 40.30780 12.91590 24.22897 32.12780 #> [2,] 20.61730 32.45977 29.62570 28.64127 39.48504 12.51000 24.56518 32.01149 #> [3,] 20.10519 32.67533 28.92077 28.50540 38.21095 12.07687 25.06315 31.72304 #> [4,] 19.90743 32.97724 31.71722 30.56328 38.13186 12.61327 27.88237 33.30088 #> [5,] 19.26812 33.34568 30.41870 29.20131 36.60507 12.20935 26.08142 32.38049 #> [6,] 19.42617 33.64338 30.16834 29.66022 37.24389 12.58774 25.84436 33.12911 #>      VXEWZCLS #> [1,] 29.00523 #> [2,] 29.72296 #> [3,] 29.20423 #> [4,] 31.84843 #> [5,] 30.60787 #> [6,] 31.67639"},{"path":"/news/index.html","id":"bvhar-120","dir":"Changelog","previous_headings":"","what":"bvhar 1.2.0","title":"bvhar 1.2.0","text":"Replace progress bar RcppProgress package custom header (bvharprogress.h). Replace checking user interruption package custom header (bvharinterrupt.h). Fix triangular algorithm. Found missing update variables (bvar_sv() bvhar_sv()).","code":""},{"path":"/news/index.html","id":"bvhar-110","dir":"Changelog","previous_headings":"","what":"bvhar 1.1.0","title":"bvhar 1.1.0","text":"CRAN release: 2023-12-18 new research, add new features shrinkage priors. Add Shrinkage priors SSVS Horseshoe (bvar_ssvs(), bvhar_ssvs(), bvar_horseshoe(), bvhar_horseshoe()). bvar_sv(), bvhar_sv() works SSVS (set_ssvs()) Horseshoe (set_horseshoe()). Update shrinkage structure spirit Minnesota. (minnesota = TRUE, minnesota = c(\"\", \"short\", \"longrun\")). Stochastic volatility models implement corrected triangular algorithm Carriero et al. (2021).","code":""},{"path":"/news/index.html","id":"bvhar-102","dir":"Changelog","previous_headings":"","what":"bvhar 1.0.2","title":"bvhar 1.0.2","text":"CRAN release: 2023-12-06 License changed GPLv3. Remove unnecessary Rcpp plugins source files.","code":""},{"path":"/news/index.html","id":"bvhar-101","dir":"Changelog","previous_headings":"","what":"bvhar 1.0.1","title":"bvhar 1.0.1","text":"CRAN release: 2023-11-10 Fix knitr::knit_print() method export methods (#2).","code":""},{"path":"/news/index.html","id":"bvhar-100","dir":"Changelog","previous_headings":"","what":"bvhar 1.0.0","title":"bvhar 1.0.0","text":"CRAN release: 2023-11-08 “Bayesian Vector Heterogeneous Autoregressive Modeling” accepted JSCS 🎉 Update major version publication.","code":""},{"path":[]},{"path":"/news/index.html","id":"bvhar-0140","dir":"Changelog","previous_headings":"","what":"bvhar 0.14.0","title":"bvhar 0.14.0","text":"Add Stochastic Search Variable Selection (SSVS) models VAR VHAR (bvar_ssvs() bvhar_ssvs()) Can corresponding variable selection (summary.ssvsmod())","code":""},{"path":"/news/index.html","id":"bvhar-0130","dir":"Changelog","previous_headings":"","what":"bvhar 0.13.0","title":"bvhar 0.13.0","text":"Add stochastic volatility models VAR-SV VHAR-SV (bvar_sv() bvhar_sv()).","code":""},{"path":"/news/index.html","id":"bvhar-0121","dir":"Changelog","previous_headings":"","what":"bvhar 0.12.1","title":"bvhar 0.12.1","text":"Fix working Hierarchical natural conjugate MNIW function (bvar_niwhm()). Use posterior package summary.normaliw() improve processing printing.","code":""},{"path":"/news/index.html","id":"bvhar-0120","dir":"Changelog","previous_headings":"","what":"bvhar 0.12.0","title":"bvhar 0.12.0","text":"Now can use heavy-tailed distribution (Multivariate t-distribution) generating VAR VHAR process (sim_var() sim_vhar()). Also provide independent MVT generation function (sim_mvt()).","code":""},{"path":"/news/index.html","id":"bvhar-0110","dir":"Changelog","previous_headings":"","what":"bvhar 0.11.0","title":"bvhar 0.11.0","text":"Added method = c(\"\", \"chol\", \"qr\") option VAR VHAR fitting function use cholesky Householder QR method (var_lm() vhar_lm()). Now include_mean works internally Rcpp.","code":""},{"path":"/news/index.html","id":"bvhar-0100","dir":"Changelog","previous_headings":"","what":"bvhar 0.10.0","title":"bvhar 0.10.0","text":"Add partial t-test VAR VHAR coefficient (summary.varlse() summary.vharlse()). Appropriate print method updated summary method (print.summary.varlse() print.summary.vharlse()).","code":""},{"path":"/news/index.html","id":"bvhar-090","dir":"Changelog","previous_headings":"","what":"bvhar 0.9.0","title":"bvhar 0.9.0","text":"Can compute impulse response function VAR (varlse) VHAR (vharlse) models (analyze_ir()). Can draw impulse -> response plot grid panels (autoplot.bvharirf()).","code":""},{"path":"/news/index.html","id":"bvhar-080","dir":"Changelog","previous_headings":"","what":"bvhar 0.8.0","title":"bvhar 0.8.0","text":"Changed way specifying lower upper bounds empirical bayes (bound_bvhar()). Added Empirical Bayes vignette.","code":""},{"path":"/news/index.html","id":"bvhar-071","dir":"Changelog","previous_headings":"","what":"bvhar 0.7.1","title":"bvhar 0.7.1","text":"simulation, asymmetric covariance error caught now (sim_mgaussian()).","code":""},{"path":"/news/index.html","id":"bvhar-070","dir":"Changelog","previous_headings":"","what":"bvhar 0.7.0","title":"bvhar 0.7.0","text":"Add one integrated function can empirical bayes (choose_bayes() bound_bvhar()).","code":""},{"path":"/news/index.html","id":"bvhar-061","dir":"Changelog","previous_headings":"","what":"bvhar 0.6.1","title":"bvhar 0.6.1","text":"Pre-process date column oxfordman elaborately (becomes etf_vix).","code":""},{"path":"/news/index.html","id":"bvhar-060","dir":"Changelog","previous_headings":"","what":"bvhar 0.6.0","title":"bvhar 0.6.0","text":"Added weekly monthly order feature VHAR family (vhar_lm() bvhar_minnesota()). functions compatible har order option (predict.vharlse(), predict.bvharmn(), choose_bvhar())","code":""},{"path":"/news/index.html","id":"bvhar-052","dir":"Changelog","previous_headings":"","what":"bvhar 0.5.2","title":"bvhar 0.5.2","text":"Added parallel option empirical bayes (choose_bvar() choose_bvhar()).","code":""},{"path":"/news/index.html","id":"bvhar-051","dir":"Changelog","previous_headings":"","what":"bvhar 0.5.1","title":"bvhar 0.5.1","text":"Added facet feature loss plot changed name (gg_loss()).","code":""},{"path":"/news/index.html","id":"bvhar-050","dir":"Changelog","previous_headings":"","what":"bvhar 0.5.0","title":"bvhar 0.5.0","text":"Added rolling window expanding window features (forecast_roll() forecast_expand()). Can compute loss rolling expanding window method (mse.bvharcv(), mae.bvharcv(), mape.bvharcv(), mape.bvharcv()).","code":""},{"path":"/news/index.html","id":"bvhar-041","dir":"Changelog","previous_headings":"","what":"bvhar 0.4.1","title":"bvhar 0.4.1","text":"Fix Marginal likelihood form (compute_logml()). Optimize empirical bayes method using stabilized marginal likelihood function (logml_stable()).","code":""},{"path":"/news/index.html","id":"bvhar-040","dir":"Changelog","previous_headings":"","what":"bvhar 0.4.0","title":"bvhar 0.4.0","text":"Change way compute CI BVAR BVHAR (predict.bvarmn(), predict.bvharmn(), predict.bvarflat()) Used custom random generation function - MN, IW, MNIW based RcppEigen","code":""},{"path":"/news/index.html","id":"bvhar-030","dir":"Changelog","previous_headings":"","what":"bvhar 0.3.0","title":"bvhar 0.3.0","text":"Added Bayesian model specification functions class (bvharspec). Replaced hyperparameters model specification Bayesian models (bvar_minnesota(), bvar_flat(), bvhar_minnesota()).","code":""},{"path":"/news/index.html","id":"bvhar-020","dir":"Changelog","previous_headings":"","what":"bvhar 0.2.0","title":"bvhar 0.2.0","text":"Added constant term choice function (var_lm(), vhar_lm(), bvar_minnesota(), bvar_flat(), bvhar_minnesota()).","code":""},{"path":"/news/index.html","id":"bvhar-010","dir":"Changelog","previous_headings":"","what":"bvhar 0.1.0","title":"bvhar 0.1.0","text":"Added NEWS.md file track changes package.","code":""}]
