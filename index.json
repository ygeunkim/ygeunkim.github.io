[{"authors":["dykim"],"categories":null,"content":"","date":1635127200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1636987357,"objectID":"3de5944d48a1702b3082d9e1d4ce474d","permalink":"https://ygeunkim.github.io/author/dongyeong-kim/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/dongyeong-kim/","section":"authors","summary":"","tags":null,"title":"Dongyeong Kim","type":"authors"},{"authors":["jwlee"],"categories":null,"content":"","date":1635127200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1636987357,"objectID":"734683caf8850d5aa2f68c421e3ca563","permalink":"https://ygeunkim.github.io/author/jaewon-lee/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/jaewon-lee/","section":"authors","summary":"","tags":null,"title":"Jaewon Lee","type":"authors"},{"authors":["khkim"],"categories":null,"content":"","date":1635127200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1636987357,"objectID":"d02b7c57ef118232b7714dd8b1b5af6e","permalink":"https://ygeunkim.github.io/author/kyung-hee-kim/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/kyung-hee-kim/","section":"authors","summary":"","tags":null,"title":"Kyung Hee Kim","type":"authors"},{"authors":["byung"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1643614778,"objectID":"ea5fce56d998e8051700517c360d0b63","permalink":"https://ygeunkim.github.io/author/byung-gil-min/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/byung-gil-min/","section":"authors","summary":"","tags":null,"title":"Byung-Gil Min","type":"authors"},{"authors":["baek"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1636987357,"objectID":"5f07733163613c772fc514f0caa943c7","permalink":"https://ygeunkim.github.io/author/changryong-baek/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/changryong-baek/","section":"authors","summary":"","tags":null,"title":"Changryong Baek","type":"authors"},{"authors":["hyoung"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1617346881,"objectID":"fd3e58bad84c339df5a08909560283cb","permalink":"https://ygeunkim.github.io/author/hyoung-chun-kim/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/hyoung-chun-kim/","section":"authors","summary":"","tags":null,"title":"Hyoung Chun Kim","type":"authors"},{"authors":["jeong"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1617346881,"objectID":"0be480a6f17742e73a6bd93b1542e286","permalink":"https://ygeunkim.github.io/author/jeong-han-yun/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/jeong-han-yun/","section":"authors","summary":"","tags":null,"title":"Jeong-Han Yun","type":"authors"},{"authors":["jinwoo"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1609910183,"objectID":"ee4d704699a0d0fbb113c6bb5ba81761","permalink":"https://ygeunkim.github.io/author/jinwoo-cho/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/jinwoo-cho/","section":"authors","summary":"","tags":null,"title":"Jinwoo Cho","type":"authors"},{"authors":["jonguk"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1609995654,"objectID":"fa8008d1edcaf315c720a15ab621cea3","permalink":"https://ygeunkim.github.io/author/jonguk-kim/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/jonguk-kim/","section":"authors","summary":"","tags":null,"title":"Jonguk Kim","type":"authors"},{"authors":["sangyup"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1617346881,"objectID":"6ec870196ef09fdcc105ed4036edce3a","permalink":"https://ygeunkim.github.io/author/sangyup-lee/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/sangyup-lee/","section":"authors","summary":"","tags":null,"title":"Sangyup Lee","type":"authors"},{"authors":["seoyoung"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1617346881,"objectID":"96e42f41af34c92f39502304b716975c","permalink":"https://ygeunkim.github.io/author/seoyoung-park/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/seoyoung-park/","section":"authors","summary":"","tags":null,"title":"Seoyoung Park","type":"authors"},{"authors":["swlee"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"a77180e9c16ddf37a8c5705cc60be540","permalink":"https://ygeunkim.github.io/author/seungwon-lee/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/seungwon-lee/","section":"authors","summary":"","tags":null,"title":"Seungwon Lee","type":"authors"},{"authors":["shahroz"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1617346881,"objectID":"34a32a7e565157f123d207483137201e","permalink":"https://ygeunkim.github.io/author/shahroz-tariq/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/shahroz-tariq/","section":"authors","summary":"","tags":null,"title":"Shahroz Tariq","type":"authors"},{"authors":["siho"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1617346881,"objectID":"39efcf034dee361056d4d758439026c8","permalink":"https://ygeunkim.github.io/author/siho-han/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/siho-han/","section":"authors","summary":"","tags":null,"title":"Siho Han","type":"authors"},{"authors":["simon"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1643941930,"objectID":"39676266dc03f7a9ebc998657bf4cd2d","permalink":"https://ygeunkim.github.io/author/simon-s.-woo/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/simon-s.-woo/","section":"authors","summary":"","tags":null,"title":"Simon S. Woo","type":"authors"},{"authors":["wonseok"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1643614778,"objectID":"82e6d2f692e5bf70a9a8064d5fb03b66","permalink":"https://ygeunkim.github.io/author/won-seok-hwang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/won-seok-hwang/","section":"authors","summary":"","tags":null,"title":"Won-Seok Hwang","type":"authors"},{"authors":null,"categories":null,"content":"Welcome to Young Geun Kim\u0026rsquo;s long-range dependent academic path! Young-geun Kim is a Ph.D. candidate at statistics, Sungkyunkwan University (SKKU). His research interest mainly begins with a time series. It includes high-dimensional time series, long-range dependency, change point detection, et cetera. He is developing forecasting models for multivariate high-frequency data.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1650983944,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://ygeunkim.github.io/author/young-geun-kim/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/young-geun-kim/","section":"authors","summary":"Welcome to Young Geun Kim\u0026rsquo;s long-range dependent academic path! Young-geun Kim is a Ph.D. candidate at statistics, Sungkyunkwan University (SKKU). His research interest mainly begins with a time series. It includes high-dimensional time series, long-range dependency, change point detection, et cetera.","tags":null,"title":"Young Geun Kim","type":"authors"},{"authors":["rok"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1609910183,"objectID":"59faa01efdc7a9aa789de3a310e485d2","permalink":"https://ygeunkim.github.io/author/youngrok-choi/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/youngrok-choi/","section":"authors","summary":"","tags":null,"title":"Youngrok Choi","type":"authors"},{"authors":["yujin"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1617346881,"objectID":"2974b3af626d9d6043aad3c10be10e48","permalink":"https://ygeunkim.github.io/author/yujin-shin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yujin-shin/","section":"authors","summary":"","tags":null,"title":"Yujin Shin","type":"authors"},{"authors":["Young Geun Kim"],"categories":["post"],"content":"MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ], displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ], skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'], processEscapes: true } });     Table of Contents   Change Point Problem Single Change Point  LSE Change Point Detection Cumulative Sum (CUSUM) Estimator   Multiple Change Pints  Binary Segmentation Wild Binary Segmentation Moving Sum (MOSUM) Statistic and Tests   Wrapping up   References    Based on the lecture of Baek (2020) in SKKU   # tidyverse family--------------------------------- library(tidyverse) # rolling arithmetics------------------------------ library(zoo) # set seed for reproducibility--------------------- set.seed(1)  Change Point Detection Problem When analyzing time series, we often use parameter models to fit given dataset. In the sample from 2005 to 2006, for example, the chosen model might forecast well. Imagine, however, we should include 2007 to 2008 period in which financial crisis occurred. The estimators of the model would change due to this eventüò≠. It is important to figure out these change points because the model parameter could change at the point. The goal of change point analysis is to mark the timestamp when some parameter has changed. Here the simplest setting is to detect change of the mean \\(\\mu_t\\) in location model.\n$$Y_t = \\mu_t + \\epsilon_t, \\quad t = 1, \\ldots, n$$\nThen change point detection can be expressed by\n$$H_0: \\mu_1 = \\cdots = \\mu_n \\quad \\text{vs} \\quad H_1: \\exists k \\colon \\mu_1 = \\cdots = \\mu_k \\neq \\mu_{k + 1} = \\cdots = \\mu_n$$\nNow, each method should\n Estimate unknown \\(k\\). Test.  Single Change Point First consider single change point problem with \\(k = 100\\).\ny1 \u0026lt;- tibble(key = \u0026quot;a\u0026quot;, value = rnorm(100, mean = 0), mean = 0) y2 \u0026lt;- tibble(key = \u0026quot;b\u0026quot;, value = rnorm(150, mean = 5), mean = 5) # bind rows and bind time index column---------------- sim_single \u0026lt;- bind_rows(y1, y2) %\u0026gt;% mutate(index = 1:n())    LSE CUSUM (PAGE 1954)  These 2 methods can find one change point.\nLSE Change Point Detection  Above figure just changes time plot to point. To estimate \\(k\\), the most easiest way is to minimize sum of within sums of square.\nLet\n\\(\\overline{Y}_k = \\frac{1}{k} \\sum_{t = 1}^k Y_t\\) and let \\(\\overline{Y}_k^\\ast = \\frac{1}{n - k} \\sum_{t = k + 1}^n Y_t\\). Then\n$$\\begin{aligned} \\hat{k}^{LS} \u0026amp; = \\arg\\min_{1 \\le k \\le n - 1} \\left( \\sum_{t = 1}^k (Y_t - \\overline{Y}_k)^2 + \\sum_{t = k + 1}^n (Y_t - \\overline{Y}_k^\\ast)^2 \\right) \\\\ \u0026amp; = \\arg\\max_{1 \\le k \\le n - 1} \\sqrt{\\frac{k (n - k)}{n}} \\left\\lvert \\overline{Y}_k - \\overline{Y}_k^\\ast \\right\\rvert \\end{aligned}$$\nObserve that by multiplying \\(\\sqrt{\\frac{k (n - k)}{n}}\\), it adjusts the location of \\(k\\) and the sample size. You can see this feature in the following figure.\nlse_output \u0026lt;- sim_single %\u0026gt;% mutate( mean_k = cumsum(value) / index, mean_ast = sapply( index + 1, function(i) { sum(value[i:n()]) } ) / (n() - index), lse_unadjust = abs(mean_k - mean_ast), lse_adjust = sqrt(index * (n() - index) / n()) * lse_unadjust )   While LSE estimator performs well, unadjusted LSE inflates against \\(k\\).\nCumulative Sum (CUSUM) Estimator This method is called CUSUM because it deals with cumulative sum (of \\(Y_t - \\overline{Y}\\) until \\(k\\)) as follows.\n$$\\begin{aligned} \\left\\lvert \\chi(k) \\right\\rvert \u0026amp; = \\frac{1}{\\sqrt{n}} \\left\\lvert \\sum_{t = 1}^k Y_t - \\frac{k}{n} \\sum_{t = 1}^n Y_t \\right\\rvert \\\\ \u0026amp; = \\frac{1}{\\sqrt{n}} \\left\\lvert \\sum_{t = 1}^k (Y_t - \\overline{Y}) \\right\\rvert \\end{aligned}$$\nwhere \\(\\overline{Y} = \\frac{1}{n} \\sum_{t = 1}^n Y_t\\). In turn, we estimate \\(k\\) by maximizing the CUSUM.\n$$\\hat{k}^{CUSUM} = \\arg\\max_{1 \\le k \\le n} \\left\\lvert \\chi(k) \\right\\rvert$$\nIn fact, CUSUM inspect the absolute difference between \\(\\overline{Y}_k\\) and \\(\\overline{Y}_k^\\ast\\), i.e.\n$$\\lvert \\chi(k) \\rvert = \\frac{1}{\\sqrt{n}} \\frac{k (n - k)}{n} \\left\\lvert \\overline{Y}_k - \\overline{Y}_k^\\ast \\right\\rvert$$\nIt follows that CUSUM change point estimator is also an LSE estimator in that\n$$\\begin{aligned} \\hat{k}^{LS} \u0026amp; = \\arg\\max_{1 \\le k \\le n - 1} \\sqrt{\\frac{k (n - k)}{n}} \\left\\lvert \\overline{Y}_k - \\overline{Y}_k^\\ast \\right\\rvert \\\\ \u0026amp; = \\arg\\max_{1 \\le k \\le n - 1} \\sqrt{\\frac{n}{k (n - k)}} \\left\\lvert \\chi(k) \\right\\rvert \\\\ \u0026amp; = \\arg\\max_{1 \\le k \\le n - 1} \\left\\lvert \\widetilde\\chi(k) \\right\\rvert \\end{aligned}$$\nwhere \\(\\left\\lvert \\widetilde\\chi(k) \\right\\rvert\\) is adjusted CUSUM defined by \\(\\left\\lvert \\widetilde\\chi(k) \\right\\rvert = \\sqrt{\\frac{n}{k (n - k)}} \\lvert \\chi(k) \\rvert\\).\ncusum_output \u0026lt;- sim_single %\u0026gt;% mutate( ave = mean(value), cusum = abs(cumsum(value - ave)) / sqrt(n()) )  We can easily find the value which maximizes CUSUMüòÄ. See the trajectory of CUSUM figure. Its maximum stands out.\n The second step is test. For this testing, we investigate some theory. As in the first Section, we test null hypothesis of no change point that \\(H_0: \\mu_1 = \\cdots = \\mu_n\\) versus single change point existence. Given each \\(\\hat{k}\\), we build test statistic and derive its (asymptotic) distribution. Under \\(H_0\\), functional central limit theorem holds under some conditions (see the tables below). Let \\(B(t)\\) is a Brownian bridge (standard Brownian motion) and let \\(\\sigma^2\\) be the long-run variance. The different part is scaling \\(\\sqrt{u (1 - u)}\\) for sample size. Multiplying unbalance against sample size raises precision of \\(\\hat{k}^{LS}\\), but it makes difficult to get p-value of \\(T_{LS}\\).\n    LSE CUSUM     Statistic $T_{LS} = \\max_{1 \\le k \\le n - 1} \\left\\lvert \\widetilde\\chi(k) \\right\\rvert$ $T_{CUSUM} = \\max_{1 \\le k \\le n} \\left\\lvert \\chi(k) \\right\\rvert$   Distribution $T_{LS} \\stackrel{\\cal{D}}{\\rightarrow} \\sigma \\sup_{0 \\le u \\le 1} \\frac{\\left\\lvert B(u) \\right\\rvert}{\\sqrt{u (1 - u)}}$ $T_{CUSUM} \\stackrel{\\cal{D}}{\\rightarrow} \\sigma \\sup_{0 \\le u \\le 1} \\left\\lvert B(u) \\right\\rvert$   p-value (computation) hard easy   $\\hat{k}$ precision good bias bad    Multiple Change Points Consider 3 change points: \\(k_1 = 100\\), \\(k_2 = 250\\), and \\(k_3 = 300\\).\ny1 \u0026lt;- tibble(key = \u0026quot;a\u0026quot;, value = rnorm(100, mean = 0), mean = 0) y2 \u0026lt;- tibble(key = \u0026quot;b\u0026quot;, value = rnorm(150, mean = 3), mean = 3) y3 \u0026lt;- tibble(key = \u0026quot;c\u0026quot;, value = rnorm(50, mean = -1), mean = -1) y4 \u0026lt;- tibble(key = \u0026quot;d\u0026quot;, value = rnorm(50, mean = 1), mean = 1) # bind rows and bind time index column---------------- sim_multiple \u0026lt;- bind_rows(y1, y2, y3, y4) %\u0026gt;% mutate(index = 1:n())   In multiple change points problem, we do not know both location and the number of of \\(k\\)‚Äôs. In single change point problem, alternative hypothesis was literally the existence of one single point. Now, we should extend this hypothesis to at least one change point. Based on above CUSUM statistic detection, we introduce the following methods. Of course there are the other advanced detection methods, this post focus on simple approach in location model.\n Binary segmentation (Vostrikova 1981) Wild binary segmentation (Fryzlewicz 2014) MOSUM (Eichinger and Kirch 2018)  Binary Segmentation Binary segmentation suggested by Vostrikova (1981) is famous with its effective computation. This is basic algorithm, so it is also called standard binary segmentation (SBS). It performs single detection by top-down way. This helps computation cheap. Fryzlewicz (2014) provides well-organized pseudocode (section 3.2).1\nSBS cuts the entire sample \\(\\{ y_t \\mathpunct{:} t = 1, \\ldots n \\}\\) with change point. In turn, it explores each part thoroughly. In the algorithm, we can find CUSUM in single stick by means of detecting change point, respectively.\nfind_binseg \u0026lt;- function(data, s = 0, e) { cusum_out \u0026lt;- data %\u0026gt;% dplyr::filter(index \u0026gt; s, index \u0026lt;= e) %\u0026gt;% mutate( ave = mean(value), cusum = abs(cumsum(value - ave)) / sqrt(n()) ) %\u0026gt;% filter(cusum == max(cusum)) list( stat = cusum_out$cusum, change_point = cusum_out$index ) }  First, we find \\(k = 250\\):\n(binseg1 \u0026lt;- find_binseg(sim_multiple, 0, nrow(sim_multiple))) #\u0026gt; $stat #\u0026gt; [1] 7.13 #\u0026gt; #\u0026gt; $change_point #\u0026gt; [1] 250  Next, see before and after \\(k = 250\\):\nfind_binseg(sim_multiple, 0, 250) #\u0026gt; $stat #\u0026gt; [1] 10.9 #\u0026gt; #\u0026gt; $change_point #\u0026gt; [1] 99 find_binseg(sim_multiple, 251, nrow(sim_multiple)) #\u0026gt; $stat #\u0026gt; [1] 5.06 #\u0026gt; #\u0026gt; $change_point #\u0026gt; [1] 300  Both statistics seems large, so we say these two points are change points.\nfind_binseg(sim_multiple, 0, 100) #\u0026gt; $stat #\u0026gt; [1] 0.506 #\u0026gt; #\u0026gt; $change_point #\u0026gt; [1] 73 find_binseg(sim_multiple, 100, 250) #\u0026gt; $stat #\u0026gt; [1] 0.755 #\u0026gt; #\u0026gt; $change_point #\u0026gt; [1] 209  Every statistic is small, so we stop here. Consider the last block, after 250. Following figure computes CUSUM in multiple change points setting. Recall that it is expected to be huge at the change point. In first two breaks, the estimators seem works okay. However, it does not at the last. Why?\n Observe their true mean from the simulation step:\n#\u0026gt; [1] 0 3 -1 1  We can expect that -1 and 1 were canceled. In the above figure, blue line is calculating CUSUM only in this area. The estimator looks like working better. In this example, binary segmentation could find 300 as change point since this block came at once after \\(k = 250\\) was found. SBS, however, is not guaranteed to include this specific local range since the process of detection is not predictable.\nFryzlewicz (2014) suggested randomly splitted localization as the solution. It is called Wild binary segmentation (WBS).\nWild Binary Segmentation Wild Binary Segmentation (WBS) is bootstrap version for binary segmentation. It chooses random interval \\([s_m, e_m]\\) ($m = 1, \\ldots M$) in each step. Moreover, the reason this technique is related to bootstrap is \\(s_m \u0026lt; e_m\\) are sampled with replacement. For instance:\nboot_size \u0026lt;- 10 # sampling with replacement-------------------- boot_eg \u0026lt;- matrix( sample(sim_multiple$index, size = boot_size * 2, replace = TRUE), nrow = 2, ncol = boot_size ) %\u0026gt;% apply(2, sort) # rownames------------------------------------- rownames(boot_eg) \u0026lt;- c(\u0026quot;sm\u0026quot;, \u0026quot;em\u0026quot;) boot_eg #\u0026gt; [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] #\u0026gt; sm 88 199 22 118 52 118 294 77 113 114 #\u0026gt; em 251 254 312 186 311 183 347 185 268 192  WBS also begins with the entire sequence as SBS does. However, it should get statistic maximum and change point for each bootstrap interval. Among them, the interval whose maxima is the largest.\nFryzlewicz (2014) provides algorithms of the wild binary segmentation (section 3.3). In this post, we follow the step as in previous section to help understand the whole procedure.\nFor the entire sequence (bootstrap size 100):\n# bootstrap---------------------------- boot1 \u0026lt;- matrix( sample(sim_multiple$index, size = 100 * 2, replace = TRUE), nrow = 2, ncol = 100 ) %\u0026gt;% apply(2, sort) # WBS---------------------------------- wbs1 \u0026lt;- boot1 %\u0026gt;% apply(2, function(x) {find_binseg(data = sim_multiple, s = x[1], e = x[2])})   Among 100 intervals, 250 gives the maximum CUSUM statistic. Next step, before 250:\n# bootstrap---------------------------- boot2 \u0026lt;- matrix( sample(1:250, size = 100 * 2, replace = TRUE), nrow = 2, ncol = 100 ) %\u0026gt;% apply(2, sort) # WBS---------------------------------- wbs2 \u0026lt;- boot2 %\u0026gt;% apply(2, function(x) {find_binseg(data = sim_multiple, s = x[1], e = x[2])})  After 250:\n# bootstrap---------------------------- boot3 \u0026lt;- matrix( sample(251:last(sim_multiple$index), size = 100 * 2, replace = TRUE), nrow = 2, ncol = 100 ) %\u0026gt;% apply(2, sort) # WBS---------------------------------- wbs3 \u0026lt;- boot3 %\u0026gt;% apply(2, function(x) {find_binseg(data = sim_multiple, s = x[1], e = x[2])})   Choose the point with the highest value in each color. Denote that they are similar to the true ones üëçüèº.\nMoving Sum (MOSUM) Statistic and Tests As we have seen above, localization of CUSUM can improve performance. MOSUM is localization of CUSUM statistic of window size \\(G\\) (Eichinger and Kirch 2018). In each window, moving sum is computed.\n$$\\left\\lvert T_{k, n}(G) \\right\\rvert = \\frac{1}{\\sqrt{2 G}} \\left\\lvert \\sum_{t = k + 1}^{k + G} Y_t - \\sum_{t = k - G + 1}^k Y_t \\right\\rvert$$\nmosum_output \u0026lt;- sim_multiple %\u0026gt;% mutate( roll_mean = rollsum(value, k = 20, na.pad = TRUE, align = \u0026quot;right\u0026quot;), mosum = abs(lead(roll_mean, n = 20) - roll_mean) / sqrt(2 * 20) )  Unlike CUSUM, MOSUM is detecting the last change point by localization.\n The next step is similar to CUSUM or the other statistic.\n$$T_n(G) = \\max_{G \\le k \\le n - G} \\frac{\\left\\lvert T_{k, n}(G) \\right\\rvert}{\\sigma}$$\nwith long-run variance \\(\\sigma\\). Now we can see additional topics to solve:\n Estimate long-run variance and choose the bandwidth.  Let \\(q = q_n\\) be the number of changes and let \\(k_1 \u0026lt; k_2 \u0026lt; \\cdots \u0026lt; k_q\\) be each change point. Then the null hypothesis of no change point can be represented by\n$$H_0: q_n = 0$$\nversus alternative hypothesis of at least one change\n$$H_1: q_n \\ge 1$$\nRecall that CUSUM converges in distribution to Brownian bridge. This enables the computation of p-value. Also in MOSUM framework, some asymptotic theorem holds. Under above null hypothesis, \\(T_n(G)\\) can use the distribution Gumbel extreme value distribution asymptotically. The form is quite complex, so we skip the details in this post. Please see Theorem 2.1 of Eichinger and Kirch (2018) üò±.\nVariance Now, we estimate long-run variance in each break instead of sample variance \\(\\hat\\sigma^2 = \\frac{1}{n - 1}\\sum_{t = 1}^n (Y_t - \\overline{Y})^2\\). Assuming i.i.d. errors, implementing the sample variance formula is suggested. Let \\(\\overline{Y}_{k - G + 1, k} = \\frac{1}{G} \\sum_{t = k - G + 1}^k Y_t\\) be the sample mean of \\(G\\) points before \\(k\\) and let \\(\\overline{Y}_{k + 1, k + G} = \\frac{1}{G} \\sum_{t = k + 1}^{k + G} Y_t\\) be the sample mean of \\(G\\) points after \\(k\\). Eichinger and Kirch (2018) computed sample variance in this window of \\(k\\)-th point:\n$$\\hat\\sigma_{k, n}^2 = \\frac{1}{2G} \\left( \\sum_{t = k - G + 1}^k (Y_t - \\overline{Y}_{k - G + 1, k})^2 + \\sum_{t = k + 1}^{k + G} (Y_t - \\overline{Y}_{k + 1, k + G})^2 \\right)$$\nmosum_var \u0026lt;- sim_multiple %\u0026gt;% mutate( roll_mean = rollsum(value, k = 20, na.pad = TRUE, align = \u0026quot;right\u0026quot;), mosum = abs(lead(roll_mean, n = 20) - roll_mean) / sqrt(2 * 20), roll_var = (rollapply(value, width = 20, var, fill = NA, align = \u0026quot;right\u0026quot;) * 19 + rollapply(value, width = 20, var, fill = NA, align = \u0026quot;left\u0026quot;) * 19) / 40, mosum_est = mosum / sqrt(roll_var) )  The following shows MOSUM statistic \\(\\hat\\sigma_{k, n}^{-1} \\left\\lvert T_{k, n}(G) \\right\\rvert\\). By multiplying standard deviation to the sum, now we can detect change point more clearly.\n Bandwidth Selection Try \\(G = 5, 10, 20, 40, 45\\). One of many assumptions in the paper of Eichinger and Kirch (2018) is that the window size \\(2G\\) should be large enough (Assumption A.2). The figure below is MOSUM statistic for each bandwidth. When \\(G = 3, 5\\), i.e.¬†the bandwidth is small, you can see it is not easy to find maximum of the statistic. In large bandwidth, the maximum points stand out.\n Wrapping up We have covered change point analysis for univariate time series. Codes I have written are absolutely not practical. In fact, many researchers already developed useful packages for this topic. Later, I plan to write a post about detecting change point using R (of course, using CRAN packages ü§ó).\n References Baek, Changryong. 2020. ‚ÄúRecent Advances in Applied Statistics (Sta5037).‚Äù Department of Statistics, Sungkyunkwan University; https://sites.google.com/view/crbaek.\n Eichinger, Birte, and Claudia Kirch. 2018. ‚ÄúA MOSUM procedure for the estimation of multiple random change points.‚Äù Bernoulli 24 (1): 526‚Äì64. https://doi.org/10.3150/16-bej887.\n Fryzlewicz, Piotr. 2014. ‚ÄúWild binary segmentation for multiple change-point detection.‚Äù The Annals of Statistics 42 (6): 2243‚Äì81. https://doi.org/10.1214/14-aos1245.\n PAGE, E. S. 1954. ‚ÄúCONTINUOUS INSPECTION SCHEMES.‚Äù Biometrika 41 (1-2): 100‚Äì115. https://doi.org/10.1093/biomet/41.1-2.100.\n Vostrikova, Lyudmila Yur‚Äôevna. 1981. ‚ÄúDetecting ‚ÄòDisorder‚Äô in Multidimensional Random Processes.‚Äù In Doklady Akademii Nauk, 259:270‚Äì74. 2. Russian Academy of Sciences.\n    Please read the article if you are interested üòé\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","date":1650931200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650983944,"objectID":"bbe03e2c31250e6691aa269ff7e72853","permalink":"https://ygeunkim.github.io/post/tscp/","publishdate":"2022-04-26T00:00:00Z","relpermalink":"/post/tscp/","section":"post","summary":"Introduction to change-point detection techniques. Focusing on univariate time series, we talk about both single and multiple changes in mean.","tags":["change-point-analysis","time-series"],"title":"Univariate Change Point Analysis","type":"post"},{"authors":["Jeong-Han Yun","Jonguk Kim","Won-Seok Hwang","Young Geun Kim","Simon S. Woo","Byung-Gil Min"],"categories":["publication"],"content":"Yun, Jeong-Han, Jonguk Kim, Won-Seok Hwang, Young Geun Kim, Simon S. Woo, and Byung-Gil Min. 2022. ‚ÄúResidual Size Is Not Enough for Anomaly Detection: Improving Detection Performance Using Residual Similarity in Multivariate Time Series.‚Äù In Proceedings of the 37th ACM/SIGAPP Symposium on Applied Computing, 87‚Äì96. SAC ‚Äô22. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/3477314.3506990.\n  .__dimensions_badge_embed__ { margin-left: 3rem; position: absolute; } .altmetric-embed { margin-left: 10rem; position: absolute; } .plx-pop { margin-top: -1.5rem; margin-left: 15rem; position: absolute; } #badge-box { text-align: center; } .__dimensions_badge_embed__, .altmetric-embed, .plx-pop { display: inline; }  Article Metrics   \n  ","date":1650844800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1651930072,"objectID":"e058abbab4e45a9de6d52db7069b0e15","permalink":"https://ygeunkim.github.io/publication/nndsac/","publishdate":"2022-04-25T00:00:00Z","relpermalink":"/publication/nndsac/","section":"publication","summary":"SAC 2022 - Virtual Event","tags":["anomaly-detection","time-series","deep-learning","cyber-physical-system"],"title":"Residual Size is Not Enough for Anomaly Detection: Improving Detection Performance using Residual Similarity in Multivariate Time Series","type":"publication"},{"authors":["Young Geun Kim","Changryong Baek","Dongyeong Kim","Jaewon Lee","Kyung Hee Kim"],"categories":["event"],"content":"","date":1635127200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1636987357,"objectID":"3d9a72e0f233d4a1171fb1a62b040b12","permalink":"https://ygeunkim.github.io/talk/r-statistical-computation-and-packages/","publishdate":"2021-10-25T00:00:00Z","relpermalink":"/talk/r-statistical-computation-and-packages/","section":"event","summary":"Seminar about R statistical computation, R parallel computing, and R packages.","tags":["seminar","r","r-package"],"title":"R Statistical Computation and Packages","type":"event"},{"authors":["Young Geun Kim","Jeong-Han Yun","Siho Han","Hyoung Chun Kim","Simon S. Woo"],"categories":["publication"],"content":"Kim, Young Geun, Jeong-Han Yun, Siho Han, Hyoung Chun Kim, and Simon S. Woo. 2021. ‚ÄúRevitalizing Self-Organizing Map: Anomaly Detection Using Forecasting Error Patterns.‚Äù In ICT Systems Security and Privacy Protection, edited by Audun J√∏sang, Lynn Futcher, and Janne Hagen, 382‚Äì97. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-030-78120-0_25.\n  .__dimensions_badge_embed__ { margin-left: 3rem; position: absolute; } .altmetric-embed { margin-left: 10rem; position: absolute; } .plx-pop { margin-top: -1.5rem; margin-left: 15rem; position: absolute; } #badge-box { text-align: center; } .__dimensions_badge_embed__, .altmetric-embed, .plx-pop { display: inline; }  Article Metrics   \n  ","date":1624492800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650983944,"objectID":"74068d47291ed74fe0bf310b85c4995e","permalink":"https://ygeunkim.github.io/publication/somifip/","publishdate":"2021-06-24T00:00:00Z","relpermalink":"/publication/somifip/","section":"publication","summary":"IFIP SEC 2021 - Oslo, Norway","tags":["anomaly-detection","time-series","self-organizing-map","cyber-physical-system"],"title":"Revitalizing Self-Organizing Map: Anomaly Detection using Forecasting Error Patterns","type":"publication"},{"authors":["Young Geun Kim","Jeong-Han Yun","Siho Han","Hyoung Chun Kim","Simon S. Woo"],"categories":["event"],"content":"I presented my paper,\nKim Y.G., Yun JH., Han S., Kim H.C., Woo S.S. (2021) Revitalizing Self-Organizing Map: Anomaly Detection Using Forecasting Error Patterns. In: J√∏sang A., Futcher L., Hagen J. (eds) ICT Systems Security and Privacy Protection. SEC 2021. IFIP Advances in Information and Communication Technology, vol 625. Springer, Cham. https://doi.org/10.1007/978-3-030-78120-0_25\nin Session 11: Machine Learning for Security (06-24 11:00 CEST - 13:00 CEST).\nThis is my first conference presentation, so I was very nervous üò±\n","date":1624354200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624715806,"objectID":"9ed492400a10eb4d5636ae70583d2471","permalink":"https://ygeunkim.github.io/talk/revitalizing-self-organizing-map-anomaly-detection-using-forecasting-error-patterns/","publishdate":"2021-06-24T00:00:00Z","relpermalink":"/talk/revitalizing-self-organizing-map-anomaly-detection-using-forecasting-error-patterns/","section":"event","summary":"IFIP SEC 2021","tags":["conference","anomaly-detection","time-series","self-organizing-map","cyber-physical-system"],"title":"Revitalizing Self-Organizing Map: Anomaly Detection using Forecasting Error Patterns","type":"event"},{"authors":["Young Geun Kim"],"categories":["code"],"content":"","date":1623715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635922996,"objectID":"33f3b8a0ff81d8bb9c05e8a596648985","permalink":"https://ygeunkim.github.io/codes/somanomaly_python/","publishdate":"2021-06-15T00:00:00Z","relpermalink":"/codes/somanomaly_python/","section":"codes","summary":"Python module for SOMAD research, [https://doi.org/10.1007/978-3-030-78120-0_25](https://link.springer.com/chapter/10.1007/978-3-030-78120-0_25)","tags":["python","anomaly-detection","time-series"],"title":"somanomaly: Self Organizing Map for Anomaly Detection","type":"codes"},{"authors":["Young Geun Kim"],"categories":["shiny"],"content":"","date":1622505600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622967883,"objectID":"2285363480f0d6a73d4e9fadb01c43eb","permalink":"https://ygeunkim.github.io/shiny/lrd-shiny/","publishdate":"2021-06-01T00:00:00Z","relpermalink":"/shiny/lrd-shiny/","section":"shiny","summary":"Flexdashboard (Shiny app) generating multivariate LRD time series. This post is directly connected to the Shiny application.","tags":["shiny","time-series","simulation"],"title":"Generating Long-range-dependent Time Series","type":"shiny"},{"authors":["Young Geun Kim"],"categories":["post"],"content":"I made my first Shiny app on https://blended.shinyapps.io/sim-lrd/ üòÑ. Above Code button links to the flexdashboard R markdown file in the Github repository.\nAlso, I added a section for the Shiny apps in the research menu in this site.\nFast Guide Writing yaml For yaml output, write flexdashboard::flex_dashborad. There are lots of options. See the specifics in my repo if you want.\n--- title: \u0026quot;Generating Multivariate Long-range-dependent Time series\u0026quot; output: flexdashboard::flex_dashboard: source_code: https://github.com/ygeunkim/sim-lrd/blob/master/index.Rmd runtime: shiny ---  Template Actually, if you click in the menu,\n File New file R Markdown From Template Flex Dashboard  then the file will have some structure.\nWe can customize the arrangement such as sidebar, row, and column.\nTo use shiny engine, I added runtime: shiny with\nlibrary(shiny)  Comments The next steps are related to defining input and making the dashboad. The website of the package, https://pkgs.rstudio.com/flexdashboard/, is useful.\nIf you try the shiny app yourself, click Shiny above üòä\n","date":1622419200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624280819,"objectID":"aa0851483c933c52363e4a0290f55f59","permalink":"https://ygeunkim.github.io/post/startshiny/","publishdate":"2021-05-31T00:00:00Z","relpermalink":"/post/startshiny/","section":"post","summary":"Shiny app generating LRD time series","tags":["shiny","time-series"],"title":"First Shiny App using Flexdashboard","type":"post"},{"authors":["Young Geun Kim"],"categories":["project"],"content":"About the project This is a project performed in SKKU Design and Analysis of Experiments (STA 5031).\n Conduct a real randomized experiment, collect data, and analyze them. Present a non-statistical paper using an (quasi-)experiment in the field outside statistics and critize them. Bring my own research that is related to an (quasi-)experiment.  I chose real experimental design, the first one.\nCoffee-Electrocardiogram Experiment Goal of the Experiment  Does caffeine affect electrocardiogram (ECG) or average heart rate? Caffeine: ‚òï drinking capsule coffee 40 ml ECG result: ‚åö average heart rate  Design We implement Latin square design. For example,\n Reduced latin square    Drinking speed      1 2 3 4   Coffee to water ratio 1 A B C D   2 B C D A   3 C D A B   4 D A B C     A, B, C, D once in every row, once in every column  About factors  Latin square: 4 by 4 2 blocking factors  Row: Coffee (40 ml) to water ratio  1:0 (Espresso) 1:2.5 (Water 100 ml) 1:5 (Water 200 ml) 1:7.5 (Water 300 ml)   Column: Drinking speed  \u0026lt;=5 sec 5-15 sec 15-30 sec 30\u0026lt; sec     Interesting factor: Intake of caffeine from Starbucks by Nespresso  House blend: 74.5 mg Sumatra: 54.5 mg Decaf espresso roast: 3 mg None or water: 0 mg   Randomly allocate these treatments 1, 2, 3, and 4 to A, B, C, and D  assign these to above table random treatment assignment    set.seed(1) sample(LETTERS[1:4]) #\u0026gt; [1] \u0026quot;A\u0026quot; \u0026quot;C\u0026quot; \u0026quot;D\u0026quot; \u0026quot;B\u0026quot;  Output  Measure ECG using Apple watch Series 4: See https://support.apple.com/en-us/HT208955 Output  Average Heart rate (in BPM) difference between after and before taking the coffee log return might be better (after got feedback)    Controlling other variables  Drink coffee every morning (between 8:30 a.m. and 9:00 a.m. KST), after eating a piece of bread When Measuring ECG,  sit at my desk rest arms on a my desk   Use same strip for apple watch: Nike sport band of same fit Nespresso machine: Pixie C61 in my home  For more details Click Slides on the üîù.\n Project: Github repository Slides: presentation pdf Code: Source codes including Rmd for the slide Dataset: datsets by this experiment including preprocessed ones Appendix: Supplementary material related to the dataset  ","date":1621814400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1623678271,"objectID":"bcd238d3171bda478188f9af62876ecd","permalink":"https://ygeunkim.github.io/project/ecg_experiment/","publishdate":"2021-05-24T00:00:00Z","relpermalink":"/project/ecg_experiment/","section":"project","summary":"Experiment about caffeine effect to ECG (average heart rate), based on Latin square design.","tags":["statistics","experimental-design","causal-inference","r"],"title":"Coffee-ECG Experiment","type":"project"},{"authors":["Young Geun Kim"],"categories":["project"],"content":"Propensity Score Estimating Using Machine Learning This is a project perfomed in SKKU Modern Statistical Methods (STA5012) about causal inference\n Simulation study or data analysis Extension of statistical method or theoretical result Conducting a thorough data analysis  Paper I reviewed\nLee, B. K., Lessler, J., \u0026amp; Stuart, E. A. (2010). Improving propensity score weighting using machine learning. Statistics in Medicine, 29(3), 337‚Äì346. doi:10.1002/sim.3782\nR Package  I made an R package with devtools for this project: propensityml.\n","date":1608249600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1623678271,"objectID":"b4d2aedb8b6ce99d568db7db52b7d02c","permalink":"https://ygeunkim.github.io/project/causal_project/","publishdate":"2020-12-18T00:00:00Z","relpermalink":"/project/causal_project/","section":"project","summary":"Estimate propensity score using machine learning.","tags":["statistics","causal-inference","simulation","r-package"],"title":"Causal Inference course project","type":"project"},{"authors":["Simon S. Woo","Young Geun Kim","Yujin Shin","Sangyup Lee","Shahroz Tariq","Jinwoo Cho","Seoyoung Park","Youngrok Choi"],"categories":["project"],"content":"This deep learning project tried to detect anomalies in real time. I collaborated with DASH lab members.\nThe given dataset is error data generated by deep learning model. Original dataset is SWaT (Secure Water Treatment) dataset and HAI (HIL-based Augmented ICS) security dataset.\nAdditionally, I made a simple R package and Python module in the linked repo (click the Code button under the title).\nPapers I am involved in Cho, Jinwoo, Shahroz Tariq, Sangyup Lee, Young Geun Kim, Jeong-Han Yun, Jonguk Kim, Hyoung Chun Kim, and Simon S. Woo. 2019. ‚ÄúContextual Anomaly Detection by Correlated Probability Distributions Using Kullback-Leibler Divergence.‚Äù Anchorage, Alaska, USA.\n Kim, Young Geun, Jeong-Han Yun, Siho Han, Hyoung Chun Kim, and Simon S. Woo. 2021. ‚ÄúRevitalizing Self-Organizing Map: Anomaly Detection Using Forecasting Error Patterns.‚Äù In ICT Systems Security and Privacy Protection, edited by Audun J√∏sang, Lynn Futcher, and Janne Hagen, 382‚Äì97. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-030-78120-0_25.\n Yun, Jeong-Han, Jonguk Kim, Won-Seok Hwang, Young Geun Kim, Simon S. Woo, and Byung-Gil Min. 2022. ‚ÄúResidual Size Is Not Enough for Anomaly Detection: Improving Detection Performance Using Residual Similarity in Multivariate Time Series.‚Äù In Proceedings of the 37th ACM/SIGAPP Symposium on Applied Computing, 87‚Äì96. SAC ‚Äô22. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/3477314.3506990.\n  ","date":1580947200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1651930072,"objectID":"da69dc7e47463a388822603df334b269","permalink":"https://ygeunkim.github.io/project/nsr_project/","publishdate":"2020-02-06T00:00:00Z","relpermalink":"/project/nsr_project/","section":"project","summary":"Anomaly detection based on the deep neural network error.","tags":["cyber-physical-system","deep-learning","anomaly-detection","time-series","python","r"],"title":"Anomaly detection in Cyber-Physical Systems","type":"project"},{"authors":["Young Geun Kim"],"categories":["code"],"content":"","date":1579046400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635922996,"objectID":"b276ef8a7edb3922f6e3de44886dddb8","permalink":"https://ygeunkim.github.io/codes/swatanomaly_pkg/","publishdate":"2020-01-15T00:00:00Z","relpermalink":"/codes/swatanomaly_pkg/","section":"codes","summary":"R package for Cho et al. (2019)","tags":["r-package","Rcpp","anomaly-detection","time-series"],"title":"swatanomaly: Anomaly Detection using KL Divergence","type":"codes"},{"authors":["Young Geun Kim"],"categories":["code"],"content":"","date":1576368000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635922996,"objectID":"e8ae06600d923641c007d05897936851","permalink":"https://ygeunkim.github.io/codes/ceshat_pkg/","publishdate":"2019-12-15T00:00:00Z","relpermalink":"/codes/ceshat_pkg/","section":"codes","summary":"R package for SKKU nonparametric statistics course project.","tags":["r-package","statistics","nonparametric-statistics","time-series","simulation"],"title":"ceshat: Nonparametric Estimation of CES","type":"codes"},{"authors":["Young Geun Kim"],"categories":["project"],"content":"Nonparametric Estimation of Conditional Expected Shortfall This is a project performed in SKKU Nonparametric statistics course (STA5015). It aims at:\n intensive review on existing statistical methods for an advanced topic not covered in the course own simulation or real data simulation development of new statistical methodology related to the course new analysis of a real data set  Reviewd Paper Cai, Z., \u0026amp; Wang, X. (2008). Nonparametric estimation of conditional VaR and expected shortfall. Journal of Econometrics, 147(1), 120-130.\nceshat This is an R package to help this project, which tries to reproduce the above paper. Click the Code button!\n","date":1576368000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1623678271,"objectID":"239df92e0939bfb901bec8ed90277c48","permalink":"https://ygeunkim.github.io/project/nonparam_project/","publishdate":"2019-12-15T00:00:00Z","relpermalink":"/project/nonparam_project/","section":"project","summary":"Estimate conditional value-at-risk and conditional expected shortfall in nonparametric way.","tags":["statistics","nonparametric-statistics","time-series","simulation","r-package"],"title":"Nonparametric statistics course project","type":"project"},{"authors":["Jinwoo Cho","Shahroz Tariq","Sangyup Lee","Young Geun Kim","Jeong-Han Yun","Jonguk Kim","Hyoung Chun Kim","Simon S. Woo"],"categories":["publication"],"content":"Cho, Jinwoo, Shahroz Tariq, Sangyup Lee, Young Geun Kim, Jeong-Han Yun, Jonguk Kim, Hyoung Chun Kim, and Simon S. Woo. 2019. ‚ÄúContextual Anomaly Detection by Correlated Probability Distributions Using Kullback-Leibler Divergence.‚Äù Anchorage, Alaska, USA.\n  ","date":1564963200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650983944,"objectID":"ee4abe6178fa6c7a8400290b7ee9ddd1","permalink":"https://ygeunkim.github.io/publication/kl_poster/","publishdate":"2019-08-05T00:00:00Z","relpermalink":"/publication/kl_poster/","section":"publication","summary":"5th Workshop on Mining and Learning from Time Series, held in conjunction with KDD'19 Aug 5, 2019 - Anchorage, Alaska, USA","tags":["anomaly-detection","time-series","cyber-physical-system","kullback-leibler-divergence"],"title":"Contextual Anomaly Detection by Correlated Probability Distributions using Kullback-Leibler Divergence","type":"publication"},{"authors":["Young Geun Kim"],"categories":["code"],"content":"","date":1557619200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635922996,"objectID":"860ad7ae2147bfe5b13a63e67e70e0fc","permalink":"https://ygeunkim.github.io/codes/propensityml_pkg/","publishdate":"2019-05-12T00:00:00Z","relpermalink":"/codes/propensityml_pkg/","section":"codes","summary":"R package for SKKU causal inference course project.","tags":["r-package","simulation","causal-inference"],"title":"propensityml: Propensity Score Weighting using Machine Learning","type":"codes"},{"authors":["Young Geun Kim"],"categories":["code"],"content":"","date":1557619200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650542383,"objectID":"dac6e72614917981a3cf96894fe24fee","permalink":"https://ygeunkim.github.io/project/youngtool_pkg/","publishdate":"2019-05-12T00:00:00Z","relpermalink":"/project/youngtool_pkg/","section":"project","summary":"Made an R package helping statistical research, especially, simulation study.","tags":["simulation","r","r-package"],"title":"youngtool: Research Tool Package","type":"project"},{"authors":["Young Geun Kim"],"categories":["code"],"content":"","date":1552953600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650542383,"objectID":"0712d491340f394d9bcfc81cfb37c2da","permalink":"https://ygeunkim.github.io/project/rmdtool_pkg/","publishdate":"2019-03-19T00:00:00Z","relpermalink":"/project/rmdtool_pkg/","section":"project","summary":"Built an R package that includes my private tools for writing R markdown documents","tags":["r","r-package","r-markdown"],"title":"rmdtool: R markdown tool package","type":"project"},{"authors":["Young Geun Kim"],"categories":["code"],"content":"","date":1551571200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650542383,"objectID":"5a6fa2feb42a8e4825934c619bb90ec4","permalink":"https://ygeunkim.github.io/codes/loglinear3_r/","publishdate":"2019-03-03T00:00:00Z","relpermalink":"/codes/loglinear3_r/","section":"codes","summary":"R functions automatically finding the best loglinear model for 3-way table","tags":["r","categorical-data"],"title":"Loglinear Models for Three-way Tables","type":"codes"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  **Two**  Three   A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609910183,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://ygeunkim.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609995654,"objectID":"1f4cb24553577f6808a73065326a8b9d","permalink":"https://ygeunkim.github.io/blog/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/blog/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609910183,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://ygeunkim.github.io/contact/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/contact/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609910183,"objectID":"f1d044c0738ab9f19347f15c290a71a1","permalink":"https://ygeunkim.github.io/research/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/research/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635922996,"objectID":"6fcae98d7df3b6c44952e7b5fed181e3","permalink":"https://ygeunkim.github.io/software/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/software/","section":"","summary":"","tags":null,"title":"","type":"widget_page"}]